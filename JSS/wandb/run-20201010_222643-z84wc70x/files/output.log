2020-10-10 22:26:45,519	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_aed16_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=23398)[0m 2020-10-10 22:26:48,458	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=23433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23373)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_22-27-30
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1828528472355433
        entropy_coeff: 0.0
        kl: 0.006112576029928667
        model: {}
        policy_loss: -0.015238628988819463
        total_loss: 498.08028520856584
        vf_explained_var: 0.5928232073783875
        vf_loss: 498.09429931640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.595348837209297
    gpu_util_percent0: 0.33
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.299999999999998
    vram_util_percent0: 0.19354039067326684
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17239958093872257
    mean_env_wait_ms: 1.1894408594351118
    mean_inference_ms: 5.595066942672518
    mean_raw_obs_processing_ms: 0.4606079797606366
  time_since_restore: 36.455790758132935
  time_this_iter_s: 36.455790758132935
  time_total_s: 36.455790758132935
  timers:
    learn_throughput: 5893.698
    learn_time_ms: 27451.696
    sample_throughput: 18111.8
    sample_time_ms: 8932.961
    update_time_ms: 31.524
  timestamp: 1602368850
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      1 |          36.4558 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3621.7430555555557
    time_step_min: 3333
  date: 2020-10-10_22-28-06
  done: false
  episode_len_mean: 891.4367088607595
  episode_reward_max: 274.0505050505052
  episode_reward_mean: 216.1582917785447
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1506917987551009
        entropy_coeff: 0.0
        kl: 0.006666098322187152
        model: {}
        policy_loss: -0.015903431074028567
        total_loss: 118.52964510236468
        vf_explained_var: 0.8311290740966797
        vf_loss: 118.5442145211356
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.85609756097561
    gpu_util_percent0: 0.3153658536585366
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.470731707317072
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16799123038392386
    mean_env_wait_ms: 1.1849201762635182
    mean_inference_ms: 5.418826296241129
    mean_raw_obs_processing_ms: 0.450771605682172
  time_since_restore: 71.85763025283813
  time_this_iter_s: 35.4018394947052
  time_total_s: 71.85763025283813
  timers:
    learn_throughput: 5911.448
    learn_time_ms: 27369.267
    sample_throughput: 19067.786
    sample_time_ms: 8485.096
    update_time_ms: 29.538
  timestamp: 1602368886
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      2 |          71.8576 | 323584 |  216.158 |              274.051 |              145.717 |            891.437 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3616.6008968609867
    time_step_min: 3333
  date: 2020-10-10_22-28-41
  done: false
  episode_len_mean: 891.42194092827
  episode_reward_max: 274.0505050505052
  episode_reward_mean: 217.5257639688017
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.141584839139666
        entropy_coeff: 0.0
        kl: 0.00823000811838678
        model: {}
        policy_loss: -0.019473046164161394
        total_loss: 41.973702566964285
        vf_explained_var: 0.9271218180656433
        vf_loss: 41.991529192243306
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.709756097560973
    gpu_util_percent0: 0.33804878048780485
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16504567580696863
    mean_env_wait_ms: 1.182693456052747
    mean_inference_ms: 5.274226129711655
    mean_raw_obs_processing_ms: 0.4436037305782373
  time_since_restore: 106.65506625175476
  time_this_iter_s: 34.797435998916626
  time_total_s: 106.65506625175476
  timers:
    learn_throughput: 5908.966
    learn_time_ms: 27380.766
    sample_throughput: 20001.531
    sample_time_ms: 8088.981
    update_time_ms: 32.794
  timestamp: 1602368921
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      3 |          106.655 | 485376 |  217.526 |              274.051 |              117.232 |            891.422 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3612.7102649006624
    time_step_min: 3333
  date: 2020-10-10_22-29-15
  done: false
  episode_len_mean: 889.9098101265823
  episode_reward_max: 274.0505050505052
  episode_reward_mean: 218.849603631249
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1265240737370081
        entropy_coeff: 0.0
        kl: 0.008853063452988863
        model: {}
        policy_loss: -0.018053898720868995
        total_loss: 23.854639870779856
        vf_explained_var: 0.9581324458122253
        vf_loss: 23.87092317853655
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.160975609756097
    gpu_util_percent0: 0.3824390243902439
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16288633656544108
    mean_env_wait_ms: 1.1814775923438583
    mean_inference_ms: 5.162511043679248
    mean_raw_obs_processing_ms: 0.4376032606958251
  time_since_restore: 141.2520046234131
  time_this_iter_s: 34.596938371658325
  time_total_s: 141.2520046234131
  timers:
    learn_throughput: 5909.503
    learn_time_ms: 27378.277
    sample_throughput: 20605.638
    sample_time_ms: 7851.832
    update_time_ms: 29.855
  timestamp: 1602368955
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      4 |          141.252 | 647168 |   218.85 |              274.051 |              117.232 |             889.91 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.9094488188975
    time_step_min: 3333
  date: 2020-10-10_22-29-50
  done: false
  episode_len_mean: 886.3240506329114
  episode_reward_max: 274.0505050505052
  episode_reward_mean: 220.43178621659615
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.103838128702981
        entropy_coeff: 0.0
        kl: 0.008741840520607573
        model: {}
        policy_loss: -0.01996608896713172
        total_loss: 20.264350073678152
        vf_explained_var: 0.963345468044281
        vf_loss: 20.28256825038365
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.34
    gpu_util_percent0: 0.28274999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4925
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16129225839669042
    mean_env_wait_ms: 1.18157182206909
    mean_inference_ms: 5.075825818994129
    mean_raw_obs_processing_ms: 0.4326191609362802
  time_since_restore: 175.97490167617798
  time_this_iter_s: 34.72289705276489
  time_total_s: 175.97490167617798
  timers:
    learn_throughput: 5902.8
    learn_time_ms: 27409.367
    sample_throughput: 21000.165
    sample_time_ms: 7704.32
    update_time_ms: 28.542
  timestamp: 1602368990
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      5 |          175.975 | 808960 |  220.432 |              274.051 |              117.232 |            886.324 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3590.512768130746
    time_step_min: 3298
  date: 2020-10-10_22-30-25
  done: false
  episode_len_mean: 880.7527308838133
  episode_reward_max: 274.0505050505052
  episode_reward_mean: 221.9034134793815
  episode_reward_min: 117.232323232323
  episodes_this_iter: 217
  episodes_total: 1007
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0736607824053084
        entropy_coeff: 0.0
        kl: 0.008690578330840384
        model: {}
        policy_loss: -0.017677095517033843
        total_loss: 24.172881535121373
        vf_explained_var: 0.9709259271621704
        vf_loss: 24.188820702689036
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.415
    gpu_util_percent0: 0.33725
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477500000000001
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1596677516218548
    mean_env_wait_ms: 1.183112196561495
    mean_inference_ms: 4.987009171597938
    mean_raw_obs_processing_ms: 0.42738785677142394
  time_since_restore: 210.57302260398865
  time_this_iter_s: 34.59812092781067
  time_total_s: 210.57302260398865
  timers:
    learn_throughput: 5905.466
    learn_time_ms: 27396.99
    sample_throughput: 21242.999
    sample_time_ms: 7616.25
    update_time_ms: 30.056
  timestamp: 1602369025
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      6 |          210.573 | 970752 |  221.903 |              274.051 |              117.232 |            880.753 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3576.0655339805826
    time_step_min: 3250
  date: 2020-10-10_22-30-59
  done: false
  episode_len_mean: 874.685917721519
  episode_reward_max: 276.7777777777772
  episode_reward_mean: 223.9700725610534
  episode_reward_min: 117.232323232323
  episodes_this_iter: 257
  episodes_total: 1264
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0919965505599976
        entropy_coeff: 0.0
        kl: 0.007773589841755373
        model: {}
        policy_loss: -0.01874285742607234
        total_loss: 19.168319157191686
        vf_explained_var: 0.9707702994346619
        vf_loss: 19.18550763811384
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.956097560975607
    gpu_util_percent0: 0.45195121951219513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480487804878049
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15830090569761632
    mean_env_wait_ms: 1.1849022936325375
    mean_inference_ms: 4.911065725778016
    mean_raw_obs_processing_ms: 0.42296200984242494
  time_since_restore: 245.02718377113342
  time_this_iter_s: 34.454161167144775
  time_total_s: 245.02718377113342
  timers:
    learn_throughput: 5909.488
    learn_time_ms: 27378.345
    sample_throughput: 21447.204
    sample_time_ms: 7543.734
    update_time_ms: 29.064
  timestamp: 1602369059
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      7 |          245.027 | 1132544 |   223.97 |              276.778 |              117.232 |            874.686 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3569.186513629842
    time_step_min: 3181
  date: 2020-10-10_22-31-34
  done: false
  episode_len_mean: 870.8410689170183
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 224.83759536291163
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.06979273046766
        entropy_coeff: 0.0
        kl: 0.008330623719042965
        model: {}
        policy_loss: -0.017857907423084334
        total_loss: 15.244202750069755
        vf_explained_var: 0.9748346209526062
        vf_loss: 15.260394709450859
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.017500000000002
    gpu_util_percent0: 0.281
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15764733294984187
    mean_env_wait_ms: 1.1859991359288375
    mean_inference_ms: 4.874319612602964
    mean_raw_obs_processing_ms: 0.4207858284484135
  time_since_restore: 279.58200669288635
  time_this_iter_s: 34.55482292175293
  time_total_s: 279.58200669288635
  timers:
    learn_throughput: 5911.979
    learn_time_ms: 27366.809
    sample_throughput: 21572.218
    sample_time_ms: 7500.017
    update_time_ms: 28.652
  timestamp: 1602369094
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      8 |          279.582 | 1294336 |  224.838 |              284.051 |              117.232 |            870.841 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3561.9690721649486
    time_step_min: 3181
  date: 2020-10-10_22-32-09
  done: false
  episode_len_mean: 867.0550632911393
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 226.21630865618192
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0448906081063407
        entropy_coeff: 0.0
        kl: 0.008253818710467644
        model: {}
        policy_loss: -0.020333407978926386
        total_loss: 13.330792699541364
        vf_explained_var: 0.9758228063583374
        vf_loss: 13.349475588117327
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.465853658536584
    gpu_util_percent0: 0.43439024390243897
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15708166437918197
    mean_env_wait_ms: 1.187030354159571
    mean_inference_ms: 4.8423137215545164
    mean_raw_obs_processing_ms: 0.418829015327035
  time_since_restore: 314.504435300827
  time_this_iter_s: 34.922428607940674
  time_total_s: 314.504435300827
  timers:
    learn_throughput: 5908.533
    learn_time_ms: 27382.769
    sample_throughput: 21655.387
    sample_time_ms: 7471.213
    update_time_ms: 36.765
  timestamp: 1602369129
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |      9 |          314.504 | 1456128 |  226.216 |              284.051 |              117.232 |            867.055 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3553.78833819242
    time_step_min: 3181
  date: 2020-10-10_22-32-43
  done: false
  episode_len_mean: 863.3625932300631
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 227.42573758236392
  episode_reward_min: 117.232323232323
  episodes_this_iter: 163
  episodes_total: 1743
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0078697076865606
        entropy_coeff: 0.0
        kl: 0.008129992123161043
        model: {}
        policy_loss: -0.01815725300444423
        total_loss: 15.33885111127581
        vf_explained_var: 0.9763135313987732
        vf_loss: 15.355382442474365
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.7625
    gpu_util_percent0: 0.27275
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1565863899338804
    mean_env_wait_ms: 1.1882161742622541
    mean_inference_ms: 4.813170040736417
    mean_raw_obs_processing_ms: 0.4170121509980259
  time_since_restore: 349.03745770454407
  time_this_iter_s: 34.53302240371704
  time_total_s: 349.03745770454407
  timers:
    learn_throughput: 5909.096
    learn_time_ms: 27380.161
    sample_throughput: 21764.643
    sample_time_ms: 7433.708
    update_time_ms: 35.69
  timestamp: 1602369163
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     10 |          349.037 | 1617920 |  227.426 |              284.051 |              117.232 |            863.363 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3537.502470355731
    time_step_min: 3181
  date: 2020-10-10_22-33-18
  done: false
  episode_len_mean: 856.6003898635478
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 230.03136629452402
  episode_reward_min: 117.232323232323
  episodes_this_iter: 309
  episodes_total: 2052
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0044723067964827
        entropy_coeff: 0.0
        kl: 0.007779126155323216
        model: {}
        policy_loss: -0.0175838205697281
        total_loss: 15.36133405140468
        vf_explained_var: 0.979647696018219
        vf_loss: 15.377361842564174
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.4375
    gpu_util_percent0: 0.296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15579961611510312
    mean_env_wait_ms: 1.1906161108597577
    mean_inference_ms: 4.768083469672863
    mean_raw_obs_processing_ms: 0.4142540461293382
  time_since_restore: 383.7127604484558
  time_this_iter_s: 34.67530274391174
  time_total_s: 383.7127604484558
  timers:
    learn_throughput: 5912.334
    learn_time_ms: 27365.165
    sample_throughput: 22259.444
    sample_time_ms: 7268.466
    update_time_ms: 36.428
  timestamp: 1602369198
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     11 |          383.713 | 1779712 |  230.031 |               286.02 |              117.232 |              856.6 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3528.253663003663
    time_step_min: 3181
  date: 2020-10-10_22-33-53
  done: false
  episode_len_mean: 853.4407775768535
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 231.29288819478677
  episode_reward_min: 117.232323232323
  episodes_this_iter: 160
  episodes_total: 2212
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9881415750299182
        entropy_coeff: 0.0
        kl: 0.007958559452423028
        model: {}
        policy_loss: -0.01975875101717455
        total_loss: 10.008304119110107
        vf_explained_var: 0.9815230965614319
        vf_loss: 10.0264710017613
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.1675
    gpu_util_percent0: 0.3225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4925
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15546201748334662
    mean_env_wait_ms: 1.1918166979549953
    mean_inference_ms: 4.748564584062934
    mean_raw_obs_processing_ms: 0.4130677043995228
  time_since_restore: 418.15928196907043
  time_this_iter_s: 34.446521520614624
  time_total_s: 418.15928196907043
  timers:
    learn_throughput: 5913.709
    learn_time_ms: 27358.803
    sample_throughput: 22536.059
    sample_time_ms: 7179.25
    update_time_ms: 35.709
  timestamp: 1602369233
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     12 |          418.159 | 1941504 |  231.293 |               286.02 |              117.232 |            853.441 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3521.0418445772843
    time_step_min: 3181
  date: 2020-10-10_22-34-27
  done: false
  episode_len_mean: 850.184388185654
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 232.4509014192557
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9687412296022687
        entropy_coeff: 0.0
        kl: 0.00775796574141298
        model: {}
        policy_loss: -0.01767064953622009
        total_loss: 11.250988347189766
        vf_explained_var: 0.977626621723175
        vf_loss: 11.267107554844447
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.773170731707317
    gpu_util_percent0: 0.46463414634146344
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15516093957048757
    mean_env_wait_ms: 1.1929802197568944
    mean_inference_ms: 4.730983749731766
    mean_raw_obs_processing_ms: 0.41197450552949394
  time_since_restore: 452.70425248146057
  time_this_iter_s: 34.54497051239014
  time_total_s: 452.70425248146057
  timers:
    learn_throughput: 5914.065
    learn_time_ms: 27357.154
    sample_throughput: 22604.798
    sample_time_ms: 7157.418
    update_time_ms: 34.151
  timestamp: 1602369267
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     13 |          452.704 | 2103296 |  232.451 |               286.02 |              117.232 |            850.184 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3511.376811594203
    time_step_min: 3181
  date: 2020-10-10_22-35-02
  done: false
  episode_len_mean: 846.2297559085625
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 233.86470673413703
  episode_reward_min: 117.232323232323
  episodes_this_iter: 211
  episodes_total: 2581
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9341754232134137
        entropy_coeff: 0.0
        kl: 0.007791768426873854
        model: {}
        policy_loss: -0.019460859209565178
        total_loss: 12.990536212921143
        vf_explained_var: 0.9809379577636719
        vf_loss: 13.00843892778669
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.5925
    gpu_util_percent0: 0.40325000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154799146895765
    mean_env_wait_ms: 1.1945630195255728
    mean_inference_ms: 4.7096758641551695
    mean_raw_obs_processing_ms: 0.41063074074756734
  time_since_restore: 487.5785667896271
  time_this_iter_s: 34.874314308166504
  time_total_s: 487.5785667896271
  timers:
    learn_throughput: 5912.472
    learn_time_ms: 27364.528
    sample_throughput: 22546.28
    sample_time_ms: 7175.995
    update_time_ms: 35.78
  timestamp: 1602369302
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     14 |          487.579 | 2265088 |  233.865 |               286.02 |              117.232 |             846.23 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3500.10546875
    time_step_min: 3178
  date: 2020-10-10_22-35-37
  done: false
  episode_len_mean: 841.9321378340366
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 235.69436985892665
  episode_reward_min: 117.232323232323
  episodes_this_iter: 263
  episodes_total: 2844
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.936458877154759
        entropy_coeff: 0.0
        kl: 0.007283476846558707
        model: {}
        policy_loss: -0.019252307363785803
        total_loss: 9.77191720690046
        vf_explained_var: 0.984029233455658
        vf_loss: 9.789712905883789
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.49512195121951
    gpu_util_percent0: 0.4239024390243903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15441574124638163
    mean_env_wait_ms: 1.196497150492867
    mean_inference_ms: 4.687013998846252
    mean_raw_obs_processing_ms: 0.40920979548217706
  time_since_restore: 522.2694435119629
  time_this_iter_s: 34.690876722335815
  time_total_s: 522.2694435119629
  timers:
    learn_throughput: 5915.757
    learn_time_ms: 27349.331
    sample_throughput: 22512.443
    sample_time_ms: 7186.781
    update_time_ms: 35.871
  timestamp: 1602369337
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     15 |          522.269 | 2426880 |  235.694 |               286.02 |              117.232 |            841.932 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3494.401479488904
    time_step_min: 3178
  date: 2020-10-10_22-36-12
  done: false
  episode_len_mean: 839.3411059293804
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 236.54954609384973
  episode_reward_min: 117.232323232323
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9159450871603829
        entropy_coeff: 0.0
        kl: 0.00795894827959793
        model: {}
        policy_loss: -0.01849518706564725
        total_loss: 8.963052953992571
        vf_explained_var: 0.9826633334159851
        vf_loss: 8.97995628629412
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.822499999999998
    gpu_util_percent0: 0.269
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542081019306469
    mean_env_wait_ms: 1.1975711494521057
    mean_inference_ms: 4.674699559212851
    mean_raw_obs_processing_ms: 0.4084331929702438
  time_since_restore: 556.8613669872284
  time_this_iter_s: 34.5919234752655
  time_total_s: 556.8613669872284
  timers:
    learn_throughput: 5917.429
    learn_time_ms: 27341.606
    sample_throughput: 22487.46
    sample_time_ms: 7194.765
    update_time_ms: 34.001
  timestamp: 1602369372
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     16 |          556.861 | 2588672 |   236.55 |               286.02 |              117.232 |            839.341 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3488.417810405362
    time_step_min: 3178
  date: 2020-10-10_22-36-47
  done: false
  episode_len_mean: 837.0433407149636
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 237.42553980168645
  episode_reward_min: 117.232323232323
  episodes_this_iter: 159
  episodes_total: 3161
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8912478046757835
        entropy_coeff: 0.0
        kl: 0.007487035356462002
        model: {}
        policy_loss: -0.020223058560597047
        total_loss: 9.134134224482946
        vf_explained_var: 0.9827831387519836
        vf_loss: 9.15285975592477
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.48536585365854
    gpu_util_percent0: 0.3012195121951219
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219512
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15401457767102425
    mean_env_wait_ms: 1.1986309712072407
    mean_inference_ms: 4.663149056776589
    mean_raw_obs_processing_ms: 0.407697561249801
  time_since_restore: 591.7277898788452
  time_this_iter_s: 34.86642289161682
  time_total_s: 591.7277898788452
  timers:
    learn_throughput: 5910.753
    learn_time_ms: 27372.486
    sample_throughput: 22480.949
    sample_time_ms: 7196.849
    update_time_ms: 40.416
  timestamp: 1602369407
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | RUNNING  | 172.17.0.4:23398 |     17 |          591.728 | 2750464 |  237.426 |               286.02 |              117.232 |            837.043 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aed16_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3478.366569767442
    time_step_min: 3176
  date: 2020-10-10_22-37-22
  done: true
  episode_len_mean: 832.7984429065745
  episode_reward_max: 286.0202020202021
  episode_reward_mean: 238.8074167278318
  episode_reward_min: 117.232323232323
  episodes_this_iter: 307
  episodes_total: 3468
  experiment_id: cd35e2a76dac4aa1ba15d953bd7da4f7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8797877601214817
        entropy_coeff: 0.0
        kl: 0.007024310396185943
        model: {}
        policy_loss: -0.01738434487820736
        total_loss: 12.708962985447474
        vf_explained_var: 0.9832947850227356
        vf_loss: 12.72494295665196
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.85
    gpu_util_percent0: 0.27025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 23398
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15368432301122203
    mean_env_wait_ms: 1.2006570489431663
    mean_inference_ms: 4.6430148120462595
    mean_raw_obs_processing_ms: 0.40644899840000154
  time_since_restore: 626.5109946727753
  time_this_iter_s: 34.783204793930054
  time_total_s: 626.5109946727753
  timers:
    learn_throughput: 5908.4
    learn_time_ms: 27383.385
    sample_throughput: 22454.219
    sample_time_ms: 7205.417
    update_time_ms: 42.27
  timestamp: 1602369442
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: aed16_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | TERMINATED |       |     18 |          626.511 | 2912256 |  238.807 |               286.02 |              117.232 |            832.798 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aed16_00000 | TERMINATED |       |     18 |          626.511 | 2912256 |  238.807 |               286.02 |              117.232 |            832.798 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1010 22:37:22.567687 23262 23262 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 22:37:22.567924 23262 23262 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 22:37:22.567996 23262 23262 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 22:37:22.568084 23262 23262 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
