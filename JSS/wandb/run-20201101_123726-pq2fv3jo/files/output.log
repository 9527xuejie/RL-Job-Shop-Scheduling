2020-11-01 12:37:30,609	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 12.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_02bc6_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=67571)[0m 2020-11-01 12:37:33,413	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=67560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67559)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1540.9259259259259
    time_step_min: 1302
  date: 2020-11-01_12-38-00
  done: false
  episode_len_mean: 118.22310126582279
  episode_reward_max: 44.242424242424256
  episode_reward_mean: 32.03126997826365
  episode_reward_min: 13.989898989898997
  episodes_this_iter: 1264
  episodes_total: 1264
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1447077592213948
        entropy_coeff: 0.0005000000000000001
        kl: 0.005619530449621379
        model: {}
        policy_loss: -0.007155387702672063
        total_loss: 40.47618579864502
        vf_explained_var: 0.7891119122505188
        vf_loss: 40.48278999328613
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.218518518518522
    gpu_util_percent0: 0.36629629629629634
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.440740740740741
    vram_util_percent0: 0.08366130971903357
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16496450454226685
    mean_env_wait_ms: 0.6576280720479034
    mean_inference_ms: 4.788716243497749
    mean_raw_obs_processing_ms: 0.4281524023401697
  time_since_restore: 22.09221601486206
  time_this_iter_s: 22.09221601486206
  time_total_s: 22.09221601486206
  timers:
    learn_throughput: 10922.862
    learn_time_ms: 14812.235
    sample_throughput: 22479.319
    sample_time_ms: 7197.371
    update_time_ms: 46.828
  timestamp: 1604234280
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      1 |          22.0922 | 161792 |  32.0313 |              44.2424 |              13.9899 |            118.223 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1531.6367083807356
    time_step_min: 1302
  date: 2020-11-01_12-38-22
  done: false
  episode_len_mean: 117.54839910647803
  episode_reward_max: 44.242424242424256
  episode_reward_mean: 32.54738374060787
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1422
  episodes_total: 2686
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1255147556463878
        entropy_coeff: 0.0005000000000000001
        kl: 0.009991972551991543
        model: {}
        policy_loss: -0.012213830874922374
        total_loss: 10.040241003036499
        vf_explained_var: 0.9008758068084717
        vf_loss: 10.051019430160522
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.98846153846154
    gpu_util_percent0: 0.4046153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.511538461538462
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16294808968714042
    mean_env_wait_ms: 0.6564847478917705
    mean_inference_ms: 4.782872969782969
    mean_raw_obs_processing_ms: 0.42698163136099937
  time_since_restore: 43.73459029197693
  time_this_iter_s: 21.642374277114868
  time_total_s: 43.73459029197693
  timers:
    learn_throughput: 10992.045
    learn_time_ms: 14719.008
    sample_throughput: 22905.576
    sample_time_ms: 7063.433
    update_time_ms: 38.41
  timestamp: 1604234302
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      2 |          43.7346 | 323584 |  32.5474 |              44.2424 |              13.0808 |            117.548 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1510.1358481262328
    time_step_min: 1302
  date: 2020-11-01_12-38-43
  done: false
  episode_len_mean: 116.32862362971986
  episode_reward_max: 44.79797979797981
  episode_reward_mean: 33.70579116376925
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1419
  episodes_total: 4105
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1123215953509014
        entropy_coeff: 0.0005000000000000001
        kl: 0.00993400338726739
        model: {}
        policy_loss: -0.013690461909087995
        total_loss: 6.506547371546428
        vf_explained_var: 0.9344742298126221
        vf_loss: 6.518807013829549
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.468000000000004
    gpu_util_percent0: 0.36560000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.508
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16101849961752382
    mean_env_wait_ms: 0.6546024350645249
    mean_inference_ms: 4.701779084784631
    mean_raw_obs_processing_ms: 0.4230887594071475
  time_since_restore: 64.32173490524292
  time_this_iter_s: 20.58714461326599
  time_total_s: 64.32173490524292
  timers:
    learn_throughput: 11037.784
    learn_time_ms: 14658.015
    sample_throughput: 24159.746
    sample_time_ms: 6696.759
    update_time_ms: 34.468
  timestamp: 1604234323
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      3 |          64.3217 | 485376 |  33.7058 |               44.798 |              13.0808 |            116.329 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1488.4381143065161
    time_step_min: 1270
  date: 2020-11-01_12-39-03
  done: false
  episode_len_mean: 114.89247699801551
  episode_reward_max: 46.01010101010102
  episode_reward_mean: 34.80499565381399
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1438
  episodes_total: 5543
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0760109821955364
        entropy_coeff: 0.0005000000000000001
        kl: 0.010554853981981674
        model: {}
        policy_loss: -0.017120405255506437
        total_loss: 4.882782578468323
        vf_explained_var: 0.9524574279785156
        vf_loss: 4.898330052693685
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.83076923076923
    gpu_util_percent0: 0.33230769230769225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5076923076923077
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15936923843872866
    mean_env_wait_ms: 0.6531312998927246
    mean_inference_ms: 4.622904338928759
    mean_raw_obs_processing_ms: 0.4189887193273442
  time_since_restore: 85.05826711654663
  time_this_iter_s: 20.73653221130371
  time_total_s: 85.05826711654663
  timers:
    learn_throughput: 11028.796
    learn_time_ms: 14669.96
    sample_throughput: 24936.84
    sample_time_ms: 6488.071
    update_time_ms: 46.059
  timestamp: 1604234343
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      4 |          85.0583 | 647168 |   34.805 |              46.0101 |              13.0808 |            114.892 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1466.4215029231427
    time_step_min: 1237
  date: 2020-11-01_12-39-24
  done: false
  episode_len_mean: 113.48583970546588
  episode_reward_max: 47.52525252525255
  episode_reward_mean: 35.910843066747915
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1519
  episodes_total: 7062
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0269921322663624
        entropy_coeff: 0.0005000000000000001
        kl: 0.010993095813319087
        model: {}
        policy_loss: -0.013592622436893484
        total_loss: 3.9119317531585693
        vf_explained_var: 0.9633958339691162
        vf_loss: 3.923839290936788
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.444000000000006
    gpu_util_percent0: 0.41679999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.516
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1580018213167273
    mean_env_wait_ms: 0.6519685995559447
    mean_inference_ms: 4.555161635142564
    mean_raw_obs_processing_ms: 0.41520922328594023
  time_since_restore: 105.7582585811615
  time_this_iter_s: 20.699991464614868
  time_total_s: 105.7582585811615
  timers:
    learn_throughput: 11021.266
    learn_time_ms: 14679.983
    sample_throughput: 25435.818
    sample_time_ms: 6360.794
    update_time_ms: 44.668
  timestamp: 1604234364
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      5 |          105.758 | 808960 |  35.9108 |              47.5253 |              13.0808 |            113.486 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1447.9500235183443
    time_step_min: 1237
  date: 2020-11-01_12-39-45
  done: false
  episode_len_mean: 112.33274874313106
  episode_reward_max: 47.52525252525255
  episode_reward_mean: 36.86168359616273
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1491
  episodes_total: 8553
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.987803190946579
        entropy_coeff: 0.0005000000000000001
        kl: 0.010113457528253397
        model: {}
        policy_loss: -0.014161262234362463
        total_loss: 3.0733113487561545
        vf_explained_var: 0.9713076949119568
        vf_loss: 3.0859439174334207
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.396
    gpu_util_percent0: 0.3632000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5239999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15689234927636098
    mean_env_wait_ms: 0.651134098255352
    mean_inference_ms: 4.500464998774646
    mean_raw_obs_processing_ms: 0.4120524597642815
  time_since_restore: 126.29982709884644
  time_this_iter_s: 20.541568517684937
  time_total_s: 126.29982709884644
  timers:
    learn_throughput: 11029.447
    learn_time_ms: 14669.094
    sample_throughput: 25808.454
    sample_time_ms: 6268.954
    update_time_ms: 43.186
  timestamp: 1604234385
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      6 |            126.3 | 970752 |  36.8617 |              47.5253 |              13.0808 |            112.333 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1430.1320079522864
    time_step_min: 1228
  date: 2020-11-01_12-40-06
  done: false
  episode_len_mean: 111.28944504896627
  episode_reward_max: 48.48484848484849
  episode_reward_mean: 37.7558351344087
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1556
  episodes_total: 10109
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9375320275624593
        entropy_coeff: 0.0005000000000000001
        kl: 0.008831425181900462
        model: {}
        policy_loss: -0.014223781297914684
        total_loss: 2.650870760281881
        vf_explained_var: 0.9759369492530823
        vf_loss: 2.6637970407803855
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.449999999999996
    gpu_util_percent0: 0.35692307692307695
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15594457790714622
    mean_env_wait_ms: 0.6505920718367179
    mean_inference_ms: 4.453229425218937
    mean_raw_obs_processing_ms: 0.409256308610765
  time_since_restore: 146.91562390327454
  time_this_iter_s: 20.6157968044281
  time_total_s: 146.91562390327454
  timers:
    learn_throughput: 11035.377
    learn_time_ms: 14661.212
    sample_throughput: 26039.628
    sample_time_ms: 6213.299
    update_time_ms: 41.221
  timestamp: 1604234406
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      7 |          146.916 | 1132544 |  37.7558 |              48.4848 |              13.0808 |            111.289 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1413.9141553297743
    time_step_min: 1219
  date: 2020-11-01_12-40-27
  done: false
  episode_len_mean: 110.37700420132042
  episode_reward_max: 49.040404040404056
  episode_reward_mean: 38.58040665594469
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1554
  episodes_total: 11663
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8849463810523351
        entropy_coeff: 0.0005000000000000001
        kl: 0.00801295922913899
        model: {}
        policy_loss: -0.012614224765760204
        total_loss: 2.1787688732147217
        vf_explained_var: 0.9803922772407532
        vf_loss: 2.190222958723704
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.924000000000007
    gpu_util_percent0: 0.3896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15514960562097774
    mean_env_wait_ms: 0.650196011864452
    mean_inference_ms: 4.41380605191362
    mean_raw_obs_processing_ms: 0.40683273492153127
  time_since_restore: 167.58297491073608
  time_this_iter_s: 20.667351007461548
  time_total_s: 167.58297491073608
  timers:
    learn_throughput: 11046.514
    learn_time_ms: 14646.43
    sample_throughput: 26162.052
    sample_time_ms: 6184.224
    update_time_ms: 41.682
  timestamp: 1604234427
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      8 |          167.583 | 1294336 |  38.5804 |              49.0404 |              13.0808 |            110.377 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1399.354544764219
    time_step_min: 1207
  date: 2020-11-01_12-40-48
  done: false
  episode_len_mean: 109.57285519745801
  episode_reward_max: 49.04040404040408
  episode_reward_mean: 39.3178455763567
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1555
  episodes_total: 13218
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8404552837212881
        entropy_coeff: 0.0005000000000000001
        kl: 0.007818623019071916
        model: {}
        policy_loss: -0.011729774332100837
        total_loss: 1.9283219973246257
        vf_explained_var: 0.9828620553016663
        vf_loss: 1.9389082888762157
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.368000000000002
    gpu_util_percent0: 0.39
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15447110974777709
    mean_env_wait_ms: 0.6499648656278564
    mean_inference_ms: 4.380306434888785
    mean_raw_obs_processing_ms: 0.4047426878747494
  time_since_restore: 188.20489048957825
  time_this_iter_s: 20.621915578842163
  time_total_s: 188.20489048957825
  timers:
    learn_throughput: 11046.003
    learn_time_ms: 14647.108
    sample_throughput: 26334.762
    sample_time_ms: 6143.667
    update_time_ms: 40.969
  timestamp: 1604234448
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      9 |          188.205 | 1456128 |  39.3178 |              49.0404 |              13.0808 |            109.573 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1385.9825049162541
    time_step_min: 1207
  date: 2020-11-01_12-41-09
  done: false
  episode_len_mean: 108.85056772100567
  episode_reward_max: 49.04040404040408
  episode_reward_mean: 40.00051201389402
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1578
  episodes_total: 14796
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7908046692609787
        entropy_coeff: 0.0005000000000000001
        kl: 0.007631780773711701
        model: {}
        policy_loss: -0.011734772803417096
        total_loss: 1.5385288000106812
        vf_explained_var: 0.9865396022796631
        vf_loss: 1.5491326252619426
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.732000000000006
    gpu_util_percent0: 0.38040000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15388031735599098
    mean_env_wait_ms: 0.6498212598888915
    mean_inference_ms: 4.351027781645246
    mean_raw_obs_processing_ms: 0.40287986554113797
  time_since_restore: 208.505108833313
  time_this_iter_s: 20.30021834373474
  time_total_s: 208.505108833313
  timers:
    learn_throughput: 11056.477
    learn_time_ms: 14633.233
    sample_throughput: 26549.982
    sample_time_ms: 6093.865
    update_time_ms: 40.654
  timestamp: 1604234469
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     10 |          208.505 | 1617920 |  40.0005 |              49.0404 |              13.0808 |            108.851 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1373.7871090163433
    time_step_min: 1207
  date: 2020-11-01_12-41-29
  done: false
  episode_len_mean: 108.19760771390212
  episode_reward_max: 49.040404040404084
  episode_reward_mean: 40.61680826327476
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1590
  episodes_total: 16386
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7443548093239466
        entropy_coeff: 0.0005000000000000001
        kl: 0.007289290855017801
        model: {}
        policy_loss: -0.011087999266843932
        total_loss: 1.2828177213668823
        vf_explained_var: 0.9888736605644226
        vf_loss: 1.2928200562795003
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.136
    gpu_util_percent0: 0.3856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15335957704686504
    mean_env_wait_ms: 0.6497293652386255
    mean_inference_ms: 4.325424204249887
    mean_raw_obs_processing_ms: 0.4011955359649914
  time_since_restore: 229.01598072052002
  time_this_iter_s: 20.51087188720703
  time_total_s: 229.01598072052002
  timers:
    learn_throughput: 11068.877
    learn_time_ms: 14616.84
    sample_throughput: 27216.446
    sample_time_ms: 5944.641
    update_time_ms: 39.857
  timestamp: 1604234489
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     11 |          229.016 | 1779712 |  40.6168 |              49.0404 |              13.0808 |            108.198 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1362.7848496680983
    time_step_min: 1207
  date: 2020-11-01_12-41-50
  done: false
  episode_len_mean: 107.6175456163774
  episode_reward_max: 49.040404040404084
  episode_reward_mean: 41.17096364175804
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1590
  episodes_total: 17976
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7057946672042211
        entropy_coeff: 0.0005000000000000001
        kl: 0.006505049881525338
        model: {}
        policy_loss: -0.011637478950433433
        total_loss: 1.0556738674640656
        vf_explained_var: 0.9909140467643738
        vf_loss: 1.066363235314687
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.067999999999998
    gpu_util_percent0: 0.38120000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15290224314841672
    mean_env_wait_ms: 0.6497100863030586
    mean_inference_ms: 4.30291912913981
    mean_raw_obs_processing_ms: 0.3997009547743406
  time_since_restore: 249.53435850143433
  time_this_iter_s: 20.518377780914307
  time_total_s: 249.53435850143433
  timers:
    learn_throughput: 11067.812
    learn_time_ms: 14618.246
    sample_throughput: 27784.289
    sample_time_ms: 5823.147
    update_time_ms: 40.514
  timestamp: 1604234510
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     12 |          249.534 | 1941504 |   41.171 |              49.0404 |              13.0808 |            107.618 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1352.7341357234316
    time_step_min: 1207
  date: 2020-11-01_12-42-11
  done: false
  episode_len_mean: 107.1025339736385
  episode_reward_max: 49.04040404040409
  episode_reward_mean: 41.67515040050036
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1598
  episodes_total: 19574
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6686889827251434
        entropy_coeff: 0.0005000000000000001
        kl: 0.0063633088720962405
        model: {}
        policy_loss: -0.01186193727577726
        total_loss: 0.8905991663535436
        vf_explained_var: 0.9923557639122009
        vf_loss: 0.9015227903922399
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.288461538461544
    gpu_util_percent0: 0.38153846153846155
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5692307692307685
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15249499620405588
    mean_env_wait_ms: 0.6497364450001253
    mean_inference_ms: 4.282874551579647
    mean_raw_obs_processing_ms: 0.39836613551654754
  time_since_restore: 270.1388850212097
  time_this_iter_s: 20.60452651977539
  time_total_s: 270.1388850212097
  timers:
    learn_throughput: 11056.406
    learn_time_ms: 14633.327
    sample_throughput: 27887.324
    sample_time_ms: 5801.632
    update_time_ms: 41.993
  timestamp: 1604234531
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     13 |          270.139 | 2103296 |  41.6752 |              49.0404 |              13.0808 |            107.103 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1343.4148870685165
    time_step_min: 1207
  date: 2020-11-01_12-42-32
  done: false
  episode_len_mean: 106.65310846560847
  episode_reward_max: 49.04040404040409
  episode_reward_mean: 42.142787951319704
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1594
  episodes_total: 21168
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6273181239763895
        entropy_coeff: 0.0005000000000000001
        kl: 0.006019947739938895
        model: {}
        policy_loss: -0.009247757125801096
        total_loss: 0.7534371664126714
        vf_explained_var: 0.9935855865478516
        vf_loss: 0.7617945869763693
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.48
    gpu_util_percent0: 0.3504
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15213206388671544
    mean_env_wait_ms: 0.6497940000882954
    mean_inference_ms: 4.2649850452281735
    mean_raw_obs_processing_ms: 0.39716794855089166
  time_since_restore: 290.5424859523773
  time_this_iter_s: 20.403600931167603
  time_total_s: 290.5424859523773
  timers:
    learn_throughput: 11072.943
    learn_time_ms: 14611.472
    sample_throughput: 27934.424
    sample_time_ms: 5791.85
    update_time_ms: 35.766
  timestamp: 1604234552
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     14 |          290.542 | 2265088 |  42.1428 |              49.0404 |              13.0808 |            106.653 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1334.9958170049756
    time_step_min: 1207
  date: 2020-11-01_12-42-53
  done: false
  episode_len_mean: 106.25092267135325
  episode_reward_max: 49.04040404040409
  episode_reward_mean: 42.566322273703655
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1592
  episodes_total: 22760
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.593339666724205
        entropy_coeff: 0.0005000000000000001
        kl: 0.0052832565270364285
        model: {}
        policy_loss: -0.007287261697153251
        total_loss: 0.6348467022180557
        vf_explained_var: 0.994635820388794
        vf_loss: 0.6413739621639252
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.588
    gpu_util_percent0: 0.3836
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518110809879511
    mean_env_wait_ms: 0.6498897805634568
    mean_inference_ms: 4.248940110401404
    mean_raw_obs_processing_ms: 0.39609601756717205
  time_since_restore: 311.00591683387756
  time_this_iter_s: 20.463430881500244
  time_total_s: 311.00591683387756
  timers:
    learn_throughput: 11097.5
    learn_time_ms: 14579.139
    sample_throughput: 27995.833
    sample_time_ms: 5779.146
    update_time_ms: 35.119
  timestamp: 1604234573
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     15 |          311.006 | 2426880 |  42.5663 |              49.0404 |              13.0808 |            106.251 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1327.4121421520238
    time_step_min: 1207
  date: 2020-11-01_12-43-14
  done: false
  episode_len_mean: 105.89524239563237
  episode_reward_max: 49.04040404040409
  episode_reward_mean: 42.95161292328897
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1601
  episodes_total: 24361
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5610497693220774
        entropy_coeff: 0.0005000000000000001
        kl: 0.005239539352866511
        model: {}
        policy_loss: -0.008563858728545407
        total_loss: 0.5433527330557505
        vf_explained_var: 0.9954302906990051
        vf_loss: 0.5511491994063059
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.983999999999995
    gpu_util_percent0: 0.37079999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15151777280002335
    mean_env_wait_ms: 0.6499960724887209
    mean_inference_ms: 4.234304826550604
    mean_raw_obs_processing_ms: 0.39511468708048586
  time_since_restore: 331.8462426662445
  time_this_iter_s: 20.840325832366943
  time_total_s: 331.8462426662445
  timers:
    learn_throughput: 11077.938
    learn_time_ms: 14604.884
    sample_throughput: 28012.835
    sample_time_ms: 5775.638
    update_time_ms: 35.504
  timestamp: 1604234594
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     16 |          331.846 | 2588672 |  42.9516 |              49.0404 |              13.0808 |            105.895 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1320.4339440694312
    time_step_min: 1207
  date: 2020-11-01_12-43-36
  done: false
  episode_len_mean: 105.57168707168707
  episode_reward_max: 49.04040404040409
  episode_reward_mean: 43.304979416090546
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1613
  episodes_total: 25974
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5246386776367823
        entropy_coeff: 0.0005000000000000001
        kl: 0.005194058952232202
        model: {}
        policy_loss: -0.010037654642170915
        total_loss: 0.3729574630657832
        vf_explained_var: 0.9968838095664978
        vf_loss: 0.3822186241547267
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.15
    gpu_util_percent0: 0.34961538461538466
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5692307692307685
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512500032596141
    mean_env_wait_ms: 0.6501069321395831
    mean_inference_ms: 4.2209558905247935
    mean_raw_obs_processing_ms: 0.3942088287210041
  time_since_restore: 352.6941442489624
  time_this_iter_s: 20.847901582717896
  time_total_s: 352.6941442489624
  timers:
    learn_throughput: 11060.738
    learn_time_ms: 14627.595
    sample_throughput: 28046.143
    sample_time_ms: 5768.779
    update_time_ms: 36.388
  timestamp: 1604234616
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     17 |          352.694 | 2750464 |   43.305 |              49.0404 |              13.0808 |            105.572 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1314.0839173535712
    time_step_min: 1207
  date: 2020-11-01_12-43-57
  done: false
  episode_len_mean: 105.28088299260548
  episode_reward_max: 49.0404040404041
  episode_reward_mean: 43.62569621105941
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1614
  episodes_total: 27588
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.49088098108768463
        entropy_coeff: 0.0005000000000000001
        kl: 0.004925240180455148
        model: {}
        policy_loss: -0.007551613341396053
        total_loss: 0.27305928741892177
        vf_explained_var: 0.997745931148529
        vf_loss: 0.27987127751111984
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.076923076923077
    gpu_util_percent0: 0.35576923076923084
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5730769230769224
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510024924486738
    mean_env_wait_ms: 0.6502222563745731
    mean_inference_ms: 4.208793894567712
    mean_raw_obs_processing_ms: 0.3933811392042326
  time_since_restore: 373.5547993183136
  time_this_iter_s: 20.860655069351196
  time_total_s: 373.5547993183136
  timers:
    learn_throughput: 11035.452
    learn_time_ms: 14661.112
    sample_throughput: 28141.143
    sample_time_ms: 5749.304
    update_time_ms: 34.956
  timestamp: 1604234637
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     18 |          373.555 | 2912256 |  43.6257 |              49.0404 |              13.0808 |            105.281 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1308.3422956891525
    time_step_min: 1207
  date: 2020-11-01_12-44-18
  done: false
  episode_len_mean: 105.01201725554643
  episode_reward_max: 49.0404040404041
  episode_reward_mean: 43.913729876137445
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1620
  episodes_total: 29208
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.4603450372815132
        entropy_coeff: 0.0005000000000000001
        kl: 0.0052619769315545755
        model: {}
        policy_loss: -0.007839118620419564
        total_loss: 0.24682058518131575
        vf_explained_var: 0.9979783892631531
        vf_loss: 0.25436367591222125
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.90384615384615
    gpu_util_percent0: 0.3811538461538462
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5692307692307685
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507749922403882
    mean_env_wait_ms: 0.6503503182530888
    mean_inference_ms: 4.197625625739776
    mean_raw_obs_processing_ms: 0.3926215964880014
  time_since_restore: 394.43259143829346
  time_this_iter_s: 20.87779211997986
  time_total_s: 394.43259143829346
  timers:
    learn_throughput: 11025.644
    learn_time_ms: 14674.154
    sample_throughput: 28102.66
    sample_time_ms: 5757.177
    update_time_ms: 33.741
  timestamp: 1604234658
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     19 |          394.433 | 3074048 |  43.9137 |              49.0404 |              13.0808 |            105.012 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1303.1952154976273
    time_step_min: 1207
  date: 2020-11-01_12-44-40
  done: false
  episode_len_mean: 104.77212396560117
  episode_reward_max: 49.0404040404041
  episode_reward_mean: 44.17383145096922
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1607
  episodes_total: 30815
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.43477704375982285
        entropy_coeff: 0.0005000000000000001
        kl: 0.004907564221260448
        model: {}
        policy_loss: -0.007642344086586188
        total_loss: 0.17235680421193442
        vf_explained_var: 0.998579740524292
        vf_loss: 0.17972578232487044
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.568
    gpu_util_percent0: 0.3516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15056551159545464
    mean_env_wait_ms: 0.650477071010486
    mean_inference_ms: 4.187399168266206
    mean_raw_obs_processing_ms: 0.39192218046315624
  time_since_restore: 415.2149660587311
  time_this_iter_s: 20.782374620437622
  time_total_s: 415.2149660587311
  timers:
    learn_throughput: 11005.002
    learn_time_ms: 14701.678
    sample_throughput: 28031.542
    sample_time_ms: 5771.784
    update_time_ms: 33.384
  timestamp: 1604234680
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     20 |          415.215 | 3235840 |  44.1738 |              49.0404 |              13.0808 |            104.772 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1298.6048573988814
    time_step_min: 1207
  date: 2020-11-01_12-45-01
  done: false
  episode_len_mean: 104.55760212267062
  episode_reward_max: 49.0404040404041
  episode_reward_mean: 44.4073915135559
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1597
  episodes_total: 32412
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.4088049481312434
        entropy_coeff: 0.0005000000000000001
        kl: 0.0050367383907238645
        model: {}
        policy_loss: -0.004726681110696518
        total_loss: 0.15046600687007108
        vf_explained_var: 0.9988059401512146
        vf_loss: 0.15514524901906648
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.25769230769231
    gpu_util_percent0: 0.3230769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5692307692307685
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15037307743519757
    mean_env_wait_ms: 0.6506021265347358
    mean_inference_ms: 4.177989463073186
    mean_raw_obs_processing_ms: 0.39127952344764305
  time_since_restore: 436.0554406642914
  time_this_iter_s: 20.840474605560303
  time_total_s: 436.0554406642914
  timers:
    learn_throughput: 10991.518
    learn_time_ms: 14719.713
    sample_throughput: 27990.599
    sample_time_ms: 5780.226
    update_time_ms: 33.786
  timestamp: 1604234701
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     21 |          436.055 | 3397632 |  44.4074 |              49.0404 |              13.0808 |            104.558 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1294.3254164459356
    time_step_min: 1207
  date: 2020-11-01_12-45-23
  done: false
  episode_len_mean: 104.35706938607576
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 44.62349862987593
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1615
  episodes_total: 34027
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.38861273725827533
        entropy_coeff: 0.0005000000000000001
        kl: 0.004962532625844081
        model: {}
        policy_loss: -0.006052409371477552
        total_loss: 0.10335199224452178
        vf_explained_var: 0.9991534352302551
        vf_loss: 0.1093505813429753
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.088461538461537
    gpu_util_percent0: 0.34846153846153843
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15019358290939233
    mean_env_wait_ms: 0.6507335363952385
    mean_inference_ms: 4.169147396856916
    mean_raw_obs_processing_ms: 0.39067463008215425
  time_since_restore: 456.7496886253357
  time_this_iter_s: 20.69424796104431
  time_total_s: 456.7496886253357
  timers:
    learn_throughput: 10986.132
    learn_time_ms: 14726.93
    sample_throughput: 28004.762
    sample_time_ms: 5777.303
    update_time_ms: 33.873
  timestamp: 1604234723
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     22 |           456.75 | 3559424 |  44.6235 |              49.0404 |              13.0808 |            104.357 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1290.3840622454425
    time_step_min: 1207
  date: 2020-11-01_12-45-44
  done: false
  episode_len_mean: 104.17307152875175
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 44.82170512983978
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1623
  episodes_total: 35650
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.36651041358709335
        entropy_coeff: 0.0005000000000000001
        kl: 0.006440783229966958
        model: {}
        policy_loss: -0.007153725775424391
        total_loss: 0.08216805756092072
        vf_explained_var: 0.999314546585083
        vf_loss: 0.0893440234164397
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.088
    gpu_util_percent0: 0.3868
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15002367096031743
    mean_env_wait_ms: 0.6508575565151
    mean_inference_ms: 4.160903003774551
    mean_raw_obs_processing_ms: 0.3901072062383884
  time_since_restore: 477.2431552410126
  time_this_iter_s: 20.49346661567688
  time_total_s: 477.2431552410126
  timers:
    learn_throughput: 11006.978
    learn_time_ms: 14699.039
    sample_throughput: 27941.378
    sample_time_ms: 5790.409
    update_time_ms: 31.7
  timestamp: 1604234744
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     23 |          477.243 | 3721216 |  44.8217 |              49.0404 |              13.0808 |            104.173 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1286.7964535196131
    time_step_min: 1207
  date: 2020-11-01_12-46-04
  done: false
  episode_len_mean: 104.00566154176393
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.00310735680616
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1619
  episodes_total: 37269
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.3446768522262573
        entropy_coeff: 0.0005000000000000001
        kl: 0.006010537773060302
        model: {}
        policy_loss: -0.006810000515542924
        total_loss: 0.05681590953220924
        vf_explained_var: 0.9995128512382507
        vf_loss: 0.06364798328528802
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.616
    gpu_util_percent0: 0.42919999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1498672084151353
    mean_env_wait_ms: 0.6509884510617694
    mean_inference_ms: 4.153243452307446
    mean_raw_obs_processing_ms: 0.38958140467964614
  time_since_restore: 497.40847873687744
  time_this_iter_s: 20.165323495864868
  time_total_s: 497.40847873687744
  timers:
    learn_throughput: 11023.912
    learn_time_ms: 14676.46
    sample_throughput: 27996.068
    sample_time_ms: 5779.097
    update_time_ms: 33.775
  timestamp: 1604234764
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 02bc6_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     24 |          497.408 | 3883008 |  45.0031 |              49.0404 |              13.0808 |            104.006 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1283.5285511912427
    time_step_min: 1207
  date: 2020-11-01_12-46-25
  done: false
  episode_len_mean: 103.8526007099861
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.16817737492225
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1605
  episodes_total: 38874
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.32262827704350155
        entropy_coeff: 0.0005000000000000001
        kl: 0.005610594448323051
        model: {}
        policy_loss: -0.004409408691572025
        total_loss: 0.04963509986797968
        vf_explained_var: 0.9995853304862976
        vf_loss: 0.054065559059381485
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.457692307692305
    gpu_util_percent0: 0.4265384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14972028928263528
    mean_env_wait_ms: 0.6511154433665545
    mean_inference_ms: 4.146093777194914
    mean_raw_obs_processing_ms: 0.3890936155505342
  time_since_restore: 517.5921437740326
  time_this_iter_s: 20.18366503715515
  time_total_s: 517.5921437740326
  timers:
    learn_throughput: 11035.673
    learn_time_ms: 14660.819
    sample_throughput: 28000.79
    sample_time_ms: 5778.123
    update_time_ms: 32.664
  timestamp: 1604234785
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 02bc6_00000
  
2020-11-01 12:46:26,652	WARNING util.py:136 -- The `process_trial` operation took 0.5261285305023193 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     25 |          517.592 | 4044800 |  45.1682 |              49.0404 |              13.0808 |            103.853 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1280.5338148716173
    time_step_min: 1207
  date: 2020-11-01_12-46-46
  done: false
  episode_len_mean: 103.71221741815936
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.319422763771136
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1601
  episodes_total: 40475
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.2999122018615405
        entropy_coeff: 0.0005000000000000001
        kl: 0.0053110466881965595
        model: {}
        policy_loss: -0.006303349079341085
        total_loss: 0.05139423534274101
        vf_explained_var: 0.9995618462562561
        vf_loss: 0.0577147655809919
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.96
    gpu_util_percent0: 0.4584
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14958343418475262
    mean_env_wait_ms: 0.6512359147663624
    mean_inference_ms: 4.139411227315708
    mean_raw_obs_processing_ms: 0.38863613088367416
  time_since_restore: 537.769278049469
  time_this_iter_s: 20.1771342754364
  time_total_s: 537.769278049469
  timers:
    learn_throughput: 11085.459
    learn_time_ms: 14594.975
    sample_throughput: 28023.358
    sample_time_ms: 5773.469
    update_time_ms: 30.886
  timestamp: 1604234806
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 02bc6_00000
  
2020-11-01 12:46:47,593	WARNING util.py:136 -- The `process_trial` operation took 0.5515177249908447 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     26 |          537.769 | 4206592 |  45.3194 |              49.0404 |              13.0808 |            103.712 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1277.717564514211
    time_step_min: 1207
  date: 2020-11-01_12-47-07
  done: false
  episode_len_mean: 103.58062906827577
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.461481590264796
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1619
  episodes_total: 42094
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.2697679474949837
        entropy_coeff: 0.0005000000000000001
        kl: 0.005566679639741778
        model: {}
        policy_loss: -0.006809816346503794
        total_loss: 0.03190007215986649
        vf_explained_var: 0.9997119307518005
        vf_loss: 0.038705606323977314
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.436000000000003
    gpu_util_percent0: 0.3812
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14945344756304582
    mean_env_wait_ms: 0.6513545610993874
    mean_inference_ms: 4.133051412280412
    mean_raw_obs_processing_ms: 0.38819843216626215
  time_since_restore: 557.9500815868378
  time_this_iter_s: 20.180803537368774
  time_total_s: 557.9500815868378
  timers:
    learn_throughput: 11129.942
    learn_time_ms: 14536.644
    sample_throughput: 28097.666
    sample_time_ms: 5758.201
    update_time_ms: 30.627
  timestamp: 1604234827
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 02bc6_00000
  
2020-11-01 12:47:08,513	WARNING util.py:136 -- The `process_trial` operation took 0.5479977130889893 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     27 |           557.95 | 4368384 |  45.4615 |              49.0404 |              13.0808 |            103.581 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1275.0976458734085
    time_step_min: 1207
  date: 2020-11-01_12-47-28
  done: false
  episode_len_mean: 103.45904339273052
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.59383551183082
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1623
  episodes_total: 43717
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.23974776516358057
        entropy_coeff: 0.0005000000000000001
        kl: 0.004747193811150889
        model: {}
        policy_loss: -0.004243802364120104
        total_loss: 0.02101877443298387
        vf_explained_var: 0.999813973903656
        vf_loss: 0.025263771259536345
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.936
    gpu_util_percent0: 0.364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14933083667741634
    mean_env_wait_ms: 0.6514677609541502
    mean_inference_ms: 4.127067697966748
    mean_raw_obs_processing_ms: 0.3877881594254328
  time_since_restore: 578.1908588409424
  time_this_iter_s: 20.240777254104614
  time_total_s: 578.1908588409424
  timers:
    learn_throughput: 11182.422
    learn_time_ms: 14468.421
    sample_throughput: 28093.626
    sample_time_ms: 5759.029
    update_time_ms: 30.485
  timestamp: 1604234848
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: 02bc6_00000
  
2020-11-01 12:47:29,582	WARNING util.py:136 -- The `process_trial` operation took 0.5904042720794678 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     28 |          578.191 | 4530176 |  45.5938 |              49.0404 |              13.0808 |            103.459 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1272.6863282026368
    time_step_min: 1207
  date: 2020-11-01_12-47-49
  done: false
  episode_len_mean: 103.34723815406335
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.71580313859499
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1615
  episodes_total: 45332
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 0.21396022414167723
        entropy_coeff: 0.0005000000000000001
        kl: 0.00464061457508554
        model: {}
        policy_loss: -0.003965421337246274
        total_loss: 0.02320340438745916
        vf_explained_var: 0.9998058676719666
        vf_loss: 0.027217798711111147
    num_steps_sampled: 4691968
    num_steps_trained: 4691968
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.857692307692307
    gpu_util_percent0: 0.34076923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14921483484635445
    mean_env_wait_ms: 0.6515697684351597
    mean_inference_ms: 4.121446270442373
    mean_raw_obs_processing_ms: 0.38740127780397765
  time_since_restore: 598.5525875091553
  time_this_iter_s: 20.36172866821289
  time_total_s: 598.5525875091553
  timers:
    learn_throughput: 11221.151
    learn_time_ms: 14418.485
    sample_throughput: 28165.983
    sample_time_ms: 5744.234
    update_time_ms: 31.72
  timestamp: 1604234869
  timesteps_since_restore: 0
  timesteps_total: 4691968
  training_iteration: 29
  trial_id: 02bc6_00000
  
2020-11-01 12:47:50,804	WARNING util.py:136 -- The `process_trial` operation took 0.6144161224365234 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     29 |          598.553 | 4691968 |  45.7158 |              49.0404 |              13.0808 |            103.347 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02bc6_00000:
  custom_metrics:
    time_step_max: 1901
    time_step_mean: 1270.4485656393304
    time_step_min: 1207
  date: 2020-11-01_12-48-10
  done: true
  episode_len_mean: 103.24400221587761
  episode_reward_max: 49.040404040404106
  episode_reward_mean: 45.82882130203902
  episode_reward_min: 13.080808080808094
  episodes_this_iter: 1602
  episodes_total: 46934
  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.0e-05
        entropy: 0.19203581909338632
        entropy_coeff: 0.0005000000000000001
        kl: 0.004001018533017486
        model: {}
        policy_loss: -0.0069229137285825955
        total_loss: 0.009018626738300858
        vf_explained_var: 0.9998963475227356
        vf_loss: 0.01601255312561989
    num_steps_sampled: 4853760
    num_steps_trained: 4853760
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.076000000000004
    gpu_util_percent0: 0.4292
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 67571
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14910530030356728
    mean_env_wait_ms: 0.6516595301622415
    mean_inference_ms: 4.116169102966147
    mean_raw_obs_processing_ms: 0.3870328506532899
  time_since_restore: 618.7089035511017
  time_this_iter_s: 20.15631604194641
  time_total_s: 618.7089035511017
  timers:
    learn_throughput: 11261.529
    learn_time_ms: 14366.788
    sample_throughput: 28251.677
    sample_time_ms: 5726.81
    update_time_ms: 31.9
  timestamp: 1604234890
  timesteps_since_restore: 0
  timesteps_total: 4853760
  training_iteration: 30
  trial_id: 02bc6_00000
  
2020-11-01 12:48:11,852	WARNING util.py:136 -- The `process_trial` operation took 0.6959054470062256 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 24.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | TERMINATED |       |     30 |          618.709 | 4853760 |  45.8288 |              49.0404 |              13.0808 |            103.244 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 24.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02bc6_00000 | TERMINATED |       |     30 |          618.709 | 4853760 |  45.8288 |              49.0404 |              13.0808 |            103.244 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


