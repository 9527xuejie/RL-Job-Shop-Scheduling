2020-10-11 23:30:30,247	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c0eb2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=49119)[0m 2020-10-11 23:30:32,987	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=49083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49015)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_23-31-06
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1768241425355275
        entropy_coeff: 0.0005000000000000001
        kl: 0.012610505878304442
        model: {}
        policy_loss: -0.009612462478495823
        total_loss: 507.0743586222331
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.665714285714277
    gpu_util_percent0: 0.3545714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5514285714285716
    vram_util_percent0: 0.08529494447828329
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17194935774206932
    mean_env_wait_ms: 1.1842501711867484
    mean_inference_ms: 6.177420912056876
    mean_raw_obs_processing_ms: 0.46873241340941063
  time_since_restore: 28.201035261154175
  time_this_iter_s: 28.201035261154175
  time_total_s: 28.201035261154175
  timers:
    learn_throughput: 8655.907
    learn_time_ms: 18691.513
    sample_throughput: 17227.377
    sample_time_ms: 9391.563
    update_time_ms: 85.425
  timestamp: 1602459066
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      1 |           28.201 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3631.472222222222
    time_step_min: 3330
  date: 2020-10-11_23-31-32
  done: false
  episode_len_mean: 891.1360759493671
  episode_reward_max: 261.4747474747477
  episode_reward_mean: 214.80951924306328
  episode_reward_min: 111.47474747474729
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.134361485640208
        entropy_coeff: 0.0005000000000000001
        kl: 0.01598474996474882
        model: {}
        policy_loss: -0.012698815340021005
        total_loss: 143.839724222819
        vf_explained_var: 0.7972996830940247
        vf_loss: 143.85139338175455
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.777419354838706
    gpu_util_percent0: 0.344516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1671592289033841
    mean_env_wait_ms: 1.1776723425827371
    mean_inference_ms: 5.837635426924808
    mean_raw_obs_processing_ms: 0.4532987688057437
  time_since_restore: 54.39419889450073
  time_this_iter_s: 26.193163633346558
  time_total_s: 54.39419889450073
  timers:
    learn_throughput: 8718.078
    learn_time_ms: 18558.218
    sample_throughput: 18945.896
    sample_time_ms: 8539.686
    update_time_ms: 53.219
  timestamp: 1602459092
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      2 |          54.3942 | 323584 |   214.81 |              261.475 |              111.475 |            891.136 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3632.378923766816
    time_step_min: 3280
  date: 2020-10-11_23-31-59
  done: false
  episode_len_mean: 885.4873417721519
  episode_reward_max: 269.050505050505
  episode_reward_mean: 215.43427950389957
  episode_reward_min: 111.47474747474729
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1184000968933105
        entropy_coeff: 0.0005000000000000001
        kl: 0.019284230656921864
        model: {}
        policy_loss: -0.015676411421736702
        total_loss: 60.846158027648926
        vf_explained_var: 0.8997156620025635
        vf_loss: 60.86046441396078
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.33125
    gpu_util_percent0: 0.3921875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1639339854667819
    mean_env_wait_ms: 1.175472090632675
    mean_inference_ms: 5.5984987317329695
    mean_raw_obs_processing_ms: 0.44201990142911524
  time_since_restore: 80.50952672958374
  time_this_iter_s: 26.115327835083008
  time_total_s: 80.50952672958374
  timers:
    learn_throughput: 8671.728
    learn_time_ms: 18657.411
    sample_throughput: 20017.827
    sample_time_ms: 8082.396
    update_time_ms: 48.991
  timestamp: 1602459119
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      3 |          80.5095 | 485376 |  215.434 |              269.051 |              111.475 |            885.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3622.592715231788
    time_step_min: 3280
  date: 2020-10-11_23-32-24
  done: false
  episode_len_mean: 879.4905063291139
  episode_reward_max: 269.050505050505
  episode_reward_mean: 217.16351809231543
  episode_reward_min: 111.47474747474729
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0924379229545593
        entropy_coeff: 0.0005000000000000001
        kl: 0.015751195217793185
        model: {}
        policy_loss: -0.014981813265573388
        total_loss: 46.172661463419594
        vf_explained_var: 0.9200791716575623
        vf_loss: 46.18661594390869
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.171875
    gpu_util_percent0: 0.36375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16162801589190126
    mean_env_wait_ms: 1.1750736601901086
    mean_inference_ms: 5.42778192240209
    mean_raw_obs_processing_ms: 0.4336865292948899
  time_since_restore: 106.36429476737976
  time_this_iter_s: 25.85476803779602
  time_total_s: 106.36429476737976
  timers:
    learn_throughput: 8681.167
    learn_time_ms: 18637.126
    sample_throughput: 20617.947
    sample_time_ms: 7847.144
    update_time_ms: 43.629
  timestamp: 1602459144
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      4 |          106.364 | 647168 |  217.164 |              269.051 |              111.475 |            879.491 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3608.011811023622
    time_step_min: 3280
  date: 2020-10-11_23-32-50
  done: false
  episode_len_mean: 874.8
  episode_reward_max: 269.050505050505
  episode_reward_mean: 219.32131440992185
  episode_reward_min: 111.47474747474729
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0356460114320118
        entropy_coeff: 0.0005000000000000001
        kl: 0.015596341496954361
        model: {}
        policy_loss: -0.01411884395808253
        total_loss: 30.98894739151001
        vf_explained_var: 0.9491283297538757
        vf_loss: 31.002023061116535
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.693548387096776
    gpu_util_percent0: 0.37741935483870964
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15990040320741253
    mean_env_wait_ms: 1.175785466895637
    mean_inference_ms: 5.29919249270271
    mean_raw_obs_processing_ms: 0.4272516538401917
  time_since_restore: 132.1736500263214
  time_this_iter_s: 25.80935525894165
  time_total_s: 132.1736500263214
  timers:
    learn_throughput: 8677.128
    learn_time_ms: 18645.801
    sample_throughput: 21040.618
    sample_time_ms: 7689.508
    update_time_ms: 38.564
  timestamp: 1602459170
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      5 |          132.174 | 808960 |  219.321 |              269.051 |              111.475 |              874.8 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3585.9517177344474
    time_step_min: 3280
  date: 2020-10-11_23-33-16
  done: false
  episode_len_mean: 864.4226244343891
  episode_reward_max: 278.5959595959592
  episode_reward_mean: 222.7193656017184
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0184950232505798
        entropy_coeff: 0.0005000000000000001
        kl: 0.014954332262277603
        model: {}
        policy_loss: -0.01255397490846614
        total_loss: 40.576768239339195
        vf_explained_var: 0.9526219367980957
        vf_loss: 40.58833599090576
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.451612903225808
    gpu_util_percent0: 0.39967741935483875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15755431541280704
    mean_env_wait_ms: 1.1784812062389567
    mean_inference_ms: 5.126822160173245
    mean_raw_obs_processing_ms: 0.4189552265972552
  time_since_restore: 157.68698716163635
  time_this_iter_s: 25.51333713531494
  time_total_s: 157.68698716163635
  timers:
    learn_throughput: 8684.012
    learn_time_ms: 18631.02
    sample_throughput: 21414.166
    sample_time_ms: 7555.372
    update_time_ms: 35.8
  timestamp: 1602459196
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      6 |          157.687 | 970752 |  222.719 |              278.596 |              90.2626 |            864.423 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3569.84142394822
    time_step_min: 3258
  date: 2020-10-11_23-33-42
  done: false
  episode_len_mean: 859.7215189873418
  episode_reward_max: 278.5959595959592
  episode_reward_mean: 225.13928046285628
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0012784053881962
        entropy_coeff: 0.0005000000000000001
        kl: 0.01476670972382029
        model: {}
        policy_loss: -0.014229802298359573
        total_loss: 17.564584255218506
        vf_explained_var: 0.9680470824241638
        vf_loss: 17.577838102976482
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.396774193548385
    gpu_util_percent0: 0.3619354838709677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15670776667869488
    mean_env_wait_ms: 1.179782684455066
    mean_inference_ms: 5.064443543710888
    mean_raw_obs_processing_ms: 0.41595646584979984
  time_since_restore: 183.52626180648804
  time_this_iter_s: 25.839274644851685
  time_total_s: 183.52626180648804
  timers:
    learn_throughput: 8675.793
    learn_time_ms: 18648.67
    sample_throughput: 21648.294
    sample_time_ms: 7473.661
    update_time_ms: 36.308
  timestamp: 1602459222
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      7 |          183.526 | 1132544 |  225.139 |              278.596 |              90.2626 |            859.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3555.6133428981348
    time_step_min: 3239
  date: 2020-10-11_23-34-07
  done: false
  episode_len_mean: 854.92194092827
  episode_reward_max: 278.89898989898995
  episode_reward_mean: 227.3406853343561
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.981043150027593
        entropy_coeff: 0.0005000000000000001
        kl: 0.014406178224210938
        model: {}
        policy_loss: -0.014604137919377536
        total_loss: 17.505566120147705
        vf_explained_var: 0.9653670191764832
        vf_loss: 17.51922019322713
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.19677419354839
    gpu_util_percent0: 0.3967741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15597932436837098
    mean_env_wait_ms: 1.1810188233777215
    mean_inference_ms: 5.010702956294317
    mean_raw_obs_processing_ms: 0.41328884834392093
  time_since_restore: 208.9575219154358
  time_this_iter_s: 25.431260108947754
  time_total_s: 208.9575219154358
  timers:
    learn_throughput: 8678.934
    learn_time_ms: 18641.922
    sample_throughput: 21909.38
    sample_time_ms: 7384.6
    update_time_ms: 34.742
  timestamp: 1602459247
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      8 |          208.958 | 1294336 |  227.341 |              278.899 |              90.2626 |            854.922 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3542.513115802943
    time_step_min: 3239
  date: 2020-10-11_23-34-33
  done: false
  episode_len_mean: 849.1954745443118
  episode_reward_max: 284.2020202020199
  episode_reward_mean: 229.4127700639328
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 169
  episodes_total: 1591
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9278488308191299
        entropy_coeff: 0.0005000000000000001
        kl: 0.015184675498555103
        model: {}
        policy_loss: -0.015378257805423345
        total_loss: 17.528507232666016
        vf_explained_var: 0.9697012305259705
        vf_loss: 17.542831420898438
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.658064516129024
    gpu_util_percent0: 0.36451612903225805
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15529429565120081
    mean_env_wait_ms: 1.1826514006976956
    mean_inference_ms: 4.960719487039978
    mean_raw_obs_processing_ms: 0.4107542589829356
  time_since_restore: 234.50521659851074
  time_this_iter_s: 25.54769468307495
  time_total_s: 234.50521659851074
  timers:
    learn_throughput: 8678.534
    learn_time_ms: 18642.781
    sample_throughput: 22097.087
    sample_time_ms: 7321.87
    update_time_ms: 33.698
  timestamp: 1602459273
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |      9 |          234.505 | 1456128 |  229.413 |              284.202 |              90.2626 |            849.195 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3519.6065310492504
    time_step_min: 3186
  date: 2020-10-11_23-34-58
  done: false
  episode_len_mean: 840.550105485232
  episode_reward_max: 290.5656565656563
  episode_reward_mean: 232.66529216212754
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 305
  episodes_total: 1896
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8983412136634191
        entropy_coeff: 0.0005000000000000001
        kl: 0.012526698488121232
        model: {}
        policy_loss: -0.012023369354816774
        total_loss: 19.02519655227661
        vf_explained_var: 0.9735334515571594
        vf_loss: 19.03641653060913
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.386666666666667
    gpu_util_percent0: 0.34500000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15431708137951927
    mean_env_wait_ms: 1.1855685703578644
    mean_inference_ms: 4.888222778351128
    mean_raw_obs_processing_ms: 0.40716680868310084
  time_since_restore: 259.903767824173
  time_this_iter_s: 25.39855122566223
  time_total_s: 259.903767824173
  timers:
    learn_throughput: 8682.218
    learn_time_ms: 18634.871
    sample_throughput: 22270.258
    sample_time_ms: 7264.936
    update_time_ms: 32.983
  timestamp: 1602459298
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     10 |          259.904 | 1617920 |  232.665 |              290.566 |              90.2626 |             840.55 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3510.407206317868
    time_step_min: 3186
  date: 2020-10-11_23-35-24
  done: false
  episode_len_mean: 836.4493670886076
  episode_reward_max: 290.5656565656563
  episode_reward_mean: 234.11792707995235
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8768516282240549
        entropy_coeff: 0.0005000000000000001
        kl: 0.012877282220870256
        model: {}
        policy_loss: -0.012240811755570272
        total_loss: 12.433447202046713
        vf_explained_var: 0.9750412106513977
        vf_loss: 12.444838603337606
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.970967741935485
    gpu_util_percent0: 0.3693548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15389053256529253
    mean_env_wait_ms: 1.1869758613200168
    mean_inference_ms: 4.857101816608438
    mean_raw_obs_processing_ms: 0.40561412913102124
  time_since_restore: 285.4311420917511
  time_this_iter_s: 25.527374267578125
  time_total_s: 285.4311420917511
  timers:
    learn_throughput: 8683.35
    learn_time_ms: 18632.44
    sample_throughput: 23099.814
    sample_time_ms: 7004.039
    update_time_ms: 26.822
  timestamp: 1602459324
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     11 |          285.431 | 1779712 |  234.118 |              290.566 |              90.2626 |            836.449 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3501.0572344322345
    time_step_min: 3184
  date: 2020-10-11_23-35-50
  done: false
  episode_len_mean: 832.9493670886076
  episode_reward_max: 290.5656565656563
  episode_reward_mean: 235.6168922498036
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8496886591116587
        entropy_coeff: 0.0005000000000000001
        kl: 0.012053813552483916
        model: {}
        policy_loss: -0.013882728584576398
        total_loss: 12.595096190770468
        vf_explained_var: 0.9731960892677307
        vf_loss: 12.608198245366415
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.73870967741936
    gpu_util_percent0: 0.39483870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15350153045541007
    mean_env_wait_ms: 1.1883777575023744
    mean_inference_ms: 4.828941598607228
    mean_raw_obs_processing_ms: 0.40417355590301407
  time_since_restore: 311.1837246417999
  time_this_iter_s: 25.752582550048828
  time_total_s: 311.1837246417999
  timers:
    learn_throughput: 8668.111
    learn_time_ms: 18665.197
    sample_throughput: 23358.295
    sample_time_ms: 6926.533
    update_time_ms: 27.199
  timestamp: 1602459350
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     12 |          311.184 | 1941504 |  235.617 |              290.566 |              90.2626 |            832.949 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3487.0773569701855
    time_step_min: 3154
  date: 2020-10-11_23-36-16
  done: false
  episode_len_mean: 827.6888446215139
  episode_reward_max: 290.5656565656563
  episode_reward_mean: 237.75598615638455
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 298
  episodes_total: 2510
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8168976306915283
        entropy_coeff: 0.0005000000000000001
        kl: 0.010934635375936827
        model: {}
        policy_loss: -0.012862508907952966
        total_loss: 16.12634865442912
        vf_explained_var: 0.9774985909461975
        vf_loss: 16.13852659861247
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.841935483870973
    gpu_util_percent0: 0.4
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528695701631802
    mean_env_wait_ms: 1.1910117188347262
    mean_inference_ms: 4.783426969774566
    mean_raw_obs_processing_ms: 0.4018645038697167
  time_since_restore: 336.7676565647125
  time_this_iter_s: 25.583931922912598
  time_total_s: 336.7676565647125
  timers:
    learn_throughput: 8680.138
    learn_time_ms: 18639.335
    sample_throughput: 23454.315
    sample_time_ms: 6898.176
    update_time_ms: 27.956
  timestamp: 1602459376
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     13 |          336.768 | 2103296 |  237.756 |              290.566 |              90.2626 |            827.689 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3478.257712565839
    time_step_min: 3115
  date: 2020-10-11_23-36-41
  done: false
  episode_len_mean: 825.1090841399852
  episode_reward_max: 294.05050505050485
  episode_reward_mean: 239.06528426483746
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 176
  episodes_total: 2686
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7923994809389114
        entropy_coeff: 0.0005000000000000001
        kl: 0.01328575323956708
        model: {}
        policy_loss: -0.012997851124964654
        total_loss: 9.111589113871256
        vf_explained_var: 0.9816264510154724
        vf_loss: 9.12365492184957
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.740000000000006
    gpu_util_percent0: 0.36066666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15254571418337223
    mean_env_wait_ms: 1.1923180192309475
    mean_inference_ms: 4.760222995900752
    mean_raw_obs_processing_ms: 0.4006975246561632
  time_since_restore: 362.3293945789337
  time_this_iter_s: 25.56173801422119
  time_total_s: 362.3293945789337
  timers:
    learn_throughput: 8673.61
    learn_time_ms: 18653.364
    sample_throughput: 23584.632
    sample_time_ms: 6860.061
    update_time_ms: 28.06
  timestamp: 1602459401
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     14 |          362.329 | 2265088 |  239.065 |              294.051 |              90.2626 |            825.109 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3471.177556818182
    time_step_min: 3115
  date: 2020-10-11_23-37-07
  done: false
  episode_len_mean: 822.9644866385373
  episode_reward_max: 294.05050505050485
  episode_reward_mean: 240.08836252823593
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7834017475446066
        entropy_coeff: 0.0005000000000000001
        kl: 0.011360851504529515
        model: {}
        policy_loss: -0.0114588655657523
        total_loss: 9.958629528681437
        vf_explained_var: 0.978266179561615
        vf_loss: 9.969343662261963
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.92903225806451
    gpu_util_percent0: 0.36225806451612896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15228111712918896
    mean_env_wait_ms: 1.193464956750324
    mean_inference_ms: 4.741113858836232
    mean_raw_obs_processing_ms: 0.39970784284935257
  time_since_restore: 387.77368903160095
  time_this_iter_s: 25.444294452667236
  time_total_s: 387.77368903160095
  timers:
    learn_throughput: 8675.53
    learn_time_ms: 18649.236
    sample_throughput: 23700.327
    sample_time_ms: 6826.572
    update_time_ms: 28.472
  timestamp: 1602459427
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     15 |          387.774 | 2426880 |  240.088 |              294.051 |              90.2626 |            822.964 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3461.4995093228654
    time_step_min: 3102
  date: 2020-10-11_23-37-32
  done: false
  episode_len_mean: 819.7442463533225
  episode_reward_max: 296.02020202020253
  episode_reward_mean: 241.62724489628863
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 241
  episodes_total: 3085
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7394362638394038
        entropy_coeff: 0.0005000000000000001
        kl: 0.01120368461124599
        model: {}
        policy_loss: -0.01176309521542862
        total_loss: 11.547801733016968
        vf_explained_var: 0.9813702702522278
        vf_loss: 11.55881436665853
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.112903225806452
    gpu_util_percent0: 0.3583870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1519195510983729
    mean_env_wait_ms: 1.195287260456727
    mean_inference_ms: 4.7149129077436935
    mean_raw_obs_processing_ms: 0.39835933725483
  time_since_restore: 413.38083839416504
  time_this_iter_s: 25.607149362564087
  time_total_s: 413.38083839416504
  timers:
    learn_throughput: 8668.995
    learn_time_ms: 18663.293
    sample_throughput: 23718.701
    sample_time_ms: 6821.284
    update_time_ms: 28.105
  timestamp: 1602459452
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     16 |          413.381 | 2588672 |  241.627 |               296.02 |              90.2626 |            819.744 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3452.6519756838907
    time_step_min: 3102
  date: 2020-10-11_23-37-58
  done: false
  episode_len_mean: 817.1522001205545
  episode_reward_max: 296.02020202020253
  episode_reward_mean: 242.9385719765466
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 233
  episodes_total: 3318
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7195741087198257
        entropy_coeff: 0.0005000000000000001
        kl: 0.011522426813219985
        model: {}
        policy_loss: -0.011878579442660945
        total_loss: 10.764711221059164
        vf_explained_var: 0.9804182648658752
        vf_loss: 10.775797287623087
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.919354838709673
    gpu_util_percent0: 0.425483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15160634584461788
    mean_env_wait_ms: 1.196713546459744
    mean_inference_ms: 4.692210297656972
    mean_raw_obs_processing_ms: 0.39719584168714206
  time_since_restore: 438.81733202934265
  time_this_iter_s: 25.436493635177612
  time_total_s: 438.81733202934265
  timers:
    learn_throughput: 8684.333
    learn_time_ms: 18630.331
    sample_throughput: 23755.352
    sample_time_ms: 6810.76
    update_time_ms: 31.644
  timestamp: 1602459478
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     17 |          438.817 | 2750464 |  242.939 |               296.02 |              90.2626 |            817.152 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3446.544373549884
    time_step_min: 3102
  date: 2020-10-11_23-38-24
  done: false
  episode_len_mean: 815.4626006904488
  episode_reward_max: 296.02020202020253
  episode_reward_mean: 243.89981808882845
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7172789523998896
        entropy_coeff: 0.0005000000000000001
        kl: 0.0119019386669
        model: {}
        policy_loss: -0.01401121960952878
        total_loss: 7.7681814432144165
        vf_explained_var: 0.9818252921104431
        vf_loss: 7.781360904375712
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.103225806451615
    gpu_util_percent0: 0.3712903225806451
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935475
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15141292444066903
    mean_env_wait_ms: 1.197662082253612
    mean_inference_ms: 4.678250004783112
    mean_raw_obs_processing_ms: 0.3964759133705677
  time_since_restore: 464.38376235961914
  time_this_iter_s: 25.56643033027649
  time_total_s: 464.38376235961914
  timers:
    learn_throughput: 8680.858
    learn_time_ms: 18637.789
    sample_throughput: 23737.324
    sample_time_ms: 6815.932
    update_time_ms: 31.777
  timestamp: 1602459504
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     18 |          464.384 | 2912256 |    243.9 |               296.02 |              90.2626 |            815.463 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3439.4297860669226
    time_step_min: 3102
  date: 2020-10-11_23-38-50
  done: false
  episode_len_mean: 813.8007621121394
  episode_reward_max: 296.02020202020253
  episode_reward_mean: 244.9722565887509
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 198
  episodes_total: 3674
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6810388416051865
        entropy_coeff: 0.0005000000000000001
        kl: 0.012077661541601023
        model: {}
        policy_loss: -0.010292738967109472
        total_loss: 8.820623318354288
        vf_explained_var: 0.983665943145752
        vf_loss: 8.83004879951477
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.438709677419357
    gpu_util_percent0: 0.3945161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511809498456432
    mean_env_wait_ms: 1.1988760402309326
    mean_inference_ms: 4.661888313251086
    mean_raw_obs_processing_ms: 0.39562738876472586
  time_since_restore: 490.20195960998535
  time_this_iter_s: 25.81819725036621
  time_total_s: 490.20195960998535
  timers:
    learn_throughput: 8672.927
    learn_time_ms: 18654.831
    sample_throughput: 23706.884
    sample_time_ms: 6824.684
    update_time_ms: 31.375
  timestamp: 1602459530
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     19 |          490.202 | 3074048 |  244.972 |               296.02 |              90.2626 |            813.801 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3430.4030612244896
    time_step_min: 3102
  date: 2020-10-11_23-39-16
  done: false
  episode_len_mean: 811.6534954407294
  episode_reward_max: 296.02020202020253
  episode_reward_mean: 246.2926069202665
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 274
  episodes_total: 3948
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6591240217288336
        entropy_coeff: 0.0005000000000000001
        kl: 0.009565678037082156
        model: {}
        policy_loss: -0.009305158707623681
        total_loss: 9.094444354375204
        vf_explained_var: 0.9853569865226746
        vf_loss: 9.103122552235922
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.938709677419357
    gpu_util_percent0: 0.3777419354838709
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509056803482833
    mean_env_wait_ms: 1.200294563476939
    mean_inference_ms: 4.641696058232161
    mean_raw_obs_processing_ms: 0.39459347346362295
  time_since_restore: 515.9844183921814
  time_this_iter_s: 25.782458782196045
  time_total_s: 515.9844183921814
  timers:
    learn_throughput: 8662.647
    learn_time_ms: 18676.97
    sample_throughput: 23654.039
    sample_time_ms: 6839.931
    update_time_ms: 31.266
  timestamp: 1602459556
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     20 |          515.984 | 3235840 |  246.293 |               296.02 |              90.2626 |            811.653 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3425.30931372549
    time_step_min: 3092
  date: 2020-10-11_23-39-42
  done: false
  episode_len_mean: 810.3244888023369
  episode_reward_max: 297.53535353535347
  episode_reward_mean: 247.06410010523933
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 160
  episodes_total: 4108
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6586944162845612
        entropy_coeff: 0.0005000000000000001
        kl: 0.011692544755836328
        model: {}
        policy_loss: -0.011315742197136084
        total_loss: 7.901407639185588
        vf_explained_var: 0.9821925759315491
        vf_loss: 7.911883473396301
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.38064516129032
    gpu_util_percent0: 0.35129032258064513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15075349543826252
    mean_env_wait_ms: 1.2010687295460047
    mean_inference_ms: 4.630792583411462
    mean_raw_obs_processing_ms: 0.3940342546552649
  time_since_restore: 541.7949798107147
  time_this_iter_s: 25.810561418533325
  time_total_s: 541.7949798107147
  timers:
    learn_throughput: 8656.432
    learn_time_ms: 18690.38
    sample_throughput: 23614.316
    sample_time_ms: 6851.437
    update_time_ms: 32.789
  timestamp: 1602459582
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     21 |          541.795 | 3397632 |  247.064 |              297.535 |              90.2626 |            810.324 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3420.3545582706765
    time_step_min: 3092
  date: 2020-10-11_23-40-07
  done: false
  episode_len_mean: 808.8702147525677
  episode_reward_max: 297.53535353535347
  episode_reward_mean: 247.8571640777523
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 176
  episodes_total: 4284
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.626565471291542
        entropy_coeff: 0.0005000000000000001
        kl: 0.01118792857353886
        model: {}
        policy_loss: -0.01167508812310795
        total_loss: 7.353695392608643
        vf_explained_var: 0.985274612903595
        vf_loss: 7.364565014839172
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.238709677419358
    gpu_util_percent0: 0.3558064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15059289906582204
    mean_env_wait_ms: 1.2019613592593383
    mean_inference_ms: 4.6194656162025804
    mean_raw_obs_processing_ms: 0.3934454468847628
  time_since_restore: 567.4443755149841
  time_this_iter_s: 25.64939570426941
  time_total_s: 567.4443755149841
  timers:
    learn_throughput: 8660.978
    learn_time_ms: 18680.569
    sample_throughput: 23618.097
    sample_time_ms: 6850.34
    update_time_ms: 32.024
  timestamp: 1602459607
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     22 |          567.444 | 3559424 |  247.857 |              297.535 |              90.2626 |             808.87 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3413.1371127224784
    time_step_min: 3092
  date: 2020-10-11_23-40-33
  done: false
  episode_len_mean: 806.3989954138458
  episode_reward_max: 297.53535353535347
  episode_reward_mean: 248.90392018018136
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 295
  episodes_total: 4579
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6090398778518041
        entropy_coeff: 0.0005000000000000001
        kl: 0.009323289074624578
        model: {}
        policy_loss: -0.009933727056098482
        total_loss: 9.770997524261475
        vf_explained_var: 0.9849693179130554
        vf_loss: 9.780303796132406
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.135483870967743
    gpu_util_percent0: 0.33806451612903227
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15035603692170096
    mean_env_wait_ms: 1.2033053528467732
    mean_inference_ms: 4.60231302258787
    mean_raw_obs_processing_ms: 0.39255303735262176
  time_since_restore: 593.0437486171722
  time_this_iter_s: 25.59937310218811
  time_total_s: 593.0437486171722
  timers:
    learn_throughput: 8661.056
    learn_time_ms: 18680.401
    sample_throughput: 23606.6
    sample_time_ms: 6853.676
    update_time_ms: 29.271
  timestamp: 1602459633
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | RUNNING  | 172.17.0.4:49119 |     23 |          593.044 | 3721216 |  248.904 |              297.535 |              90.2626 |            806.399 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c0eb2_00000:
  custom_metrics:
    time_step_max: 4320
    time_step_mean: 3409.822156196944
    time_step_min: 3092
  date: 2020-10-11_23-40-59
  done: true
  episode_len_mean: 805.0962025316455
  episode_reward_max: 297.53535353535347
  episode_reward_mean: 249.41768955376554
  episode_reward_min: 90.26262626262643
  episodes_this_iter: 161
  episodes_total: 4740
  experiment_id: 2c4bb92b315944e1bd95f6fbc2c3a759
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6139463980992635
        entropy_coeff: 0.0005000000000000001
        kl: 0.010337946781267723
        model: {}
        policy_loss: -0.011777529902853226
        total_loss: 6.258352875709534
        vf_explained_var: 0.9863322377204895
        vf_loss: 6.269403457641602
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.92258064516129
    gpu_util_percent0: 0.33612903225806456
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 49119
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15023264252290042
    mean_env_wait_ms: 1.203993363146749
    mean_inference_ms: 4.593575016635022
    mean_raw_obs_processing_ms: 0.3921050454446278
  time_since_restore: 618.705629825592
  time_this_iter_s: 25.6618812084198
  time_total_s: 618.705629825592
  timers:
    learn_throughput: 8657.919
    learn_time_ms: 18687.169
    sample_throughput: 23601.212
    sample_time_ms: 6855.241
    update_time_ms: 29.211
  timestamp: 1602459659
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: c0eb2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | TERMINATED |       |     24 |          618.706 | 3883008 |  249.418 |              297.535 |              90.2626 |            805.096 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c0eb2_00000 | TERMINATED |       |     24 |          618.706 | 3883008 |  249.418 |              297.535 |              90.2626 |            805.096 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


