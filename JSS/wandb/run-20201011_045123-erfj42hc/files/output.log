2020-10-11 04:51:25,892	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_6bcb6_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=47374)[0m 2020-10-11 04:51:28,822	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=47403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47366)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_04-52-11
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1806098307882036
        entropy_coeff: 0.00010000000000000002
        kl: 0.008401303618614162
        model: {}
        policy_loss: -0.016525878171835626
        total_loss: 498.079347882952
        vf_explained_var: 0.5928232073783875
        vf_loss: 498.09429931640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.365116279069763
    gpu_util_percent0: 0.2904651162790698
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00023255813953488373
    ram_util_percent: 6.295348837209301
    vram_util_percent0: 0.19243061011235096
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1819978138663659
    mean_env_wait_ms: 1.2356986481306473
    mean_inference_ms: 6.454209857385959
    mean_raw_obs_processing_ms: 0.5015813292232182
  time_since_restore: 36.927441358566284
  time_this_iter_s: 36.927441358566284
  time_total_s: 36.927441358566284
  timers:
    learn_throughput: 5978.947
    learn_time_ms: 27060.286
    sample_throughput: 16540.393
    sample_time_ms: 9781.63
    update_time_ms: 47.534
  timestamp: 1602391931
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      1 |          36.9274 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3628.1319444444443
    time_step_min: 3292
  date: 2020-10-11_04-52-46
  done: false
  episode_len_mean: 892.8037974683544
  episode_reward_max: 272.6868686868681
  episode_reward_mean: 217.0688211226184
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1461803827966963
        entropy_coeff: 0.00010000000000000002
        kl: 0.009918748999812774
        model: {}
        policy_loss: -0.01916975130526615
        total_loss: 113.34390095302037
        vf_explained_var: 0.8326239585876465
        vf_loss: 113.36120278494698
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.9
    gpu_util_percent0: 0.26925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477500000000001
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17579243239228404
    mean_env_wait_ms: 1.219953138629666
    mean_inference_ms: 6.076386616800394
    mean_raw_obs_processing_ms: 0.48184739936499654
  time_since_restore: 71.44816088676453
  time_this_iter_s: 34.52071952819824
  time_total_s: 71.44816088676453
  timers:
    learn_throughput: 6028.02
    learn_time_ms: 26839.991
    sample_throughput: 18399.686
    sample_time_ms: 8793.194
    update_time_ms: 46.654
  timestamp: 1602391966
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      2 |          71.4482 | 323584 |  217.069 |              272.687 |              111.626 |            892.804 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3620.8744394618834
    time_step_min: 3292
  date: 2020-10-11_04-53-20
  done: false
  episode_len_mean: 891.4957805907173
  episode_reward_max: 272.6868686868681
  episode_reward_mean: 218.16251118782745
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1331622345106942
        entropy_coeff: 0.00010000000000000002
        kl: 0.012332265464855092
        model: {}
        policy_loss: -0.021276289131492376
        total_loss: 39.89602279663086
        vf_explained_var: 0.9305887222290039
        vf_loss: 39.91494532993862
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.645000000000003
    gpu_util_percent0: 0.30174999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17156858933821095
    mean_env_wait_ms: 1.2117534792867763
    mean_inference_ms: 5.805120746708291
    mean_raw_obs_processing_ms: 0.467511882136867
  time_since_restore: 105.75683188438416
  time_this_iter_s: 34.30867099761963
  time_total_s: 105.75683188438416
  timers:
    learn_throughput: 6024.129
    learn_time_ms: 26857.325
    sample_throughput: 19503.769
    sample_time_ms: 8295.422
    update_time_ms: 46.76
  timestamp: 1602392000
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      3 |          105.757 | 485376 |  218.163 |              272.687 |              111.626 |            891.496 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3608.5562913907283
    time_step_min: 3278
  date: 2020-10-11_04-53-54
  done: false
  episode_len_mean: 889.6550632911392
  episode_reward_max: 272.6868686868681
  episode_reward_mean: 220.00466692238825
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1091668180056982
        entropy_coeff: 0.00010000000000000002
        kl: 0.011442085395434074
        model: {}
        policy_loss: -0.020707938886646713
        total_loss: 27.67284733908517
        vf_explained_var: 0.9493371248245239
        vf_loss: 27.69137872968401
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.610256410256405
    gpu_util_percent0: 0.3141025641025641
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494871794871794
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16862975805720354
    mean_env_wait_ms: 1.2069546305648755
    mean_inference_ms: 5.613382007333076
    mean_raw_obs_processing_ms: 0.4571566809653125
  time_since_restore: 139.77235174179077
  time_this_iter_s: 34.015519857406616
  time_total_s: 139.77235174179077
  timers:
    learn_throughput: 6027.065
    learn_time_ms: 26844.243
    sample_throughput: 20220.37
    sample_time_ms: 8001.436
    update_time_ms: 44.037
  timestamp: 1602392034
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      4 |          139.772 | 647168 |  220.005 |              272.687 |              111.626 |            889.655 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3594.051181102362
    time_step_min: 3184
  date: 2020-10-11_04-54-28
  done: false
  episode_len_mean: 886.0658227848102
  episode_reward_max: 283.59595959595936
  episode_reward_mean: 222.13585219281399
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0798207521438599
        entropy_coeff: 0.00010000000000000002
        kl: 0.011214170871036393
        model: {}
        policy_loss: -0.02059193584136665
        total_loss: 19.548652376447404
        vf_explained_var: 0.9631001353263855
        vf_loss: 19.567109516688756
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.685000000000002
    gpu_util_percent0: 0.38225000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1664666254967194
    mean_env_wait_ms: 1.2040590836857246
    mean_inference_ms: 5.470548983698335
    mean_raw_obs_processing_ms: 0.44924805366372383
  time_since_restore: 174.00727581977844
  time_this_iter_s: 34.23492407798767
  time_total_s: 174.00727581977844
  timers:
    learn_throughput: 6017.337
    learn_time_ms: 26887.642
    sample_throughput: 20696.675
    sample_time_ms: 7817.294
    update_time_ms: 43.564
  timestamp: 1602392068
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      5 |          174.007 | 808960 |  222.136 |              283.596 |              111.626 |            886.066 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3573.439528023599
    time_step_min: 3184
  date: 2020-10-11_04-55-02
  done: false
  episode_len_mean: 877.0736842105263
  episode_reward_max: 283.59595959595936
  episode_reward_mean: 225.52781402542146
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 255
  episodes_total: 1045
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0480442302567619
        entropy_coeff: 0.00010000000000000002
        kl: 0.011407650142375911
        model: {}
        policy_loss: -0.018919215820330595
        total_loss: 22.484064510890416
        vf_explained_var: 0.9707564115524292
        vf_loss: 22.50080762590681
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.205000000000002
    gpu_util_percent0: 0.367
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16402289503518028
    mean_env_wait_ms: 1.2033525830969207
    mean_inference_ms: 5.307215848554901
    mean_raw_obs_processing_ms: 0.4403795819202064
  time_since_restore: 208.09579062461853
  time_this_iter_s: 34.08851480484009
  time_total_s: 208.09579062461853
  timers:
    learn_throughput: 6025.609
    learn_time_ms: 26850.731
    sample_throughput: 20945.371
    sample_time_ms: 7724.475
    update_time_ms: 53.63
  timestamp: 1602392102
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      6 |          208.096 | 970752 |  225.528 |              283.596 |              111.626 |            877.074 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3554.1674757281553
    time_step_min: 3184
  date: 2020-10-11_04-55-37
  done: false
  episode_len_mean: 869.9193037974684
  episode_reward_max: 283.59595959595936
  episode_reward_mean: 228.17809423347381
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 219
  episodes_total: 1264
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.05707619871412
        entropy_coeff: 0.00010000000000000002
        kl: 0.011848425293075187
        model: {}
        policy_loss: -0.02114954331357564
        total_loss: 13.864338874816895
        vf_explained_var: 0.975281298160553
        vf_loss: 13.883224282945905
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.238461538461536
    gpu_util_percent0: 0.29358974358974355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502564102564102
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16249476557426412
    mean_env_wait_ms: 1.203386122629166
    mean_inference_ms: 5.207267118841815
    mean_raw_obs_processing_ms: 0.4348146560287971
  time_since_restore: 242.1076180934906
  time_this_iter_s: 34.01182746887207
  time_total_s: 242.1076180934906
  timers:
    learn_throughput: 6024.723
    learn_time_ms: 26854.678
    sample_throughput: 21213.011
    sample_time_ms: 7627.017
    update_time_ms: 51.417
  timestamp: 1602392137
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      7 |          242.108 | 1132544 |  228.178 |              283.596 |              111.626 |            869.919 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3543.205882352941
    time_step_min: 3184
  date: 2020-10-11_04-56-10
  done: false
  episode_len_mean: 864.5710267229255
  episode_reward_max: 283.59595959595936
  episode_reward_mean: 229.49290372075163
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0280042716435023
        entropy_coeff: 0.00010000000000000002
        kl: 0.011616885595555817
        model: {}
        policy_loss: -0.020105198333372494
        total_loss: 12.459809167044503
        vf_explained_var: 0.976662278175354
        vf_loss: 12.47769376209804
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.425641025641028
    gpu_util_percent0: 0.3558974358974359
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502564102564102
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1616152811066986
    mean_env_wait_ms: 1.2038842191155374
    mean_inference_ms: 5.148541907168564
    mean_raw_obs_processing_ms: 0.4315903987987597
  time_since_restore: 275.89526200294495
  time_this_iter_s: 33.787643909454346
  time_total_s: 275.89526200294495
  timers:
    learn_throughput: 6028.841
    learn_time_ms: 26836.337
    sample_throughput: 21434.341
    sample_time_ms: 7548.261
    update_time_ms: 48.458
  timestamp: 1602392170
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      8 |          275.895 | 1294336 |  229.493 |              283.596 |              111.626 |            864.571 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3533.903994845361
    time_step_min: 3184
  date: 2020-10-11_04-56-45
  done: false
  episode_len_mean: 859.803164556962
  episode_reward_max: 283.59595959595936
  episode_reward_mean: 230.7367344329368
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9945191613265446
        entropy_coeff: 0.00010000000000000002
        kl: 0.011348826012441091
        model: {}
        policy_loss: -0.021085576121030108
        total_loss: 13.235097817012242
        vf_explained_var: 0.9746939539909363
        vf_loss: 13.25401258468628
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.46923076923077
    gpu_util_percent0: 0.3048717948717949
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.507692307692308
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1608495179678036
    mean_env_wait_ms: 1.2044996311274667
    mean_inference_ms: 5.097362351863963
    mean_raw_obs_processing_ms: 0.42872649642054217
  time_since_restore: 309.9962215423584
  time_this_iter_s: 34.10095953941345
  time_total_s: 309.9962215423584
  timers:
    learn_throughput: 6028.251
    learn_time_ms: 26838.963
    sample_throughput: 21557.068
    sample_time_ms: 7505.288
    update_time_ms: 45.712
  timestamp: 1602392205
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |      9 |          309.996 | 1456128 |  230.737 |              283.596 |              111.626 |            859.803 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3518.3255051884216
    time_step_min: 3184
  date: 2020-10-11_04-57-18
  done: false
  episode_len_mean: 851.4502420656266
  episode_reward_max: 285.8686868686867
  episode_reward_mean: 233.28942463907484
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 279
  episodes_total: 1859
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9512987945760999
        entropy_coeff: 0.00010000000000000002
        kl: 0.011145597922482662
        model: {}
        policy_loss: -0.020414674255464758
        total_loss: 15.44251653126308
        vf_explained_var: 0.979333221912384
        vf_loss: 15.460796560559954
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.243589743589748
    gpu_util_percent0: 0.2966666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482051282051282
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15973261397989763
    mean_env_wait_ms: 1.2063460905897767
    mean_inference_ms: 5.02332367751771
    mean_raw_obs_processing_ms: 0.4246506975148699
  time_since_restore: 343.810311794281
  time_this_iter_s: 33.81409025192261
  time_total_s: 343.810311794281
  timers:
    learn_throughput: 6031.461
    learn_time_ms: 26824.678
    sample_throughput: 21696.092
    sample_time_ms: 7457.195
    update_time_ms: 45.057
  timestamp: 1602392238
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     10 |           343.81 | 1617920 |  233.289 |              285.869 |              111.626 |             851.45 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3509.356367226061
    time_step_min: 3184
  date: 2020-10-11_04-57-53
  done: false
  episode_len_mean: 846.9532619279455
  episode_reward_max: 285.8686868686867
  episode_reward_mean: 234.66231939649649
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 195
  episodes_total: 2054
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9435468656676156
        entropy_coeff: 0.00010000000000000002
        kl: 0.010105292512370008
        model: {}
        policy_loss: -0.02005289963978742
        total_loss: 11.551343713487897
        vf_explained_var: 0.9797296524047852
        vf_loss: 11.569470133100237
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.7
    gpu_util_percent0: 0.372
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4925000000000015
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15908435026508394
    mean_env_wait_ms: 1.2075401879757295
    mean_inference_ms: 4.980592908383032
    mean_raw_obs_processing_ms: 0.4222857588689647
  time_since_restore: 377.917866230011
  time_this_iter_s: 34.10755443572998
  time_total_s: 377.917866230011
  timers:
    learn_throughput: 6037.222
    learn_time_ms: 26799.08
    sample_throughput: 22471.461
    sample_time_ms: 7199.888
    update_time_ms: 43.767
  timestamp: 1602392273
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     11 |          377.918 | 1779712 |  234.662 |              285.869 |              111.626 |            846.953 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3503.102106227106
    time_step_min: 3184
  date: 2020-10-11_04-58-26
  done: false
  episode_len_mean: 843.9566003616636
  episode_reward_max: 285.8686868686867
  episode_reward_mean: 235.66367563519452
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9231253351484027
        entropy_coeff: 0.00010000000000000002
        kl: 0.011194150894880295
        model: {}
        policy_loss: -0.021514514328113625
        total_loss: 10.660347257341657
        vf_explained_var: 0.9795951843261719
        vf_loss: 10.67971522467477
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.005128205128205
    gpu_util_percent0: 0.2846153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.158622002774928
    mean_env_wait_ms: 1.2084668410426127
    mean_inference_ms: 4.949998928085935
    mean_raw_obs_processing_ms: 0.42060354184790405
  time_since_restore: 411.52671909332275
  time_this_iter_s: 33.60885286331177
  time_total_s: 411.52671909332275
  timers:
    learn_throughput: 6040.247
    learn_time_ms: 26785.661
    sample_throughput: 22717.372
    sample_time_ms: 7121.951
    update_time_ms: 42.854
  timestamp: 1602392306
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     12 |          411.527 | 1941504 |  235.664 |              285.869 |              111.626 |            843.957 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3497.230834752981
    time_step_min: 3184
  date: 2020-10-11_04-59-00
  done: false
  episode_len_mean: 840.8926767676768
  episode_reward_max: 288.14141414141415
  episode_reward_mean: 236.64188603203746
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 164
  episodes_total: 2376
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8867138028144836
        entropy_coeff: 0.00010000000000000002
        kl: 0.011122131454093116
        model: {}
        policy_loss: -0.021963200166023204
        total_loss: 10.28539766584124
        vf_explained_var: 0.9823418855667114
        vf_loss: 10.305224895477295
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.25128205128205
    gpu_util_percent0: 0.39128205128205135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581876824343939
    mean_env_wait_ms: 1.209474109724844
    mean_inference_ms: 4.921259638706784
    mean_raw_obs_processing_ms: 0.4189788557623401
  time_since_restore: 445.2378988265991
  time_this_iter_s: 33.71117973327637
  time_total_s: 445.2378988265991
  timers:
    learn_throughput: 6045.572
    learn_time_ms: 26762.066
    sample_throughput: 22828.961
    sample_time_ms: 7087.138
    update_time_ms: 42.544
  timestamp: 1602392340
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     13 |          445.238 | 2103296 |  236.642 |              288.141 |              111.626 |            840.893 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3486.872597059932
    time_step_min: 3184
  date: 2020-10-11_04-59-34
  done: false
  episode_len_mean: 835.9794852666915
  episode_reward_max: 288.14141414141415
  episode_reward_mean: 238.23144160742063
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 305
  episodes_total: 2681
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8756763253893171
        entropy_coeff: 0.00010000000000000002
        kl: 0.009692818458591188
        model: {}
        policy_loss: -0.018102587666362524
        total_loss: 12.971363816942487
        vf_explained_var: 0.9826785922050476
        vf_loss: 12.98761544908796
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.91025641025641
    gpu_util_percent0: 0.4256410256410257
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.47948717948718
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15749354162822748
    mean_env_wait_ms: 1.2113541284424145
    mean_inference_ms: 4.875071718577976
    mean_raw_obs_processing_ms: 0.416439446228408
  time_since_restore: 478.7617313861847
  time_this_iter_s: 33.52383255958557
  time_total_s: 478.7617313861847
  timers:
    learn_throughput: 6059.782
    learn_time_ms: 26699.31
    sample_throughput: 22788.115
    sample_time_ms: 7099.841
    update_time_ms: 42.564
  timestamp: 1602392374
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     14 |          478.762 | 2265088 |  238.231 |              288.141 |              111.626 |            835.979 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3481.938565340909
    time_step_min: 3184
  date: 2020-10-11_05-00-08
  done: false
  episode_len_mean: 833.8597046413502
  episode_reward_max: 288.14141414141415
  episode_reward_mean: 238.88769552060688
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 163
  episodes_total: 2844
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8561465399605888
        entropy_coeff: 0.00010000000000000002
        kl: 0.010626444460025855
        model: {}
        policy_loss: -0.020302974352879182
        total_loss: 8.675974573407855
        vf_explained_var: 0.9837983846664429
        vf_loss: 8.694237845284599
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.475
    gpu_util_percent0: 0.41600000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15717086009630685
    mean_env_wait_ms: 1.2122497895705848
    mean_inference_ms: 4.8536985492006135
    mean_raw_obs_processing_ms: 0.41524747550665464
  time_since_restore: 512.5199847221375
  time_this_iter_s: 33.75825333595276
  time_total_s: 512.5199847221375
  timers:
    learn_throughput: 6071.62
    learn_time_ms: 26647.253
    sample_throughput: 22776.261
    sample_time_ms: 7103.536
    update_time_ms: 42.667
  timestamp: 1602392408
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     15 |           512.52 | 2426880 |  238.888 |              288.141 |              111.626 |             833.86 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3477.42938802959
    time_step_min: 3184
  date: 2020-10-11_05-00-42
  done: false
  episode_len_mean: 832.2008660892739
  episode_reward_max: 288.14141414141415
  episode_reward_mean: 239.6385978371321
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8319873086043766
        entropy_coeff: 0.00010000000000000002
        kl: 0.010733343793877534
        model: {}
        policy_loss: -0.020152185968722085
        total_loss: 8.741615636008126
        vf_explained_var: 0.9820079803466797
        vf_loss: 8.75970458984375
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.246153846153845
    gpu_util_percent0: 0.47846153846153844
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15688105002886404
    mean_env_wait_ms: 1.2130738383955892
    mean_inference_ms: 4.834567336481907
    mean_raw_obs_processing_ms: 0.4141792708251881
  time_since_restore: 546.2885317802429
  time_this_iter_s: 33.76854705810547
  time_total_s: 546.2885317802429
  timers:
    learn_throughput: 6075.663
    learn_time_ms: 26629.521
    sample_throughput: 22802.927
    sample_time_ms: 7095.23
    update_time_ms: 36.682
  timestamp: 1602392442
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     16 |          546.289 | 2588672 |  239.639 |              288.141 |              111.626 |            832.201 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3469.8154613466336
    time_step_min: 3104
  date: 2020-10-11_05-01-15
  done: false
  episode_len_mean: 829.9332509270705
  episode_reward_max: 295.7171717171717
  episode_reward_mean: 240.78323719269324
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 234
  episodes_total: 3236
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8008734328406197
        entropy_coeff: 0.00010000000000000002
        kl: 0.0100013964277293
        model: {}
        policy_loss: -0.01986196680393602
        total_loss: 9.553466933114189
        vf_explained_var: 0.985657811164856
        vf_loss: 9.571408680507115
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.112820512820516
    gpu_util_percent0: 0.331025641025641
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48974358974359
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15647449459025592
    mean_env_wait_ms: 1.21428237488013
    mean_inference_ms: 4.808798887600311
    mean_raw_obs_processing_ms: 0.4127352470507476
  time_since_restore: 579.7192213535309
  time_this_iter_s: 33.430689573287964
  time_total_s: 579.7192213535309
  timers:
    learn_throughput: 6087.62
    learn_time_ms: 26577.217
    sample_throughput: 22845.911
    sample_time_ms: 7081.88
    update_time_ms: 42.669
  timestamp: 1602392475
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | RUNNING  | 172.17.0.4:47374 |     17 |          579.719 | 2750464 |  240.783 |              295.717 |              111.626 |            829.933 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6bcb6_00000:
  custom_metrics:
    time_step_max: 4319
    time_step_mean: 3463.4841891499855
    time_step_min: 3104
  date: 2020-10-11_05-01-49
  done: true
  episode_len_mean: 828.1772661870503
  episode_reward_max: 295.7171717171717
  episode_reward_mean: 241.63729380132256
  episode_reward_min: 111.62626262626226
  episodes_this_iter: 239
  episodes_total: 3475
  experiment_id: 7ae87662a80f4d3eb0aa5192eca9758b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7990088505404336
        entropy_coeff: 0.00010000000000000002
        kl: 0.010261865399245704
        model: {}
        policy_loss: -0.01934962480195931
        total_loss: 8.225102867398943
        vf_explained_var: 0.9864827990531921
        vf_loss: 8.242480039596558
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.563157894736843
    gpu_util_percent0: 0.32315789473684214
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492105263157895
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 47374
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15613242990774456
    mean_env_wait_ms: 1.215417760915379
    mean_inference_ms: 4.785568630096931
    mean_raw_obs_processing_ms: 0.4114537471554266
  time_since_restore: 612.9757430553436
  time_this_iter_s: 33.256521701812744
  time_total_s: 612.9757430553436
  timers:
    learn_throughput: 6098.462
    learn_time_ms: 26529.97
    sample_throughput: 22864.737
    sample_time_ms: 7076.049
    update_time_ms: 41.827
  timestamp: 1602392509
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 6bcb6_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | TERMINATED |       |     18 |          612.976 | 2912256 |  241.637 |              295.717 |              111.626 |            828.177 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6bcb6_00000 | TERMINATED |       |     18 |          612.976 | 2912256 |  241.637 |              295.717 |              111.626 |            828.177 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


