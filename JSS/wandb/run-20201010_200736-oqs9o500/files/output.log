2020-10-10 20:07:38,302	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_3f866_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=73632)[0m 2020-10-10 20:07:41,266	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=73606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73534)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_20-08-20
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1860926832471574
        entropy_coeff: 0.00010000000000000002
        kl: 0.0032946039157520446
        model: {}
        policy_loss: -0.011216985344487642
        total_loss: 499.54930332728793
        vf_explained_var: 0.5819914937019348
        vf_loss: 499.55997358049666
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.1875
    gpu_util_percent0: 0.28825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00025
    ram_util_percent: 6.275
    vram_util_percent0: 0.1902222040013119
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17215999345346597
    mean_env_wait_ms: 1.1939728234277238
    mean_inference_ms: 6.515039250820497
    mean_raw_obs_processing_ms: 0.4653912350217956
  time_since_restore: 33.62714862823486
  time_this_iter_s: 33.62714862823486
  time_total_s: 33.62714862823486
  timers:
    learn_throughput: 7014.69
    learn_time_ms: 23064.74
    sample_throughput: 15426.37
    sample_time_ms: 10488.015
    update_time_ms: 30.512
  timestamp: 1602360500
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      1 |          33.6271 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3616.7951388888887
    time_step_min: 3353
  date: 2020-10-10_20-08-51
  done: false
  episode_len_mean: 889.8164556962025
  episode_reward_max: 261.62626262626264
  episode_reward_mean: 217.52816136043958
  episode_reward_min: 134.20202020201987
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1596399801118034
        entropy_coeff: 0.00010000000000000002
        kl: 0.004653839727065393
        model: {}
        policy_loss: -0.01130429477780126
        total_loss: 119.92388425554547
        vf_explained_var: 0.8239707946777344
        vf_loss: 119.93484279087612
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.26111111111111
    gpu_util_percent0: 0.3327777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.469444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16740017953626393
    mean_env_wait_ms: 1.1887601854321836
    mean_inference_ms: 6.089901699399365
    mean_raw_obs_processing_ms: 0.45192040737211586
  time_since_restore: 64.6495156288147
  time_this_iter_s: 31.022367000579834
  time_total_s: 64.6495156288147
  timers:
    learn_throughput: 7007.754
    learn_time_ms: 23087.569
    sample_throughput: 17653.213
    sample_time_ms: 9165.017
    update_time_ms: 26.18
  timestamp: 1602360531
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      2 |          64.6495 | 323584 |  217.528 |              261.626 |              134.202 |            889.816 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3612.5560538116592
    time_step_min: 3295
  date: 2020-10-10_20-09-21
  done: false
  episode_len_mean: 889.3164556962025
  episode_reward_max: 266.77777777777766
  episode_reward_mean: 217.71883390870713
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1513628789356776
        entropy_coeff: 0.00010000000000000002
        kl: 0.005450372816994786
        model: {}
        policy_loss: -0.01306106244737748
        total_loss: 48.58227784293039
        vf_explained_var: 0.9169869422912598
        vf_loss: 48.59518187386649
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.962857142857143
    gpu_util_percent0: 0.3365714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4799999999999995
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1644477774441131
    mean_env_wait_ms: 1.186693749017275
    mean_inference_ms: 5.8111574908013095
    mean_raw_obs_processing_ms: 0.44334731178024
  time_since_restore: 94.8579089641571
  time_this_iter_s: 30.208393335342407
  time_total_s: 94.8579089641571
  timers:
    learn_throughput: 7045.039
    learn_time_ms: 22965.381
    sample_throughput: 18854.658
    sample_time_ms: 8581.01
    update_time_ms: 25.475
  timestamp: 1602360561
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      3 |          94.8579 | 485376 |  217.719 |              266.778 |              133.596 |            889.316 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3609.134105960265
    time_step_min: 3295
  date: 2020-10-10_20-09-52
  done: false
  episode_len_mean: 886.7025316455696
  episode_reward_max: 266.92929292929324
  episode_reward_mean: 219.05434087712547
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1395776867866516
        entropy_coeff: 0.00010000000000000002
        kl: 0.005577786260151437
        model: {}
        policy_loss: -0.013741492701228708
        total_loss: 29.845005171639578
        vf_explained_var: 0.9461264610290527
        vf_loss: 29.85858236040388
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.00277777777778
    gpu_util_percent0: 0.27666666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16235339729897139
    mean_env_wait_ms: 1.185554366096383
    mean_inference_ms: 5.616331826516528
    mean_raw_obs_processing_ms: 0.43698404623604103
  time_since_restore: 125.08748412132263
  time_this_iter_s: 30.229575157165527
  time_total_s: 125.08748412132263
  timers:
    learn_throughput: 7055.31
    learn_time_ms: 22931.947
    sample_throughput: 19577.415
    sample_time_ms: 8264.217
    update_time_ms: 27.72
  timestamp: 1602360592
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      4 |          125.087 | 647168 |  219.054 |              266.929 |              133.596 |            886.703 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3598.4291338582675
    time_step_min: 3249
  date: 2020-10-10_20-10-22
  done: false
  episode_len_mean: 883.946835443038
  episode_reward_max: 273.7474747474743
  episode_reward_mean: 220.2169799258405
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1179757118225098
        entropy_coeff: 0.00010000000000000002
        kl: 0.0052992299066058225
        model: {}
        policy_loss: -0.014401016889938287
        total_loss: 24.659941809517996
        vf_explained_var: 0.9565388560295105
        vf_loss: 24.67419011252267
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.67142857142857
    gpu_util_percent0: 0.40314285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714286
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16080302410463984
    mean_env_wait_ms: 1.185330682958861
    mean_inference_ms: 5.471765921694267
    mean_raw_obs_processing_ms: 0.4318191965048613
  time_since_restore: 155.3392653465271
  time_this_iter_s: 30.251781225204468
  time_total_s: 155.3392653465271
  timers:
    learn_throughput: 7059.486
    learn_time_ms: 22918.381
    sample_throughput: 20040.905
    sample_time_ms: 8073.088
    update_time_ms: 27.147
  timestamp: 1602360622
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      5 |          155.339 | 808960 |  220.217 |              273.747 |              133.596 |            883.947 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3583.1771037181998
    time_step_min: 3238
  date: 2020-10-10_20-10-52
  done: false
  episode_len_mean: 877.1285714285714
  episode_reward_max: 277.2323232323235
  episode_reward_mean: 223.01327561327543
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 260
  episodes_total: 1050
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0986038616725378
        entropy_coeff: 0.00010000000000000002
        kl: 0.005098884492846472
        model: {}
        policy_loss: -0.013224984531656705
        total_loss: 30.715921265738352
        vf_explained_var: 0.9619913697242737
        vf_loss: 30.72900131770543
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.447222222222223
    gpu_util_percent0: 0.26999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15899427983209735
    mean_env_wait_ms: 1.186683461453728
    mean_inference_ms: 5.3055903344247435
    mean_raw_obs_processing_ms: 0.4255595451233823
  time_since_restore: 185.52758479118347
  time_this_iter_s: 30.188319444656372
  time_total_s: 185.52758479118347
  timers:
    learn_throughput: 7060.998
    learn_time_ms: 22913.476
    sample_throughput: 20398.747
    sample_time_ms: 7931.467
    update_time_ms: 26.512
  timestamp: 1602360652
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      6 |          185.528 | 970752 |  223.013 |              277.232 |              133.596 |            877.129 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3571.571197411003
    time_step_min: 3238
  date: 2020-10-10_20-11-23
  done: false
  episode_len_mean: 872.4398734177215
  episode_reward_max: 277.2323232323235
  episode_reward_mean: 225.46868207390344
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 214
  episodes_total: 1264
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1141586984906877
        entropy_coeff: 0.00010000000000000002
        kl: 0.004915357600631458
        model: {}
        policy_loss: -0.015136342562202896
        total_loss: 14.780154977525983
        vf_explained_var: 0.9740357995033264
        vf_loss: 14.795156955718994
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.822857142857142
    gpu_util_percent0: 0.3757142857142858
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579609197667625
    mean_env_wait_ms: 1.1880105059372499
    mean_inference_ms: 5.209099628427949
    mean_raw_obs_processing_ms: 0.422211522783047
  time_since_restore: 215.74007964134216
  time_this_iter_s: 30.21249485015869
  time_total_s: 215.74007964134216
  timers:
    learn_throughput: 7064.959
    learn_time_ms: 22900.629
    sample_throughput: 20634.687
    sample_time_ms: 7840.778
    update_time_ms: 28.967
  timestamp: 1602360683
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      7 |           215.74 | 1132544 |  225.469 |              277.232 |              133.596 |             872.44 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3560.252510760402
    time_step_min: 3238
  date: 2020-10-10_20-11-53
  done: false
  episode_len_mean: 869.0246132208158
  episode_reward_max: 277.2323232323235
  episode_reward_mean: 226.93536632144207
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.0945317830358232
        entropy_coeff: 0.00010000000000000002
        kl: 0.005521425179072789
        model: {}
        policy_loss: -0.014304674679546483
        total_loss: 13.489289215632848
        vf_explained_var: 0.9744372963905334
        vf_loss: 13.503565243312291
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.27777777777778
    gpu_util_percent0: 0.32972222222222225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157339536757762
    mean_env_wait_ms: 1.188924479364911
    mean_inference_ms: 5.150889932821983
    mean_raw_obs_processing_ms: 0.4200512417341922
  time_since_restore: 245.97589373588562
  time_this_iter_s: 30.235814094543457
  time_total_s: 245.97589373588562
  timers:
    learn_throughput: 7070.671
    learn_time_ms: 22882.128
    sample_throughput: 20780.26
    sample_time_ms: 7785.85
    update_time_ms: 29.382
  timestamp: 1602360713
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      8 |          245.976 | 1294336 |  226.935 |              277.232 |              133.596 |            869.025 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3551.1887886597938
    time_step_min: 3238
  date: 2020-10-10_20-12-23
  done: false
  episode_len_mean: 865.8430379746835
  episode_reward_max: 277.2323232323235
  episode_reward_mean: 228.1300984528831
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.078474657876151
        entropy_coeff: 0.00010000000000000002
        kl: 0.005664016984935317
        model: {}
        policy_loss: -0.015145135611029608
        total_loss: 13.698078768593925
        vf_explained_var: 0.9732908606529236
        vf_loss: 13.713190010615758
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.697142857142858
    gpu_util_percent0: 0.3002857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285715
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15679562838224612
    mean_env_wait_ms: 1.1898023238973947
    mean_inference_ms: 5.100355999559662
    mean_raw_obs_processing_ms: 0.41812941987838187
  time_since_restore: 276.1882133483887
  time_this_iter_s: 30.21231961250305
  time_total_s: 276.1882133483887
  timers:
    learn_throughput: 7068.01
    learn_time_ms: 22890.744
    sample_throughput: 20963.683
    sample_time_ms: 7717.728
    update_time_ms: 29.147
  timestamp: 1602360743
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |      9 |          276.188 | 1456128 |   228.13 |              277.232 |              133.596 |            865.843 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3541.7209573847053
    time_step_min: 3238
  date: 2020-10-10_20-12-53
  done: false
  episode_len_mean: 862.8954623779437
  episode_reward_max: 278.74747474747466
  episode_reward_mean: 229.4746778526214
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 161
  episodes_total: 1741
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.0460829905101232
        entropy_coeff: 0.00010000000000000002
        kl: 0.005178378362740789
        model: {}
        policy_loss: -0.014436428667977452
        total_loss: 14.906891822814941
        vf_explained_var: 0.974901556968689
        vf_loss: 14.921303885323661
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.119444444444447
    gpu_util_percent0: 0.29583333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15632182015968762
    mean_env_wait_ms: 1.1907697623941556
    mean_inference_ms: 5.055702338491485
    mean_raw_obs_processing_ms: 0.4163698183825968
  time_since_restore: 306.36675000190735
  time_this_iter_s: 30.178536653518677
  time_total_s: 306.36675000190735
  timers:
    learn_throughput: 7067.303
    learn_time_ms: 22893.034
    sample_throughput: 21108.309
    sample_time_ms: 7664.849
    update_time_ms: 28.343
  timestamp: 1602360773
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     10 |          306.367 | 1617920 |  229.475 |              278.747 |              133.596 |            862.895 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3526.3402571711176
    time_step_min: 3225
  date: 2020-10-10_20-13-24
  done: false
  episode_len_mean: 857.8575609756098
  episode_reward_max: 278.74747474747466
  episode_reward_mean: 231.831436314363
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 309
  episodes_total: 2050
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.0373592291559492
        entropy_coeff: 0.00010000000000000002
        kl: 0.005237542225846222
        model: {}
        policy_loss: -0.013978065082483226
        total_loss: 16.971344334738596
        vf_explained_var: 0.9770342111587524
        vf_loss: 16.98529509135655
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.34444444444445
    gpu_util_percent0: 0.30222222222222217
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15556995052640982
    mean_env_wait_ms: 1.1926374419907502
    mean_inference_ms: 4.984826869259845
    mean_raw_obs_processing_ms: 0.4136427027513095
  time_since_restore: 336.9428548812866
  time_this_iter_s: 30.576104879379272
  time_total_s: 336.9428548812866
  timers:
    learn_throughput: 7066.421
    learn_time_ms: 22895.891
    sample_throughput: 22024.058
    sample_time_ms: 7346.148
    update_time_ms: 29.415
  timestamp: 1602360804
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     11 |          336.943 | 1779712 |  231.831 |              278.747 |              133.596 |            857.858 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3517.4688644688645
    time_step_min: 3225
  date: 2020-10-10_20-13-55
  done: false
  episode_len_mean: 855.6772151898734
  episode_reward_max: 279.353535353535
  episode_reward_mean: 233.00805066944295
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 162
  episodes_total: 2212
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.0235610519136702
        entropy_coeff: 0.00010000000000000002
        kl: 0.004701269125299794
        model: {}
        policy_loss: -0.01405788616310539
        total_loss: 10.904009819030762
        vf_explained_var: 0.9798542261123657
        vf_loss: 10.918052400861468
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.837142857142855
    gpu_util_percent0: 0.32514285714285723
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285715
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15525211576595063
    mean_env_wait_ms: 1.1934880844366238
    mean_inference_ms: 4.95414178035958
    mean_raw_obs_processing_ms: 0.4124625151290244
  time_since_restore: 367.31643438339233
  time_this_iter_s: 30.373579502105713
  time_total_s: 367.31643438339233
  timers:
    learn_throughput: 7071.472
    learn_time_ms: 22879.537
    sample_throughput: 22177.978
    sample_time_ms: 7295.165
    update_time_ms: 31.228
  timestamp: 1602360835
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     12 |          367.316 | 1941504 |  233.008 |              279.354 |              133.596 |            855.677 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3510.5841161400513
    time_step_min: 3175
  date: 2020-10-10_20-14-25
  done: false
  episode_len_mean: 853.4873417721519
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 234.00121467842973
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0139859744480677
        entropy_coeff: 0.00010000000000000002
        kl: 0.00507284135424665
        model: {}
        policy_loss: -0.014092240682137864
        total_loss: 12.471036570412773
        vf_explained_var: 0.9760551452636719
        vf_loss: 12.485166958400182
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.874285714285715
    gpu_util_percent0: 0.3077142857142858
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142856
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15496625885569262
    mean_env_wait_ms: 1.1942560534402253
    mean_inference_ms: 4.927075432761323
    mean_raw_obs_processing_ms: 0.4113941471669357
  time_since_restore: 397.54555320739746
  time_this_iter_s: 30.229118824005127
  time_total_s: 397.54555320739746
  timers:
    learn_throughput: 7063.161
    learn_time_ms: 22906.457
    sample_throughput: 22256.236
    sample_time_ms: 7269.513
    update_time_ms: 31.47
  timestamp: 1602360865
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     13 |          397.546 | 2103296 |  234.001 |              289.505 |              133.596 |            853.487 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3503.625299281724
    time_step_min: 3175
  date: 2020-10-10_20-14-55
  done: false
  episode_len_mean: 851.2557221783741
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 235.17496990425153
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 164
  episodes_total: 2534
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9835632017680577
        entropy_coeff: 0.00010000000000000002
        kl: 0.005351109696286065
        model: {}
        policy_loss: -0.015746969888693587
        total_loss: 11.527123655591692
        vf_explained_var: 0.9795533418655396
        vf_loss: 11.542901924678258
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.705714285714283
    gpu_util_percent0: 0.3522857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546920839282085
    mean_env_wait_ms: 1.1950186118975497
    mean_inference_ms: 4.901459813822385
    mean_raw_obs_processing_ms: 0.41037227458152203
  time_since_restore: 427.8199303150177
  time_this_iter_s: 30.27437710762024
  time_total_s: 427.8199303150177
  timers:
    learn_throughput: 7062.88
    learn_time_ms: 22907.369
    sample_throughput: 22244.654
    sample_time_ms: 7273.298
    update_time_ms: 30.521
  timestamp: 1602360895
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     14 |           427.82 | 2265088 |  235.175 |              289.505 |              133.596 |            851.256 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3492.220206332266
    time_step_min: 3175
  date: 2020-10-10_20-15-26
  done: false
  episode_len_mean: 847.9528002817893
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 236.94274196704615
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 305
  episodes_total: 2839
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9657969091619764
        entropy_coeff: 0.00010000000000000002
        kl: 0.005142190460381764
        model: {}
        policy_loss: -0.013281873876361974
        total_loss: 15.81534821646554
        vf_explained_var: 0.9790207743644714
        vf_loss: 15.828662599836077
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.891666666666666
    gpu_util_percent0: 0.3016666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888888
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15424961512867186
    mean_env_wait_ms: 1.1964585576508873
    mean_inference_ms: 4.860556181203473
    mean_raw_obs_processing_ms: 0.4087765124807283
  time_since_restore: 458.40637707710266
  time_this_iter_s: 30.58644676208496
  time_total_s: 458.40637707710266
  timers:
    learn_throughput: 7052.091
    learn_time_ms: 22942.415
    sample_throughput: 22255.379
    sample_time_ms: 7269.793
    update_time_ms: 32.0
  timestamp: 1602360926
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     15 |          458.406 | 2426880 |  236.943 |              289.505 |              133.596 |            847.953 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3486.522864828514
    time_step_min: 3154
  date: 2020-10-10_20-15-57
  done: false
  episode_len_mean: 846.346435709527
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 237.9064192894971
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 163
  episodes_total: 3002
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9534048821244921
        entropy_coeff: 0.00010000000000000002
        kl: 0.004733065076704536
        model: {}
        policy_loss: -0.014000122618329312
        total_loss: 9.430276462009974
        vf_explained_var: 0.9825257062911987
        vf_loss: 9.444312572479248
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.808571428571426
    gpu_util_percent0: 0.2971428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285715
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404038707941164
    mean_env_wait_ms: 1.1971116636460193
    mean_inference_ms: 4.8412179858564475
    mean_raw_obs_processing_ms: 0.4080280646226588
  time_since_restore: 488.79160737991333
  time_this_iter_s: 30.38523030281067
  time_total_s: 488.79160737991333
  timers:
    learn_throughput: 7048.7
    learn_time_ms: 22953.452
    sample_throughput: 22230.577
    sample_time_ms: 7277.904
    update_time_ms: 31.966
  timestamp: 1602360957
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     16 |          488.792 | 2588672 |  237.906 |              289.505 |              133.596 |            846.346 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3481.580459770115
    time_step_min: 3154
  date: 2020-10-10_20-16-27
  done: false
  episode_len_mean: 844.9674050632912
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 238.68221774709104
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9445052317210606
        entropy_coeff: 0.00010000000000000002
        kl: 0.0053568776430828234
        model: {}
        policy_loss: -0.014230267776708518
        total_loss: 12.496155738830566
        vf_explained_var: 0.9754217863082886
        vf_loss: 12.510447025299072
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.622857142857143
    gpu_util_percent0: 0.31028571428571433
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15385039576870196
    mean_env_wait_ms: 1.1977239820911931
    mean_inference_ms: 4.823901252061392
    mean_raw_obs_processing_ms: 0.407347247605494
  time_since_restore: 518.9008934497833
  time_this_iter_s: 30.109286069869995
  time_total_s: 518.9008934497833
  timers:
    learn_throughput: 7046.276
    learn_time_ms: 22961.349
    sample_throughput: 22282.753
    sample_time_ms: 7260.862
    update_time_ms: 29.491
  timestamp: 1602360987
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     17 |          518.901 | 2750464 |  238.682 |              289.505 |              133.596 |            844.967 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3476.7067919951487
    time_step_min: 3154
  date: 2020-10-10_20-16-57
  done: false
  episode_len_mean: 843.7158749248347
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 239.45120477170977
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 166
  episodes_total: 3326
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.918665464435305
        entropy_coeff: 0.00010000000000000002
        kl: 0.005234634503722191
        model: {}
        policy_loss: -0.014006703892456633
        total_loss: 10.177470343453544
        vf_explained_var: 0.9820380210876465
        vf_loss: 10.191535881587438
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.371428571428574
    gpu_util_percent0: 0.34400000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1536668481192844
    mean_env_wait_ms: 1.1983072316610899
    mean_inference_ms: 4.806910583028609
    mean_raw_obs_processing_ms: 0.40666861331631904
  time_since_restore: 548.791063785553
  time_this_iter_s: 29.890170335769653
  time_total_s: 548.791063785553
  timers:
    learn_throughput: 7046.038
    learn_time_ms: 22962.123
    sample_throughput: 22396.857
    sample_time_ms: 7223.871
    update_time_ms: 30.011
  timestamp: 1602361017
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     18 |          548.791 | 2912256 |  239.451 |              289.505 |              133.596 |            843.716 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3467.552682791215
    time_step_min: 3142
  date: 2020-10-10_20-17-28
  done: false
  episode_len_mean: 841.6615172413793
  episode_reward_max: 294.9595959595961
  episode_reward_mean: 240.8236293974224
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 299
  episodes_total: 3625
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.8990497716835567
        entropy_coeff: 0.00010000000000000002
        kl: 0.004830614563875965
        model: {}
        policy_loss: -0.012397399222079133
        total_loss: 14.858607292175293
        vf_explained_var: 0.9797409772872925
        vf_loss: 14.87106466293335
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.01944444444445
    gpu_util_percent0: 0.33111111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15336562894322348
    mean_env_wait_ms: 1.1993524594438971
    mean_inference_ms: 4.7797420416726215
    mean_raw_obs_processing_ms: 0.4056083854817603
  time_since_restore: 579.4335150718689
  time_this_iter_s: 30.642451286315918
  time_total_s: 579.4335150718689
  timers:
    learn_throughput: 7041.047
    learn_time_ms: 22978.4
    sample_throughput: 22318.29
    sample_time_ms: 7249.301
    update_time_ms: 30.572
  timestamp: 1602361048
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | RUNNING  | 172.17.0.4:73632 |     19 |          579.434 | 3074048 |  240.824 |               294.96 |              133.596 |            841.662 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3f866_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3462.8870882040383
    time_step_min: 3142
  date: 2020-10-10_20-17-58
  done: true
  episode_len_mean: 840.507911392405
  episode_reward_max: 294.9595959595961
  episode_reward_mean: 241.53180539572935
  episode_reward_min: 133.5959595959594
  episodes_this_iter: 167
  episodes_total: 3792
  experiment_id: 60fa372464ea4b09bf50cda6284251e1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 5.000000000000001e-05
        entropy: 0.8873999076230186
        entropy_coeff: 0.00010000000000000002
        kl: 0.0048316218225019315
        model: {}
        policy_loss: -0.014597887313617062
        total_loss: 8.974073614392962
        vf_explained_var: 0.9832248687744141
        vf_loss: 8.988745212554932
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.055555555555557
    gpu_util_percent0: 0.3697222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 73632
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15322068240891734
    mean_env_wait_ms: 1.1998691132461945
    mean_inference_ms: 4.765954142774957
    mean_raw_obs_processing_ms: 0.40506129492300624
  time_since_restore: 609.4452970027924
  time_this_iter_s: 30.011781930923462
  time_total_s: 609.4452970027924
  timers:
    learn_throughput: 7041.914
    learn_time_ms: 22975.573
    sample_throughput: 22365.671
    sample_time_ms: 7233.944
    update_time_ms: 31.413
  timestamp: 1602361078
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 3f866_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | TERMINATED |       |     20 |          609.445 | 3235840 |  241.532 |               294.96 |              133.596 |            840.508 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3f866_00000 | TERMINATED |       |     20 |          609.445 | 3235840 |  241.532 |               294.96 |              133.596 |            840.508 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


