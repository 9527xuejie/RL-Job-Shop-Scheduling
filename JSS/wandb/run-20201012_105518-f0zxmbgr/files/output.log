2020-10-12 10:55:22,455	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_6dc57_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=52163)[0m 2020-10-12 10:55:25,246	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=52158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52178)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_10-55-59
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1823383669058483
        entropy_coeff: 0.0005000000000000001
        kl: 0.006917016425480445
        model: {}
        policy_loss: -0.009157503198366612
        total_loss: 507.07493591308594
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.251515151515154
    gpu_util_percent0: 0.3718181818181819
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.566666666666667
    vram_util_percent0: 0.08736346740610434
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17147091885855553
    mean_env_wait_ms: 1.1835253551514953
    mean_inference_ms: 5.7652556215329245
    mean_raw_obs_processing_ms: 0.4616651007995889
  time_since_restore: 28.869199991226196
  time_this_iter_s: 28.869199991226196
  time_total_s: 28.869199991226196
  timers:
    learn_throughput: 8237.186
    learn_time_ms: 19641.659
    sample_throughput: 17651.248
    sample_time_ms: 9166.037
    update_time_ms: 28.822
  timestamp: 1602500159
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      1 |          28.8692 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3614.2256944444443
    time_step_min: 3379
  date: 2020-10-12_10-56-26
  done: false
  episode_len_mean: 892.4873417721519
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 217.54734049354283
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.149937113126119
        entropy_coeff: 0.0005000000000000001
        kl: 0.007523950111741821
        model: {}
        policy_loss: -0.00998671705989788
        total_loss: 126.33550771077473
        vf_explained_var: 0.8110877871513367
        vf_loss: 126.34455998738606
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.475
    gpu_util_percent0: 0.3421875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16716277233710714
    mean_env_wait_ms: 1.1780378196190102
    mean_inference_ms: 5.585069303097012
    mean_raw_obs_processing_ms: 0.4514916274955019
  time_since_restore: 56.27803659439087
  time_this_iter_s: 27.408836603164673
  time_total_s: 56.27803659439087
  timers:
    learn_throughput: 8276.418
    learn_time_ms: 19548.553
    sample_throughput: 18989.984
    sample_time_ms: 8519.86
    update_time_ms: 32.285
  timestamp: 1602500186
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      2 |           56.278 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3605.479820627803
    time_step_min: 3310
  date: 2020-10-12_10-56-53
  done: false
  episode_len_mean: 888.5801687763714
  episode_reward_max: 264.50505050505006
  episode_reward_mean: 219.20585602864062
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1411352157592773
        entropy_coeff: 0.0005000000000000001
        kl: 0.010440803055341044
        model: {}
        policy_loss: -0.013970387983135879
        total_loss: 54.93683338165283
        vf_explained_var: 0.8966913819313049
        vf_loss: 54.94928582509359
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.906451612903226
    gpu_util_percent0: 0.2567741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16416068482864943
    mean_env_wait_ms: 1.1764073313687264
    mean_inference_ms: 5.41271049974388
    mean_raw_obs_processing_ms: 0.44254761530967934
  time_since_restore: 82.95011138916016
  time_this_iter_s: 26.672074794769287
  time_total_s: 82.95011138916016
  timers:
    learn_throughput: 8275.25
    learn_time_ms: 19551.314
    sample_throughput: 20161.139
    sample_time_ms: 8024.943
    update_time_ms: 30.097
  timestamp: 1602500213
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      3 |          82.9501 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3591.1639072847684
    time_step_min: 3227
  date: 2020-10-12_10-57-20
  done: false
  episode_len_mean: 885.4873417721519
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 221.420326684567
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1191200812657673
        entropy_coeff: 0.0005000000000000001
        kl: 0.011468215147033334
        model: {}
        policy_loss: -0.013862663588952273
        total_loss: 39.326786041259766
        vf_explained_var: 0.9241357445716858
        vf_loss: 39.33891359965006
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.122580645161296
    gpu_util_percent0: 0.3067741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16203772838314764
    mean_env_wait_ms: 1.1756419669558824
    mean_inference_ms: 5.281175406047125
    mean_raw_obs_processing_ms: 0.43528602585015497
  time_since_restore: 109.46789050102234
  time_this_iter_s: 26.517779111862183
  time_total_s: 109.46789050102234
  timers:
    learn_throughput: 8295.557
    learn_time_ms: 19503.452
    sample_throughput: 20769.091
    sample_time_ms: 7790.038
    update_time_ms: 28.106
  timestamp: 1602500240
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      4 |          109.468 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3577.469816272966
    time_step_min: 3227
  date: 2020-10-12_10-57-46
  done: false
  episode_len_mean: 882.6164556962025
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 223.37348165196246
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0904998779296875
        entropy_coeff: 0.0005000000000000001
        kl: 0.010465693194419146
        model: {}
        policy_loss: -0.013936646308138734
        total_loss: 29.070746898651123
        vf_explained_var: 0.9454066157341003
        vf_loss: 29.0831356048584
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.53870967741935
    gpu_util_percent0: 0.2938709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1604253042931813
    mean_env_wait_ms: 1.1754901553139634
    mean_inference_ms: 5.1789854550669325
    mean_raw_obs_processing_ms: 0.4294192239943622
  time_since_restore: 135.85770750045776
  time_this_iter_s: 26.389816999435425
  time_total_s: 135.85770750045776
  timers:
    learn_throughput: 8303.132
    learn_time_ms: 19485.659
    sample_throughput: 21259.941
    sample_time_ms: 7610.181
    update_time_ms: 29.296
  timestamp: 1602500266
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      5 |          135.858 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3562.2380487804876
    time_step_min: 3215
  date: 2020-10-12_10-58-13
  done: false
  episode_len_mean: 875.4055080721747
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 225.90998302109395
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 263
  episodes_total: 1053
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0669801433881123
        entropy_coeff: 0.0005000000000000001
        kl: 0.010119187956055006
        model: {}
        policy_loss: -0.014624884177464992
        total_loss: 30.67037757237752
        vf_explained_var: 0.9617660641670227
        vf_loss: 30.683512210845947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.938709677419357
    gpu_util_percent0: 0.2916129032258064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1586324585785928
    mean_env_wait_ms: 1.176979295536505
    mean_inference_ms: 5.05538347401539
    mean_raw_obs_processing_ms: 0.4225521220118445
  time_since_restore: 162.56656551361084
  time_this_iter_s: 26.708858013153076
  time_total_s: 162.56656551361084
  timers:
    learn_throughput: 8290.95
    learn_time_ms: 19514.291
    sample_throughput: 21567.052
    sample_time_ms: 7501.813
    update_time_ms: 31.603
  timestamp: 1602500293
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      6 |          162.567 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3547.7540453074434
    time_step_min: 3215
  date: 2020-10-12_10-58-40
  done: false
  episode_len_mean: 868.5514240506329
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 228.15807601329732
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 211
  episodes_total: 1264
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0668786863485973
        entropy_coeff: 0.0005000000000000001
        kl: 0.012256689059237639
        model: {}
        policy_loss: -0.01610318278350557
        total_loss: 20.370780150095623
        vf_explained_var: 0.963979959487915
        vf_loss: 20.384966214497883
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.616129032258065
    gpu_util_percent0: 0.23774193548387104
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15748831276889352
    mean_env_wait_ms: 1.1783620018052106
    mean_inference_ms: 4.984924423970675
    mean_raw_obs_processing_ms: 0.4185332833118741
  time_since_restore: 189.28819298744202
  time_this_iter_s: 26.721627473831177
  time_total_s: 189.28819298744202
  timers:
    learn_throughput: 8282.185
    learn_time_ms: 19534.941
    sample_throughput: 21790.152
    sample_time_ms: 7425.005
    update_time_ms: 33.042
  timestamp: 1602500320
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      7 |          189.288 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3536.647776183644
    time_step_min: 3215
  date: 2020-10-12_10-59-06
  done: false
  episode_len_mean: 862.704641350211
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 229.98016025231198
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0334690809249878
        entropy_coeff: 0.0005000000000000001
        kl: 0.010793289790550867
        model: {}
        policy_loss: -0.015747709141578525
        total_loss: 15.715624650319418
        vf_explained_var: 0.969296395778656
        vf_loss: 15.729730685551962
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.24838709677419
    gpu_util_percent0: 0.28161290322580645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15681990846501556
    mean_env_wait_ms: 1.1795715076372215
    mean_inference_ms: 4.940636360012669
    mean_raw_obs_processing_ms: 0.4160430537362301
  time_since_restore: 215.92076349258423
  time_this_iter_s: 26.632570505142212
  time_total_s: 215.92076349258423
  timers:
    learn_throughput: 8284.815
    learn_time_ms: 19528.74
    sample_throughput: 21920.108
    sample_time_ms: 7380.986
    update_time_ms: 31.907
  timestamp: 1602500346
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      8 |          215.921 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3525.568943298969
    time_step_min: 3215
  date: 2020-10-12_10-59-33
  done: false
  episode_len_mean: 857.1208860759493
  episode_reward_max: 279.3535353535359
  episode_reward_mean: 231.70662319396482
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0033017992973328
        entropy_coeff: 0.0005000000000000001
        kl: 0.010770521514738599
        model: {}
        policy_loss: -0.015525121105990062
        total_loss: 16.273523728052776
        vf_explained_var: 0.9674468040466309
        vf_loss: 16.28739635149638
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.63225806451613
    gpu_util_percent0: 0.26741935483870966
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1562294682658002
    mean_env_wait_ms: 1.1809391128188538
    mean_inference_ms: 4.901836322882982
    mean_raw_obs_processing_ms: 0.41382111977571656
  time_since_restore: 242.5742666721344
  time_this_iter_s: 26.65350317955017
  time_total_s: 242.5742666721344
  timers:
    learn_throughput: 8289.336
    learn_time_ms: 19518.09
    sample_throughput: 21999.761
    sample_time_ms: 7354.262
    update_time_ms: 31.829
  timestamp: 1602500373
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      9 |          242.574 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3504.7218934911243
    time_step_min: 3186
  date: 2020-10-12_11-00-00
  done: false
  episode_len_mean: 847.3826179120297
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 234.9192882722293
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 307
  episodes_total: 1887
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9698180854320526
        entropy_coeff: 0.0005000000000000001
        kl: 0.008762541770314177
        model: {}
        policy_loss: -0.011754670903125467
        total_loss: 22.15676514307658
        vf_explained_var: 0.9699413776397705
        vf_loss: 22.167253017425537
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.21612903225806
    gpu_util_percent0: 0.23774193548387096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15529209587370074
    mean_env_wait_ms: 1.184021604402104
    mean_inference_ms: 4.840365767194604
    mean_raw_obs_processing_ms: 0.4103636780759023
  time_since_restore: 269.3142466545105
  time_this_iter_s: 26.7399799823761
  time_total_s: 269.3142466545105
  timers:
    learn_throughput: 8283.409
    learn_time_ms: 19532.055
    sample_throughput: 22108.221
    sample_time_ms: 7318.183
    update_time_ms: 30.681
  timestamp: 1602500400
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     10 |          269.314 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3494.990128331688
    time_step_min: 3159
  date: 2020-10-12_11-00-26
  done: false
  episode_len_mean: 842.626582278481
  episode_reward_max: 287.38383838383817
  episode_reward_mean: 236.53693212553955
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.959399938583374
        entropy_coeff: 0.0005000000000000001
        kl: 0.009050344349816442
        model: {}
        policy_loss: -0.014448691198291877
        total_loss: 14.143741130828857
        vf_explained_var: 0.9704552292823792
        vf_loss: 14.156859795252482
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.841935483870966
    gpu_util_percent0: 0.307741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548694538024578
    mean_env_wait_ms: 1.1856497023990709
    mean_inference_ms: 4.812829084442159
    mean_raw_obs_processing_ms: 0.40881206201022163
  time_since_restore: 295.81349515914917
  time_this_iter_s: 26.499248504638672
  time_total_s: 295.81349515914917
  timers:
    learn_throughput: 8293.203
    learn_time_ms: 19508.988
    sample_throughput: 22780.223
    sample_time_ms: 7102.301
    update_time_ms: 30.482
  timestamp: 1602500426
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     11 |          295.813 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3486.236721611722
    time_step_min: 3147
  date: 2020-10-12_11-00-53
  done: false
  episode_len_mean: 839.50226039783
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 237.80845069136197
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9463174144426981
        entropy_coeff: 0.0005000000000000001
        kl: 0.009074758971109986
        model: {}
        policy_loss: -0.014368217787705362
        total_loss: 10.841783205668131
        vf_explained_var: 0.9763579368591309
        vf_loss: 10.854809761047363
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.526666666666664
    gpu_util_percent0: 0.3186666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545074057078582
    mean_env_wait_ms: 1.1870713770777694
    mean_inference_ms: 4.789291310377852
    mean_raw_obs_processing_ms: 0.40744564222192137
  time_since_restore: 322.13705468177795
  time_this_iter_s: 26.323559522628784
  time_total_s: 322.13705468177795
  timers:
    learn_throughput: 8300.926
    learn_time_ms: 19490.838
    sample_throughput: 23072.528
    sample_time_ms: 7012.322
    update_time_ms: 28.973
  timestamp: 1602500453
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     12 |          322.137 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3477.1867900715188
    time_step_min: 3147
  date: 2020-10-12_11-01-20
  done: false
  episode_len_mean: 836.276923076923
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 239.12358512358495
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 193
  episodes_total: 2405
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9069925745328268
        entropy_coeff: 0.0005000000000000001
        kl: 0.009530291194096208
        model: {}
        policy_loss: -0.014515867456793785
        total_loss: 15.319237470626831
        vf_explained_var: 0.9747470021247864
        vf_loss: 15.332300901412964
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.29354838709677
    gpu_util_percent0: 0.2983870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15411688777863225
    mean_env_wait_ms: 1.1888071745009974
    mean_inference_ms: 4.763259120832632
    mean_raw_obs_processing_ms: 0.40591348902537194
  time_since_restore: 348.8731298446655
  time_this_iter_s: 26.736075162887573
  time_total_s: 348.8731298446655
  timers:
    learn_throughput: 8295.844
    learn_time_ms: 19502.778
    sample_throughput: 23098.117
    sample_time_ms: 7004.554
    update_time_ms: 30.571
  timestamp: 1602500480
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     13 |          348.873 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3465.9672686230247
    time_step_min: 3147
  date: 2020-10-12_11-01-46
  done: false
  episode_len_mean: 832.3082650781831
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 240.80178553968565
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 281
  episodes_total: 2686
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9011691262324651
        entropy_coeff: 0.0005000000000000001
        kl: 0.010886709050585827
        model: {}
        policy_loss: -0.01605825025762897
        total_loss: 13.799258867899576
        vf_explained_var: 0.9779562950134277
        vf_loss: 13.813590288162231
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.783870967741933
    gpu_util_percent0: 0.22258064516129034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15360998507930224
    mean_env_wait_ms: 1.191015474262433
    mean_inference_ms: 4.731020836732773
    mean_raw_obs_processing_ms: 0.40406295374842327
  time_since_restore: 375.4877142906189
  time_this_iter_s: 26.61458444595337
  time_total_s: 375.4877142906189
  timers:
    learn_throughput: 8289.533
    learn_time_ms: 19517.625
    sample_throughput: 23119.834
    sample_time_ms: 6997.974
    update_time_ms: 30.585
  timestamp: 1602500506
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     14 |          375.488 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3459.754971590909
    time_step_min: 3147
  date: 2020-10-12_11-02-13
  done: false
  episode_len_mean: 830.3291139240506
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 241.694508374888
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8705271085103353
        entropy_coeff: 0.0005000000000000001
        kl: 0.010132285223032037
        model: {}
        policy_loss: -0.01209646585630253
        total_loss: 9.354986588160196
        vf_explained_var: 0.9806396961212158
        vf_loss: 9.36549154917399
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.34516129032258
    gpu_util_percent0: 0.3393548387096775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15336340446248875
    mean_env_wait_ms: 1.192160805414192
    mean_inference_ms: 4.71496093314174
    mean_raw_obs_processing_ms: 0.40314242716245324
  time_since_restore: 402.0596549510956
  time_this_iter_s: 26.571940660476685
  time_total_s: 402.0596549510956
  timers:
    learn_throughput: 8287.414
    learn_time_ms: 19522.615
    sample_throughput: 23073.317
    sample_time_ms: 7012.082
    update_time_ms: 29.135
  timestamp: 1602500533
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     15 |           402.06 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3454.032279757902
    time_step_min: 3147
  date: 2020-10-12_11-02-40
  done: false
  episode_len_mean: 828.5073284477015
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 242.50461645098542
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8471738596757253
        entropy_coeff: 0.0005000000000000001
        kl: 0.009305963292717934
        model: {}
        policy_loss: -0.01094130908313673
        total_loss: 10.646601835886637
        vf_explained_var: 0.9784726500511169
        vf_loss: 10.656105756759644
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.512903225806454
    gpu_util_percent0: 0.23612903225806453
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.793548387096774
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15313484688014142
    mean_env_wait_ms: 1.1932362942460533
    mean_inference_ms: 4.700063028477268
    mean_raw_obs_processing_ms: 0.40227414635633235
  time_since_restore: 428.6733150482178
  time_this_iter_s: 26.613660097122192
  time_total_s: 428.6733150482178
  timers:
    learn_throughput: 8291.51
    learn_time_ms: 19512.972
    sample_throughput: 23070.439
    sample_time_ms: 7012.957
    update_time_ms: 26.747
  timestamp: 1602500560
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     16 |          428.673 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3446.2361408882084
    time_step_min: 3147
  date: 2020-10-12_11-03-07
  done: false
  episode_len_mean: 825.9881566960219
  episode_reward_max: 289.9595959595964
  episode_reward_mean: 243.72948433622582
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 291
  episodes_total: 3293
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8250234176715215
        entropy_coeff: 0.0005000000000000001
        kl: 0.008491925351942578
        model: {}
        policy_loss: -0.014777651784243062
        total_loss: 15.209494908650717
        vf_explained_var: 0.9786728024482727
        vf_loss: 15.222986777623495
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.87096774193549
    gpu_util_percent0: 0.27645161290322584
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764516129032258
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527630716566746
    mean_env_wait_ms: 1.1950387108952798
    mean_inference_ms: 4.675569550209842
    mean_raw_obs_processing_ms: 0.40087135530926965
  time_since_restore: 455.30483841896057
  time_this_iter_s: 26.631523370742798
  time_total_s: 455.30483841896057
  timers:
    learn_throughput: 8300.637
    learn_time_ms: 19491.515
    sample_throughput: 23025.116
    sample_time_ms: 7026.762
    update_time_ms: 24.775
  timestamp: 1602500587
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     17 |          455.305 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3440.9040023201856
    time_step_min: 3098
  date: 2020-10-12_11-03-33
  done: false
  episode_len_mean: 824.563003452244
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 244.5732671943833
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 183
  episodes_total: 3476
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8241499215364456
        entropy_coeff: 0.0005000000000000001
        kl: 0.007864817045629025
        model: {}
        policy_loss: -0.01140341673938868
        total_loss: 8.79675587018331
        vf_explained_var: 0.9828992486000061
        vf_loss: 8.806998491287231
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.39354838709677
    gpu_util_percent0: 0.34419354838709676
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15254898746596612
    mean_env_wait_ms: 1.1961064700696495
    mean_inference_ms: 4.661854285209326
    mean_raw_obs_processing_ms: 0.400080847959462
  time_since_restore: 481.973614692688
  time_this_iter_s: 26.668776273727417
  time_total_s: 481.973614692688
  timers:
    learn_throughput: 8301.255
    learn_time_ms: 19490.065
    sample_throughput: 23019.881
    sample_time_ms: 7028.359
    update_time_ms: 26.892
  timestamp: 1602500613
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     18 |          481.974 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3436.840266222962
    time_step_min: 3098
  date: 2020-10-12_11-04-00
  done: false
  episode_len_mean: 823.8428728673638
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.09397497262097
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8113949745893478
        entropy_coeff: 0.0005000000000000001
        kl: 0.008743428780386845
        model: {}
        policy_loss: -0.012751462903300611
        total_loss: 8.8964794476827
        vf_explained_var: 0.9816879630088806
        vf_loss: 8.907887935638428
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.96774193548387
    gpu_util_percent0: 0.2393548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7935483870967746
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523788747405599
    mean_env_wait_ms: 1.1969151479156113
    mean_inference_ms: 4.650815710239755
    mean_raw_obs_processing_ms: 0.3994453254229546
  time_since_restore: 508.44709849357605
  time_this_iter_s: 26.47348380088806
  time_total_s: 508.44709849357605
  timers:
    learn_throughput: 8297.503
    learn_time_ms: 19498.877
    sample_throughput: 23113.225
    sample_time_ms: 6999.975
    update_time_ms: 25.659
  timestamp: 1602500640
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     19 |          508.447 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3432.525217850541
    time_step_min: 3098
  date: 2020-10-12_11-04-26
  done: false
  episode_len_mean: 823.0579292267365
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.79004990931585
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 181
  episodes_total: 3815
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7609985868136088
        entropy_coeff: 0.0005000000000000001
        kl: 0.00916624628007412
        model: {}
        policy_loss: -0.012107667707217237
        total_loss: 10.657151778539022
        vf_explained_var: 0.9814252257347107
        vf_loss: 10.66780686378479
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.62
    gpu_util_percent0: 0.3993333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521991805884218
    mean_env_wait_ms: 1.1977767451158385
    mean_inference_ms: 4.638926391821517
    mean_raw_obs_processing_ms: 0.3987586788662761
  time_since_restore: 534.712043762207
  time_this_iter_s: 26.26494526863098
  time_total_s: 534.712043762207
  timers:
    learn_throughput: 8310.527
    learn_time_ms: 19468.32
    sample_throughput: 23165.882
    sample_time_ms: 6984.064
    update_time_ms: 25.726
  timestamp: 1602500666
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     20 |          534.712 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3425.473593711619
    time_step_min: 3098
  date: 2020-10-12_11-04-53
  done: false
  episode_len_mean: 821.8972920224445
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 246.80025184758034
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 284
  episodes_total: 4099
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7578712403774261
        entropy_coeff: 0.0005000000000000001
        kl: 0.0086368964985013
        model: {}
        policy_loss: -0.011422600480727851
        total_loss: 10.725571791330973
        vf_explained_var: 0.9839944839477539
        vf_loss: 10.735645691553751
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.761290322580646
    gpu_util_percent0: 0.33645161290322584
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15193798695622557
    mean_env_wait_ms: 1.1989676300864034
    mean_inference_ms: 4.622008917330003
    mean_raw_obs_processing_ms: 0.3977947303873345
  time_since_restore: 561.3735568523407
  time_this_iter_s: 26.661513090133667
  time_total_s: 561.3735568523407
  timers:
    learn_throughput: 8302.137
    learn_time_ms: 19487.995
    sample_throughput: 23182.502
    sample_time_ms: 6979.057
    update_time_ms: 25.283
  timestamp: 1602500693
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     21 |          561.374 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3421.670599339311
    time_step_min: 3098
  date: 2020-10-12_11-05-20
  done: false
  episode_len_mean: 821.5065635255509
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.35105627299706
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 4266
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7521579414606094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007824398732433716
        model: {}
        policy_loss: -0.01322558480508936
        total_loss: 7.959930698076884
        vf_explained_var: 0.9843184947967529
        vf_loss: 7.971967538197835
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.929032258064517
    gpu_util_percent0: 0.24225806451612902
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7935483870967746
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15179522713170052
    mean_env_wait_ms: 1.1995884924415834
    mean_inference_ms: 4.612889760179764
    mean_raw_obs_processing_ms: 0.3972663517974564
  time_since_restore: 587.8923697471619
  time_this_iter_s: 26.518812894821167
  time_total_s: 587.8923697471619
  timers:
    learn_throughput: 8288.691
    learn_time_ms: 19519.608
    sample_throughput: 23235.59
    sample_time_ms: 6963.111
    update_time_ms: 27.54
  timestamp: 1602500720
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     22 |          587.892 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6dc57_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3418.63762511374
    time_step_min: 3098
  date: 2020-10-12_11-05-46
  done: true
  episode_len_mean: 821.0913200723327
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.84626098233684
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: eaabf8ddae654dad83878fd4dc55a029
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.739922359585762
        entropy_coeff: 0.0005000000000000001
        kl: 0.008788479414458076
        model: {}
        policy_loss: -0.013709326779159406
        total_loss: 7.252472162246704
        vf_explained_var: 0.9847645163536072
        vf_loss: 7.264793713887532
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.986666666666665
    gpu_util_percent0: 0.4276666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52163
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15166941056392566
    mean_env_wait_ms: 1.2001324363843482
    mean_inference_ms: 4.604699596101915
    mean_raw_obs_processing_ms: 0.3967937448701103
  time_since_restore: 614.3653018474579
  time_this_iter_s: 26.47293210029602
  time_total_s: 614.3653018474579
  timers:
    learn_throughput: 8293.393
    learn_time_ms: 19508.542
    sample_throughput: 23285.641
    sample_time_ms: 6948.145
    update_time_ms: 26.961
  timestamp: 1602500746
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 6dc57_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | TERMINATED |       |     23 |          614.365 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6dc57_00000 | TERMINATED |       |     23 |          614.365 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


