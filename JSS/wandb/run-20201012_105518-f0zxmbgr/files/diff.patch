diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index d0ca168..9b1a807 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
@@ -67,14 +67,8 @@
     "            'clip_param': {\n",
     "                'values': [0.3, 0.5]\n",
     "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
-    "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
-    "            },\n",
     "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "                'values': [25, 30]\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +76,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 15,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: y2n6znmq\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\n"
      ]
     }
    ],
@@ -108,203 +102,201 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-12 10:34:03,998 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 10:34:04,420 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 10:34:04,420 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
       "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "2020-10-12 10:34:04,423 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --num_sgd_iter=25\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 10:34:09,440 - wandb.wandb_agent - INFO - Running runs: ['2deggwjd']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2deggwjd\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_103406-2deggwjd\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 10:34:10,061\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=732)\u001b[0m 2020-10-12 10:34:12,767\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=716)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=716)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=722)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=722)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=708)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=729)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=729)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=668)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=668)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=735)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=735)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=604)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=604)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=671)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=671)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=673)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=673)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=663)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=663)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=660)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=660)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=603)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=603)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=618)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=618)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=619)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=619)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=616)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=616)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=667)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=667)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=676)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=676)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=662)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=662)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=706)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=706)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=713)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=713)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_10-34-46\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,21 +304,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        entropy: 1.1850829323132832\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004093626630492508\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
+      "        policy_loss: -0.007868677183675269\n",
+      "        total_loss: 507.0761362711589\n",
       "        vf_explained_var: 0.540532648563385\n",
       "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
@@ -336,6100 +328,56 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 28.13030303030303\n",
+      "    gpu_util_percent0: 0.34545454545454546\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.566666666666667\n",
+      "    vram_util_percent0: 0.08750757824224535\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.16933092256871662\n",
+      "    mean_env_wait_ms: 1.1741114030763227\n",
+      "    mean_inference_ms: 5.667092522635582\n",
+      "    mean_raw_obs_processing_ms: 0.4496598044969888\n",
+      "  time_since_restore: 28.243332386016846\n",
+      "  time_this_iter_s: 28.243332386016846\n",
+      "  time_total_s: 28.243332386016846\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 8451.021\n",
+      "    learn_time_ms: 19144.668\n",
+      "    sample_throughput: 17931.057\n",
+      "    sample_time_ms: 9023.004\n",
+      "    update_time_ms: 32.461\n",
+      "  timestamp: 1602498886\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
-      "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
-      "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
-      "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
-      "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
-      "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
-      "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
-      "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
-      "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
-      "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
-      "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
-      "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
-      "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
-      "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
-      "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
-      "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
-      "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
-      "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
-      "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
-      "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
-      "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
-      "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
-      "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
-      "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
-      "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
-      "        vf_explained_var: 0.5664147734642029\n",
-      "        vf_loss: 502.24672444661456\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
-      "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
-      "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
-      "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
-      "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
-      "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
-      "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
-      "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
-      "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
-      "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
-      "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
-      "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
-      "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
-      "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285714\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
-      "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
-      "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
-      "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
-      "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
-      "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
-      "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
-      "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
-      "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
-      "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
-      "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
-      "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
-      "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
-      "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
-      "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
-      "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
-      "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
-      "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
-      "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
-      "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
-      "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
-      "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
-      "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
-      "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      1 |          28.2433 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent y2n6znmq"
    ]
   },
   {
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index d0ca168..cbe6aee 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
@@ -67,14 +67,8 @@
     "            'clip_param': {\n",
     "                'values': [0.3, 0.5]\n",
     "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
-    "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
-    "            },\n",
     "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "                'values': [25, 30]\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +76,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 15,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: y2n6znmq\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\n"
      ]
     }
    ],
@@ -108,203 +102,201 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-12 10:34:03,998 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 10:34:04,420 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 10:34:04,420 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
       "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "2020-10-12 10:34:04,423 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --num_sgd_iter=25\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 10:34:09,440 - wandb.wandb_agent - INFO - Running runs: ['2deggwjd']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2deggwjd\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_103406-2deggwjd\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 10:34:10,061\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=732)\u001b[0m 2020-10-12 10:34:12,767\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=716)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=716)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=722)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=722)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=708)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=729)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=729)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=668)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=668)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=735)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=735)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=604)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=604)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=671)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=671)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=673)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=673)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=663)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=663)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=660)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=660)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=603)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=603)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=618)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=618)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=619)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=619)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=616)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=616)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=667)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=667)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=676)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=676)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=662)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=662)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=706)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=706)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=713)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=713)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_10-34-46\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,21 +304,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        entropy: 1.1850829323132832\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004093626630492508\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
+      "        policy_loss: -0.007868677183675269\n",
+      "        total_loss: 507.0761362711589\n",
       "        vf_explained_var: 0.540532648563385\n",
       "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
@@ -336,65 +328,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 28.13030303030303\n",
+      "    gpu_util_percent0: 0.34545454545454546\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.566666666666667\n",
+      "    vram_util_percent0: 0.08750757824224535\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.16933092256871662\n",
+      "    mean_env_wait_ms: 1.1741114030763227\n",
+      "    mean_inference_ms: 5.667092522635582\n",
+      "    mean_raw_obs_processing_ms: 0.4496598044969888\n",
+      "  time_since_restore: 28.243332386016846\n",
+      "  time_this_iter_s: 28.243332386016846\n",
+      "  time_total_s: 28.243332386016846\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 8451.021\n",
+      "    learn_time_ms: 19144.668\n",
+      "    sample_throughput: 17931.057\n",
+      "    sample_time_ms: 9023.004\n",
+      "    update_time_ms: 32.461\n",
+      "  timestamp: 1602498886\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      1 |          28.2433 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3608.8055555555557\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_10-35-13\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 890.7056962025316\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.07793121084234\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -403,14 +395,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        entropy: 1.1567376752694447\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0070590757532045245\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.010883362002156597\n",
+      "        total_loss: 129.9215234120687\n",
+      "        vf_explained_var: 0.8072310090065002\n",
+      "        vf_loss: 129.93181800842285\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,65 +410,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 26.084374999999998\n",
+      "    gpu_util_percent0: 0.3503125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.7593750000000004\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.1649267986261869\n",
+      "    mean_env_wait_ms: 1.1701357295854296\n",
+      "    mean_inference_ms: 5.452435751356474\n",
+      "    mean_raw_obs_processing_ms: 0.4394414823862937\n",
+      "  time_since_restore: 55.3238570690155\n",
+      "  time_this_iter_s: 27.080524682998657\n",
+      "  time_total_s: 55.3238570690155\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 8423.471\n",
+      "    learn_time_ms: 19207.283\n",
+      "    sample_throughput: 19301.756\n",
+      "    sample_time_ms: 8382.242\n",
+      "    update_time_ms: 25.876\n",
+      "  timestamp: 1602498913\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      2 |          55.3239 | 323584 |  217.078 |              273.596 |              138.899 |            890.706 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3602.798206278027\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_10-35-39\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 886.1392405063291\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 218.34343434343413\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -485,14 +477,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        entropy: 1.143834412097931\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00900065409950912\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.012952111646882258\n",
+      "        total_loss: 62.266885121663414\n",
+      "        vf_explained_var: 0.8935738205909729\n",
+      "        vf_loss: 62.279051780700684\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,65 +492,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 24.68064516129032\n",
+      "    gpu_util_percent0: 0.30032258064516126\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7741935483870965\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16206126907167195\n",
+      "    mean_env_wait_ms: 1.1694681355227807\n",
+      "    mean_inference_ms: 5.281464279659669\n",
+      "    mean_raw_obs_processing_ms: 0.43116658445242273\n",
+      "  time_since_restore: 81.6922254562378\n",
+      "  time_this_iter_s: 26.36836838722229\n",
+      "  time_total_s: 81.6922254562378\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 8411.993\n",
+      "    learn_time_ms: 19233.491\n",
+      "    sample_throughput: 20490.931\n",
+      "    sample_time_ms: 7895.786\n",
+      "    update_time_ms: 31.698\n",
+      "  timestamp: 1602498939\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      3 |          81.6922 | 485376 |  218.343 |              273.596 |               137.99 |            886.139 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3596.7533112582782\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_10-36-06\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 882.5870253164557\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 219.16725802327048\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -567,14 +559,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        entropy: 1.1256821552912395\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00838832138106227\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.013208418832315752\n",
+      "        total_loss: 44.44708792368571\n",
+      "        vf_explained_var: 0.9239999651908875\n",
+      "        vf_loss: 44.45957056681315\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,65 +574,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 24.003225806451614\n",
+      "    gpu_util_percent0: 0.3496774193548387\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.16006576052477228\n",
+      "    mean_env_wait_ms: 1.1692682755662736\n",
+      "    mean_inference_ms: 5.156015909406596\n",
+      "    mean_raw_obs_processing_ms: 0.42467633120668596\n",
+      "  time_since_restore: 108.28819131851196\n",
+      "  time_this_iter_s: 26.59596586227417\n",
+      "  time_total_s: 108.28819131851196\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 8384.595\n",
+      "    learn_time_ms: 19296.341\n",
+      "    sample_throughput: 21117.84\n",
+      "    sample_time_ms: 7661.39\n",
+      "    update_time_ms: 31.674\n",
+      "  timestamp: 1602498966\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      4 |          108.288 | 647168 |  219.167 |              273.596 |               137.99 |            882.587 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3591.5629921259842\n",
+      "    time_step_min: 3242\n",
+      "  date: 2020-10-12_10-36-32\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 878.2569620253165\n",
+      "  episode_reward_max: 274.8080808080809\n",
+      "  episode_reward_mean: 220.1586753612068\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -649,14 +641,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        entropy: 1.0966354012489319\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008652650052681565\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.013121832271281164\n",
+      "        total_loss: 35.068282763163246\n",
+      "        vf_explained_var: 0.9439868927001953\n",
+      "        vf_loss: 35.080649058024086\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,65 +656,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 25.403333333333332\n",
+      "    gpu_util_percent0: 0.2933333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
+      "    ram_util_percent: 3.769999999999999\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.1586091055156298\n",
+      "    mean_env_wait_ms: 1.1701168023423736\n",
+      "    mean_inference_ms: 5.060829505330093\n",
+      "    mean_raw_obs_processing_ms: 0.41969310004805094\n",
+      "  time_since_restore: 134.52119374275208\n",
+      "  time_this_iter_s: 26.233002424240112\n",
+      "  time_total_s: 134.52119374275208\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 8384.916\n",
+      "    learn_time_ms: 19295.602\n",
+      "    sample_throughput: 21571.257\n",
+      "    sample_time_ms: 7500.351\n",
+      "    update_time_ms: 33.014\n",
+      "  timestamp: 1602498992\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      5 |          134.521 | 808960 |  220.159 |              274.808 |               137.99 |            878.257 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3575.0697674418607\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-36-59\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 868.2937443336356\n",
+      "  episode_reward_max: 283.14141414141375\n",
+      "  episode_reward_mean: 223.16600272901252\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 313\n",
+      "  episodes_total: 1103\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -731,14 +723,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        entropy: 1.0826950172583263\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008017374784685671\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.009852176726174852\n",
+      "        total_loss: 37.77317714691162\n",
+      "        vf_explained_var: 0.9565708637237549\n",
+      "        vf_loss: 37.78233687082926\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,65 +738,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 24.190322580645162\n",
+      "    gpu_util_percent0: 0.23612903225806453\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764516129032258\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15664185353614687\n",
+      "    mean_env_wait_ms: 1.1733919147808136\n",
+      "    mean_inference_ms: 4.933464734194755\n",
+      "    mean_raw_obs_processing_ms: 0.41334844709820934\n",
+      "  time_since_restore: 161.07573556900024\n",
+      "  time_this_iter_s: 26.55454182624817\n",
+      "  time_total_s: 161.07573556900024\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 8371.537\n",
+      "    learn_time_ms: 19326.439\n",
+      "    sample_throughput: 21813.622\n",
+      "    sample_time_ms: 7417.017\n",
+      "    update_time_ms: 30.93\n",
+      "  timestamp: 1602499019\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      6 |          161.076 | 970752 |  223.166 |              283.141 |               137.99 |            868.294 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3561.846278317152\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-37-26\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 862.3742088607595\n",
+      "  episode_reward_max: 283.14141414141375\n",
+      "  episode_reward_mean: 225.2731747858328\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 161\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -813,14 +805,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        entropy: 1.0706466734409332\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007869300238477686\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.013351764432930699\n",
+      "        total_loss: 18.482054869333904\n",
+      "        vf_explained_var: 0.9659532904624939\n",
+      "        vf_loss: 18.49472649892171\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,65 +820,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 24.938709677419357\n",
+      "    gpu_util_percent0: 0.3\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.15591166101973544\n",
+      "    mean_env_wait_ms: 1.1749379809941753\n",
+      "    mean_inference_ms: 4.886064883205583\n",
+      "    mean_raw_obs_processing_ms: 0.41093302096182477\n",
+      "  time_since_restore: 187.52741384506226\n",
+      "  time_this_iter_s: 26.45167827606201\n",
+      "  time_total_s: 187.52741384506226\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 8363.488\n",
+      "    learn_time_ms: 19345.04\n",
+      "    sample_throughput: 22033.156\n",
+      "    sample_time_ms: 7343.115\n",
+      "    update_time_ms: 33.276\n",
+      "  timestamp: 1602499046\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      7 |          187.527 | 1132544 |  225.273 |              283.141 |               137.99 |            862.374 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3551.647776183644\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-37-52\n",
       "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 858.2130801687764\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 227.1781954566763\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -895,14 +887,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
+      "        entropy: 1.0530053079128265\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007424288894981146\n",
       "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
+      "        policy_loss: -0.014031020080437884\n",
+      "        total_loss: 18.28844420115153\n",
+      "        vf_explained_var: 0.9650914669036865\n",
+      "        vf_loss: 18.30183744430542\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -910,65 +902,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
+      "    cpu_util_percent: 24.380645161290314\n",
+      "    gpu_util_percent0: 0.22225806451612906\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7806451612903227\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
+      "    mean_action_processing_ms: 0.15530326568095648\n",
+      "    mean_env_wait_ms: 1.1764298007735843\n",
+      "    mean_inference_ms: 4.846314058519118\n",
+      "    mean_raw_obs_processing_ms: 0.40887256534763894\n",
+      "  time_since_restore: 214.2479329109192\n",
+      "  time_this_iter_s: 26.720519065856934\n",
+      "  time_total_s: 214.2479329109192\n",
       "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
+      "    learn_throughput: 8345.973\n",
+      "    learn_time_ms: 19385.636\n",
+      "    sample_throughput: 22180.4\n",
+      "    sample_time_ms: 7294.368\n",
+      "    update_time_ms: 34.431\n",
+      "  timestamp: 1602499072\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      8 |          214.248 | 1294336 |  227.178 |              286.929 |               137.99 |            858.213 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3540.2345360824743\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-38-19\n",
       "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 854.4341772151898\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 228.90886715253788\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -977,14 +969,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
+      "        entropy: 1.0118485788504283\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007579043585186203\n",
       "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
+      "        policy_loss: -0.010258643926742176\n",
+      "        total_loss: 15.40296204884847\n",
+      "        vf_explained_var: 0.9705337882041931\n",
+      "        vf_loss: 15.412563880284628\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -992,65 +984,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
+      "    cpu_util_percent: 24.158064516129027\n",
+      "    gpu_util_percent0: 0.38258064516129037\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7741935483870965\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
+      "    mean_action_processing_ms: 0.15476785735377394\n",
+      "    mean_env_wait_ms: 1.1778500832508265\n",
+      "    mean_inference_ms: 4.811731373476194\n",
+      "    mean_raw_obs_processing_ms: 0.40699710981876513\n",
+      "  time_since_restore: 240.72339725494385\n",
+      "  time_this_iter_s: 26.475464344024658\n",
+      "  time_total_s: 240.72339725494385\n",
       "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
+      "    learn_throughput: 8342.974\n",
+      "    learn_time_ms: 19392.605\n",
+      "    sample_throughput: 22304.999\n",
+      "    sample_time_ms: 7253.621\n",
+      "    update_time_ms: 34.828\n",
+      "  timestamp: 1602499099\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      9 |          240.723 | 1456128 |  228.909 |              286.929 |               137.99 |            854.434 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3518.7373791621912\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_10-38-45\n",
       "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 847.1243386243386\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 232.65247715247702\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 310\n",
+      "  episodes_total: 1890\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1059,14 +1051,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
+      "        entropy: 0.9885825465122858\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00694818701595068\n",
       "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
+      "        policy_loss: -0.011202118165480593\n",
+      "        total_loss: 19.333553791046143\n",
+      "        vf_explained_var: 0.9741263389587402\n",
+      "        vf_loss: 19.344160079956055\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -1074,65 +1066,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
+      "    cpu_util_percent: 24.709677419354836\n",
+      "    gpu_util_percent0: 0.27290322580645165\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
+      "    ram_util_percent: 3.7677419354838704\n",
       "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
+      "    mean_action_processing_ms: 0.15392287472502042\n",
+      "    mean_env_wait_ms: 1.1807863849799112\n",
+      "    mean_inference_ms: 4.7571964111281115\n",
+      "    mean_raw_obs_processing_ms: 0.4041469352140854\n",
+      "  time_since_restore: 267.1956088542938\n",
+      "  time_this_iter_s: 26.472211599349976\n",
+      "  time_total_s: 267.1956088542938\n",
       "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
+      "    learn_throughput: 8346.803\n",
+      "    learn_time_ms: 19383.71\n",
+      "    sample_throughput: 22356.441\n",
+      "    sample_time_ms: 7236.93\n",
+      "    update_time_ms: 33.941\n",
+      "  timestamp: 1602499125\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     10 |          267.196 | 1617920 |  232.652 |              286.929 |               137.99 |            847.124 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3508.0286278381045\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_10-39-12\n",
       "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
+      "  episode_len_mean: 843.8758519961052\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 234.34446214825948\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 164\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1141,14 +1133,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
+      "        entropy: 0.9782296568155289\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0074202436953783035\n",
       "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
+      "        policy_loss: -0.011524421182305863\n",
+      "        total_loss: 11.349893887837728\n",
+      "        vf_explained_var: 0.9778836369514465\n",
+      "        vf_loss: 11.360774596532186\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -1156,65 +1148,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
+      "    cpu_util_percent: 24.56129032258064\n",
+      "    gpu_util_percent0: 0.3477419354838709\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
+      "    mean_action_processing_ms: 0.15355425518756677\n",
+      "    mean_env_wait_ms: 1.1820984902846068\n",
+      "    mean_inference_ms: 4.73331126022154\n",
+      "    mean_raw_obs_processing_ms: 0.4029051173011415\n",
+      "  time_since_restore: 293.6323890686035\n",
+      "  time_this_iter_s: 26.436780214309692\n",
+      "  time_total_s: 293.6323890686035\n",
       "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
+      "    learn_throughput: 8335.377\n",
+      "    learn_time_ms: 19410.281\n",
+      "    sample_throughput: 23016.163\n",
+      "    sample_time_ms: 7029.495\n",
+      "    update_time_ms: 32.961\n",
+      "  timestamp: 1602499152\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     11 |          293.632 | 1779712 |  234.344 |              286.929 |               137.99 |            843.876 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3497.526098901099\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_10-39-39\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 840.8141952983725\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 236.0104069629385\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1223,14 +1215,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
+      "        entropy: 0.9659954756498337\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00687529263086617\n",
       "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
+      "        policy_loss: -0.011743300943635404\n",
+      "        total_loss: 12.973399877548218\n",
+      "        vf_explained_var: 0.9719108939170837\n",
+      "        vf_loss: 12.984552383422852\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -1238,65 +1230,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
+      "    cpu_util_percent: 24.412903225806446\n",
+      "    gpu_util_percent0: 0.3206451612903226\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
+      "    mean_action_processing_ms: 0.15323285279483564\n",
+      "    mean_env_wait_ms: 1.1832804784605555\n",
+      "    mean_inference_ms: 4.712784382778184\n",
+      "    mean_raw_obs_processing_ms: 0.4018179425599785\n",
+      "  time_since_restore: 320.4737470149994\n",
+      "  time_this_iter_s: 26.841357946395874\n",
+      "  time_total_s: 320.4737470149994\n",
       "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
+      "    learn_throughput: 8319.589\n",
+      "    learn_time_ms: 19447.113\n",
+      "    sample_throughput: 23226.654\n",
+      "    sample_time_ms: 6965.79\n",
+      "    update_time_ms: 33.642\n",
+      "  timestamp: 1602499179\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     12 |          320.474 | 1941504 |   236.01 |              289.505 |               137.99 |            840.814 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3487.3178360101438\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-40-06\n",
       "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 837.5388471177945\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 237.452001215159\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 182\n",
+      "  episodes_total: 2394\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1305,14 +1297,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
+      "        entropy: 0.9220593820015589\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007104225301494201\n",
       "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
+      "        policy_loss: -0.013087665856194993\n",
+      "        total_loss: 14.173670689264933\n",
+      "        vf_explained_var: 0.976102352142334\n",
+      "        vf_loss: 14.186140378316244\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -1320,65 +1312,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
+      "    cpu_util_percent: 24.419354838709673\n",
+      "    gpu_util_percent0: 0.2954838709677419\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7774193548387096\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
+      "    mean_action_processing_ms: 0.15289814529481696\n",
+      "    mean_env_wait_ms: 1.1846964701491667\n",
+      "    mean_inference_ms: 4.691346183301928\n",
+      "    mean_raw_obs_processing_ms: 0.40064349388162007\n",
+      "  time_since_restore: 347.0233097076416\n",
+      "  time_this_iter_s: 26.549562692642212\n",
+      "  time_total_s: 347.0233097076416\n",
       "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
+      "    learn_throughput: 8314.854\n",
+      "    learn_time_ms: 19458.189\n",
+      "    sample_throughput: 23179.376\n",
+      "    sample_time_ms: 6979.998\n",
+      "    update_time_ms: 31.984\n",
+      "  timestamp: 1602499206\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     13 |          347.023 | 2103296 |  237.452 |              289.505 |               137.99 |            837.539 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3473.3540255831454\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-40-32\n",
       "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 833.4810126582279\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 239.5821054927532\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 292\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1387,14 +1379,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
+      "        entropy: 0.9201588133970896\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006468101870268583\n",
       "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
+      "        policy_loss: -0.012541183774980405\n",
+      "        total_loss: 12.514065821965536\n",
+      "        vf_explained_var: 0.980458676815033\n",
+      "        vf_loss: 12.526052554448446\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -1402,65 +1394,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
+      "    cpu_util_percent: 24.877419354838718\n",
+      "    gpu_util_percent0: 0.23096774193548392\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.770967741935483\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
+      "    mean_action_processing_ms: 0.1524375582923526\n",
+      "    mean_env_wait_ms: 1.1867413039923655\n",
+      "    mean_inference_ms: 4.662413518353599\n",
+      "    mean_raw_obs_processing_ms: 0.39911492607401206\n",
+      "  time_since_restore: 373.6990442276001\n",
+      "  time_this_iter_s: 26.675734519958496\n",
+      "  time_total_s: 373.6990442276001\n",
       "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
+      "    learn_throughput: 8311.21\n",
+      "    learn_time_ms: 19466.719\n",
+      "    sample_throughput: 23157.733\n",
+      "    sample_time_ms: 6986.522\n",
+      "    update_time_ms: 31.223\n",
+      "  timestamp: 1602499232\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     14 |          373.699 | 2265088 |  239.582 |              289.505 |               137.99 |            833.481 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3466.54296875\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-40-59\n",
       "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 831.3913502109705\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 240.64524996803468\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1469,14 +1461,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
+      "        entropy: 0.9064158648252487\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00678737946630766\n",
       "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
+      "        policy_loss: -0.012710827655003717\n",
+      "        total_loss: 10.679505268732706\n",
+      "        vf_explained_var: 0.9777107238769531\n",
+      "        vf_loss: 10.691628138224283\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -1484,65 +1476,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
+      "    cpu_util_percent: 24.619354838709675\n",
+      "    gpu_util_percent0: 0.3261290322580645\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
+      "    mean_action_processing_ms: 0.15222078204296272\n",
+      "    mean_env_wait_ms: 1.1877630325702035\n",
+      "    mean_inference_ms: 4.648666565690875\n",
+      "    mean_raw_obs_processing_ms: 0.39837897466394867\n",
+      "  time_since_restore: 400.2849922180176\n",
+      "  time_this_iter_s: 26.58594799041748\n",
+      "  time_total_s: 400.2849922180176\n",
       "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
+      "    learn_throughput: 8302.729\n",
+      "    learn_time_ms: 19486.604\n",
+      "    sample_throughput: 23107.773\n",
+      "    sample_time_ms: 7001.627\n",
+      "    update_time_ms: 29.563\n",
+      "  timestamp: 1602499259\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     15 |          400.285 | 2426880 |  240.645 |              289.505 |               137.99 |            831.391 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3459.892737054472\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-41-26\n",
       "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 830.020652898068\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 241.5691289981762\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1551,14 +1543,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
+      "        entropy: 0.8919036090373993\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065164086408913136\n",
       "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
+      "        policy_loss: -0.011898661767190788\n",
+      "        total_loss: 10.162490367889404\n",
+      "        vf_explained_var: 0.9785982966423035\n",
+      "        vf_loss: 10.173826615015665\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -1566,65 +1558,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
+      "    cpu_util_percent: 24.887096774193544\n",
+      "    gpu_util_percent0: 0.3709677419354839\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.787096774193548\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
+      "    mean_action_processing_ms: 0.15202076624090607\n",
+      "    mean_env_wait_ms: 1.1887146176559318\n",
+      "    mean_inference_ms: 4.635949922921678\n",
+      "    mean_raw_obs_processing_ms: 0.39768803533396757\n",
+      "  time_since_restore: 426.76628279685974\n",
+      "  time_this_iter_s: 26.481290578842163\n",
+      "  time_total_s: 426.76628279685974\n",
       "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
+      "    learn_throughput: 8309.412\n",
+      "    learn_time_ms: 19470.933\n",
+      "    sample_throughput: 23085.494\n",
+      "    sample_time_ms: 7008.384\n",
+      "    update_time_ms: 29.45\n",
+      "  timestamp: 1602499286\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     16 |          426.766 | 2588672 |  241.569 |              289.505 |               137.99 |            830.021 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3451.432941903585\n",
+      "    time_step_min: 3158\n",
+      "  date: 2020-10-12_10-41-52\n",
       "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 827.9087009803922\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 242.70980020796188\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 262\n",
+      "  episodes_total: 3264\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1633,14 +1625,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
+      "        entropy: 0.8572876205046972\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006706862438780566\n",
       "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
+      "        policy_loss: -0.011741302907466888\n",
+      "        total_loss: 15.199506441752115\n",
+      "        vf_explained_var: 0.97942715883255\n",
+      "        vf_loss: 15.210662841796875\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -1648,65 +1640,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
+      "    cpu_util_percent: 24.719354838709684\n",
+      "    gpu_util_percent0: 0.32548387096774195\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7612903225806447\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
+      "    mean_action_processing_ms: 0.15172864965332547\n",
+      "    mean_env_wait_ms: 1.1902196110419858\n",
+      "    mean_inference_ms: 4.617188440695888\n",
+      "    mean_raw_obs_processing_ms: 0.3966868085580042\n",
+      "  time_since_restore: 453.4419045448303\n",
+      "  time_this_iter_s: 26.67562174797058\n",
+      "  time_total_s: 453.4419045448303\n",
       "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
+      "    learn_throughput: 8310.197\n",
+      "    learn_time_ms: 19469.093\n",
+      "    sample_throughput: 23005.301\n",
+      "    sample_time_ms: 7032.814\n",
+      "    update_time_ms: 28.266\n",
+      "  timestamp: 1602499312\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     17 |          453.442 | 2750464 |   242.71 |              289.505 |               137.99 |            827.909 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3445.4002320185614\n",
+      "    time_step_min: 3146\n",
+      "  date: 2020-10-12_10-42-19\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 826.5290563866513\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 243.6558072090292\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 212\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1715,14 +1707,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
+      "        entropy: 0.8529605269432068\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005917649987774591\n",
       "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
+      "        policy_loss: -0.011277009830034027\n",
+      "        total_loss: 11.547587235768637\n",
+      "        vf_explained_var: 0.9794904589653015\n",
+      "        vf_loss: 11.558358192443848\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -1730,65 +1722,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
+      "    cpu_util_percent: 24.622580645161293\n",
+      "    gpu_util_percent0: 0.407741935483871\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
+      "    mean_action_processing_ms: 0.15151245459591453\n",
+      "    mean_env_wait_ms: 1.191304723107444\n",
+      "    mean_inference_ms: 4.603265801752061\n",
+      "    mean_raw_obs_processing_ms: 0.39595422067554054\n",
+      "  time_since_restore: 479.8950695991516\n",
+      "  time_this_iter_s: 26.45316505432129\n",
+      "  time_total_s: 479.8950695991516\n",
       "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
+      "    learn_throughput: 8321.629\n",
+      "    learn_time_ms: 19442.346\n",
+      "    sample_throughput: 23005.85\n",
+      "    sample_time_ms: 7032.646\n",
+      "    update_time_ms: 28.083\n",
+      "  timestamp: 1602499339\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     18 |          479.895 | 2912256 |  243.656 |              289.505 |               137.99 |            826.529 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3440.769828064337\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-42-46\n",
       "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
+      "  episode_len_mean: 825.8247110621904\n",
+      "  episode_reward_max: 294.80808080808083\n",
+      "  episode_reward_mean: 244.29612303552858\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1797,14 +1789,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
+      "        entropy: 0.8457075009743372\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065199139062315226\n",
       "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
+      "        policy_loss: -0.01116289470034341\n",
+      "        total_loss: 10.043978214263916\n",
+      "        vf_explained_var: 0.9801807403564453\n",
+      "        vf_loss: 10.05457361539205\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -1812,65 +1804,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    cpu_util_percent: 24.23548387096774\n",
+      "    gpu_util_percent0: 0.29129032258064513\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7806451612903222\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
+      "    mean_action_processing_ms: 0.1513673572672517\n",
+      "    mean_env_wait_ms: 1.1920175917054816\n",
+      "    mean_inference_ms: 4.593864716977697\n",
+      "    mean_raw_obs_processing_ms: 0.39545767616024086\n",
+      "  time_since_restore: 506.6568546295166\n",
+      "  time_this_iter_s: 26.76178503036499\n",
+      "  time_total_s: 506.6568546295166\n",
       "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
+      "    learn_throughput: 8311.575\n",
+      "    learn_time_ms: 19465.865\n",
+      "    sample_throughput: 22990.042\n",
+      "    sample_time_ms: 7037.482\n",
+      "    update_time_ms: 28.491\n",
+      "  timestamp: 1602499366\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     19 |          506.657 | 3074048 |  244.296 |              294.808 |               137.99 |            825.825 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3436.3805732484075\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-43-12\n",
       "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 825.2513171759747\n",
+      "  episode_reward_max: 294.80808080808083\n",
+      "  episode_reward_mean: 244.92866228140193\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 162\n",
+      "  episodes_total: 3796\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1879,14 +1871,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
+      "        entropy: 0.8178661465644836\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006614145318356653\n",
       "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
+      "        policy_loss: -0.012304873768395433\n",
+      "        total_loss: 9.505411148071289\n",
+      "        vf_explained_var: 0.9820902943611145\n",
+      "        vf_loss: 9.517136255900065\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -1894,65 +1886,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
+      "    cpu_util_percent: 24.777419354838703\n",
+      "    gpu_util_percent0: 0.3029032258064516\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.774193548387097\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
+      "    mean_action_processing_ms: 0.15122639986088446\n",
+      "    mean_env_wait_ms: 1.1926882058948682\n",
+      "    mean_inference_ms: 4.584833213203808\n",
+      "    mean_raw_obs_processing_ms: 0.3949704778072739\n",
+      "  time_since_restore: 533.0624232292175\n",
+      "  time_this_iter_s: 26.405568599700928\n",
+      "  time_total_s: 533.0624232292175\n",
       "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
+      "    learn_throughput: 8310.33\n",
+      "    learn_time_ms: 19468.781\n",
+      "    sample_throughput: 23027.336\n",
+      "    sample_time_ms: 7026.084\n",
+      "    update_time_ms: 29.68\n",
+      "  timestamp: 1602499392\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     20 |          533.062 | 3235840 |  244.929 |              294.808 |               137.99 |            825.251 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3430.280848963475\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-43-39\n",
       "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.5730392156863\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 245.9245023767082\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4080\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1961,14 +1953,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
+      "        entropy: 0.7949359466632208\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005695687839761376\n",
       "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
+      "        policy_loss: -0.010721294248166183\n",
+      "        total_loss: 15.119903961817423\n",
+      "        vf_explained_var: 0.9795476794242859\n",
+      "        vf_loss: 15.13013505935669\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -1976,65 +1968,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
+      "    cpu_util_percent: 24.409677419354836\n",
+      "    gpu_util_percent0: 0.41064516129032247\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7612903225806447\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
+      "    mean_action_processing_ms: 0.15100422673970484\n",
+      "    mean_env_wait_ms: 1.1937338300371503\n",
+      "    mean_inference_ms: 4.57043850055062\n",
+      "    mean_raw_obs_processing_ms: 0.39420999465212736\n",
+      "  time_since_restore: 559.6542797088623\n",
+      "  time_this_iter_s: 26.591856479644775\n",
+      "  time_total_s: 559.6542797088623\n",
       "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
+      "    learn_throughput: 8309.624\n",
+      "    learn_time_ms: 19470.435\n",
+      "    sample_throughput: 22984.662\n",
+      "    sample_time_ms: 7039.129\n",
+      "    update_time_ms: 29.704\n",
+      "  timestamp: 1602499419\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     21 |          559.654 | 3397632 |  245.925 |              297.687 |               137.99 |            824.573 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3425.592968381312\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-44-06\n",
       "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.3506797937177\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 246.62825157339924\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 186\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2043,14 +2035,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
+      "        entropy: 0.7829316059748331\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006042617450778683\n",
       "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
+      "        policy_loss: -0.012270252065112194\n",
+      "        total_loss: 7.568831443786621\n",
+      "        vf_explained_var: 0.9859895706176758\n",
+      "        vf_loss: 7.580575466156006\n",
       "    num_steps_sampled: 3559424\n",
       "    num_steps_trained: 3559424\n",
       "  iterations_since_restore: 22\n",
@@ -2058,65 +2050,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
+      "    cpu_util_percent: 24.18125\n",
+      "    gpu_util_percent0: 0.234375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7843750000000003\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
+      "    mean_action_processing_ms: 0.1508696818648715\n",
+      "    mean_env_wait_ms: 1.1943520393111597\n",
+      "    mean_inference_ms: 4.5617273912222736\n",
+      "    mean_raw_obs_processing_ms: 0.3937429550222564\n",
+      "  time_since_restore: 586.5587210655212\n",
+      "  time_this_iter_s: 26.904441356658936\n",
+      "  time_total_s: 586.5587210655212\n",
       "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
+      "    learn_throughput: 8309.025\n",
+      "    learn_time_ms: 19471.84\n",
+      "    sample_throughput: 22972.149\n",
+      "    sample_time_ms: 7042.963\n",
+      "    update_time_ms: 31.012\n",
+      "  timestamp: 1602499446\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3559424\n",
       "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     22 |          586.559 | 3559424 |  246.628 |              297.687 |               137.99 |            824.351 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3422.125568698817\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-44-33\n",
+      "  done: true\n",
+      "  episode_len_mean: 823.993444846293\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 247.1778681936909\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2125,14 +2117,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
+      "        entropy: 0.7830241670211157\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005572947518279155\n",
       "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
+      "        policy_loss: -0.008857697199952478\n",
+      "        total_loss: 9.253699541091919\n",
+      "        vf_explained_var: 0.9810841679573059\n",
+      "        vf_loss: 9.262078205744425\n",
       "    num_steps_sampled: 3721216\n",
       "    num_steps_trained: 3721216\n",
       "  iterations_since_restore: 23\n",
@@ -2140,164 +2132,82 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
+      "    cpu_util_percent: 24.612903225806452\n",
+      "    gpu_util_percent0: 0.3764516129032258\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
+      "    mean_action_processing_ms: 0.1507628397075941\n",
+      "    mean_env_wait_ms: 1.1948203537338653\n",
+      "    mean_inference_ms: 4.554879763789217\n",
+      "    mean_raw_obs_processing_ms: 0.3933762180280804\n",
+      "  time_since_restore: 613.339967250824\n",
+      "  time_this_iter_s: 26.781246185302734\n",
+      "  time_total_s: 613.339967250824\n",
       "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
+      "    learn_throughput: 8307.761\n",
+      "    learn_time_ms: 19474.802\n",
+      "    sample_throughput: 22910.952\n",
+      "    sample_time_ms: 7061.775\n",
+      "    update_time_ms: 32.075\n",
+      "  timestamp: 1602499473\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3721216\n",
       "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
-      "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
+      "| PPO_jss_env_7762f_00000 | TERMINATED |       |     23 |           613.34 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
+      "| PPO_jss_env_7762f_00000 | TERMINATED |       |     23 |           613.34 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 488\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_103406-2deggwjd/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_103406-2deggwjd/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3110\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 627\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602499473\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4145\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3422.12557\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 297.68687\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 137.9899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.17787\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
@@ -2313,204 +2223,202 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mchocolate-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2deggwjd\u001b[0m\n",
+      "2020-10-12 10:44:45,312 - wandb.wandb_agent - INFO - Cleaning up finished run: 2deggwjd\n",
+      "2020-10-12 10:44:45,804 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 10:44:45,804 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
       "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
+      "2020-10-12 10:44:45,807 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --num_sgd_iter=30\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
+      "2020-10-12 10:44:50,823 - wandb.wandb_agent - INFO - Running runs: ['zrncloep']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-sweep-2\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zrncloep\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_104447-zrncloep\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 10:44:51,511\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "\u001b[2m\u001b[36m(pid=27951)\u001b[0m 2020-10-12 10:44:54,244\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=27941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27897)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27897)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27933)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27933)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27911)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27911)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27922)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27922)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27931)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27931)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27912)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27912)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27939)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27939)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27935)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27935)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27918)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27918)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27946)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27946)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27920)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27920)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27945)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27945)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27924)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27924)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27926)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27926)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27921)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27921)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27938)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27938)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
+      "  date: 2020-10-12_10-45-32\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -2518,21 +2426,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
+      "        entropy: 1.1846147278944652\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
+      "        kl: 0.004924804321490228\n",
       "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
+      "        policy_loss: -0.010641525208484381\n",
+      "        total_loss: 502.23648834228516\n",
       "        vf_explained_var: 0.5664147734642029\n",
       "        vf_loss: 502.24672444661456\n",
       "    num_steps_sampled: 161792\n",
@@ -2542,65 +2450,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
+      "    cpu_util_percent: 25.06578947368421\n",
+      "    gpu_util_percent0: 0.23210526315789473\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
+      "    ram_util_percent: 3.581578947368421\n",
+      "    vram_util_percent0: 0.08847163004263696\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
+      "    mean_action_processing_ms: 0.1715364924328089\n",
+      "    mean_env_wait_ms: 1.1764125023111955\n",
+      "    mean_inference_ms: 6.053061519150528\n",
+      "    mean_raw_obs_processing_ms: 0.4638343403537392\n",
+      "  time_since_restore: 32.95468473434448\n",
+      "  time_this_iter_s: 32.95468473434448\n",
+      "  time_total_s: 32.95468473434448\n",
       "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
+      "    learn_throughput: 6948.182\n",
+      "    learn_time_ms: 23285.516\n",
+      "    sample_throughput: 16871.285\n",
+      "    sample_time_ms: 9589.785\n",
+      "    update_time_ms: 44.906\n",
+      "  timestamp: 1602499532\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 27.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      1 |          32.9547 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
+      "    time_step_max: 4185\n",
+      "    time_step_mean: 3622.6423611111113\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-12_10-46-03\n",
       "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
+      "  episode_len_mean: 890.2246835443038\n",
+      "  episode_reward_max: 262.6868686868683\n",
+      "  episode_reward_mean: 216.1472637770104\n",
+      "  episode_reward_min: 131.9292929292925\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2609,14 +2517,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
+      "        entropy: 1.1507324576377869\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
+      "        kl: 0.007903704070486128\n",
       "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
+      "        policy_loss: -0.010593259202626845\n",
+      "        total_loss: 127.33559099833171\n",
+      "        vf_explained_var: 0.8138229846954346\n",
+      "        vf_loss: 127.34597078959148\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -2624,65 +2532,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
+      "    cpu_util_percent: 23.180555555555557\n",
+      "    gpu_util_percent0: 0.26916666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
+      "    ram_util_percent: 3.766666666666668\n",
       "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
+      "    mean_action_processing_ms: 0.16686884579590536\n",
+      "    mean_env_wait_ms: 1.1726176230359397\n",
+      "    mean_inference_ms: 5.762905636344878\n",
+      "    mean_raw_obs_processing_ms: 0.4520184496332657\n",
+      "  time_since_restore: 63.70615220069885\n",
+      "  time_this_iter_s: 30.75146746635437\n",
+      "  time_total_s: 63.70615220069885\n",
       "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
+      "    learn_throughput: 7022.83\n",
+      "    learn_time_ms: 23038.005\n",
+      "    sample_throughput: 18514.195\n",
+      "    sample_time_ms: 8738.808\n",
+      "    update_time_ms: 35.829\n",
+      "  timestamp: 1602499563\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      2 |          63.7062 | 323584 |  216.147 |              262.687 |              131.929 |            890.225 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
+      "    time_step_max: 4185\n",
+      "    time_step_mean: 3625.3340807174886\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-12_10-46-33\n",
       "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 885.3924050632911\n",
+      "  episode_reward_max: 262.6868686868683\n",
+      "  episode_reward_mean: 216.5537015726887\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2691,14 +2599,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
+      "        entropy: 1.1411346793174744\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
+      "        kl: 0.009678286267444491\n",
       "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
+      "        policy_loss: -0.014822538554047545\n",
+      "        total_loss: 59.26638380686442\n",
+      "        vf_explained_var: 0.9010727405548096\n",
+      "        vf_loss: 59.28081130981445\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -2706,65 +2614,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
+      "    cpu_util_percent: 22.72285714285714\n",
+      "    gpu_util_percent0: 0.278\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7771428571428576\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
+      "    mean_action_processing_ms: 0.16389218629932192\n",
+      "    mean_env_wait_ms: 1.1723028183524362\n",
+      "    mean_inference_ms: 5.549334093675588\n",
+      "    mean_raw_obs_processing_ms: 0.44287348924922826\n",
+      "  time_since_restore: 93.79876685142517\n",
+      "  time_this_iter_s: 30.09261465072632\n",
+      "  time_total_s: 93.79876685142517\n",
       "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
+      "    learn_throughput: 7048.038\n",
+      "    learn_time_ms: 22955.609\n",
+      "    sample_throughput: 19641.219\n",
+      "    sample_time_ms: 8237.371\n",
+      "    update_time_ms: 31.797\n",
+      "  timestamp: 1602499593\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      3 |          93.7988 | 485376 |  216.554 |              262.687 |               88.596 |            885.392 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
+      "    time_step_max: 4214\n",
+      "    time_step_mean: 3625.890728476821\n",
+      "    time_step_min: 3319\n",
+      "  date: 2020-10-12_10-47-03\n",
       "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 881.0474683544304\n",
+      "  episode_reward_max: 263.1414141414135\n",
+      "  episode_reward_mean: 216.6672580232705\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2773,14 +2681,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
+      "        entropy: 1.1199288368225098\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
+      "        kl: 0.008813565596938133\n",
       "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
+      "        policy_loss: -0.01598833860286201\n",
+      "        total_loss: 43.194626808166504\n",
+      "        vf_explained_var: 0.9295213222503662\n",
+      "        vf_loss: 43.21029249827067\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -2788,65 +2696,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
+      "    cpu_util_percent: 21.75277777777778\n",
+      "    gpu_util_percent0: 0.2755555555555556\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.775000000000001\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
+      "    mean_action_processing_ms: 0.16171133782142091\n",
+      "    mean_env_wait_ms: 1.172442399851389\n",
+      "    mean_inference_ms: 5.393240447801279\n",
+      "    mean_raw_obs_processing_ms: 0.43569823102312366\n",
+      "  time_since_restore: 124.19757580757141\n",
+      "  time_this_iter_s: 30.39880895614624\n",
+      "  time_total_s: 124.19757580757141\n",
       "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
+      "    learn_throughput: 7029.44\n",
+      "    learn_time_ms: 23016.343\n",
+      "    sample_throughput: 20329.92\n",
+      "    sample_time_ms: 7958.32\n",
+      "    update_time_ms: 32.048\n",
+      "  timestamp: 1602499623\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      4 |          124.198 | 647168 |  216.667 |              263.141 |               88.596 |            881.047 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
+      "    time_step_max: 4270\n",
+      "    time_step_mean: 3617.989501312336\n",
+      "    time_step_min: 3319\n",
+      "  date: 2020-10-12_10-47-34\n",
       "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 876.6645569620254\n",
+      "  episode_reward_max: 266.4747474747477\n",
+      "  episode_reward_mean: 217.92468993734798\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2855,14 +2763,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
+      "        entropy: 1.0852691729863484\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
+      "        kl: 0.008571949942658344\n",
       "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
+      "        policy_loss: -0.015522021086023111\n",
+      "        total_loss: 32.49041668574015\n",
+      "        vf_explained_var: 0.9495692253112793\n",
+      "        vf_loss: 32.50562445322672\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -2870,65 +2778,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
+      "    cpu_util_percent: 22.04857142857143\n",
+      "    gpu_util_percent0: 0.28485714285714286\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.782857142857143\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
+      "    mean_action_processing_ms: 0.16012965724921266\n",
+      "    mean_env_wait_ms: 1.1736239690286292\n",
+      "    mean_inference_ms: 5.2755181225819605\n",
+      "    mean_raw_obs_processing_ms: 0.42999393542261516\n",
+      "  time_since_restore: 154.43998551368713\n",
+      "  time_this_iter_s: 30.242409706115723\n",
+      "  time_total_s: 154.43998551368713\n",
       "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
+      "    learn_throughput: 7022.643\n",
+      "    learn_time_ms: 23038.62\n",
+      "    sample_throughput: 20815.054\n",
+      "    sample_time_ms: 7772.836\n",
+      "    update_time_ms: 32.127\n",
+      "  timestamp: 1602499654\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      5 |           154.44 | 808960 |  217.925 |              266.475 |               88.596 |            876.665 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3598.4014869888474\n",
+      "    time_step_min: 3287\n",
+      "  date: 2020-10-12_10-48-04\n",
       "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 867.0471014492754\n",
+      "  episode_reward_max: 267.98989898989913\n",
+      "  episode_reward_mean: 220.5384826526129\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 314\n",
+      "  episodes_total: 1104\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2937,14 +2845,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
+      "        entropy: 1.0762771268685658\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
+      "        kl: 0.00847935164347291\n",
       "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
+      "        policy_loss: -0.014069491167902015\n",
+      "        total_loss: 36.22017447153727\n",
+      "        vf_explained_var: 0.9600384831428528\n",
+      "        vf_loss: 36.23393313090006\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -2952,65 +2860,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
+      "    cpu_util_percent: 22.274285714285714\n",
+      "    gpu_util_percent0: 0.35999999999999993\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
+      "    ram_util_percent: 3.7771428571428576\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
+      "    mean_action_processing_ms: 0.157985195797773\n",
+      "    mean_env_wait_ms: 1.176888885605026\n",
+      "    mean_inference_ms: 5.117378266251005\n",
+      "    mean_raw_obs_processing_ms: 0.4225404292097058\n",
+      "  time_since_restore: 184.78620219230652\n",
+      "  time_this_iter_s: 30.346216678619385\n",
+      "  time_total_s: 184.78620219230652\n",
       "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
+      "    learn_throughput: 7013.777\n",
+      "    learn_time_ms: 23067.743\n",
+      "    sample_throughput: 21143.968\n",
+      "    sample_time_ms: 7651.922\n",
+      "    update_time_ms: 32.739\n",
+      "  timestamp: 1602499684\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      6 |          184.786 | 970752 |  220.538 |               267.99 |               88.596 |            867.047 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3586.6108414239484\n",
+      "    time_step_min: 3287\n",
+      "  date: 2020-10-12_10-48-35\n",
       "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 862.6424050632911\n",
+      "  episode_reward_max: 272.53535353535324\n",
+      "  episode_reward_mean: 222.52336657716384\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 160\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3019,14 +2927,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
+      "        entropy: 1.0611263513565063\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
+      "        kl: 0.00855419528670609\n",
       "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
+      "        policy_loss: -0.01313585601747036\n",
+      "        total_loss: 17.229157129923504\n",
+      "        vf_explained_var: 0.9695212244987488\n",
+      "        vf_loss: 17.24196783701579\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -3034,65 +2942,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
+      "    cpu_util_percent: 21.344444444444445\n",
+      "    gpu_util_percent0: 0.3055555555555556\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
+      "    ram_util_percent: 3.7805555555555554\n",
       "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
+      "    mean_action_processing_ms: 0.15721883999003455\n",
+      "    mean_env_wait_ms: 1.1784417316102376\n",
+      "    mean_inference_ms: 5.059418580537698\n",
+      "    mean_raw_obs_processing_ms: 0.41974201605546413\n",
+      "  time_since_restore: 215.12676668167114\n",
+      "  time_this_iter_s: 30.340564489364624\n",
+      "  time_total_s: 215.12676668167114\n",
       "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
+      "    learn_throughput: 7013.954\n",
+      "    learn_time_ms: 23067.159\n",
+      "    sample_throughput: 21358.13\n",
+      "    sample_time_ms: 7575.195\n",
+      "    update_time_ms: 33.358\n",
+      "  timestamp: 1602499715\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      7 |          215.127 | 1132544 |  222.523 |              272.535 |               88.596 |            862.642 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3574.7453371592537\n",
+      "    time_step_min: 3224\n",
+      "  date: 2020-10-12_10-49-05\n",
       "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 858.2257383966245\n",
+      "  episode_reward_max: 277.5353535353528\n",
+      "  episode_reward_mean: 224.2597707028085\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3101,14 +3009,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
+      "        entropy: 1.0459068516890209\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
+      "        kl: 0.007586693585229416\n",
       "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
+      "        policy_loss: -0.01487944574910216\n",
+      "        total_loss: 17.728309154510498\n",
+      "        vf_explained_var: 0.9674603343009949\n",
+      "        vf_loss: 17.742952823638916\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -3116,65 +3024,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
+      "    cpu_util_percent: 22.362857142857145\n",
+      "    gpu_util_percent0: 0.3745714285714286\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
+      "    ram_util_percent: 3.7857142857142865\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
+      "    mean_action_processing_ms: 0.15656386820306947\n",
+      "    mean_env_wait_ms: 1.1799183178085746\n",
+      "    mean_inference_ms: 5.009826195708607\n",
+      "    mean_raw_obs_processing_ms: 0.41727490601484446\n",
+      "  time_since_restore: 245.46431922912598\n",
+      "  time_this_iter_s: 30.337552547454834\n",
+      "  time_total_s: 245.46431922912598\n",
       "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
+      "    learn_throughput: 7013.118\n",
+      "    learn_time_ms: 23069.91\n",
+      "    sample_throughput: 21502.897\n",
+      "    sample_time_ms: 7524.195\n",
+      "    update_time_ms: 33.171\n",
+      "  timestamp: 1602499745\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      8 |          245.464 | 1294336 |   224.26 |              277.535 |               88.596 |            858.226 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3562.860824742268\n",
+      "    time_step_min: 3224\n",
+      "  date: 2020-10-12_10-49-35\n",
       "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 854.1151898734178\n",
+      "  episode_reward_max: 277.5353535353528\n",
+      "  episode_reward_mean: 226.03343562204307\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3183,14 +3091,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
+      "        entropy: 1.009189561009407\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
+      "        kl: 0.008226582664065063\n",
       "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
+      "        policy_loss: -0.015366594326527169\n",
+      "        total_loss: 15.938408533732096\n",
+      "        vf_explained_var: 0.9702828526496887\n",
+      "        vf_loss: 15.953457037607828\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -3198,65 +3106,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
+      "    cpu_util_percent: 22.262857142857147\n",
+      "    gpu_util_percent0: 0.32799999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.774285714285715\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
+      "    mean_action_processing_ms: 0.15599313435917495\n",
+      "    mean_env_wait_ms: 1.1813674882165615\n",
+      "    mean_inference_ms: 4.966630800288264\n",
+      "    mean_raw_obs_processing_ms: 0.41506544527338496\n",
+      "  time_since_restore: 275.5794014930725\n",
+      "  time_this_iter_s: 30.115082263946533\n",
+      "  time_total_s: 275.5794014930725\n",
       "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
+      "    learn_throughput: 7017.998\n",
+      "    learn_time_ms: 23053.868\n",
+      "    sample_throughput: 21639.369\n",
+      "    sample_time_ms: 7476.743\n",
+      "    update_time_ms: 32.887\n",
+      "  timestamp: 1602499775\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      9 |          275.579 | 1456128 |  226.033 |              277.535 |               88.596 |            854.115 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3538.880580957504\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-50-06\n",
       "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 847.3190249072602\n",
+      "  episode_reward_max: 280.2626262626269\n",
+      "  episode_reward_mean: 229.68314303608406\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1887\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3265,14 +3173,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
+      "        entropy: 0.9917601197957993\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
+      "        kl: 0.00740070086127768\n",
       "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
+      "        policy_loss: -0.013341124024009332\n",
+      "        total_loss: 19.074730396270752\n",
+      "        vf_explained_var: 0.9753614068031311\n",
+      "        vf_loss: 19.08782688776652\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -3280,65 +3188,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
+      "    cpu_util_percent: 21.191666666666663\n",
+      "    gpu_util_percent0: 0.30111111111111105\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
+      "    ram_util_percent: 3.7722222222222226\n",
       "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
+      "    mean_action_processing_ms: 0.1550921774885076\n",
+      "    mean_env_wait_ms: 1.1841642257143155\n",
+      "    mean_inference_ms: 4.898659841728468\n",
+      "    mean_raw_obs_processing_ms: 0.4116808708719114\n",
+      "  time_since_restore: 305.95650362968445\n",
+      "  time_this_iter_s: 30.37710213661194\n",
+      "  time_total_s: 305.95650362968445\n",
       "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
+      "    learn_throughput: 7015.346\n",
+      "    learn_time_ms: 23062.584\n",
+      "    sample_throughput: 21757.544\n",
+      "    sample_time_ms: 7436.133\n",
+      "    update_time_ms: 33.038\n",
+      "  timestamp: 1602499806\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     10 |          305.957 | 1617920 |  229.683 |              280.263 |               88.596 |            847.319 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3528.9536031589337\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-50-36\n",
       "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
+      "  episode_len_mean: 844.2448880233691\n",
+      "  episode_reward_max: 280.2626262626269\n",
+      "  episode_reward_mean: 231.221140322406\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 167\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3347,14 +3255,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
+      "        entropy: 0.9727244724829992\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
+      "        kl: 0.0071904356591403484\n",
       "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
+      "        policy_loss: -0.014005071396240965\n",
+      "        total_loss: 11.84699296951294\n",
+      "        vf_explained_var: 0.9785725474357605\n",
+      "        vf_loss: 11.860765298207602\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -3362,65 +3270,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
+      "    cpu_util_percent: 21.597142857142856\n",
+      "    gpu_util_percent0: 0.3817142857142857\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
+      "    ram_util_percent: 3.788571428571429\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
+      "    mean_action_processing_ms: 0.15469427227659796\n",
+      "    mean_env_wait_ms: 1.1855035444070465\n",
+      "    mean_inference_ms: 4.868324146809752\n",
+      "    mean_raw_obs_processing_ms: 0.410149660829387\n",
+      "  time_since_restore: 336.20317029953003\n",
+      "  time_this_iter_s: 30.24666666984558\n",
+      "  time_total_s: 336.20317029953003\n",
       "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
+      "    learn_throughput: 7024.762\n",
+      "    learn_time_ms: 23031.671\n",
+      "    sample_throughput: 22484.123\n",
+      "    sample_time_ms: 7195.833\n",
+      "    update_time_ms: 31.936\n",
+      "  timestamp: 1602499836\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     11 |          336.203 | 1779712 |  231.221 |              280.263 |               88.596 |            844.245 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3520.5668498168498\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-51-06\n",
       "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 841.4041591320072\n",
+      "  episode_reward_max: 280.2626262626269\n",
+      "  episode_reward_mean: 232.48480282024573\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3429,14 +3337,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
+      "        entropy: 0.9606796552737554\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
+      "        kl: 0.007471592941631873\n",
       "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
+      "        policy_loss: -0.015197008498944342\n",
+      "        total_loss: 13.117705742518107\n",
+      "        vf_explained_var: 0.9743028283119202\n",
+      "        vf_loss: 13.132635911305746\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -3444,65 +3352,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
+      "    cpu_util_percent: 21.165714285714287\n",
+      "    gpu_util_percent0: 0.3628571428571429\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
       "    ram_util_percent: 3.782857142857143\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
+      "    mean_action_processing_ms: 0.15435514340299025\n",
+      "    mean_env_wait_ms: 1.186665990444814\n",
+      "    mean_inference_ms: 4.842549195167609\n",
+      "    mean_raw_obs_processing_ms: 0.4087971802318489\n",
+      "  time_since_restore: 366.355286359787\n",
+      "  time_this_iter_s: 30.152116060256958\n",
+      "  time_total_s: 366.355286359787\n",
       "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
+      "    learn_throughput: 7018.363\n",
+      "    learn_time_ms: 23052.67\n",
+      "    sample_throughput: 22740.933\n",
+      "    sample_time_ms: 7114.572\n",
+      "    update_time_ms: 31.556\n",
+      "  timestamp: 1602499866\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     12 |          366.355 | 1941504 |  232.485 |              280.263 |               88.596 |            841.404 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3511.8174872665536\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-51-37\n",
       "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 838.8875838926175\n",
+      "  episode_reward_max: 284.20202020202026\n",
+      "  episode_reward_mean: 233.88233848552625\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 172\n",
+      "  episodes_total: 2384\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3511,14 +3419,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
+      "        entropy: 0.9221795598665873\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
+      "        kl: 0.007596092570262651\n",
       "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
+      "        policy_loss: -0.015219444719453653\n",
+      "        total_loss: 13.35711113611857\n",
+      "        vf_explained_var: 0.977639377117157\n",
+      "        vf_loss: 13.372032086054483\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -3526,65 +3434,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
+      "    cpu_util_percent: 21.697142857142858\n",
+      "    gpu_util_percent0: 0.29714285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7800000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
+      "    mean_action_processing_ms: 0.15402548836072014\n",
+      "    mean_env_wait_ms: 1.187927580487614\n",
+      "    mean_inference_ms: 4.817554249564923\n",
+      "    mean_raw_obs_processing_ms: 0.40744852108449703\n",
+      "  time_since_restore: 396.4389011859894\n",
+      "  time_this_iter_s: 30.083614826202393\n",
+      "  time_total_s: 396.4389011859894\n",
       "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
+      "    learn_throughput: 7011.034\n",
+      "    learn_time_ms: 23076.768\n",
+      "    sample_throughput: 22827.071\n",
+      "    sample_time_ms: 7087.725\n",
+      "    update_time_ms: 32.421\n",
+      "  timestamp: 1602499897\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     13 |          396.439 | 2103296 |  233.882 |              284.202 |               88.596 |            838.888 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3498.1188863807374\n",
+      "    time_step_min: 3188\n",
+      "  date: 2020-10-12_10-52-07\n",
       "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 834.5979151154132\n",
+      "  episode_reward_max: 284.20202020202026\n",
+      "  episode_reward_mean: 235.96700813044805\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 302\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3593,14 +3501,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
+      "        entropy: 0.9214861939350764\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
+      "        kl: 0.0071946926570187015\n",
       "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
+      "        policy_loss: -0.013351308540829146\n",
+      "        total_loss: 14.835413376490274\n",
+      "        vf_explained_var: 0.979828417301178\n",
+      "        vf_loss: 14.848505894343058\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -3608,65 +3516,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
+      "    cpu_util_percent: 21.805714285714288\n",
+      "    gpu_util_percent0: 0.36428571428571427\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
       "    ram_util_percent: 3.7714285714285714\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
+      "    mean_action_processing_ms: 0.15351155806648764\n",
+      "    mean_env_wait_ms: 1.190011853534101\n",
+      "    mean_inference_ms: 4.778664218564182\n",
+      "    mean_raw_obs_processing_ms: 0.405442385544107\n",
+      "  time_since_restore: 426.4023401737213\n",
+      "  time_this_iter_s: 29.963438987731934\n",
+      "  time_total_s: 426.4023401737213\n",
       "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
+      "    learn_throughput: 7017.406\n",
+      "    learn_time_ms: 23055.812\n",
+      "    sample_throughput: 22903.105\n",
+      "    sample_time_ms: 7064.195\n",
+      "    update_time_ms: 32.756\n",
+      "  timestamp: 1602499927\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     14 |          426.402 | 2265088 |  235.967 |              284.202 |               88.596 |            834.598 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3491.8394886363635\n",
+      "    time_step_min: 3188\n",
+      "  date: 2020-10-12_10-52-37\n",
       "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
+      "  episode_len_mean: 832.3867791842475\n",
+      "  episode_reward_max: 284.20202020202026\n",
+      "  episode_reward_mean: 236.9671717171716\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3675,14 +3583,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
+      "        entropy: 0.9004226724306742\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
+      "        kl: 0.007208069786429405\n",
       "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
+      "        policy_loss: -0.013761558337137103\n",
+      "        total_loss: 10.551711877187094\n",
+      "        vf_explained_var: 0.9797658324241638\n",
+      "        vf_loss: 10.565202951431274\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -3690,65 +3598,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
+      "    cpu_util_percent: 21.92571428571428\n",
+      "    gpu_util_percent0: 0.27685714285714286\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
+      "    ram_util_percent: 3.788571428571429\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
+      "    mean_action_processing_ms: 0.15327906662279647\n",
+      "    mean_env_wait_ms: 1.1910056333044456\n",
+      "    mean_inference_ms: 4.761055339662379\n",
+      "    mean_raw_obs_processing_ms: 0.40451655661329533\n",
+      "  time_since_restore: 456.6521706581116\n",
+      "  time_this_iter_s: 30.24983048439026\n",
+      "  time_total_s: 456.6521706581116\n",
       "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
+      "    learn_throughput: 7020.873\n",
+      "    learn_time_ms: 23044.428\n",
+      "    sample_throughput: 22861.865\n",
+      "    sample_time_ms: 7076.938\n",
+      "    update_time_ms: 31.497\n",
+      "  timestamp: 1602499957\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     15 |          456.652 | 2426880 |  236.967 |              284.202 |               88.596 |            832.387 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3485.892064559516\n",
+      "    time_step_min: 3188\n",
+      "  date: 2020-10-12_10-53-07\n",
       "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 830.3870752831446\n",
+      "  episode_reward_max: 287.98989898989873\n",
+      "  episode_reward_mean: 237.99570320123274\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3757,14 +3665,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
+      "        entropy: 0.883683979511261\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
+      "        kl: 0.006876855467756589\n",
       "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
+      "        policy_loss: -0.015000158843273917\n",
+      "        total_loss: 9.659654299418131\n",
+      "        vf_explained_var: 0.9799847602844238\n",
+      "        vf_loss: 9.674408833185831\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -3772,65 +3680,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
+      "    cpu_util_percent: 21.666666666666668\n",
+      "    gpu_util_percent0: 0.4347222222222223\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7916666666666674\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
+      "    mean_action_processing_ms: 0.15306299362268355\n",
+      "    mean_env_wait_ms: 1.191954532027558\n",
+      "    mean_inference_ms: 4.744688514554501\n",
+      "    mean_raw_obs_processing_ms: 0.40362988460399163\n",
+      "  time_since_restore: 487.09628772735596\n",
+      "  time_this_iter_s: 30.444117069244385\n",
+      "  time_total_s: 487.09628772735596\n",
       "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
+      "    learn_throughput: 7017.009\n",
+      "    learn_time_ms: 23057.118\n",
+      "    sample_throughput: 22879.197\n",
+      "    sample_time_ms: 7071.577\n",
+      "    update_time_ms: 32.472\n",
+      "  timestamp: 1602499987\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     16 |          487.096 | 2588672 |  237.996 |               287.99 |               88.596 |            830.387 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3475.6844047985237\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-12_10-53-38\n",
       "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 827.1854223848734\n",
+      "  episode_reward_max: 287.98989898989873\n",
+      "  episode_reward_mean: 239.62352712855906\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 277\n",
+      "  episodes_total: 3279\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3839,14 +3747,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
+      "        entropy: 0.8587738970915476\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
+      "        kl: 0.006916678316580753\n",
       "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
+      "        policy_loss: -0.012511584752549728\n",
+      "        total_loss: 14.398477554321289\n",
+      "        vf_explained_var: 0.9803693890571594\n",
+      "        vf_loss: 14.41072670618693\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -3854,65 +3762,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
+      "    cpu_util_percent: 21.645714285714284\n",
+      "    gpu_util_percent0: 0.37799999999999995\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
+      "    ram_util_percent: 3.7714285714285714\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
+      "    mean_action_processing_ms: 0.15273481962961288\n",
+      "    mean_env_wait_ms: 1.1936538248240764\n",
+      "    mean_inference_ms: 4.7192378919427\n",
+      "    mean_raw_obs_processing_ms: 0.40228302607192723\n",
+      "  time_since_restore: 517.2829170227051\n",
+      "  time_this_iter_s: 30.18662929534912\n",
+      "  time_total_s: 517.2829170227051\n",
       "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
+      "    learn_throughput: 7016.909\n",
+      "    learn_time_ms: 23057.447\n",
+      "    sample_throughput: 22903.263\n",
+      "    sample_time_ms: 7064.146\n",
+      "    update_time_ms: 30.629\n",
+      "  timestamp: 1602500018\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     17 |          517.283 | 2750464 |  239.624 |               287.99 |               88.596 |            827.185 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3469.3190255220416\n",
+      "    time_step_min: 3144\n",
+      "  date: 2020-10-12_10-54-08\n",
       "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 824.9479286536249\n",
+      "  episode_reward_max: 289.65656565656536\n",
+      "  episode_reward_mean: 240.624545222071\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 197\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3921,14 +3829,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
+      "        entropy: 0.8442238519589106\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
+      "        kl: 0.007084058636489014\n",
       "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
+      "        policy_loss: -0.014629053592216223\n",
+      "        total_loss: 10.824065446853638\n",
+      "        vf_explained_var: 0.9808571338653564\n",
+      "        vf_loss: 10.83840799331665\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -3936,65 +3844,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
+      "    cpu_util_percent: 22.057142857142853\n",
+      "    gpu_util_percent0: 0.3442857142857143\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7857142857142865\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
+      "    mean_action_processing_ms: 0.15250983796903406\n",
+      "    mean_env_wait_ms: 1.194694048196607\n",
+      "    mean_inference_ms: 4.70271967975275\n",
+      "    mean_raw_obs_processing_ms: 0.4014121366382054\n",
+      "  time_since_restore: 547.3402900695801\n",
+      "  time_this_iter_s: 30.057373046875\n",
+      "  time_total_s: 547.3402900695801\n",
       "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
+      "    learn_throughput: 7017.142\n",
+      "    learn_time_ms: 23056.679\n",
+      "    sample_throughput: 23001.567\n",
+      "    sample_time_ms: 7033.956\n",
+      "    update_time_ms: 32.23\n",
+      "  timestamp: 1602500048\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     18 |           547.34 | 2912256 |  240.625 |              289.657 |               88.596 |            824.948 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3465.189961175818\n",
+      "    time_step_min: 3144\n",
+      "  date: 2020-10-12_10-54-38\n",
       "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
+      "  episode_len_mean: 823.5038525041277\n",
+      "  episode_reward_max: 289.65656565656536\n",
+      "  episode_reward_mean: 241.21011713169108\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4003,14 +3911,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
+      "        entropy: 0.8410505006710688\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
+      "        kl: 0.007028338382951915\n",
       "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
+      "        policy_loss: -0.012794313098614415\n",
+      "        total_loss: 10.480183601379395\n",
+      "        vf_explained_var: 0.9795172810554504\n",
+      "        vf_loss: 10.492695411046347\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -4018,2418 +3926,56 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
+      "    cpu_util_percent: 21.87142857142857\n",
+      "    gpu_util_percent0: 0.4517142857142856\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
+      "    ram_util_percent: 3.7800000000000002\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
+      "    mean_action_processing_ms: 0.15234923422949861\n",
+      "    mean_env_wait_ms: 1.1954980474610577\n",
+      "    mean_inference_ms: 4.690587971836767\n",
+      "    mean_raw_obs_processing_ms: 0.4007655976235748\n",
+      "  time_since_restore: 577.2354960441589\n",
+      "  time_this_iter_s: 29.895205974578857\n",
+      "  time_total_s: 577.2354960441589\n",
       "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
+      "    learn_throughput: 7018.912\n",
+      "    learn_time_ms: 23050.867\n",
+      "    sample_throughput: 23055.833\n",
+      "    sample_time_ms: 7017.4\n",
+      "    update_time_ms: 32.148\n",
+      "  timestamp: 1602500078\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
-      "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     19 |          577.235 | 3074048 |   241.21 |              289.657 |               88.596 |            823.504 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
-      "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
-      "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
-      "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
-      "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
-      "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
-      "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
-      "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
-      "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
-      "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
-      "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
-      "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
-      "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
-      "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
-      "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
-      "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
-      "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
-      "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent y2n6znmq"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index ac81b03..9a26d28 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index 0786a30..36d1db9 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 1e-4,
+    "entropy_coeff": 5e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 8ee10cb..34b7e3d 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug-internal.log
\ No newline at end of file
+run-20201012_105518-f0zxmbgr/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4f3bf3b..e4e8120 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug.log
\ No newline at end of file
+run-20201012_105518-f0zxmbgr/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 8be457f..d14646c 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201012_023117-p62mhra8
\ No newline at end of file
+run-20201012_105518-f0zxmbgr
\ No newline at end of file
