2020-10-11 12:55:26,564	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_0957b_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=74415)[0m 2020-10-11 12:55:29,283	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=74396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74352)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3606.536231884058
    time_step_min: 3277
  date: 2020-10-11_12-56-36
  done: false
  episode_len_mean: 890.3196202531645
  episode_reward_max: 269.5050505050508
  episode_reward_mean: 220.52154455951901
  episode_reward_min: 122.23232323232297
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1789257049560546
        entropy_coeff: 0.0001
        kl: 0.010489314794540405
        model: {}
        policy_loss: -0.021394818648695947
        total_loss: 487.7284637451172
        vf_explained_var: 0.6129164099693298
        vf_loss: 487.7478729248047
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.53698630136986
    gpu_util_percent0: 0.3389041095890411
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8520547945205488
    vram_util_percent0: 0.09413034590276625
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23618876253171037
    mean_env_wait_ms: 2.2784717144072517
    mean_inference_ms: 9.809360984079115
    mean_raw_obs_processing_ms: 0.8262353121553463
  time_since_restore: 61.441073179244995
  time_this_iter_s: 61.441073179244995
  time_total_s: 61.441073179244995
  timers:
    learn_throughput: 7020.088
    learn_time_ms: 46094.009
    sample_throughput: 21178.643
    sample_time_ms: 15278.788
    update_time_ms: 32.551
  timestamp: 1602420996
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 30.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      1 |          61.4411 | 323584 |  220.522 |              269.505 |              122.232 |             890.32 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3622.8623326959846
    time_step_min: 3277
  date: 2020-10-11_12-57-35
  done: false
  episode_len_mean: 888.2674050632911
  episode_reward_max: 270.4141414141409
  episode_reward_mean: 218.84073328218875
  episode_reward_min: 122.23232323232297
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1453650712966919
        entropy_coeff: 0.0001
        kl: 0.01124701090157032
        model: {}
        policy_loss: -0.02423451537033543
        total_loss: 108.81335945129395
        vf_explained_var: 0.8565881848335266
        vf_loss: 108.83545951843261
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.27857142857143
    gpu_util_percent0: 0.35871428571428565
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.189999999999999
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23047854775278848
    mean_env_wait_ms: 2.2620514374163068
    mean_inference_ms: 9.223860204888862
    mean_raw_obs_processing_ms: 0.8062961996123408
  time_since_restore: 120.81622910499573
  time_this_iter_s: 59.37515592575073
  time_total_s: 120.81622910499573
  timers:
    learn_throughput: 6966.642
    learn_time_ms: 46447.626
    sample_throughput: 23333.793
    sample_time_ms: 13867.612
    update_time_ms: 33.013
  timestamp: 1602421055
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      2 |          120.816 | 647168 |  218.841 |              270.414 |              122.232 |            888.267 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3619.0476758045293
    time_step_min: 3277
  date: 2020-10-11_12-58-34
  done: false
  episode_len_mean: 888.9694092827004
  episode_reward_max: 270.4141414141409
  episode_reward_mean: 218.7223820483312
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1271400034427643
        entropy_coeff: 0.0001
        kl: 0.012096974533051252
        model: {}
        policy_loss: -0.02591819120571017
        total_loss: 27.82328815460205
        vf_explained_var: 0.9563124775886536
        vf_loss: 27.846899890899657
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.285507246376813
    gpu_util_percent0: 0.3730434782608696
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.211594202898549
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22707037616098893
    mean_env_wait_ms: 2.24963391467598
    mean_inference_ms: 8.873210898716838
    mean_raw_obs_processing_ms: 0.7931695981653204
  time_since_restore: 179.56883001327515
  time_this_iter_s: 58.75260090827942
  time_total_s: 179.56883001327515
  timers:
    learn_throughput: 6964.65
    learn_time_ms: 46460.915
    sample_throughput: 24350.961
    sample_time_ms: 13288.346
    update_time_ms: 37.781
  timestamp: 1602421114
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      3 |          179.569 | 970752 |  218.722 |              270.414 |              114.808 |            888.969 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3612.5489177489176
    time_step_min: 3274
  date: 2020-10-11_12-59-32
  done: false
  episode_len_mean: 887.0854430379746
  episode_reward_max: 270.4141414141409
  episode_reward_mean: 220.03595288326278
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.106074982881546
        entropy_coeff: 0.0001
        kl: 0.01211608638986945
        model: {}
        policy_loss: -0.026496155629865827
        total_loss: 18.603939533233643
        vf_explained_var: 0.9667423367500305
        vf_loss: 18.628123188018797
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.504411764705882
    gpu_util_percent0: 0.3683823529411765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.205882352941177
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22483484314277888
    mean_env_wait_ms: 2.2426449420197803
    mean_inference_ms: 8.636951181891733
    mean_raw_obs_processing_ms: 0.783425640857186
  time_since_restore: 238.10744714736938
  time_this_iter_s: 58.53861713409424
  time_total_s: 238.10744714736938
  timers:
    learn_throughput: 6968.209
    learn_time_ms: 46437.181
    sample_throughput: 24944.454
    sample_time_ms: 12972.182
    update_time_ms: 37.952
  timestamp: 1602421172
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      4 |          238.107 | 1294336 |  220.036 |              270.414 |              114.808 |            887.085 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3601.93609789259
    time_step_min: 3274
  date: 2020-10-11_13-00-32
  done: false
  episode_len_mean: 883.7892405063291
  episode_reward_max: 270.4141414141409
  episode_reward_mean: 221.83713719473195
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 316
  episodes_total: 1580
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0792196452617646
        entropy_coeff: 0.0001
        kl: 0.012244415050372482
        model: {}
        policy_loss: -0.027472141571342944
        total_loss: 17.625648784637452
        vf_explained_var: 0.968270480632782
        vf_loss: 17.650779914855956
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.881428571428565
    gpu_util_percent0: 0.3502857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.257142857142858
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.223208923909742
    mean_env_wait_ms: 2.238583624236154
    mean_inference_ms: 8.466280782172795
    mean_raw_obs_processing_ms: 0.7758691008851248
  time_since_restore: 297.364563703537
  time_this_iter_s: 59.2571165561676
  time_total_s: 297.364563703537
  timers:
    learn_throughput: 6958.453
    learn_time_ms: 46502.288
    sample_throughput: 25181.801
    sample_time_ms: 12849.915
    update_time_ms: 40.02
  timestamp: 1602421232
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      5 |          297.365 | 1617920 |  221.837 |              270.414 |              114.808 |            883.789 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3581.5902217741937
    time_step_min: 3211
  date: 2020-10-11_13-01-31
  done: false
  episode_len_mean: 876.9426660296225
  episode_reward_max: 279.5050505050509
  episode_reward_mean: 224.25703764834182
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 513
  episodes_total: 2093
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0500548779964447
        entropy_coeff: 0.0001
        kl: 0.011319789523258805
        model: {}
        policy_loss: -0.02509042180608958
        total_loss: 25.9422399520874
        vf_explained_var: 0.9687948226928711
        vf_loss: 25.965171813964844
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.063768115942025
    gpu_util_percent0: 0.37028985507246376
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.246376811594203
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22134228968717037
    mean_env_wait_ms: 2.237312836213154
    mean_inference_ms: 8.27312099869982
    mean_raw_obs_processing_ms: 0.7668894457492194
  time_since_restore: 356.2365298271179
  time_this_iter_s: 58.87196612358093
  time_total_s: 356.2365298271179
  timers:
    learn_throughput: 6959.437
    learn_time_ms: 46495.714
    sample_throughput: 25370.273
    sample_time_ms: 12754.455
    update_time_ms: 41.126
  timestamp: 1602421291
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      6 |          356.237 | 1941504 |  224.257 |              279.505 |              114.808 |            876.943 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3566.6250516742457
    time_step_min: 3211
  date: 2020-10-11_13-02-30
  done: false
  episode_len_mean: 871.8097310126582
  episode_reward_max: 279.5050505050509
  episode_reward_mean: 226.66318245748607
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 435
  episodes_total: 2528
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0549808204174043
        entropy_coeff: 0.0001
        kl: 0.011254569981247187
        model: {}
        policy_loss: -0.02825084696523845
        total_loss: 13.770083904266357
        vf_explained_var: 0.9760850071907043
        vf_loss: 13.796189546585083
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.078260869565216
    gpu_util_percent0: 0.35739130434782607
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.26376811594203
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22026866197811923
    mean_env_wait_ms: 2.2372593140097345
    mean_inference_ms: 8.156540846553288
    mean_raw_obs_processing_ms: 0.761580741450144
  time_since_restore: 415.1758699417114
  time_this_iter_s: 58.939340114593506
  time_total_s: 415.1758699417114
  timers:
    learn_throughput: 6952.178
    learn_time_ms: 46544.265
    sample_throughput: 25592.011
    sample_time_ms: 12643.946
    update_time_ms: 40.288
  timestamp: 1602421350
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      7 |          415.176 | 2265088 |  226.663 |              279.505 |              114.808 |             871.81 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3557.218281535649
    time_step_min: 3195
  date: 2020-10-11_13-03-29
  done: false
  episode_len_mean: 868.3748241912799
  episode_reward_max: 281.92929292929296
  episode_reward_mean: 228.04786259216618
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0277260780334472
        entropy_coeff: 0.0001
        kl: 0.011789066949859262
        model: {}
        policy_loss: -0.029191050678491592
        total_loss: 12.70274043083191
        vf_explained_var: 0.977298378944397
        vf_loss: 12.729676389694214
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.108695652173914
    gpu_util_percent0: 0.32405797101449274
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.268115942028985
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21963352728250785
    mean_env_wait_ms: 2.237588757584534
    mean_inference_ms: 8.088185123742868
    mean_raw_obs_processing_ms: 0.7584828180659299
  time_since_restore: 473.9523684978485
  time_this_iter_s: 58.776498556137085
  time_total_s: 473.9523684978485
  timers:
    learn_throughput: 6955.251
    learn_time_ms: 46523.696
    sample_throughput: 25685.587
    sample_time_ms: 12597.882
    update_time_ms: 39.825
  timestamp: 1602421409
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      8 |          473.952 | 2588672 |  228.048 |              281.929 |              114.808 |            868.375 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3548.1094723041624
    time_step_min: 3195
  date: 2020-10-11_13-04-28
  done: false
  episode_len_mean: 865.5775316455696
  episode_reward_max: 281.92929292929296
  episode_reward_mean: 229.3605836849506
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 316
  episodes_total: 3160
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0049212336540223
        entropy_coeff: 0.0001
        kl: 0.011349478783085943
        model: {}
        policy_loss: -0.02959783561527729
        total_loss: 11.613105058670044
        vf_explained_var: 0.9781259298324585
        vf_loss: 11.640533351898194
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.99565217391304
    gpu_util_percent0: 0.3436231884057971
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.260869565217392
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21908888320544148
    mean_env_wait_ms: 2.237925437717533
    mean_inference_ms: 8.029196152444856
    mean_raw_obs_processing_ms: 0.7557315837156464
  time_since_restore: 532.7904779911041
  time_this_iter_s: 58.838109493255615
  time_total_s: 532.7904779911041
  timers:
    learn_throughput: 6956.095
    learn_time_ms: 46518.051
    sample_throughput: 25769.937
    sample_time_ms: 12556.647
    update_time_ms: 40.565
  timestamp: 1602421468
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |      9 |           532.79 | 2912256 |  229.361 |              281.929 |              114.808 |            865.578 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3539.9405325443786
    time_step_min: 3195
  date: 2020-10-11_13-05-27
  done: false
  episode_len_mean: 863.0556033247349
  episode_reward_max: 282.080808080808
  episode_reward_mean: 230.65728653690803
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 329
  episodes_total: 3489
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.960999071598053
        entropy_coeff: 0.0001
        kl: 0.011158609343692661
        model: {}
        policy_loss: -0.029591354774311185
        total_loss: 13.39948878288269
        vf_explained_var: 0.9784002304077148
        vf_loss: 13.42694444656372
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.910144927536233
    gpu_util_percent0: 0.3595652173913043
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.2608695652173925
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21860523196923765
    mean_env_wait_ms: 2.2384141973077707
    mean_inference_ms: 7.975889517871923
    mean_raw_obs_processing_ms: 0.753101154816986
  time_since_restore: 591.8935077190399
  time_this_iter_s: 59.10302972793579
  time_total_s: 591.8935077190399
  timers:
    learn_throughput: 6950.915
    learn_time_ms: 46552.722
    sample_throughput: 25860.592
    sample_time_ms: 12512.629
    update_time_ms: 39.381
  timestamp: 1602421527
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | RUNNING  | 172.17.0.4:74415 |     10 |          591.894 | 3235840 |  230.657 |              282.081 |              114.808 |            863.056 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0957b_00000:
  custom_metrics:
    time_step_max: 4259
    time_step_mean: 3522.4568489713997
    time_step_min: 3195
  date: 2020-10-11_13-06-26
  done: true
  episode_len_mean: 858.6495726495726
  episode_reward_max: 285.5656565656569
  episode_reward_mean: 233.12494912494898
  episode_reward_min: 114.80808080808085
  episodes_this_iter: 606
  episodes_total: 4095
  experiment_id: 154a83ab78e448a2aa8864d438bf8112
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9545941174030304
        entropy_coeff: 0.0001
        kl: 0.010374826937913894
        model: {}
        policy_loss: -0.027549075055867435
        total_loss: 15.229001808166505
        vf_explained_var: 0.9800213575363159
        vf_loss: 15.254570865631104
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.12463768115942
    gpu_util_percent0: 0.35246376811594204
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.246376811594204
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74415
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2178629869987086
    mean_env_wait_ms: 2.239665630415449
    mean_inference_ms: 7.895670321033296
    mean_raw_obs_processing_ms: 0.7492423487891253
  time_since_restore: 651.0993485450745
  time_this_iter_s: 59.205840826034546
  time_total_s: 651.0993485450745
  timers:
    learn_throughput: 6942.272
    learn_time_ms: 46610.679
    sample_throughput: 26466.895
    sample_time_ms: 12225.99
    update_time_ms: 38.651
  timestamp: 1602421586
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 11
  trial_id: 0957b_00000
  
== Status ==
Memory usage on this node: 31.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | TERMINATED |       |     11 |          651.099 | 3559424 |  233.125 |              285.566 |              114.808 |             858.65 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 31.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0957b_00000 | TERMINATED |       |     11 |          651.099 | 3559424 |  233.125 |              285.566 |              114.808 |             858.65 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


