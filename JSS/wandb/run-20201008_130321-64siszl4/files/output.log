2020-10-08 13:03:23,547	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8269[39m[22m
== Status ==
Memory usage on this node: 37.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a66ba_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=48420)[0m 2020-10-08 13:03:26,448	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=48400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48432)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48428)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48428)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48408)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_13-04-02
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1603952676057816
        entropy_coeff: 0.0
        kl: 0.006529558636248112
        model: {}
        policy_loss: -0.01697929573711008
        total_loss: 6.624263763427734
        vf_explained_var: 0.8197423815727234
        vf_loss: 6.639937055110932
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.04857142857142
    gpu_util_percent0: 0.2725714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00028571428571428574
    ram_util_percent: 6.868571428571428
    vram_util_percent0: 0.1419669212388137
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17684283761486444
    mean_env_wait_ms: 1.6125988643748705
    mean_inference_ms: 6.031567699271022
    mean_raw_obs_processing_ms: 0.48085302804568264
  time_since_restore: 30.11922836303711
  time_this_iter_s: 30.11922836303711
  time_total_s: 30.11922836303711
  timers:
    learn_throughput: 8088.741
    learn_time_ms: 20002.124
    sample_throughput: 16103.928
    sample_time_ms: 10046.741
    update_time_ms: 38.232
  timestamp: 1602162242
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 52.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      1 |          30.1192 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_13-04-30
  done: false
  episode_len_mean: 869.3417721518987
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.90004475131036
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1352683365345002
        entropy_coeff: 0.0
        kl: 0.007792104431428015
        model: {}
        policy_loss: -0.020531148964073508
        total_loss: 5.638339829444885
        vf_explained_var: 0.9249752759933472
        vf_loss: 5.657312452793121
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.21212121212121
    gpu_util_percent0: 0.2715151515151515
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.069696969696969
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17175043990631078
    mean_env_wait_ms: 1.612560008483974
    mean_inference_ms: 5.697708034370405
    mean_raw_obs_processing_ms: 0.4654917298335798
  time_since_restore: 58.14509844779968
  time_this_iter_s: 28.025870084762573
  time_total_s: 58.14509844779968
  timers:
    learn_throughput: 8179.868
    learn_time_ms: 19779.291
    sample_throughput: 17556.662
    sample_time_ms: 9215.419
    update_time_ms: 38.524
  timestamp: 1602162270
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      2 |          58.1451 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3247.0
  date: 2020-10-08_13-04-58
  done: false
  episode_len_mean: 864.6983122362869
  episode_reward_max: 278.99999999999983
  episode_reward_mean: 225.52218386395583
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1208289206027984
        entropy_coeff: 0.0
        kl: 0.008471710339654237
        model: {}
        policy_loss: -0.024524397612549365
        total_loss: 4.379646378755569
        vf_explained_var: 0.9663649797439575
        vf_loss: 4.4024763882160185
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.842424242424244
    gpu_util_percent0: 0.26878787878787874
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.087878787878787
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16835567750479274
    mean_env_wait_ms: 1.6123591488447364
    mean_inference_ms: 5.500225972412794
    mean_raw_obs_processing_ms: 0.45395802121858475
  time_since_restore: 85.81576776504517
  time_this_iter_s: 27.670669317245483
  time_total_s: 85.81576776504517
  timers:
    learn_throughput: 8196.573
    learn_time_ms: 19738.98
    sample_throughput: 18409.652
    sample_time_ms: 8788.433
    update_time_ms: 34.699
  timestamp: 1602162298
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      3 |          85.8158 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3247.0
  date: 2020-10-08_13-05-25
  done: false
  episode_len_mean: 860.242088607595
  episode_reward_max: 278.99999999999983
  episode_reward_mean: 225.50586561820717
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0932798445224763
        entropy_coeff: 0.0
        kl: 0.009407231188379227
        model: {}
        policy_loss: -0.026628604688448833
        total_loss: 4.111228054761886
        vf_explained_var: 0.9783345460891724
        vf_loss: 4.135975193977356
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.568749999999998
    gpu_util_percent0: 0.30874999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.074999999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16590883993937328
    mean_env_wait_ms: 1.614039687505855
    mean_inference_ms: 5.354406275754719
    mean_raw_obs_processing_ms: 0.44568708821756753
  time_since_restore: 113.32211327552795
  time_this_iter_s: 27.506345510482788
  time_total_s: 113.32211327552795
  timers:
    learn_throughput: 8195.223
    learn_time_ms: 19742.233
    sample_throughput: 19008.098
    sample_time_ms: 8511.741
    update_time_ms: 31.179
  timestamp: 1602162325
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      4 |          113.322 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3235.0
  date: 2020-10-08_13-05-53
  done: false
  episode_len_mean: 853.6054421768707
  episode_reward_max: 278.99999999999983
  episode_reward_mean: 226.6438076914266
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 250
  episodes_total: 882
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0601136475801467
        entropy_coeff: 0.0
        kl: 0.008663335489109159
        model: {}
        policy_loss: -0.029689956549555065
        total_loss: 5.979247343540192
        vf_explained_var: 0.9847942590713501
        vf_loss: 6.007204520702362
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.196969696969695
    gpu_util_percent0: 0.28151515151515155
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.078787878787878
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16322613586806162
    mean_env_wait_ms: 1.618564715142128
    mean_inference_ms: 5.1965775987407
    mean_raw_obs_processing_ms: 0.43688733469373264
  time_since_restore: 140.94446516036987
  time_this_iter_s: 27.62235188484192
  time_total_s: 140.94446516036987
  timers:
    learn_throughput: 8201.83
    learn_time_ms: 19726.329
    sample_throughput: 19300.882
    sample_time_ms: 8382.622
    update_time_ms: 33.788
  timestamp: 1602162353
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      5 |          140.944 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3235.0
  date: 2020-10-08_13-06-21
  done: false
  episode_len_mean: 847.8264014466546
  episode_reward_max: 278.99999999999983
  episode_reward_mean: 227.10596927685518
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 224
  episodes_total: 1106
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0766338467597962
        entropy_coeff: 0.0
        kl: 0.008614842919632793
        model: {}
        policy_loss: -0.030333096848335118
        total_loss: 4.108908116817474
        vf_explained_var: 0.987047553062439
        vf_loss: 4.137518179416657
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.91818181818182
    gpu_util_percent0: 0.2675757575757575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.093939393939394
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16170303457671983
    mean_env_wait_ms: 1.6223100669775932
    mean_inference_ms: 5.1020076494140145
    mean_raw_obs_processing_ms: 0.4318509637184022
  time_since_restore: 168.99340772628784
  time_this_iter_s: 28.04894256591797
  time_total_s: 168.99340772628784
  timers:
    learn_throughput: 8189.649
    learn_time_ms: 19755.669
    sample_throughput: 19458.479
    sample_time_ms: 8314.73
    update_time_ms: 44.893
  timestamp: 1602162381
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      6 |          168.993 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-06-49
  done: false
  episode_len_mean: 844.1083860759494
  episode_reward_max: 282.4848484848477
  episode_reward_mean: 227.6303302007414
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0495809823274613
        entropy_coeff: 0.0
        kl: 0.008355090976692736
        model: {}
        policy_loss: -0.03242016874719411
        total_loss: 3.189230865240097
        vf_explained_var: 0.9909769296646118
        vf_loss: 3.2199800491333006
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.393749999999997
    gpu_util_percent0: 0.2890625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.09375
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16083207028712804
    mean_env_wait_ms: 1.6246649103902648
    mean_inference_ms: 5.047979912651508
    mean_raw_obs_processing_ms: 0.4289438974397711
  time_since_restore: 196.5391137599945
  time_this_iter_s: 27.545706033706665
  time_total_s: 196.5391137599945
  timers:
    learn_throughput: 8192.368
    learn_time_ms: 19749.112
    sample_throughput: 19649.458
    sample_time_ms: 8233.917
    update_time_ms: 43.465
  timestamp: 1602162409
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      7 |          196.539 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-07-17
  done: false
  episode_len_mean: 840.8741209563995
  episode_reward_max: 282.4848484848477
  episode_reward_mean: 227.87909332424087
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0188148379325868
        entropy_coeff: 0.0
        kl: 0.008204545732587576
        model: {}
        policy_loss: -0.03408731806557626
        total_loss: 3.0473277091979982
        vf_explained_var: 0.9921058416366577
        vf_loss: 3.079774135351181
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.34375
    gpu_util_percent0: 0.26187499999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.090624999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1600692160166658
    mean_env_wait_ms: 1.6269229831056464
    mean_inference_ms: 5.001360241831795
    mean_raw_obs_processing_ms: 0.42636690475877
  time_since_restore: 224.0884222984314
  time_this_iter_s: 27.54930853843689
  time_total_s: 224.0884222984314
  timers:
    learn_throughput: 8190.648
    learn_time_ms: 19753.259
    sample_throughput: 19817.121
    sample_time_ms: 8164.253
    update_time_ms: 42.962
  timestamp: 1602162437
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      8 |          224.088 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-07-44
  done: false
  episode_len_mean: 835.0944055944055
  episode_reward_max: 282.4848484848477
  episode_reward_mean: 228.1691507146051
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 294
  episodes_total: 1716
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9918270707130432
        entropy_coeff: 0.0
        kl: 0.007521937682759017
        model: {}
        policy_loss: -0.03050975254736841
        total_loss: 5.504689037799835
        vf_explained_var: 0.9918516874313354
        vf_loss: 5.53369448184967
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.893749999999997
    gpu_util_percent0: 0.27468750000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.081250000000001
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15893424360220432
    mean_env_wait_ms: 1.6312548911336793
    mean_inference_ms: 4.931393440296031
    mean_raw_obs_processing_ms: 0.42259131362554386
  time_since_restore: 251.39063906669617
  time_this_iter_s: 27.30221676826477
  time_total_s: 251.39063906669617
  timers:
    learn_throughput: 8195.137
    learn_time_ms: 19742.439
    sample_throughput: 19980.359
    sample_time_ms: 8097.552
    update_time_ms: 41.219
  timestamp: 1602162464
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      9 |          251.391 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-08-12
  done: false
  episode_len_mean: 832.079641350211
  episode_reward_max: 282.4848484848477
  episode_reward_mean: 228.59731279035063
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 180
  episodes_total: 1896
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9763310596346855
        entropy_coeff: 0.0
        kl: 0.007896899722982197
        model: {}
        policy_loss: -0.033220290520694105
        total_loss: 2.953149896860123
        vf_explained_var: 0.993627667427063
        vf_loss: 2.98479083776474
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.2125
    gpu_util_percent0: 0.2575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.090624999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15839508313317022
    mean_env_wait_ms: 1.6336331012374383
    mean_inference_ms: 4.8972865076615
    mean_raw_obs_processing_ms: 0.42074921067835536
  time_since_restore: 279.0602397918701
  time_this_iter_s: 27.66960072517395
  time_total_s: 279.0602397918701
  timers:
    learn_throughput: 8190.217
    learn_time_ms: 19754.3
    sample_throughput: 20073.856
    sample_time_ms: 8059.837
    update_time_ms: 40.691
  timestamp: 1602162492
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     10 |           279.06 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-08-39
  done: false
  episode_len_mean: 830.1703992210321
  episode_reward_max: 282.4848484848477
  episode_reward_mean: 229.0675253017024
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9670185938477516
        entropy_coeff: 0.0
        kl: 0.007682974718045443
        model: {}
        policy_loss: -0.03496774770319462
        total_loss: 2.589013671875
        vf_explained_var: 0.9946534037590027
        vf_loss: 2.622444784641266
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.9375
    gpu_util_percent0: 0.28125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.090624999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579654496622953
    mean_env_wait_ms: 1.6355676311935072
    mean_inference_ms: 4.870419542024985
    mean_raw_obs_processing_ms: 0.41930659432398215
  time_since_restore: 306.65611481666565
  time_this_iter_s: 27.595875024795532
  time_total_s: 306.65611481666565
  timers:
    learn_throughput: 8194.743
    learn_time_ms: 19743.388
    sample_throughput: 20698.258
    sample_time_ms: 7816.697
    update_time_ms: 40.274
  timestamp: 1602162519
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     11 |          306.656 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-09-07
  done: false
  episode_len_mean: 828.50904159132
  episode_reward_max: 287.9191919191919
  episode_reward_mean: 229.5476966774434
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.940390695631504
        entropy_coeff: 0.0
        kl: 0.007805287896189839
        model: {}
        policy_loss: -0.035866627853829415
        total_loss: 2.6927455008029937
        vf_explained_var: 0.9949959516525269
        vf_loss: 2.7270510613918306
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.03125
    gpu_util_percent0: 0.2884375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.096874999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15758185014791637
    mean_env_wait_ms: 1.6374025587863599
    mean_inference_ms: 4.8461770891818805
    mean_raw_obs_processing_ms: 0.41798002916463206
  time_since_restore: 333.9199523925781
  time_this_iter_s: 27.263837575912476
  time_total_s: 333.9199523925781
  timers:
    learn_throughput: 8203.151
    learn_time_ms: 19723.152
    sample_throughput: 20847.854
    sample_time_ms: 7760.607
    update_time_ms: 39.779
  timestamp: 1602162547
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     12 |           333.92 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-09-35
  done: false
  episode_len_mean: 825.9173259493671
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 230.737545550441
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9119029730558396
        entropy_coeff: 0.0
        kl: 0.007374470541253686
        model: {}
        policy_loss: -0.031025875953491776
        total_loss: 3.626113736629486
        vf_explained_var: 0.9953392744064331
        vf_loss: 3.655664700269699
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.278787878787877
    gpu_util_percent0: 0.26242424242424245
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.078787878787878
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15692756531146781
    mean_env_wait_ms: 1.6407068507668097
    mean_inference_ms: 4.804748256271755
    mean_raw_obs_processing_ms: 0.4157399628394673
  time_since_restore: 361.73055267333984
  time_this_iter_s: 27.81060028076172
  time_total_s: 361.73055267333984
  timers:
    learn_throughput: 8193.451
    learn_time_ms: 19746.504
    sample_throughput: 20873.804
    sample_time_ms: 7750.959
    update_time_ms: 39.512
  timestamp: 1602162575
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     13 |          361.731 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-10-02
  done: false
  episode_len_mean: 824.9274013402829
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 231.18682355949656
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8989204004406929
        entropy_coeff: 0.0
        kl: 0.0074366391287185255
        model: {}
        policy_loss: -0.03388760575326159
        total_loss: 2.3619153201580048
        vf_explained_var: 0.9957093000411987
        vf_loss: 2.394315606355667
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.628124999999997
    gpu_util_percent0: 0.270625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.090624999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15664376348269557
    mean_env_wait_ms: 1.642168947228257
    mean_inference_ms: 4.7868873460739
    mean_raw_obs_processing_ms: 0.41477525757369893
  time_since_restore: 389.24887132644653
  time_this_iter_s: 27.51831865310669
  time_total_s: 389.24887132644653
  timers:
    learn_throughput: 8192.237
    learn_time_ms: 19749.428
    sample_throughput: 20883.748
    sample_time_ms: 7747.268
    update_time_ms: 40.855
  timestamp: 1602162602
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     14 |          389.249 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-10-30
  done: false
  episode_len_mean: 824.0777074542897
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 231.63322749293204
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.895898899435997
        entropy_coeff: 0.0
        kl: 0.007697970513254404
        model: {}
        policy_loss: -0.03602396983187646
        total_loss: 1.9372931450605393
        vf_explained_var: 0.9962417483329773
        vf_loss: 1.9717775255441665
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.75625
    gpu_util_percent0: 0.2996875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.1
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15638277949636234
    mean_env_wait_ms: 1.6435161713443915
    mean_inference_ms: 4.770368733513049
    mean_raw_obs_processing_ms: 0.41387653588677614
  time_since_restore: 416.92683267593384
  time_this_iter_s: 27.677961349487305
  time_total_s: 416.92683267593384
  timers:
    learn_throughput: 8187.713
    learn_time_ms: 19760.342
    sample_throughput: 20895.148
    sample_time_ms: 7743.041
    update_time_ms: 38.352
  timestamp: 1602162630
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     15 |          416.927 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-10-58
  done: false
  episode_len_mean: 822.9910447761195
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 232.33685444829712
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 171
  episodes_total: 3015
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8683042243123055
        entropy_coeff: 0.0
        kl: 0.007607861259020865
        model: {}
        policy_loss: -0.036039730068296194
        total_loss: 2.116857588291168
        vf_explained_var: 0.9965157508850098
        vf_loss: 2.1513757526874544
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.765625
    gpu_util_percent0: 0.264375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.093749999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1561274407042432
    mean_env_wait_ms: 1.6449275619289732
    mean_inference_ms: 4.7538760001880425
    mean_raw_obs_processing_ms: 0.41298375172845214
  time_since_restore: 444.42542719841003
  time_this_iter_s: 27.498594522476196
  time_total_s: 444.42542719841003
  timers:
    learn_throughput: 8205.125
    learn_time_ms: 19718.408
    sample_throughput: 20914.127
    sample_time_ms: 7736.015
    update_time_ms: 32.523
  timestamp: 1602162658
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     16 |          444.425 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-11-25
  done: false
  episode_len_mean: 821.0216998191681
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 233.1551683197252
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 303
  episodes_total: 3318
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8348902150988579
        entropy_coeff: 0.0
        kl: 0.00740289380773902
        model: {}
        policy_loss: -0.029998348827939482
        total_loss: 2.5100847482681274
        vf_explained_var: 0.9960853457450867
        vf_loss: 2.538602519035339
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.384848484848487
    gpu_util_percent0: 0.2733333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.084848484848485
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557249214530076
    mean_env_wait_ms: 1.6472950848938899
    mean_inference_ms: 4.72807427169106
    mean_raw_obs_processing_ms: 0.41163200120001464
  time_since_restore: 471.9680824279785
  time_this_iter_s: 27.54265522956848
  time_total_s: 471.9680824279785
  timers:
    learn_throughput: 8203.679
    learn_time_ms: 19721.884
    sample_throughput: 20932.974
    sample_time_ms: 7729.05
    update_time_ms: 33.068
  timestamp: 1602162685
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     17 |          471.968 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-11-53
  done: false
  episode_len_mean: 820.0376869965478
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 233.58232206995146
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8338133722543717
        entropy_coeff: 0.0
        kl: 0.007797137019224465
        model: {}
        policy_loss: -0.0366627115290612
        total_loss: 1.7475906014442444
        vf_explained_var: 0.9965535998344421
        vf_loss: 1.7826938778162003
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.625
    gpu_util_percent0: 0.2828125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.090624999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15553702279016246
    mean_env_wait_ms: 1.6484300169434907
    mean_inference_ms: 4.716036479297133
    mean_raw_obs_processing_ms: 0.4110046184978835
  time_since_restore: 499.3933494091034
  time_this_iter_s: 27.425266981124878
  time_total_s: 499.3933494091034
  timers:
    learn_throughput: 8210.879
    learn_time_ms: 19704.59
    sample_throughput: 20925.136
    sample_time_ms: 7731.945
    update_time_ms: 33.368
  timestamp: 1602162713
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     18 |          499.393 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-12-21
  done: false
  episode_len_mean: 819.1164006604292
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 234.0312925623877
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8341425269842148
        entropy_coeff: 0.0
        kl: 0.007575143571011722
        model: {}
        policy_loss: -0.03457739797886461
        total_loss: 1.834545186161995
        vf_explained_var: 0.9961616396903992
        vf_loss: 1.8676075398921967
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.003030303030304
    gpu_util_percent0: 0.27454545454545454
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.109090909090909
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15536040332395953
    mean_env_wait_ms: 1.6495075288779244
    mean_inference_ms: 4.704714417712872
    mean_raw_obs_processing_ms: 0.4104060889788023
  time_since_restore: 527.4742221832275
  time_this_iter_s: 28.080872774124146
  time_total_s: 527.4742221832275
  timers:
    learn_throughput: 8198.495
    learn_time_ms: 19734.355
    sample_throughput: 20800.761
    sample_time_ms: 7778.177
    update_time_ms: 34.299
  timestamp: 1602162741
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     19 |          527.474 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-12-49
  done: false
  episode_len_mean: 817.554763117677
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 234.8146184205786
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 292
  episodes_total: 3926
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.7916461393237114
        entropy_coeff: 0.0
        kl: 0.007353159273043275
        model: {}
        policy_loss: -0.03166137257358059
        total_loss: 2.4200849175453185
        vf_explained_var: 0.9965318441390991
        vf_loss: 2.450275695323944
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.609375
    gpu_util_percent0: 0.2859375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.081249999999999
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550703221428815
    mean_env_wait_ms: 1.651463438051546
    mean_inference_ms: 4.6855771363783765
    mean_raw_obs_processing_ms: 0.4094023764924248
  time_since_restore: 555.0455634593964
  time_this_iter_s: 27.571341276168823
  time_total_s: 555.0455634593964
  timers:
    learn_throughput: 8208.213
    learn_time_ms: 19710.989
    sample_throughput: 20771.059
    sample_time_ms: 7789.299
    update_time_ms: 35.589
  timestamp: 1602162769
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     20 |          555.046 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-13-17
  done: false
  episode_len_mean: 816.6701557935735
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 235.22827594346575
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 182
  episodes_total: 4108
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.7638061985373497
        entropy_coeff: 0.0
        kl: 0.007330618624109775
        model: {}
        policy_loss: -0.03147139406064525
        total_loss: 1.8828283458948136
        vf_explained_var: 0.9963488578796387
        vf_loss: 1.912833634018898
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.512121212121215
    gpu_util_percent0: 0.26939393939393935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.093939393939394
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548976772280636
    mean_env_wait_ms: 1.6525637514629699
    mean_inference_ms: 4.674894397263583
    mean_raw_obs_processing_ms: 0.40883941125309264
  time_since_restore: 582.9639811515808
  time_this_iter_s: 27.91841769218445
  time_total_s: 582.9639811515808
  timers:
    learn_throughput: 8208.833
    learn_time_ms: 19709.502
    sample_throughput: 20682.718
    sample_time_ms: 7822.57
    update_time_ms: 34.663
  timestamp: 1602162797
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     21 |          582.964 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a66ba_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-08_13-13-45
  done: true
  episode_len_mean: 815.9498359118612
  episode_reward_max: 289.9797979797982
  episode_reward_mean: 235.53961319713775
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.7843831703066826
        entropy_coeff: 0.0
        kl: 0.007404250220861286
        model: {}
        policy_loss: -0.03531548953615129
        total_loss: 1.534095871448517
        vf_explained_var: 0.996734619140625
        vf_loss: 1.5679305166006088
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.2
    gpu_util_percent0: 0.26666666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.093939393939394
    vram_util_percent0: 0.14890127910790424
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48420
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1547595503397134
    mean_env_wait_ms: 1.653500753996499
    mean_inference_ms: 4.666083329815146
    mean_raw_obs_processing_ms: 0.4083720965414222
  time_since_restore: 610.8142249584198
  time_this_iter_s: 27.85024380683899
  time_total_s: 610.8142249584198
  timers:
    learn_throughput: 8188.645
    learn_time_ms: 19758.093
    sample_throughput: 20657.849
    sample_time_ms: 7831.987
    update_time_ms: 33.895
  timestamp: 1602162825
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: a66ba_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | TERMINATED |       |     22 |          610.814 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 53.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a66ba_00000 | TERMINATED |       |     22 |          610.814 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "train.py", line 68, in <module>
    train_func()
  File "train.py", line 53, in train_func
    result = analysis.dataframe().to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 89, in dataframe
    metric = self._validate_metric(metric)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 64, in _validate_metric
    raise ValueError(
ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.
