diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index d0ca168..d9fd4a8 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -67,14 +67,11 @@
     "            'clip_param': {\n",
     "                'values': [0.3, 0.5]\n",
     "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
     "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
+    "                'values': [1e-3, 5e-4, 1e-4]\n",
     "            },\n",
     "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "                'values': [20, 25]\n",
     "            }\n",
     "        }\n",
     "    }"
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index d0ca168..447e503 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 11,
    "metadata": {},
    "outputs": [
     {
@@ -67,14 +67,11 @@
     "            'clip_param': {\n",
     "                'values': [0.3, 0.5]\n",
     "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
     "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
+    "                'values': [1e-3, 5e-4, 1e-4]\n",
     "            },\n",
     "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "                'values': [20, 25]\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +79,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 12,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: q78e25ms\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\n"
      ]
     }
    ],
@@ -108,203 +105,235 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-12 07:55:17,807 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 07:55:18,127 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 07:55:18,127 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "\tentropy_coeff: 0.001\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 07:55:18,129 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.001 --num_sgd_iter=20\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33micy-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/oa6h6n34\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_075519-oa6h6n34\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 07:55:23,142 - wandb.wandb_agent - INFO - Running runs: ['oa6h6n34']\n",
+      "2020-10-12 07:55:23,655\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m F1012 07:55:25.842725 47316 47316 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35227\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a1296ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a12a84c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a1293c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a1295e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a0e0789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e241ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e242ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e24491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e26801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509da7ed6  ray::CoreWorker::CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509dabc14  ray::CoreWorkerProcess::CreateWorker()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509dace82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509dad84b  ray::CoreWorkerProcess::Initialize()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509ceb448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509cecba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df60137d  _PyObject_MakeTpCall\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df689d09  _PyEval_EvalFrameDefault\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64ebaf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64f643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5c4de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64e6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64f454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df6ddbbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df6ddc64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df70fd14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5d8625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5d8a0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5d98cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df712829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050b42e840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df6a2b33  (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=47416)\u001b[0m 2020-10-12 07:55:26,358\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=47424)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47424)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47415)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47415)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47401)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47401)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47290)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47290)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47419)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47419)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47295)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47295)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47399)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47399)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47396)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47396)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47296)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47296)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47374)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47374)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47303)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47303)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47293)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47293)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47305)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47305)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47389)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47389)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47360)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47360)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47291)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47291)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47302)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47302)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47367)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47367)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47403)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47403)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_07-55-56\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,23 +341,23 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        entropy: 1.1858798464139302\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.004064181082261105\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
+      "        policy_loss: -0.006395086013526452\n",
+      "        total_loss: 514.7333170572916\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -336,65 +365,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 33.325\n",
+      "    gpu_util_percent0: 0.2092857142857143\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.521428571428572\n",
+      "    vram_util_percent0: 0.0827847537834419\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.1714163571458129\n",
+      "    mean_env_wait_ms: 1.1807994247771\n",
+      "    mean_inference_ms: 6.147634724696208\n",
+      "    mean_raw_obs_processing_ms: 0.4624706714673703\n",
+      "  time_since_restore: 24.50074791908264\n",
+      "  time_this_iter_s: 24.50074791908264\n",
+      "  time_total_s: 24.50074791908264\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 10802.415\n",
+      "    learn_time_ms: 14977.391\n",
+      "    sample_throughput: 17107.315\n",
+      "    sample_time_ms: 9457.475\n",
+      "    update_time_ms: 31.281\n",
+      "  timestamp: 1602489356\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      1 |          24.5007 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3627.0208333333335\n",
+      "    time_step_min: 3371\n",
+      "  date: 2020-10-12_07-56-18\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 890.1550632911392\n",
+      "  episode_reward_max: 261.3232323232323\n",
+      "  episode_reward_mean: 216.59365809998698\n",
+      "  episode_reward_min: 136.92929292929247\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -403,14 +432,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        entropy: 1.1566268702348073\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0074133020437632995\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.006318914315973719\n",
+      "        total_loss: 150.94015757242838\n",
+      "        vf_explained_var: 0.7832780480384827\n",
+      "        vf_loss: 150.94689814249674\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,65 +447,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 30.403846153846153\n",
+      "    gpu_util_percent0: 0.2919230769230769\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.738461538461538\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.16644640977929873\n",
+      "    mean_env_wait_ms: 1.1752532318633375\n",
+      "    mean_inference_ms: 5.803889831603577\n",
+      "    mean_raw_obs_processing_ms: 0.44867825635494135\n",
+      "  time_since_restore: 46.78164482116699\n",
+      "  time_this_iter_s: 22.28089690208435\n",
+      "  time_total_s: 46.78164482116699\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 10923.565\n",
+      "    learn_time_ms: 14811.282\n",
+      "    sample_throughput: 19007.513\n",
+      "    sample_time_ms: 8512.003\n",
+      "    update_time_ms: 24.435\n",
+      "  timestamp: 1602489378\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      2 |          46.7816 | 323584 |  216.594 |              261.323 |              136.929 |            890.155 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3626.109865470852\n",
+      "    time_step_min: 3272\n",
+      "  date: 2020-10-12_07-56-40\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 884.9831223628692\n",
+      "  episode_reward_max: 270.2626262626259\n",
+      "  episode_reward_mean: 216.85513361462705\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -485,14 +514,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        entropy: 1.1470215519269307\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00852755201049149\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.009047169092809781\n",
+      "        total_loss: 76.8135159810384\n",
+      "        vf_explained_var: 0.8726572394371033\n",
+      "        vf_loss: 76.82285753885905\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,65 +529,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 29.192000000000004\n",
+      "    gpu_util_percent0: 0.3004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16333984937915608\n",
+      "    mean_env_wait_ms: 1.1739520111463604\n",
+      "    mean_inference_ms: 5.565249658448001\n",
+      "    mean_raw_obs_processing_ms: 0.4384964806056524\n",
+      "  time_since_restore: 68.35362577438354\n",
+      "  time_this_iter_s: 21.571980953216553\n",
+      "  time_total_s: 68.35362577438354\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 11013.223\n",
+      "    learn_time_ms: 14690.705\n",
+      "    sample_throughput: 20158.612\n",
+      "    sample_time_ms: 8025.949\n",
+      "    update_time_ms: 22.645\n",
+      "  timestamp: 1602489400\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      3 |          68.3536 | 485376 |  216.855 |              270.263 |              131.475 |            884.983 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3616.112582781457\n",
+      "    time_step_min: 3272\n",
+      "  date: 2020-10-12_07-57-01\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 880.873417721519\n",
+      "  episode_reward_max: 270.2626262626259\n",
+      "  episode_reward_mean: 217.44137578314778\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -567,14 +596,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        entropy: 1.1285836795965831\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00767273692569385\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.010500759337446652\n",
+      "        total_loss: 59.14047654469808\n",
+      "        vf_explained_var: 0.8996696472167969\n",
+      "        vf_loss: 59.15133762359619\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,65 +611,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 28.415999999999993\n",
+      "    gpu_util_percent0: 0.2936\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.16111490150136074\n",
+      "    mean_env_wait_ms: 1.1737004337712953\n",
+      "    mean_inference_ms: 5.3947826177609235\n",
+      "    mean_raw_obs_processing_ms: 0.430652089513709\n",
+      "  time_since_restore: 89.98465132713318\n",
+      "  time_this_iter_s: 21.631025552749634\n",
+      "  time_total_s: 89.98465132713318\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 10998.429\n",
+      "    learn_time_ms: 14710.464\n",
+      "    sample_throughput: 20976.687\n",
+      "    sample_time_ms: 7712.944\n",
+      "    update_time_ms: 25.621\n",
+      "  timestamp: 1602489421\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      4 |          89.9847 | 647168 |  217.441 |              270.263 |              131.475 |            880.873 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3609.715223097113\n",
+      "    time_step_min: 3272\n",
+      "  date: 2020-10-12_07-57-23\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 876.7126582278481\n",
+      "  episode_reward_max: 270.86868686868655\n",
+      "  episode_reward_mean: 219.01483186293294\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -649,14 +678,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        entropy: 1.0982058942317963\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007201045867986977\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.010341917989232266\n",
+      "        total_loss: 42.64804267883301\n",
+      "        vf_explained_var: 0.9292742609977722\n",
+      "        vf_loss: 42.65876293182373\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,65 +693,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 28.268\n",
+      "    gpu_util_percent0: 0.41200000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.15946129373348403\n",
+      "    mean_env_wait_ms: 1.1745178858430907\n",
+      "    mean_inference_ms: 5.267336295216427\n",
+      "    mean_raw_obs_processing_ms: 0.42471797495802377\n",
+      "  time_since_restore: 111.63249826431274\n",
+      "  time_this_iter_s: 21.647846937179565\n",
+      "  time_total_s: 111.63249826431274\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 10988.215\n",
+      "    learn_time_ms: 14724.138\n",
+      "    sample_throughput: 21486.438\n",
+      "    sample_time_ms: 7529.959\n",
+      "    update_time_ms: 24.854\n",
+      "  timestamp: 1602489443\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      5 |          111.632 | 808960 |  219.015 |              270.869 |              131.475 |            876.713 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3587.309412861137\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-57-45\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 867.2933696639419\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 222.83136542537073\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 311\n",
+      "  episodes_total: 1101\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -731,14 +760,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        entropy: 1.089649925629298\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007361165403078\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.009514839436936503\n",
+      "        total_loss: 46.27031675974528\n",
+      "        vf_explained_var: 0.943225085735321\n",
+      "        vf_loss: 46.28018538157145\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,65 +775,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 27.864000000000004\n",
+      "    gpu_util_percent0: 0.3748\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15725032607004152\n",
+      "    mean_env_wait_ms: 1.1776184097035538\n",
+      "    mean_inference_ms: 5.098571486930799\n",
+      "    mean_raw_obs_processing_ms: 0.4170828285387513\n",
+      "  time_since_restore: 133.61357593536377\n",
+      "  time_this_iter_s: 21.981077671051025\n",
+      "  time_total_s: 133.61357593536377\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 10942.983\n",
+      "    learn_time_ms: 14784.999\n",
+      "    sample_throughput: 21830.619\n",
+      "    sample_time_ms: 7411.242\n",
+      "    update_time_ms: 23.625\n",
+      "  timestamp: 1602489465\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      6 |          133.614 | 970752 |  222.831 |               279.96 |              131.475 |            867.293 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3576.204692556634\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-58-07\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 863.2911392405064\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 224.62120412990652\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 163\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -813,14 +842,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        entropy: 1.078253577152888\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00760688950928549\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.00808424704397718\n",
+      "        total_loss: 24.090112050374348\n",
+      "        vf_explained_var: 0.9561929702758789\n",
+      "        vf_loss: 24.098513921101887\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,65 +857,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 28.566666666666666\n",
+      "    gpu_util_percent0: 0.29375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7708333333333335\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.1564654163893213\n",
+      "    mean_env_wait_ms: 1.1790260759751634\n",
+      "    mean_inference_ms: 5.035471631648462\n",
+      "    mean_raw_obs_processing_ms: 0.4142370056618957\n",
+      "  time_since_restore: 155.21138048171997\n",
+      "  time_this_iter_s: 21.5978045463562\n",
+      "  time_total_s: 155.21138048171997\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 10958.033\n",
+      "    learn_time_ms: 14764.693\n",
+      "    sample_throughput: 22056.652\n",
+      "    sample_time_ms: 7335.293\n",
+      "    update_time_ms: 23.414\n",
+      "  timestamp: 1602489487\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      7 |          155.211 | 1132544 |  224.621 |               279.96 |              131.475 |            863.291 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3563.761836441894\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-58-28\n",
       "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 859.7215189873418\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 226.28391510037065\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -895,14 +924,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
+      "        entropy: 1.0665611525376637\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007063437098016341\n",
       "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
+      "        policy_loss: -0.011236034988542087\n",
+      "        total_loss: 23.269086996714275\n",
+      "        vf_explained_var: 0.9564061164855957\n",
+      "        vf_loss: 23.280683676401775\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -910,65 +939,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
+      "    cpu_util_percent: 28.136\n",
+      "    gpu_util_percent0: 0.2932\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
+      "    mean_action_processing_ms: 0.15580133340075322\n",
+      "    mean_env_wait_ms: 1.180217866621754\n",
+      "    mean_inference_ms: 4.983044491631497\n",
+      "    mean_raw_obs_processing_ms: 0.411793605828682\n",
+      "  time_since_restore: 176.72998452186584\n",
+      "  time_this_iter_s: 21.518604040145874\n",
+      "  time_total_s: 176.72998452186584\n",
       "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
+      "    learn_throughput: 10960.775\n",
+      "    learn_time_ms: 14761.0\n",
+      "    sample_throughput: 22300.07\n",
+      "    sample_time_ms: 7255.224\n",
+      "    update_time_ms: 25.162\n",
+      "  timestamp: 1602489508\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      8 |           176.73 | 1294336 |  226.284 |               279.96 |              131.475 |            859.722 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3554.637886597938\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-58-50\n",
       "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 856.3879746835443\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 227.5292162127604\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -977,14 +1006,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
+      "        entropy: 1.0308950543403625\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0075525245629251\n",
       "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
+      "        policy_loss: -0.009404902209401675\n",
+      "        total_loss: 19.759908358256023\n",
+      "        vf_explained_var: 0.9632963538169861\n",
+      "        vf_loss: 19.769589106241863\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -992,65 +1021,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
+      "    cpu_util_percent: 27.592\n",
+      "    gpu_util_percent0: 0.4132\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7640000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
+      "    mean_action_processing_ms: 0.15522609255515757\n",
+      "    mean_env_wait_ms: 1.1813788429250602\n",
+      "    mean_inference_ms: 4.93757485426149\n",
+      "    mean_raw_obs_processing_ms: 0.4096284903807881\n",
+      "  time_since_restore: 198.41875982284546\n",
+      "  time_this_iter_s: 21.688775300979614\n",
+      "  time_total_s: 198.41875982284546\n",
       "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
+      "    learn_throughput: 10952.147\n",
+      "    learn_time_ms: 14772.628\n",
+      "    sample_throughput: 22477.809\n",
+      "    sample_time_ms: 7197.855\n",
+      "    update_time_ms: 25.989\n",
+      "  timestamp: 1602489530\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      9 |          198.419 | 1456128 |  227.529 |               279.96 |              131.475 |            856.388 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3536.35698808234\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_07-59-12\n",
       "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 849.9642475987193\n",
+      "  episode_reward_max: 288.59595959595976\n",
+      "  episode_reward_mean: 230.30434548257375\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 294\n",
+      "  episodes_total: 1874\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1059,14 +1088,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
+      "        entropy: 1.0002753188212712\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007455945403004686\n",
       "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
+      "        policy_loss: -0.010204158699101148\n",
+      "        total_loss: 24.197932084401447\n",
+      "        vf_explained_var: 0.9683513641357422\n",
+      "        vf_loss: 24.208391030629475\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -1074,65 +1103,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
+      "    cpu_util_percent: 27.928\n",
+      "    gpu_util_percent0: 0.29960000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.756\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
+      "    mean_action_processing_ms: 0.15436430506291107\n",
+      "    mean_env_wait_ms: 1.1838305992833973\n",
+      "    mean_inference_ms: 4.868544754944554\n",
+      "    mean_raw_obs_processing_ms: 0.4063909084512901\n",
+      "  time_since_restore: 220.12364220619202\n",
+      "  time_this_iter_s: 21.704882383346558\n",
+      "  time_total_s: 220.12364220619202\n",
       "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
+      "    learn_throughput: 10949.037\n",
+      "    learn_time_ms: 14776.825\n",
+      "    sample_throughput: 22602.127\n",
+      "    sample_time_ms: 7158.264\n",
+      "    update_time_ms: 26.962\n",
+      "  timestamp: 1602489552\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     10 |          220.124 | 1617920 |  230.304 |              288.596 |              131.475 |            849.964 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3525.1461006910167\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_07-59-34\n",
       "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
+      "  episode_len_mean: 846.1324245374879\n",
+      "  episode_reward_max: 288.59595959595976\n",
+      "  episode_reward_mean: 232.04503162098086\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 180\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1141,14 +1170,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
+      "        entropy: 0.9904046803712845\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00673914875369519\n",
       "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
+      "        policy_loss: -0.00991532149297806\n",
+      "        total_loss: 13.990095853805542\n",
+      "        vf_explained_var: 0.9738118648529053\n",
+      "        vf_loss: 14.000327746073404\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -1156,65 +1185,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
+      "    cpu_util_percent: 28.933333333333334\n",
+      "    gpu_util_percent0: 0.29000000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.775\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
+      "    mean_action_processing_ms: 0.15391489145310477\n",
+      "    mean_env_wait_ms: 1.1852050260285005\n",
+      "    mean_inference_ms: 4.834181265578874\n",
+      "    mean_raw_obs_processing_ms: 0.4047779605513047\n",
+      "  time_since_restore: 241.79468941688538\n",
+      "  time_this_iter_s: 21.67104721069336\n",
+      "  time_total_s: 241.79468941688538\n",
       "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
+      "    learn_throughput: 10963.723\n",
+      "    learn_time_ms: 14757.031\n",
+      "    sample_throughput: 23472.344\n",
+      "    sample_time_ms: 6892.878\n",
+      "    update_time_ms: 27.456\n",
+      "  timestamp: 1602489574\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     11 |          241.795 | 1779712 |  232.045 |              288.596 |              131.475 |            846.132 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3516.3241758241757\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_07-59-56\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 843.4877938517179\n",
+      "  episode_reward_max: 288.59595959595976\n",
+      "  episode_reward_mean: 233.29224432388978\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1223,14 +1252,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
+      "        entropy: 0.9801873713731766\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006010051351040602\n",
       "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
+      "        policy_loss: -0.009126228047534823\n",
+      "        total_loss: 15.280177116394043\n",
+      "        vf_explained_var: 0.97007817029953\n",
+      "        vf_loss: 15.289682388305664\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -1238,65 +1267,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
+      "    cpu_util_percent: 27.676923076923075\n",
+      "    gpu_util_percent0: 0.3492307692307693\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7576923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
+      "    mean_action_processing_ms: 0.15356980009174312\n",
+      "    mean_env_wait_ms: 1.1862927867683948\n",
+      "    mean_inference_ms: 4.807153098875207\n",
+      "    mean_raw_obs_processing_ms: 0.40347536671037615\n",
+      "  time_since_restore: 263.58598041534424\n",
+      "  time_this_iter_s: 21.791290998458862\n",
+      "  time_total_s: 263.58598041534424\n",
       "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
+      "    learn_throughput: 10959.991\n",
+      "    learn_time_ms: 14762.056\n",
+      "    sample_throughput: 23687.883\n",
+      "    sample_time_ms: 6830.159\n",
+      "    update_time_ms: 27.684\n",
+      "  timestamp: 1602489596\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     12 |          263.586 | 1941504 |  233.292 |              288.596 |              131.475 |            843.488 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3509.2247334754798\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-00-17\n",
       "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 841.2806573957016\n",
+      "  episode_reward_max: 289.2020202020203\n",
+      "  episode_reward_mean: 234.43851919958107\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 2373\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1305,14 +1334,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
+      "        entropy: 0.9412872145573298\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006324911878133814\n",
       "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
+      "        policy_loss: -0.009316468562853212\n",
+      "        total_loss: 15.226327737172445\n",
+      "        vf_explained_var: 0.9722931385040283\n",
+      "        vf_loss: 15.235953092575073\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -1320,65 +1349,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
+      "    cpu_util_percent: 28.983333333333334\n",
+      "    gpu_util_percent0: 0.27166666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7708333333333335\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
+      "    mean_action_processing_ms: 0.15325367165896728\n",
+      "    mean_env_wait_ms: 1.187351681010106\n",
+      "    mean_inference_ms: 4.7823496059783706\n",
+      "    mean_raw_obs_processing_ms: 0.4022524139138643\n",
+      "  time_since_restore: 285.0491192340851\n",
+      "  time_this_iter_s: 21.463138818740845\n",
+      "  time_total_s: 285.0491192340851\n",
       "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
+      "    learn_throughput: 10948.329\n",
+      "    learn_time_ms: 14777.781\n",
+      "    sample_throughput: 23786.854\n",
+      "    sample_time_ms: 6801.74\n",
+      "    update_time_ms: 29.054\n",
+      "  timestamp: 1602489617\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     13 |          285.049 | 2103296 |  234.439 |              289.202 |              131.475 |            841.281 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3494.709811320755\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-00-39\n",
       "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 837.9985063480209\n",
+      "  episode_reward_max: 289.2020202020203\n",
+      "  episode_reward_mean: 236.4201499686936\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 305\n",
+      "  episodes_total: 2678\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1387,14 +1416,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
+      "        entropy: 0.9193607121706009\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005588505533523858\n",
       "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
+      "        policy_loss: -0.008722007876106849\n",
+      "        total_loss: 18.580758730570476\n",
+      "        vf_explained_var: 0.9753453135490417\n",
+      "        vf_loss: 18.589841842651367\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -1402,65 +1431,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
+      "    cpu_util_percent: 28.628\n",
+      "    gpu_util_percent0: 0.2636\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.748\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
+      "    mean_action_processing_ms: 0.1527339914723438\n",
+      "    mean_env_wait_ms: 1.1892359688684517\n",
+      "    mean_inference_ms: 4.741593468063049\n",
+      "    mean_raw_obs_processing_ms: 0.40029834826674837\n",
+      "  time_since_restore: 306.7374804019928\n",
+      "  time_this_iter_s: 21.688361167907715\n",
+      "  time_total_s: 306.7374804019928\n",
       "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
+      "    learn_throughput: 10956.442\n",
+      "    learn_time_ms: 14766.838\n",
+      "    sample_throughput: 23724.753\n",
+      "    sample_time_ms: 6819.544\n",
+      "    update_time_ms: 27.668\n",
+      "  timestamp: 1602489639\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     14 |          306.737 | 2265088 |   236.42 |              289.202 |              131.475 |            837.999 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3488.3952414772725\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-01-01\n",
       "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 836.292194092827\n",
+      "  episode_reward_max: 289.35353535353516\n",
+      "  episode_reward_mean: 237.4111686485104\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 166\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1469,14 +1498,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
+      "        entropy: 0.9131054629882177\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005497211551604171\n",
       "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
+      "        policy_loss: -0.007378635054919869\n",
+      "        total_loss: 11.72153385480245\n",
+      "        vf_explained_var: 0.9775063991546631\n",
+      "        vf_loss: 11.729275782903036\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -1484,65 +1513,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
+      "    cpu_util_percent: 27.951999999999998\n",
+      "    gpu_util_percent0: 0.30200000000000005\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7720000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
+      "    mean_action_processing_ms: 0.1524858565651682\n",
+      "    mean_env_wait_ms: 1.1901572464312566\n",
+      "    mean_inference_ms: 4.7225269139524615\n",
+      "    mean_raw_obs_processing_ms: 0.39938440810721976\n",
+      "  time_since_restore: 328.52804470062256\n",
+      "  time_this_iter_s: 21.79056429862976\n",
+      "  time_total_s: 328.52804470062256\n",
       "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
+      "    learn_throughput: 10963.331\n",
+      "    learn_time_ms: 14757.558\n",
+      "    sample_throughput: 23645.81\n",
+      "    sample_time_ms: 6842.311\n",
+      "    update_time_ms: 27.3\n",
+      "  timestamp: 1602489661\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     15 |          328.528 | 2426880 |  237.411 |              289.354 |              131.475 |            836.292 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3483.3301950235373\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-01-23\n",
       "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 834.7891405729514\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 238.28404632601823\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1551,14 +1580,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
+      "        entropy: 0.9084820051987966\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006018294564758738\n",
       "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
+      "        policy_loss: -0.007524173070123652\n",
+      "        total_loss: 12.962319930394491\n",
+      "        vf_explained_var: 0.9735670685768127\n",
+      "        vf_loss: 12.97015110651652\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -1566,65 +1595,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
+      "    cpu_util_percent: 28.04\n",
+      "    gpu_util_percent0: 0.3156\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
+      "    mean_action_processing_ms: 0.15227382725048905\n",
+      "    mean_env_wait_ms: 1.19098373725698\n",
+      "    mean_inference_ms: 4.705735246407954\n",
+      "    mean_raw_obs_processing_ms: 0.39857025145429437\n",
+      "  time_since_restore: 350.29178285598755\n",
+      "  time_this_iter_s: 21.76373815536499\n",
+      "  time_total_s: 350.29178285598755\n",
       "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
+      "    learn_throughput: 10974.293\n",
+      "    learn_time_ms: 14742.818\n",
+      "    sample_throughput: 23676.909\n",
+      "    sample_time_ms: 6833.324\n",
+      "    update_time_ms: 29.076\n",
+      "  timestamp: 1602489683\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     16 |          350.292 | 2588672 |  238.284 |              290.566 |              131.475 |            834.789 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3477.5213404995256\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-01-45\n",
       "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 832.9103729238483\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 239.1295626272122\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 189\n",
+      "  episodes_total: 3191\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1633,14 +1662,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
+      "        entropy: 0.8652510742346445\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005546345414283375\n",
       "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
+      "        policy_loss: -0.009394650240816796\n",
+      "        total_loss: 15.037363767623901\n",
+      "        vf_explained_var: 0.975414514541626\n",
+      "        vf_loss: 15.047069152196249\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -1648,65 +1677,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
+      "    cpu_util_percent: 27.28\n",
+      "    gpu_util_percent0: 0.3452\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
+      "    mean_action_processing_ms: 0.152045327822301\n",
+      "    mean_env_wait_ms: 1.1919710779649575\n",
+      "    mean_inference_ms: 4.687307194280671\n",
+      "    mean_raw_obs_processing_ms: 0.39768841070955224\n",
+      "  time_since_restore: 372.28986644744873\n",
+      "  time_this_iter_s: 21.99808359146118\n",
+      "  time_total_s: 372.28986644744873\n",
       "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
+      "    learn_throughput: 10951.776\n",
+      "    learn_time_ms: 14773.128\n",
+      "    sample_throughput: 23646.205\n",
+      "    sample_time_ms: 6842.197\n",
+      "    update_time_ms: 29.179\n",
+      "  timestamp: 1602489705\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     17 |           372.29 | 2750464 |   239.13 |              290.566 |              131.475 |             832.91 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3470.0330818340103\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-02-07\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 830.6729994242947\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 240.3484150660316\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 283\n",
+      "  episodes_total: 3474\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1715,14 +1744,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
+      "        entropy: 0.8562458703915278\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0056136711888636155\n",
       "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
+      "        policy_loss: -0.008814311237074435\n",
+      "        total_loss: 12.922985871632894\n",
+      "        vf_explained_var: 0.9803910255432129\n",
+      "        vf_loss: 12.932095050811768\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -1730,65 +1759,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
+      "    cpu_util_percent: 28.131999999999998\n",
+      "    gpu_util_percent0: 0.3864\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.752\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
+      "    mean_action_processing_ms: 0.15173502064916347\n",
+      "    mean_env_wait_ms: 1.1933266139357905\n",
+      "    mean_inference_ms: 4.662769914171586\n",
+      "    mean_raw_obs_processing_ms: 0.3964979335973578\n",
+      "  time_since_restore: 394.223580121994\n",
+      "  time_this_iter_s: 21.933713674545288\n",
+      "  time_total_s: 394.223580121994\n",
       "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
+      "    learn_throughput: 10942.497\n",
+      "    learn_time_ms: 14785.656\n",
+      "    sample_throughput: 23545.734\n",
+      "    sample_time_ms: 6871.393\n",
+      "    update_time_ms: 27.489\n",
+      "  timestamp: 1602489727\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     18 |          394.224 | 2912256 |  240.348 |              290.566 |              131.475 |            830.673 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3465.9986134220744\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-02-29\n",
       "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
+      "  episode_len_mean: 829.3965327462851\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 240.93648093482983\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 160\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1797,14 +1826,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
+      "        entropy: 0.8458269933859507\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005238918277124564\n",
       "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
+      "        policy_loss: -0.008863923489116132\n",
+      "        total_loss: 11.462480147679647\n",
+      "        vf_explained_var: 0.9772316813468933\n",
+      "        vf_loss: 11.47166625658671\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -1812,65 +1841,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    cpu_util_percent: 28.348\n",
+      "    gpu_util_percent0: 0.2864\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
+      "    mean_action_processing_ms: 0.15157817273439375\n",
+      "    mean_env_wait_ms: 1.194051067524682\n",
+      "    mean_inference_ms: 4.650287496491038\n",
+      "    mean_raw_obs_processing_ms: 0.3958943252438647\n",
+      "  time_since_restore: 415.73195481300354\n",
+      "  time_this_iter_s: 21.50837469100952\n",
+      "  time_total_s: 415.73195481300354\n",
       "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
+      "    learn_throughput: 10966.22\n",
+      "    learn_time_ms: 14753.671\n",
+      "    sample_throughput: 23498.986\n",
+      "    sample_time_ms: 6885.063\n",
+      "    update_time_ms: 26.453\n",
+      "  timestamp: 1602489749\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     19 |          415.732 | 3074048 |  240.936 |              290.566 |              131.475 |            829.397 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3461.7851261620185\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-02-51\n",
       "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 828.2813076720274\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 241.56190963151147\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 3793\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1879,14 +1908,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
+      "        entropy: 0.8354400197664896\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006724536186084151\n",
       "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
+      "        policy_loss: -0.00911139192370077\n",
+      "        total_loss: 11.11555004119873\n",
+      "        vf_explained_var: 0.9771101474761963\n",
+      "        vf_loss: 11.1248246828715\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -1894,65 +1923,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
+      "    cpu_util_percent: 27.765384615384612\n",
+      "    gpu_util_percent0: 0.42576923076923073\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
+      "    mean_action_processing_ms: 0.15143153977037152\n",
+      "    mean_env_wait_ms: 1.19475205207732\n",
+      "    mean_inference_ms: 4.638693538397803\n",
+      "    mean_raw_obs_processing_ms: 0.39532808620572457\n",
+      "  time_since_restore: 437.7973186969757\n",
+      "  time_this_iter_s: 22.065363883972168\n",
+      "  time_total_s: 437.7973186969757\n",
       "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
+      "    learn_throughput: 10956.318\n",
+      "    learn_time_ms: 14767.004\n",
+      "    sample_throughput: 23424.906\n",
+      "    sample_time_ms: 6906.837\n",
+      "    update_time_ms: 25.358\n",
+      "  timestamp: 1602489771\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     20 |          437.797 | 3235840 |  241.562 |              290.566 |              131.475 |            828.281 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3454.446708074534\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-03-13\n",
       "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 826.1258327165062\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 242.65150393647795\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 260\n",
+      "  episodes_total: 4053\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1961,14 +1990,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
+      "        entropy: 0.8038722376028696\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005003524556135138\n",
       "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
+      "        policy_loss: -0.007377958051317061\n",
+      "        total_loss: 13.692698876063028\n",
+      "        vf_explained_var: 0.9796187877655029\n",
+      "        vf_loss: 13.700380086898804\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -1976,65 +2005,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
+      "    cpu_util_percent: 28.34\n",
+      "    gpu_util_percent0: 0.42400000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.752\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
+      "    mean_action_processing_ms: 0.15121696352248112\n",
+      "    mean_env_wait_ms: 1.1958913902831356\n",
+      "    mean_inference_ms: 4.621158716371925\n",
+      "    mean_raw_obs_processing_ms: 0.39449719521269605\n",
+      "  time_since_restore: 459.43015336990356\n",
+      "  time_this_iter_s: 21.632834672927856\n",
+      "  time_total_s: 459.43015336990356\n",
       "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
+      "    learn_throughput: 10961.455\n",
+      "    learn_time_ms: 14760.085\n",
+      "    sample_throughput: 23418.203\n",
+      "    sample_time_ms: 6908.814\n",
+      "    update_time_ms: 25.193\n",
+      "  timestamp: 1602489793\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     21 |           459.43 | 3397632 |  242.652 |              290.566 |              131.475 |            826.126 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3448.8378952336006\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-03-35\n",
       "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.4301453352086\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 243.4875974939266\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2043,14 +2072,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
+      "        entropy: 0.7977566868066788\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005455355780820052\n",
       "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
+      "        policy_loss: -0.00767945071614425\n",
+      "        total_loss: 10.277512709299723\n",
+      "        vf_explained_var: 0.9814075827598572\n",
+      "        vf_loss: 10.285443782806396\n",
       "    num_steps_sampled: 3559424\n",
       "    num_steps_trained: 3559424\n",
       "  iterations_since_restore: 22\n",
@@ -2058,65 +2087,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
+      "    cpu_util_percent: 28.120000000000005\n",
+      "    gpu_util_percent0: 0.3268\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.752\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
+      "    mean_action_processing_ms: 0.15104737207579993\n",
+      "    mean_env_wait_ms: 1.1967581522595114\n",
+      "    mean_inference_ms: 4.608215003769806\n",
+      "    mean_raw_obs_processing_ms: 0.39386805388018364\n",
+      "  time_since_restore: 481.1195831298828\n",
+      "  time_this_iter_s: 21.689429759979248\n",
+      "  time_total_s: 481.1195831298828\n",
       "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
+      "    learn_throughput: 10962.993\n",
+      "    learn_time_ms: 14758.014\n",
+      "    sample_throughput: 23448.37\n",
+      "    sample_time_ms: 6899.925\n",
+      "    update_time_ms: 25.154\n",
+      "  timestamp: 1602489815\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3559424\n",
       "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     22 |           481.12 | 3559424 |  243.488 |              290.566 |              131.475 |             824.43 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3444.6345235387766\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-03-57\n",
       "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
-      "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 823.2205649717514\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 244.06426981681216\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 4425\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2125,14 +2154,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
+      "        entropy: 0.8060282667477926\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005679386241051058\n",
       "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
+      "        policy_loss: -0.010035674378741533\n",
+      "        total_loss: 10.034321387608847\n",
+      "        vf_explained_var: 0.978935182094574\n",
+      "        vf_loss: 10.044595638910929\n",
       "    num_steps_sampled: 3721216\n",
       "    num_steps_trained: 3721216\n",
       "  iterations_since_restore: 23\n",
@@ -2140,65 +2169,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
+      "    cpu_util_percent: 28.368000000000002\n",
+      "    gpu_util_percent0: 0.29960000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
+      "    mean_action_processing_ms: 0.15093291820308186\n",
+      "    mean_env_wait_ms: 1.1973932493733186\n",
+      "    mean_inference_ms: 4.599187677452534\n",
+      "    mean_raw_obs_processing_ms: 0.3934317186327627\n",
+      "  time_since_restore: 502.85791778564453\n",
+      "  time_this_iter_s: 21.73833465576172\n",
+      "  time_total_s: 502.85791778564453\n",
       "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
+      "    learn_throughput: 10957.609\n",
+      "    learn_time_ms: 14765.265\n",
+      "    sample_throughput: 23407.54\n",
+      "    sample_time_ms: 6911.961\n",
+      "    update_time_ms: 23.641\n",
+      "  timestamp: 1602489837\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3721216\n",
       "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     23 |          502.858 | 3721216 |  244.064 |              290.566 |              131.475 |            823.221 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3439.959219088937\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-04-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.3749460974558\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 244.75604035177128\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 4638\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2207,14 +2236,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
+      "        entropy: 0.7703086733818054\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005429171995880703\n",
       "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
+      "        policy_loss: -0.007289163496655722\n",
+      "        total_loss: 12.348905007044474\n",
+      "        vf_explained_var: 0.979224681854248\n",
+      "        vf_loss: 12.356421629587809\n",
       "    num_steps_sampled: 3883008\n",
       "    num_steps_trained: 3883008\n",
       "  iterations_since_restore: 24\n",
@@ -2222,303 +2251,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
+      "    cpu_util_percent: 28.8125\n",
+      "    gpu_util_percent0: 0.43249999999999994\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7541666666666664\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
+      "    mean_action_processing_ms: 0.15079284947059365\n",
+      "    mean_env_wait_ms: 1.1982450189298106\n",
+      "    mean_inference_ms: 4.587776541874426\n",
+      "    mean_raw_obs_processing_ms: 0.3928856835406434\n",
+      "  time_since_restore: 524.5500221252441\n",
+      "  time_this_iter_s: 21.69210433959961\n",
+      "  time_total_s: 524.5500221252441\n",
       "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
+      "    learn_throughput: 10957.433\n",
+      "    learn_time_ms: 14765.502\n",
+      "    sample_throughput: 23416.047\n",
+      "    sample_time_ms: 6909.45\n",
+      "    update_time_ms: 25.924\n",
+      "  timestamp: 1602489858\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3883008\n",
       "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     24 |           524.55 | 3883008 |  244.756 |              290.566 |              131.475 |            821.375 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3434.701314708299\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-04-41\n",
       "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 819.6397058823529\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 245.61130298078825\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 258\n",
+      "  episodes_total: 4896\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2527,244 +2318,1711 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
+      "        entropy: 0.7541884630918503\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.004939307885554929\n",
       "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
-      "        vf_explained_var: 0.5664147734642029\n",
-      "        vf_loss: 502.24672444661456\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.008982530465194335\n",
+      "        total_loss: 9.952500502268473\n",
+      "        vf_explained_var: 0.9837613105773926\n",
+      "        vf_loss: 9.961743275324503\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
+      "    cpu_util_percent: 26.99230769230769\n",
+      "    gpu_util_percent0: 0.29961538461538456\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
+      "    ram_util_percent: 3.75\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
+      "    mean_action_processing_ms: 0.15062599456951525\n",
+      "    mean_env_wait_ms: 1.1992428855480324\n",
+      "    mean_inference_ms: 4.575118912763768\n",
+      "    mean_raw_obs_processing_ms: 0.39227961602231826\n",
+      "  time_since_restore: 546.621901512146\n",
+      "  time_this_iter_s: 22.071879386901855\n",
+      "  time_total_s: 546.621901512146\n",
       "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
+      "    learn_throughput: 10944.955\n",
+      "    learn_time_ms: 14782.336\n",
+      "    sample_throughput: 23415.435\n",
+      "    sample_time_ms: 6909.63\n",
+      "    update_time_ms: 27.731\n",
+      "  timestamp: 1602489881\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     25 |          546.622 | 4044800 |  245.611 |              290.566 |              131.475 |             819.64 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3431.5177008750993\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-05-02\n",
       "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 818.6079905063291\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 246.10366121659632\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 5056\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
+      "        entropy: 0.7627150317033132\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006050152898145218\n",
       "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.009301517896043757\n",
+      "        total_loss: 8.128399848937988\n",
+      "        vf_explained_var: 0.9824613928794861\n",
+      "        vf_loss: 8.138161698977152\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
+      "    cpu_util_percent: 28.45416666666667\n",
+      "    gpu_util_percent0: 0.245\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7708333333333335\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
+      "    mean_action_processing_ms: 0.1505320904163101\n",
+      "    mean_env_wait_ms: 1.1998304190756985\n",
+      "    mean_inference_ms: 4.567782822219138\n",
+      "    mean_raw_obs_processing_ms: 0.3919296307204451\n",
+      "  time_since_restore: 568.2212522029877\n",
+      "  time_this_iter_s: 21.599350690841675\n",
+      "  time_total_s: 568.2212522029877\n",
       "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
+      "    learn_throughput: 10956.324\n",
+      "    learn_time_ms: 14766.997\n",
+      "    sample_throughput: 23417.631\n",
+      "    sample_time_ms: 6908.982\n",
+      "    update_time_ms: 26.463\n",
+      "  timestamp: 1602489902\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     26 |          568.221 | 4206592 |  246.104 |              290.566 |              131.475 |            818.608 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3428.084934665642\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-05-24\n",
       "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 817.4225917431193\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 246.58821008247608\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 176\n",
+      "  episodes_total: 5232\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
+      "        entropy: 0.7432082245747248\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005775055265985429\n",
       "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.009028180410192968\n",
+      "        total_loss: 9.281757434209188\n",
+      "        vf_explained_var: 0.982418954372406\n",
+      "        vf_loss: 9.291240135828653\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
+      "    cpu_util_percent: 28.484000000000005\n",
+      "    gpu_util_percent0: 0.29919999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
+      "    mean_action_processing_ms: 0.15043915088222498\n",
+      "    mean_env_wait_ms: 1.2004804583814097\n",
+      "    mean_inference_ms: 4.56007833511155\n",
+      "    mean_raw_obs_processing_ms: 0.3915655176555837\n",
+      "  time_since_restore: 589.9885222911835\n",
+      "  time_this_iter_s: 21.7672700881958\n",
+      "  time_total_s: 589.9885222911835\n",
       "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
+      "    learn_throughput: 10958.884\n",
+      "    learn_time_ms: 14763.547\n",
+      "    sample_throughput: 23485.785\n",
+      "    sample_time_ms: 6888.933\n",
+      "    update_time_ms: 26.0\n",
+      "  timestamp: 1602489924\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     27 |          589.989 | 4368384 |  246.588 |              290.566 |              131.475 |            817.423 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3423.254469171835\n",
+      "    time_step_min: 3145\n",
+      "  date: 2020-10-12_08-05-46\n",
+      "  done: true\n",
+      "  episode_len_mean: 815.7878402903812\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 247.24255256741642\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 278\n",
+      "  episodes_total: 5510\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7183508972326914\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005954385424653689\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007631552017604311\n",
+      "        total_loss: 10.137248754501343\n",
+      "        vf_explained_var: 0.9847092032432556\n",
+      "        vf_loss: 10.14530062675476\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.072\n",
+      "    gpu_util_percent0: 0.36760000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.756\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 47416\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15029441536490598\n",
+      "    mean_env_wait_ms: 1.2014855944746754\n",
+      "    mean_inference_ms: 4.548813510251206\n",
+      "    mean_raw_obs_processing_ms: 0.39103728768479246\n",
+      "  time_since_restore: 611.7375376224518\n",
+      "  time_this_iter_s: 21.74901533126831\n",
+      "  time_total_s: 611.7375376224518\n",
+      "  timers:\n",
+      "    learn_throughput: 10953.469\n",
+      "    learn_time_ms: 14770.846\n",
+      "    sample_throughput: 23575.025\n",
+      "    sample_time_ms: 6862.856\n",
+      "    update_time_ms: 25.694\n",
+      "  timestamp: 1602489946\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 4935d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | TERMINATED |       |     28 |          611.738 | 4530176 |  247.243 |              290.566 |              131.475 |            815.788 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | TERMINATED |       |     28 |          611.738 | 4530176 |  247.243 |              290.566 |              131.475 |            815.788 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 47152\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_075519-oa6h6n34/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_075519-oa6h6n34/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3145\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602489947\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4188\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3423.25447\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.56566\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 131.47475\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.24255\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5510\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33micy-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/oa6h6n34\u001b[0m\n",
+      "2020-10-12 08:05:54,192 - wandb.wandb_agent - INFO - Cleaning up finished run: oa6h6n34\n",
+      "2020-10-12 08:05:54,502 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:05:54,503 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.3\n",
+      "\tentropy_coeff: 0.001\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 08:05:54,506 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.001 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 08:05:59,522 - wandb.wandb_agent - INFO - Running runs: ['xgblq0zg']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/xgblq0zg\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_080556-xgblq0zg\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:06:00,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=79399)\u001b[0m 2020-10-12 08:06:02,983\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=79350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79349)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79349)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79285)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79285)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79294)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79294)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79360)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79360)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79378)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79378)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79283)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79283)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79303)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79303)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79330)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79330)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79295)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79295)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79305)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79305)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79297)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79297)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-06-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.185120274623235\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.004055787847998242\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007851610066912448\n",
+      "        total_loss: 507.07507578531903\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.89090909090909\n",
+      "    gpu_util_percent0: 0.38969696969696965\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.566666666666667\n",
+      "    vram_util_percent0: 0.08750757824224535\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1671859768298939\n",
+      "    mean_env_wait_ms: 1.1685175894218744\n",
+      "    mean_inference_ms: 5.542697244015841\n",
+      "    mean_raw_obs_processing_ms: 0.4403039149643279\n",
+      "  time_since_restore: 27.98508620262146\n",
+      "  time_this_iter_s: 27.98508620262146\n",
+      "  time_total_s: 27.98508620262146\n",
+      "  timers:\n",
+      "    learn_throughput: 8511.254\n",
+      "    learn_time_ms: 19009.184\n",
+      "    sample_throughput: 18188.236\n",
+      "    sample_time_ms: 8895.42\n",
+      "    update_time_ms: 25.517\n",
+      "  timestamp: 1602489996\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      1 |          27.9851 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3615.2916666666665\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-07-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 890.9303797468355\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.42123769338934\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.15665665268898\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007565491638767223\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010795095736587731\n",
+      "        total_loss: 126.37152163187663\n",
+      "        vf_explained_var: 0.8081408143043518\n",
+      "        vf_loss: 126.38271840413411\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.083870967741937\n",
+      "    gpu_util_percent0: 0.3458064516129033\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7580645161290316\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1630873611830732\n",
+      "    mean_env_wait_ms: 1.1651816796611996\n",
+      "    mean_inference_ms: 5.320372510974211\n",
+      "    mean_raw_obs_processing_ms: 0.4290420705682716\n",
+      "  time_since_restore: 54.57611012458801\n",
+      "  time_this_iter_s: 26.591023921966553\n",
+      "  time_total_s: 54.57611012458801\n",
+      "  timers:\n",
+      "    learn_throughput: 8492.107\n",
+      "    learn_time_ms: 19052.045\n",
+      "    sample_throughput: 19867.256\n",
+      "    sample_time_ms: 8143.651\n",
+      "    update_time_ms: 40.696\n",
+      "  timestamp: 1602490023\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      2 |          54.5761 | 323584 |  217.421 |              273.596 |              138.899 |             890.93 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3613.952914798206\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-07-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 886.1983122362869\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 218.40800409154815\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1415385901927948\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00994268455542624\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012222195859067142\n",
+      "        total_loss: 64.50122865041097\n",
+      "        vf_explained_var: 0.8894491195678711\n",
+      "        vf_loss: 64.51359748840332\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.9\n",
+      "    gpu_util_percent0: 0.34400000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.78\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16056376792462443\n",
+      "    mean_env_wait_ms: 1.1654815807931842\n",
+      "    mean_inference_ms: 5.160581395537171\n",
+      "    mean_raw_obs_processing_ms: 0.4210465552605851\n",
+      "  time_since_restore: 80.85679578781128\n",
+      "  time_this_iter_s: 26.280685663223267\n",
+      "  time_total_s: 80.85679578781128\n",
+      "  timers:\n",
+      "    learn_throughput: 8489.867\n",
+      "    learn_time_ms: 19057.072\n",
+      "    sample_throughput: 20738.298\n",
+      "    sample_time_ms: 7801.605\n",
+      "    update_time_ms: 40.121\n",
+      "  timestamp: 1602490049\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      3 |          80.8568 | 485376 |  218.408 |              273.596 |              138.899 |            886.198 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3600.026490066225\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-07-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 881.0632911392405\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 220.77398989898967\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1262759864330292\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007932808017358184\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010753356424781183\n",
+      "        total_loss: 40.0422420501709\n",
+      "        vf_explained_var: 0.9258741736412048\n",
+      "        vf_loss: 40.05332660675049\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.79666666666667\n",
+      "    gpu_util_percent0: 0.36266666666666664\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15881682262783847\n",
+      "    mean_env_wait_ms: 1.1667191329418642\n",
+      "    mean_inference_ms: 5.0460795669711525\n",
+      "    mean_raw_obs_processing_ms: 0.4151562783082309\n",
+      "  time_since_restore: 106.90822958946228\n",
+      "  time_this_iter_s: 26.051433801651\n",
+      "  time_total_s: 106.90822958946228\n",
+      "  timers:\n",
+      "    learn_throughput: 8480.346\n",
+      "    learn_time_ms: 19078.466\n",
+      "    sample_throughput: 21401.448\n",
+      "    sample_time_ms: 7559.862\n",
+      "    update_time_ms: 35.028\n",
+      "  timestamp: 1602490075\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      4 |          106.908 | 647168 |  220.774 |              273.596 |              138.899 |            881.063 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3586.272965879265\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-08-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 876.5278481012658\n",
+      "  episode_reward_max: 274.35353535353505\n",
+      "  episode_reward_mean: 223.04858713719454\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0917210976282756\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008220920106396079\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013464094430673867\n",
+      "        total_loss: 28.93033440907796\n",
+      "        vf_explained_var: 0.9479137063026428\n",
+      "        vf_loss: 28.944067160288494\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.173333333333332\n",
+      "    gpu_util_percent0: 0.33833333333333343\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769999999999999\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15751531511699007\n",
+      "    mean_env_wait_ms: 1.1684766662620152\n",
+      "    mean_inference_ms: 4.95970615273041\n",
+      "    mean_raw_obs_processing_ms: 0.4106852566028239\n",
+      "  time_since_restore: 132.92763376235962\n",
+      "  time_this_iter_s: 26.01940417289734\n",
+      "  time_total_s: 132.92763376235962\n",
+      "  timers:\n",
+      "    learn_throughput: 8474.744\n",
+      "    learn_time_ms: 19091.079\n",
+      "    sample_throughput: 21836.933\n",
+      "    sample_time_ms: 7409.099\n",
+      "    update_time_ms: 32.404\n",
+      "  timestamp: 1602490101\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      5 |          132.928 | 808960 |  223.049 |              274.354 |              138.899 |            876.528 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3562.720930232558\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-08-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 866.970988213962\n",
+      "  episode_reward_max: 275.7171717171718\n",
+      "  episode_reward_mean: 226.50675384854873\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 313\n",
+      "  episodes_total: 1103\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0828292568524678\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007986097635390857\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01176670480829974\n",
+      "        total_loss: 28.82416566212972\n",
+      "        vf_explained_var: 0.9627106189727783\n",
+      "        vf_loss: 28.836217085520428\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.993103448275857\n",
+      "    gpu_util_percent0: 0.34206896551724136\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7689655172413787\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1557423331251979\n",
+      "    mean_env_wait_ms: 1.1728611992308515\n",
+      "    mean_inference_ms: 4.843886786218583\n",
+      "    mean_raw_obs_processing_ms: 0.40510099711437697\n",
+      "  time_since_restore: 158.39731907844543\n",
+      "  time_this_iter_s: 25.469685316085815\n",
+      "  time_total_s: 158.39731907844543\n",
+      "  timers:\n",
+      "    learn_throughput: 8511.93\n",
+      "    learn_time_ms: 19007.676\n",
+      "    sample_throughput: 22135.621\n",
+      "    sample_time_ms: 7309.124\n",
+      "    update_time_ms: 29.98\n",
+      "  timestamp: 1602490127\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      6 |          158.397 | 970752 |  226.507 |              275.717 |              138.899 |            866.971 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3553.5307443365696\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-09-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 863.0727848101266\n",
+      "  episode_reward_max: 275.7171717171718\n",
+      "  episode_reward_mean: 227.83155127221562\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.071872740983963\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00846466759685427\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013406029562853897\n",
+      "        total_loss: 19.26950518290202\n",
+      "        vf_explained_var: 0.9649848341941833\n",
+      "        vf_loss: 19.28313668568929\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.403225806451612\n",
+      "    gpu_util_percent0: 0.44258064516129036\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.780645161290322\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15508125173145895\n",
+      "    mean_env_wait_ms: 1.1746607097364452\n",
+      "    mean_inference_ms: 4.801153989323884\n",
+      "    mean_raw_obs_processing_ms: 0.4030365619774304\n",
+      "  time_since_restore: 184.4202537536621\n",
+      "  time_this_iter_s: 26.022934675216675\n",
+      "  time_total_s: 184.4202537536621\n",
+      "  timers:\n",
+      "    learn_throughput: 8507.604\n",
+      "    learn_time_ms: 19017.34\n",
+      "    sample_throughput: 22352.663\n",
+      "    sample_time_ms: 7238.153\n",
+      "    update_time_ms: 36.921\n",
+      "  timestamp: 1602490153\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      7 |           184.42 | 1132544 |  227.832 |              275.717 |              138.899 |            863.073 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3545.019368723099\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-09-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 860.4458509142054\n",
+      "  episode_reward_max: 275.7171717171718\n",
+      "  episode_reward_mean: 229.1102800153431\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0527766644954681\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007615982904098928\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012027044120865563\n",
+      "        total_loss: 16.963534673055012\n",
+      "        vf_explained_var: 0.9683038592338562\n",
+      "        vf_loss: 16.975852966308594\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.863333333333333\n",
+      "    gpu_util_percent0: 0.2586666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15452219062147216\n",
+      "    mean_env_wait_ms: 1.1761659446759791\n",
+      "    mean_inference_ms: 4.765321018664555\n",
+      "    mean_raw_obs_processing_ms: 0.4012817864251415\n",
+      "  time_since_restore: 210.67793703079224\n",
+      "  time_this_iter_s: 26.257683277130127\n",
+      "  time_total_s: 210.67793703079224\n",
+      "  timers:\n",
+      "    learn_throughput: 8505.771\n",
+      "    learn_time_ms: 19021.438\n",
+      "    sample_throughput: 22391.774\n",
+      "    sample_time_ms: 7225.511\n",
+      "    update_time_ms: 34.921\n",
+      "  timestamp: 1602490179\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      8 |          210.678 | 1294336 |   229.11 |              275.717 |              138.899 |            860.446 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3536.619201030928\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-10-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 857.7284810126582\n",
+      "  episode_reward_max: 281.92929292929284\n",
+      "  episode_reward_mean: 230.51368111494673\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0236333707968395\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008085604213799039\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011290598209598102\n",
+      "        total_loss: 15.170008023579916\n",
+      "        vf_explained_var: 0.970684289932251\n",
+      "        vf_loss: 15.18151330947876\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.749999999999996\n",
+      "    gpu_util_percent0: 0.251\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7733333333333334\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1540308837771974\n",
+      "    mean_env_wait_ms: 1.1774970942409586\n",
+      "    mean_inference_ms: 4.734334782954239\n",
+      "    mean_raw_obs_processing_ms: 0.3997390670523251\n",
+      "  time_since_restore: 236.742493391037\n",
+      "  time_this_iter_s: 26.06455636024475\n",
+      "  time_total_s: 236.742493391037\n",
+      "  timers:\n",
+      "    learn_throughput: 8505.518\n",
+      "    learn_time_ms: 19022.004\n",
+      "    sample_throughput: 22482.023\n",
+      "    sample_time_ms: 7196.506\n",
+      "    update_time_ms: 33.142\n",
+      "  timestamp: 1602490205\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      9 |          236.742 | 1456128 |  230.514 |              281.929 |              138.899 |            857.728 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3519.6370656370655\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-10-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.4513851167843\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 233.1354885081119\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 261\n",
+      "  episodes_total: 1841\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9897792836030325\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008098231783757607\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010045850300230086\n",
+      "        total_loss: 20.74252223968506\n",
+      "        vf_explained_var: 0.9716846346855164\n",
+      "        vf_loss: 20.752748171488445\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.766666666666666\n",
+      "    gpu_util_percent0: 0.28366666666666673\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7633333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15336646876524834\n",
+      "    mean_env_wait_ms: 1.179771053805273\n",
+      "    mean_inference_ms: 4.691936826434794\n",
+      "    mean_raw_obs_processing_ms: 0.39762402378600903\n",
+      "  time_since_restore: 262.79794573783875\n",
+      "  time_this_iter_s: 26.055452346801758\n",
+      "  time_total_s: 262.79794573783875\n",
+      "  timers:\n",
+      "    learn_throughput: 8506.736\n",
+      "    learn_time_ms: 19019.281\n",
+      "    sample_throughput: 22547.752\n",
+      "    sample_time_ms: 7175.527\n",
+      "    update_time_ms: 31.912\n",
+      "  timestamp: 1602490231\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     10 |          262.798 | 1617920 |  233.135 |              288.747 |              138.899 |            852.451 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3509.591806515301\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-10-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.2750730282376\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 234.99839682118142\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9871509124835333\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007209118106402457\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012315249536186457\n",
+      "        total_loss: 13.081322272618612\n",
+      "        vf_explained_var: 0.9765751957893372\n",
+      "        vf_loss: 13.09390377998352\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.37741935483871\n",
+      "    gpu_util_percent0: 0.4119354838709678\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15291547541255573\n",
+      "    mean_env_wait_ms: 1.1813891282293203\n",
+      "    mean_inference_ms: 4.663419804013761\n",
+      "    mean_raw_obs_processing_ms: 0.39626592689167284\n",
+      "  time_since_restore: 288.9913504123688\n",
+      "  time_this_iter_s: 26.19340467453003\n",
+      "  time_total_s: 288.9913504123688\n",
+      "  timers:\n",
+      "    learn_throughput: 8502.356\n",
+      "    learn_time_ms: 19029.079\n",
+      "    sample_throughput: 23156.003\n",
+      "    sample_time_ms: 6987.043\n",
+      "    update_time_ms: 31.229\n",
+      "  timestamp: 1602490258\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     11 |          288.991 | 1779712 |  234.998 |              288.747 |              138.899 |            848.275 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3500.4253663003665\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-11-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.25226039783\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 236.21548669333458\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9684580465157827\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0071360117290169\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011122295356472023\n",
+      "        total_loss: 14.169920762379965\n",
+      "        vf_explained_var: 0.9724215865135193\n",
+      "        vf_loss: 14.181298096974691\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.079999999999995\n",
+      "    gpu_util_percent0: 0.25166666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7766666666666664\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15262288825471745\n",
+      "    mean_env_wait_ms: 1.1825289172355695\n",
+      "    mean_inference_ms: 4.645050441375069\n",
+      "    mean_raw_obs_processing_ms: 0.39535490470579415\n",
+      "  time_since_restore: 315.16404151916504\n",
+      "  time_this_iter_s: 26.172691106796265\n",
+      "  time_total_s: 315.16404151916504\n",
+      "  timers:\n",
+      "    learn_throughput: 8504.47\n",
+      "    learn_time_ms: 19024.348\n",
+      "    sample_throughput: 23270.287\n",
+      "    sample_time_ms: 6952.729\n",
+      "    update_time_ms: 27.675\n",
+      "  timestamp: 1602490284\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     12 |          315.164 | 1941504 |  236.215 |              288.747 |              138.899 |            845.252 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3492.3398720682303\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-11-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.0539401601349\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 237.38396608308096\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 2373\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9432903180519739\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0064480928316091495\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010764235218327181\n",
+      "        total_loss: 13.248364766438803\n",
+      "        vf_explained_var: 0.9748766422271729\n",
+      "        vf_loss: 13.259427547454834\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.170000000000005\n",
+      "    gpu_util_percent0: 0.3536666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15235432334814986\n",
+      "    mean_env_wait_ms: 1.1837337370144503\n",
+      "    mean_inference_ms: 4.628123902236818\n",
+      "    mean_raw_obs_processing_ms: 0.39449204277665234\n",
+      "  time_since_restore: 341.18098974227905\n",
+      "  time_this_iter_s: 26.016948223114014\n",
+      "  time_total_s: 341.18098974227905\n",
+      "  timers:\n",
+      "    learn_throughput: 8501.095\n",
+      "    learn_time_ms: 19031.901\n",
+      "    sample_throughput: 23383.904\n",
+      "    sample_time_ms: 6918.947\n",
+      "    update_time_ms: 27.753\n",
+      "  timestamp: 1602490310\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     13 |          341.181 | 2103296 |  237.384 |              288.747 |              138.899 |            842.054 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3480.9777358490564\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-12-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.1299477221808\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 239.0731927188236\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 305\n",
+      "  episodes_total: 2678\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9245238403479258\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006356651700722675\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0093736828227217\n",
+      "        total_loss: 16.56673304239909\n",
+      "        vf_explained_var: 0.977961540222168\n",
+      "        vf_loss: 16.576395829518635\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.896666666666665\n",
+      "    gpu_util_percent0: 0.29466666666666674\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7633333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15190957765651997\n",
+      "    mean_env_wait_ms: 1.1859752986928445\n",
+      "    mean_inference_ms: 4.600343130214659\n",
+      "    mean_raw_obs_processing_ms: 0.3931069726348402\n",
+      "  time_since_restore: 367.24762058258057\n",
+      "  time_this_iter_s: 26.066630840301514\n",
+      "  time_total_s: 367.24762058258057\n",
+      "  timers:\n",
+      "    learn_throughput: 8501.73\n",
+      "    learn_time_ms: 19030.48\n",
+      "    sample_throughput: 23378.515\n",
+      "    sample_time_ms: 6920.542\n",
+      "    update_time_ms: 29.402\n",
+      "  timestamp: 1602490336\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     14 |          367.248 | 2265088 |  239.073 |              288.747 |              138.899 |             837.13 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3474.9868607954545\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-12-43\n",
       "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 834.7232770745429\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 239.94718279844844\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 166\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2773,80 +4031,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
+      "        entropy: 0.906185562411944\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006180410894254844\n",
       "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.012563393373663226\n",
+      "        total_loss: 10.936929861704508\n",
+      "        vf_explained_var: 0.979099452495575\n",
+      "        vf_loss: 10.949781576792398\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
+      "    cpu_util_percent: 24.083870967741934\n",
+      "    gpu_util_percent0: 0.3635483870967742\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
+      "    mean_action_processing_ms: 0.15170192871649035\n",
+      "    mean_env_wait_ms: 1.187075900566473\n",
+      "    mean_inference_ms: 4.587271974323672\n",
+      "    mean_raw_obs_processing_ms: 0.3924657739112036\n",
+      "  time_since_restore: 393.44245624542236\n",
+      "  time_this_iter_s: 26.194835662841797\n",
+      "  time_total_s: 393.44245624542236\n",
       "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
+      "    learn_throughput: 8500.238\n",
+      "    learn_time_ms: 19033.821\n",
+      "    sample_throughput: 23336.365\n",
+      "    sample_time_ms: 6933.042\n",
+      "    update_time_ms: 29.449\n",
+      "  timestamp: 1602490363\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     15 |          393.442 | 2426880 |  239.947 |              288.747 |              138.899 |            834.723 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3469.194351042367\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-13-09\n",
       "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 832.4070619586942\n",
+      "  episode_reward_max: 291.6262626262627\n",
+      "  episode_reward_mean: 240.8477412364819\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2855,80 +4113,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
+      "        entropy: 0.8940609991550446\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007062381831929088\n",
       "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.01240032100273917\n",
+      "        total_loss: 9.784063498179117\n",
+      "        vf_explained_var: 0.9792147278785706\n",
+      "        vf_loss: 9.796651442845663\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
+      "    cpu_util_percent: 25.439999999999998\n",
+      "    gpu_util_percent0: 0.2953333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7899999999999996\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
+      "    mean_action_processing_ms: 0.15151935101577735\n",
+      "    mean_env_wait_ms: 1.1880832907069834\n",
+      "    mean_inference_ms: 4.5757290796410865\n",
+      "    mean_raw_obs_processing_ms: 0.39187675467872235\n",
+      "  time_since_restore: 419.5664372444153\n",
+      "  time_this_iter_s: 26.12398099899292\n",
+      "  time_total_s: 419.5664372444153\n",
       "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
+      "    learn_throughput: 8475.187\n",
+      "    learn_time_ms: 19090.079\n",
+      "    sample_throughput: 23315.951\n",
+      "    sample_time_ms: 6939.112\n",
+      "    update_time_ms: 31.854\n",
+      "  timestamp: 1602490389\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     16 |          419.566 | 2588672 |  240.848 |              291.626 |              138.899 |            832.407 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3461.9522776572667\n",
+      "    time_step_min: 3146\n",
+      "  date: 2020-10-12_08-13-35\n",
       "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 829.152380952381\n",
+      "  episode_reward_max: 291.6262626262627\n",
+      "  episode_reward_mean: 241.9287808965227\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 253\n",
+      "  episodes_total: 3255\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2937,80 +4195,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
+      "        entropy: 0.8715203603108724\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0068582673169051605\n",
       "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
+      "        policy_loss: -0.009826259381952696\n",
+      "        total_loss: 13.900481621424357\n",
+      "        vf_explained_var: 0.9798092246055603\n",
+      "        vf_loss: 13.910493532816568\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
+      "    cpu_util_percent: 24.28666666666667\n",
+      "    gpu_util_percent0: 0.256\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.77\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
+      "    mean_action_processing_ms: 0.15125671270769184\n",
+      "    mean_env_wait_ms: 1.1897326970724291\n",
+      "    mean_inference_ms: 4.559082586406331\n",
+      "    mean_raw_obs_processing_ms: 0.391031531764309\n",
+      "  time_since_restore: 445.54023838043213\n",
+      "  time_this_iter_s: 25.973801136016846\n",
+      "  time_total_s: 445.54023838043213\n",
       "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
+      "    learn_throughput: 8471.862\n",
+      "    learn_time_ms: 19097.573\n",
+      "    sample_throughput: 23339.019\n",
+      "    sample_time_ms: 6932.254\n",
+      "    update_time_ms: 26.287\n",
+      "  timestamp: 1602490415\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     17 |           445.54 | 2750464 |  241.929 |              291.626 |              138.899 |            829.152 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3456.317865429234\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-14-01\n",
       "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 826.6527617951668\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 242.82325847659547\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 221\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3019,80 +4277,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
+      "        entropy: 0.8578323672215143\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0062772125626603765\n",
       "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
+      "        policy_loss: -0.011194397937894488\n",
+      "        total_loss: 11.216416676839193\n",
+      "        vf_explained_var: 0.9811086058616638\n",
+      "        vf_loss: 11.2278413772583\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
+      "    cpu_util_percent: 24.15\n",
+      "    gpu_util_percent0: 0.275\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7666666666666657\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
+      "    mean_action_processing_ms: 0.15105210665216098\n",
+      "    mean_env_wait_ms: 1.1910411370697684\n",
+      "    mean_inference_ms: 4.546026524305814\n",
+      "    mean_raw_obs_processing_ms: 0.3904015773843836\n",
+      "  time_since_restore: 471.62775897979736\n",
+      "  time_this_iter_s: 26.087520599365234\n",
+      "  time_total_s: 471.62775897979736\n",
       "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
+      "    learn_throughput: 8466.865\n",
+      "    learn_time_ms: 19108.844\n",
+      "    sample_throughput: 23450.467\n",
+      "    sample_time_ms: 6899.308\n",
+      "    update_time_ms: 28.072\n",
+      "  timestamp: 1602490441\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     18 |          471.628 | 2912256 |  242.823 |              293.293 |              138.899 |            826.653 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3451.5252357182476\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-14-27\n",
       "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 825.2999449642267\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 243.52266195249118\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3101,80 +4359,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
+      "        entropy: 0.8522786746422449\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006254845376436909\n",
       "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
+      "        policy_loss: -0.012950713620133078\n",
+      "        total_loss: 9.356015682220459\n",
+      "        vf_explained_var: 0.9807977080345154\n",
+      "        vf_loss: 9.369193077087402\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
+      "    cpu_util_percent: 24.18709677419354\n",
+      "    gpu_util_percent0: 0.3722580645161291\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7741935483870965\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
+      "    mean_action_processing_ms: 0.15091926952523643\n",
+      "    mean_env_wait_ms: 1.1919120175490399\n",
+      "    mean_inference_ms: 4.537482004930605\n",
+      "    mean_raw_obs_processing_ms: 0.38997728772240287\n",
+      "  time_since_restore: 497.7250077724457\n",
+      "  time_this_iter_s: 26.097248792648315\n",
+      "  time_total_s: 497.7250077724457\n",
       "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
+      "    learn_throughput: 8461.979\n",
+      "    learn_time_ms: 19119.877\n",
+      "    sample_throughput: 23489.436\n",
+      "    sample_time_ms: 6887.862\n",
+      "    update_time_ms: 30.171\n",
+      "  timestamp: 1602490467\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     19 |          497.725 | 3074048 |  243.523 |              293.293 |              138.899 |              825.3 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3446.582144743793\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-14-54\n",
       "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 823.849764027268\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 244.2001530777093\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 180\n",
+      "  episodes_total: 3814\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3183,80 +4441,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
+      "        entropy: 0.8286279241243998\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006430626187163095\n",
       "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
+      "        policy_loss: -0.012222413827354709\n",
+      "        total_loss: 9.228648900985718\n",
+      "        vf_explained_var: 0.9839107990264893\n",
+      "        vf_loss: 9.2410569190979\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
+      "    cpu_util_percent: 25.133333333333333\n",
+      "    gpu_util_percent0: 0.3453333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.78\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
+      "    mean_action_processing_ms: 0.15077733023374773\n",
+      "    mean_env_wait_ms: 1.1928851969603187\n",
+      "    mean_inference_ms: 4.528347029744211\n",
+      "    mean_raw_obs_processing_ms: 0.3895120865590016\n",
+      "  time_since_restore: 523.7741742134094\n",
+      "  time_this_iter_s: 26.049166440963745\n",
+      "  time_total_s: 523.7741742134094\n",
       "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
+      "    learn_throughput: 8456.501\n",
+      "    learn_time_ms: 19132.264\n",
+      "    sample_throughput: 23545.959\n",
+      "    sample_time_ms: 6871.328\n",
+      "    update_time_ms: 32.795\n",
+      "  timestamp: 1602490494\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     20 |          523.774 | 3235840 |    244.2 |              293.293 |              138.899 |             823.85 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3438.918773006135\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-15-20\n",
       "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 821.5028028271996\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 245.33389709919064\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 289\n",
+      "  episodes_total: 4103\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3265,80 +4523,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
+      "        entropy: 0.8048954059680303\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005603969019527237\n",
       "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
+      "        policy_loss: -0.013911528105381876\n",
+      "        total_loss: 11.3087530930837\n",
+      "        vf_explained_var: 0.9836416244506836\n",
+      "        vf_loss: 11.322909275690714\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
+      "    cpu_util_percent: 24.470000000000006\n",
+      "    gpu_util_percent0: 0.2516666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
+      "    mean_action_processing_ms: 0.1505739045388427\n",
+      "    mean_env_wait_ms: 1.1943338077267522\n",
+      "    mean_inference_ms: 4.515047112702623\n",
+      "    mean_raw_obs_processing_ms: 0.38885284610818543\n",
+      "  time_since_restore: 549.8376796245575\n",
+      "  time_this_iter_s: 26.06350541114807\n",
+      "  time_total_s: 549.8376796245575\n",
       "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
+      "    learn_throughput: 8455.134\n",
+      "    learn_time_ms: 19135.356\n",
+      "    sample_throughput: 23614.521\n",
+      "    sample_time_ms: 6851.378\n",
+      "    update_time_ms: 35.316\n",
+      "  timestamp: 1602490520\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     21 |          549.838 | 3397632 |  245.334 |              293.293 |              138.899 |            821.503 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3434.6906559697973\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-15-46\n",
       "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 820.2461322081575\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 245.97136626461509\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3347,80 +4605,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
+      "        entropy: 0.7969592610994974\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006330874321671824\n",
       "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
+      "        policy_loss: -0.011175491047955196\n",
+      "        total_loss: 6.920762340227763\n",
+      "        vf_explained_var: 0.986197292804718\n",
+      "        vf_loss: 6.932101647059123\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
+      "    cpu_util_percent: 24.106451612903232\n",
+      "    gpu_util_percent0: 0.3683870967741936\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
+      "    mean_action_processing_ms: 0.15046625659796298\n",
+      "    mean_env_wait_ms: 1.1950829782948686\n",
+      "    mean_inference_ms: 4.508158694182665\n",
+      "    mean_raw_obs_processing_ms: 0.3885170657875346\n",
+      "  time_since_restore: 576.0177464485168\n",
+      "  time_this_iter_s: 26.18006682395935\n",
+      "  time_total_s: 576.0177464485168\n",
       "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
+      "    learn_throughput: 8446.374\n",
+      "    learn_time_ms: 19155.203\n",
+      "    sample_throughput: 23696.753\n",
+      "    sample_time_ms: 6827.602\n",
+      "    update_time_ms: 38.423\n",
+      "  timestamp: 1602490546\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     22 |          576.018 | 3559424 |  245.971 |              293.293 |              138.899 |            820.246 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3430.9893206089523\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-16-12\n",
+      "  done: true\n",
+      "  episode_len_mean: 818.8347256717092\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 246.54997479878926\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 4429\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3429,162 +4687,419 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
+      "        entropy: 0.7878765910863876\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005924326988557975\n",
       "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
+      "        policy_loss: -0.012837671786352681\n",
+      "        total_loss: 8.265578190485636\n",
+      "        vf_explained_var: 0.9834974408149719\n",
+      "        vf_loss: 8.278611381848654\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
+      "    cpu_util_percent: 23.970000000000002\n",
+      "    gpu_util_percent0: 0.30333333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
+      "    mean_action_processing_ms: 0.15036522832821625\n",
+      "    mean_env_wait_ms: 1.1958362960216486\n",
+      "    mean_inference_ms: 4.5016834026606345\n",
+      "    mean_raw_obs_processing_ms: 0.3881896853970501\n",
+      "  time_since_restore: 602.1439270973206\n",
+      "  time_this_iter_s: 26.12618064880371\n",
+      "  time_total_s: 602.1439270973206\n",
       "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
+      "    learn_throughput: 8446.113\n",
+      "    learn_time_ms: 19155.793\n",
+      "    sample_throughput: 23657.57\n",
+      "    sample_time_ms: 6838.91\n",
+      "    update_time_ms: 36.492\n",
+      "  timestamp: 1602490572\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | TERMINATED |       |     23 |          602.144 | 3721216 |   246.55 |              293.293 |              138.899 |            818.835 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m 2020-10-12 08:16:13,040\tERROR worker.py:372 -- SystemExit was raised from the worker\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 553, in ray._raylet.task_execution_handler\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 440, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py\", line 553, in actor_method_executor\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     return method(actor, *args, **kwargs)\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 929, in __ray_terminate__\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     ray.actor.exit_actor()\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 991, in exit_actor\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     ray.state.state.disconnect()\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/state.py\", line 61, in disconnect\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     self.global_state_accessor = None\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 369, in sigterm_handler\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     sys.exit(1)\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m SystemExit: 1\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | TERMINATED |       |     23 |          602.144 | 3721216 |   246.55 |              293.293 |              138.899 |            818.835 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "2020-10-12 08:16:13,085\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79130\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_080556-xgblq0zg/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_080556-xgblq0zg/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3120\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 617\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602490573\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4139\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3430.98932\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 293.29293\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 138.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 246.54997\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4429\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfearless-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/xgblq0zg\u001b[0m\n",
+      "2020-10-12 08:16:20,100 - wandb.wandb_agent - INFO - Cleaning up finished run: xgblq0zg\n",
+      "2020-10-12 08:16:20,408 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:16:20,408 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.3\n",
+      "\tentropy_coeff: 0.0005\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 08:16:20,411 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --num_sgd_iter=20\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 08:16:25,428 - wandb.wandb_agent - INFO - Running runs: ['6nvy6bhw']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/6nvy6bhw\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_081622-6nvy6bhw\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:16:26,316\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "\u001b[2m\u001b[36m(pid=24878)\u001b[0m 2020-10-12 08:16:29,112\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=24825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24870)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24870)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24779)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24779)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24782)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24782)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24842)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24842)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24778)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24778)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24783)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24783)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24787)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24787)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24789)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24789)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-16-58\n",
       "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
+      "        entropy: 1.185864080985387\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
+      "        kl: 0.004079875051199148\n",
       "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
+      "        policy_loss: -0.006393474138045955\n",
+      "        total_loss: 514.7339019775391\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
+      "    cpu_util_percent: 34.08275862068966\n",
+      "    gpu_util_percent0: 0.2706896551724137\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.53448275862069\n",
+      "    vram_util_percent0: 0.08293561484262792\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
+      "    mean_action_processing_ms: 0.16959718290248305\n",
+      "    mean_env_wait_ms: 1.1668397527154708\n",
+      "    mean_inference_ms: 5.6675725838548425\n",
+      "    mean_raw_obs_processing_ms: 0.45125070049572086\n",
+      "  time_since_restore: 24.041186809539795\n",
+      "  time_this_iter_s: 24.041186809539795\n",
+      "  time_total_s: 24.041186809539795\n",
       "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
+      "    learn_throughput: 10872.209\n",
+      "    learn_time_ms: 14881.244\n",
+      "    sample_throughput: 17812.94\n",
+      "    sample_time_ms: 9082.835\n",
+      "    update_time_ms: 47.25\n",
+      "  timestamp: 1602490618\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      1 |          24.0412 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3621.2881944444443\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-17-21\n",
       "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 890.0727848101266\n",
+      "  episode_reward_max: 271.62626262626253\n",
+      "  episode_reward_mean: 217.58521928142156\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3593,80 +5108,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
+      "        entropy: 1.1563906073570251\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
+      "        kl: 0.007153310541373988\n",
       "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
+      "        policy_loss: -0.006601389720647906\n",
+      "        total_loss: 148.90216318766275\n",
+      "        vf_explained_var: 0.7816783785820007\n",
+      "        vf_loss: 148.90863291422525\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
+      "    cpu_util_percent: 30.835714285714285\n",
+      "    gpu_util_percent0: 0.29464285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285714\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7428571428571424\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
+      "    mean_action_processing_ms: 0.16544807941264583\n",
+      "    mean_env_wait_ms: 1.165790257442274\n",
+      "    mean_inference_ms: 5.466143985210929\n",
+      "    mean_raw_obs_processing_ms: 0.43924275373531213\n",
+      "  time_since_restore: 46.73395586013794\n",
+      "  time_this_iter_s: 22.692769050598145\n",
+      "  time_total_s: 46.73395586013794\n",
       "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
+      "    learn_throughput: 10915.082\n",
+      "    learn_time_ms: 14822.793\n",
+      "    sample_throughput: 19177.544\n",
+      "    sample_time_ms: 8436.534\n",
+      "    update_time_ms: 68.763\n",
+      "  timestamp: 1602490641\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      2 |           46.734 | 323584 |  217.585 |              271.626 |              145.717 |            890.073 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3617.560538116592\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-17-43\n",
       "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 884.5611814345991\n",
+      "  episode_reward_max: 271.62626262626253\n",
+      "  episode_reward_mean: 217.97167881345075\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3675,80 +5190,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
+      "        entropy: 1.147742599248886\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
+      "        kl: 0.007976852473802865\n",
       "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
+      "        policy_loss: -0.010943490701417128\n",
+      "        total_loss: 72.53540929158528\n",
+      "        vf_explained_var: 0.8764762282371521\n",
+      "        vf_loss: 72.54612922668457\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
+      "    cpu_util_percent: 30.673076923076923\n",
+      "    gpu_util_percent0: 0.32769230769230767\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
+      "    ram_util_percent: 3.7653846153846158\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
+      "    mean_action_processing_ms: 0.16269042725297467\n",
+      "    mean_env_wait_ms: 1.1667953562932982\n",
+      "    mean_inference_ms: 5.300973246000417\n",
+      "    mean_raw_obs_processing_ms: 0.4303547572544862\n",
+      "  time_since_restore: 68.67958068847656\n",
+      "  time_this_iter_s: 21.945624828338623\n",
+      "  time_total_s: 68.67958068847656\n",
       "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
+      "    learn_throughput: 10942.549\n",
+      "    learn_time_ms: 14785.586\n",
+      "    sample_throughput: 20197.389\n",
+      "    sample_time_ms: 8010.54\n",
+      "    update_time_ms: 55.862\n",
+      "  timestamp: 1602490663\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      3 |          68.6796 | 485376 |  217.972 |              271.626 |              118.596 |            884.561 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3614.201986754967\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-18-05\n",
       "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 878.743670886076\n",
+      "  episode_reward_max: 271.62626262626253\n",
+      "  episode_reward_mean: 219.13441375783128\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3757,80 +5272,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
+      "        entropy: 1.1307151317596436\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
+      "        kl: 0.007435552775859833\n",
       "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.008821662476596734\n",
+      "        total_loss: 57.703648249308266\n",
+      "        vf_explained_var: 0.8985523581504822\n",
+      "        vf_loss: 57.71229076385498\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
+      "    cpu_util_percent: 30.37307692307692\n",
+      "    gpu_util_percent0: 0.37769230769230766\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
+      "    ram_util_percent: 3.757692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
+      "    mean_action_processing_ms: 0.16071866402244744\n",
+      "    mean_env_wait_ms: 1.1686171756642982\n",
+      "    mean_inference_ms: 5.177265320403001\n",
+      "    mean_raw_obs_processing_ms: 0.42365264313897055\n",
+      "  time_since_restore: 90.54482674598694\n",
+      "  time_this_iter_s: 21.865246057510376\n",
+      "  time_total_s: 90.54482674598694\n",
       "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
+      "    learn_throughput: 10943.822\n",
+      "    learn_time_ms: 14783.866\n",
+      "    sample_throughput: 20855.405\n",
+      "    sample_time_ms: 7757.797\n",
+      "    update_time_ms: 51.57\n",
+      "  timestamp: 1602490685\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      4 |          90.5448 | 647168 |  219.134 |              271.626 |              118.596 |            878.744 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3603.303149606299\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-18-27\n",
       "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 872.032911392405\n",
+      "  episode_reward_max: 277.989898989899\n",
+      "  episode_reward_mean: 220.47570643140241\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3839,80 +5354,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
+      "        entropy: 1.0931349396705627\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
+      "        kl: 0.00779568237097313\n",
       "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.008994614414405078\n",
+      "        total_loss: 45.30020809173584\n",
+      "        vf_explained_var: 0.932476282119751\n",
+      "        vf_loss: 45.30897013346354\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
+      "    cpu_util_percent: 28.75925925925926\n",
+      "    gpu_util_percent0: 0.36481481481481487\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.755555555555555\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
+      "    mean_action_processing_ms: 0.15922985707676396\n",
+      "    mean_env_wait_ms: 1.1714250251780574\n",
+      "    mean_inference_ms: 5.082715379115769\n",
+      "    mean_raw_obs_processing_ms: 0.4184893832756008\n",
+      "  time_since_restore: 112.39339995384216\n",
+      "  time_this_iter_s: 21.848573207855225\n",
+      "  time_total_s: 112.39339995384216\n",
       "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
+      "    learn_throughput: 10950.47\n",
+      "    learn_time_ms: 14774.891\n",
+      "    sample_throughput: 21290.579\n",
+      "    sample_time_ms: 7599.23\n",
+      "    update_time_ms: 48.6\n",
+      "  timestamp: 1602490707\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      5 |          112.393 | 808960 |  220.476 |               277.99 |              118.596 |            872.033 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3580.025974025974\n",
+      "    time_step_min: 3252\n",
+      "  date: 2020-10-12_08-18-48\n",
       "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 859.9168173598554\n",
+      "  episode_reward_max: 277.989898989899\n",
+      "  episode_reward_mean: 224.50477651743455\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3921,80 +5436,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
+      "        entropy: 1.0964580277601879\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
+      "        kl: 0.0070520887384191155\n",
       "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.009450642672769996\n",
+      "        total_loss: 36.19568475087484\n",
+      "        vf_explained_var: 0.9530174732208252\n",
+      "        vf_loss: 36.2049773534139\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
+      "    cpu_util_percent: 30.42\n",
+      "    gpu_util_percent0: 0.28240000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.756\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
+      "    mean_action_processing_ms: 0.15727627060891738\n",
+      "    mean_env_wait_ms: 1.176935910840223\n",
+      "    mean_inference_ms: 4.9546206565535345\n",
+      "    mean_raw_obs_processing_ms: 0.4118872265080656\n",
+      "  time_since_restore: 133.9969527721405\n",
+      "  time_this_iter_s: 21.60355281829834\n",
+      "  time_total_s: 133.9969527721405\n",
       "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
+      "    learn_throughput: 10972.109\n",
+      "    learn_time_ms: 14745.752\n",
+      "    sample_throughput: 21605.627\n",
+      "    sample_time_ms: 7488.42\n",
+      "    update_time_ms: 43.97\n",
+      "  timestamp: 1602490728\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      6 |          133.997 | 970752 |  224.505 |               277.99 |              118.596 |            859.917 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3568.9069579288025\n",
+      "    time_step_min: 3223\n",
+      "  date: 2020-10-12_08-19-11\n",
       "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 855.3409810126582\n",
+      "  episode_reward_max: 277.989898989899\n",
+      "  episode_reward_mean: 226.3009365809997\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4003,80 +5518,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
+      "        entropy: 1.0852240125338237\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
+      "        kl: 0.006654882531923552\n",
       "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.008402673081339648\n",
+      "        total_loss: 22.136696815490723\n",
+      "        vf_explained_var: 0.9591858386993408\n",
+      "        vf_loss: 22.1449769337972\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
+      "    cpu_util_percent: 29.133333333333333\n",
+      "    gpu_util_percent0: 0.3274074074074074\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.774074074074074\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
+      "    mean_action_processing_ms: 0.15656674946834911\n",
+      "    mean_env_wait_ms: 1.1790376306777075\n",
+      "    mean_inference_ms: 4.908632400838693\n",
+      "    mean_raw_obs_processing_ms: 0.4094826609603066\n",
+      "  time_since_restore: 156.16001439094543\n",
+      "  time_this_iter_s: 22.16306161880493\n",
+      "  time_total_s: 156.16001439094543\n",
       "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
+      "    learn_throughput: 10962.953\n",
+      "    learn_time_ms: 14758.067\n",
+      "    sample_throughput: 21706.713\n",
+      "    sample_time_ms: 7453.547\n",
+      "    update_time_ms: 42.91\n",
+      "  timestamp: 1602490751\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      7 |           156.16 | 1132544 |  226.301 |               277.99 |              118.596 |            855.341 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3559.409612625538\n",
+      "    time_step_min: 3213\n",
+      "  date: 2020-10-12_08-19-33\n",
       "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 851.2285513361463\n",
+      "  episode_reward_max: 279.2020202020205\n",
+      "  episode_reward_mean: 227.61643864808408\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4085,80 +5600,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
+      "        entropy: 1.064836581548055\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
+      "        kl: 0.007024736143648624\n",
       "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.01098796930940201\n",
+      "        total_loss: 18.97636540730794\n",
+      "        vf_explained_var: 0.9632197022438049\n",
+      "        vf_loss: 18.98718277613322\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
+      "    cpu_util_percent: 29.669230769230772\n",
+      "    gpu_util_percent0: 0.38384615384615384\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.773076923076923\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
+      "    mean_action_processing_ms: 0.15595891964857586\n",
+      "    mean_env_wait_ms: 1.1809454626407365\n",
+      "    mean_inference_ms: 4.868793649237494\n",
+      "    mean_raw_obs_processing_ms: 0.407373353338115\n",
+      "  time_since_restore: 178.08209371566772\n",
+      "  time_this_iter_s: 21.92207932472229\n",
+      "  time_total_s: 178.08209371566772\n",
       "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
+      "    learn_throughput: 10962.634\n",
+      "    learn_time_ms: 14758.497\n",
+      "    sample_throughput: 21846.272\n",
+      "    sample_time_ms: 7405.932\n",
+      "    update_time_ms: 42.294\n",
+      "  timestamp: 1602490773\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      8 |          178.082 | 1294336 |  227.616 |              279.202 |              118.596 |            851.229 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3544.464445868033\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_08-19-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 847.2133417243549\n",
+      "  episode_reward_max: 282.53535353535335\n",
+      "  episode_reward_mean: 229.62328762769275\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 167\n",
+      "  episodes_total: 1589\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4167,318 +5682,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
+      "        entropy: 1.0196023285388947\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
+      "        kl: 0.006671490341735383\n",
       "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.0071269801701419055\n",
+      "        total_loss: 18.681314945220947\n",
+      "        vf_explained_var: 0.9678203463554382\n",
+      "        vf_loss: 18.688284556070965\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
+      "    cpu_util_percent: 29.38148148148148\n",
+      "    gpu_util_percent0: 0.31999999999999995\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.155400467758317\n",
+      "    mean_env_wait_ms: 1.183039650073914\n",
+      "    mean_inference_ms: 4.832418911477187\n",
+      "    mean_raw_obs_processing_ms: 0.40543635804228817\n",
+      "  time_since_restore: 200.01625061035156\n",
+      "  time_this_iter_s: 21.934156894683838\n",
+      "  time_total_s: 200.01625061035156\n",
+      "  timers:\n",
+      "    learn_throughput: 10966.485\n",
+      "    learn_time_ms: 14753.314\n",
+      "    sample_throughput: 21935.371\n",
+      "    sample_time_ms: 7375.85\n",
+      "    update_time_ms: 41.465\n",
+      "  timestamp: 1602490795\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      9 |          200.016 | 1456128 |  229.623 |              282.535 |              118.596 |            847.213 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3524.805674518201\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_08-20-16\n",
       "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 839.9789029535865\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 232.63740250607327\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4487,80 +5764,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
+      "        entropy: 1.0076924065748851\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
+      "        kl: 0.006664008173781137\n",
       "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.007970896758100329\n",
+      "        total_loss: 19.40124209721883\n",
+      "        vf_explained_var: 0.9715626239776611\n",
+      "        vf_loss: 19.409050464630127\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
+      "    cpu_util_percent: 29.65\n",
+      "    gpu_util_percent0: 0.3926923076923077\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
+      "    ram_util_percent: 3.761538461538461\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
+      "    mean_action_processing_ms: 0.1545620977237074\n",
+      "    mean_env_wait_ms: 1.186670827850528\n",
+      "    mean_inference_ms: 4.777711485075414\n",
+      "    mean_raw_obs_processing_ms: 0.40263050559742963\n",
+      "  time_since_restore: 221.60317945480347\n",
+      "  time_this_iter_s: 21.586928844451904\n",
+      "  time_total_s: 221.60317945480347\n",
       "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
+      "    learn_throughput: 10981.455\n",
+      "    learn_time_ms: 14733.202\n",
+      "    sample_throughput: 22066.542\n",
+      "    sample_time_ms: 7332.005\n",
+      "    update_time_ms: 41.18\n",
+      "  timestamp: 1602490816\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     10 |          221.603 | 1617920 |  232.637 |              288.141 |              118.596 |            839.979 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3515.567620927937\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_08-20-38\n",
       "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 836.7551119766309\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 234.13157377081416\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4569,80 +5846,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
+      "        entropy: 0.9877197394768397\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
+      "        kl: 0.007032672797019283\n",
       "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.0085028958710609\n",
+      "        total_loss: 13.62386417388916\n",
+      "        vf_explained_var: 0.972416877746582\n",
+      "        vf_loss: 13.632157802581787\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
+      "    cpu_util_percent: 29.884615384615383\n",
+      "    gpu_util_percent0: 0.35500000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
+      "    ram_util_percent: 3.7807692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
+      "    mean_action_processing_ms: 0.15420689223114267\n",
+      "    mean_env_wait_ms: 1.188281984880439\n",
+      "    mean_inference_ms: 4.754489900097536\n",
+      "    mean_raw_obs_processing_ms: 0.40144947710727935\n",
+      "  time_since_restore: 243.3785741329193\n",
+      "  time_this_iter_s: 21.775394678115845\n",
+      "  time_total_s: 243.3785741329193\n",
       "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
+      "    learn_throughput: 10994.005\n",
+      "    learn_time_ms: 14716.384\n",
+      "    sample_throughput: 22725.409\n",
+      "    sample_time_ms: 7119.432\n",
+      "    update_time_ms: 41.124\n",
+      "  timestamp: 1602490838\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     11 |          243.379 | 1779712 |  234.132 |              288.141 |              118.596 |            836.755 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3506.289377289377\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-21-00\n",
       "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 834.1546112115732\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 235.46928142181295\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4651,80 +5928,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
+      "        entropy: 0.9678831497828165\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
+      "        kl: 0.006004722556099296\n",
       "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.009751358816477781\n",
+      "        total_loss: 12.226415316263834\n",
+      "        vf_explained_var: 0.9737133383750916\n",
+      "        vf_loss: 12.23604973157247\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
+      "    cpu_util_percent: 28.969230769230776\n",
+      "    gpu_util_percent0: 0.3538461538461538\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
+      "    ram_util_percent: 3.7615384615384615\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
+      "    mean_action_processing_ms: 0.15388558015710302\n",
+      "    mean_env_wait_ms: 1.1897205745623838\n",
+      "    mean_inference_ms: 4.733412954819154\n",
+      "    mean_raw_obs_processing_ms: 0.40035092487229396\n",
+      "  time_since_restore: 265.1564075946808\n",
+      "  time_this_iter_s: 21.777833461761475\n",
+      "  time_total_s: 265.1564075946808\n",
       "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
+      "    learn_throughput: 11014.664\n",
+      "    learn_time_ms: 14688.781\n",
+      "    sample_throughput: 22915.538\n",
+      "    sample_time_ms: 7060.362\n",
+      "    update_time_ms: 35.679\n",
+      "  timestamp: 1602490860\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     12 |          265.156 | 1941504 |  235.469 |              288.141 |              118.596 |            834.155 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3491.8694060211556\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-21-22\n",
       "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 830.4947707160096\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 237.5231031148166\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 274\n",
+      "  episodes_total: 2486\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4733,80 +6010,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
+      "        entropy: 0.9290325542291006\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
+      "        kl: 0.006295189222631355\n",
       "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.008376634260154484\n",
+      "        total_loss: 16.791339874267578\n",
+      "        vf_explained_var: 0.9763460755348206\n",
+      "        vf_loss: 16.799551486968994\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
+      "    cpu_util_percent: 29.807692307692307\n",
+      "    gpu_util_percent0: 0.35038461538461535\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
+      "    ram_util_percent: 3.753846153846154\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
+      "    mean_action_processing_ms: 0.1534026797728033\n",
+      "    mean_env_wait_ms: 1.1921915934861729\n",
+      "    mean_inference_ms: 4.701865327501849\n",
+      "    mean_raw_obs_processing_ms: 0.39870932714343327\n",
+      "  time_since_restore: 286.9444353580475\n",
+      "  time_this_iter_s: 21.7880277633667\n",
+      "  time_total_s: 286.9444353580475\n",
       "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
+      "    learn_throughput: 11020.361\n",
+      "    learn_time_ms: 14681.189\n",
+      "    sample_throughput: 22948.562\n",
+      "    sample_time_ms: 7050.202\n",
+      "    update_time_ms: 36.619\n",
+      "  timestamp: 1602490882\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     13 |          286.944 | 2103296 |  237.523 |              288.141 |              118.596 |            830.495 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3483.349134687735\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-21-43\n",
       "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 828.1734921816828\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 238.66669675158124\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 200\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4815,80 +6092,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
+      "        entropy: 0.9232238580783209\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
+      "        kl: 0.006286289620523651\n",
       "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.01046323703970605\n",
+      "        total_loss: 11.78066317240397\n",
+      "        vf_explained_var: 0.9783161282539368\n",
+      "        vf_loss: 11.79095975557963\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
+      "    cpu_util_percent: 31.0\n",
+      "    gpu_util_percent0: 0.2956\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
+      "    ram_util_percent: 3.7799999999999994\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
+      "    mean_action_processing_ms: 0.15309949060833375\n",
+      "    mean_env_wait_ms: 1.1936688099878277\n",
+      "    mean_inference_ms: 4.68158069729053\n",
+      "    mean_raw_obs_processing_ms: 0.3976814010577938\n",
+      "  time_since_restore: 308.1764705181122\n",
+      "  time_this_iter_s: 21.232035160064697\n",
+      "  time_total_s: 308.1764705181122\n",
       "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
+      "    learn_throughput: 11062.35\n",
+      "    learn_time_ms: 14625.464\n",
+      "    sample_throughput: 22970.509\n",
+      "    sample_time_ms: 7043.466\n",
+      "    update_time_ms: 34.789\n",
+      "  timestamp: 1602490903\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     14 |          308.176 | 2265088 |  238.667 |              288.141 |              118.596 |            828.173 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3477.3824573863635\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-22-05\n",
       "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 826.8424753867791\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 239.64862762647567\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4897,80 +6174,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
+      "        entropy: 0.9125363181034724\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
+      "        kl: 0.00608441144383202\n",
       "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
+      "        policy_loss: -0.008707707068727663\n",
+      "        total_loss: 9.64974331855774\n",
+      "        vf_explained_var: 0.9798218607902527\n",
+      "        vf_loss: 9.65829865137736\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
+      "    cpu_util_percent: 29.60769230769231\n",
+      "    gpu_util_percent0: 0.3346153846153846\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
+      "    ram_util_percent: 3.776923076923077\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
+      "    mean_action_processing_ms: 0.15288317920572567\n",
+      "    mean_env_wait_ms: 1.194748016689442\n",
+      "    mean_inference_ms: 4.667225431805814\n",
+      "    mean_raw_obs_processing_ms: 0.3969378355610825\n",
+      "  time_since_restore: 329.7988615036011\n",
+      "  time_this_iter_s: 21.62239098548889\n",
+      "  time_total_s: 329.7988615036011\n",
       "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
+      "    learn_throughput: 11071.0\n",
+      "    learn_time_ms: 14614.036\n",
+      "    sample_throughput: 22991.378\n",
+      "    sample_time_ms: 7037.073\n",
+      "    update_time_ms: 34.298\n",
+      "  timestamp: 1602490925\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     15 |          329.799 | 2426880 |  239.649 |              288.141 |              118.596 |            826.842 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3471.586357526882\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-22-27\n",
       "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 825.6671105193076\n",
+      "  episode_reward_max: 290.11111111111103\n",
+      "  episode_reward_mean: 240.53267024438787\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 3004\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4979,80 +6256,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
+      "        entropy: 0.8860243856906891\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
+      "        kl: 0.006397477972010772\n",
       "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
+      "        policy_loss: -0.008911015300933892\n",
+      "        total_loss: 11.561505238215128\n",
+      "        vf_explained_var: 0.9785943031311035\n",
+      "        vf_loss: 11.57021967569987\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
+      "    cpu_util_percent: 29.15925925925926\n",
+      "    gpu_util_percent0: 0.3262962962962963\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.77037037037037\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
+      "    mean_action_processing_ms: 0.15268173840271962\n",
+      "    mean_env_wait_ms: 1.19574489708898\n",
+      "    mean_inference_ms: 4.653763309399263\n",
+      "    mean_raw_obs_processing_ms: 0.39622961868207607\n",
+      "  time_since_restore: 351.7714014053345\n",
+      "  time_this_iter_s: 21.9725399017334\n",
+      "  time_total_s: 351.7714014053345\n",
       "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
+      "    learn_throughput: 11050.606\n",
+      "    learn_time_ms: 14641.007\n",
+      "    sample_throughput: 22973.716\n",
+      "    sample_time_ms: 7042.483\n",
+      "    update_time_ms: 36.284\n",
+      "  timestamp: 1602490947\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     16 |          351.771 | 2588672 |  240.533 |              290.111 |              118.596 |            825.667 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3461.5548112058464\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-22-49\n",
       "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 823.8010265700483\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 242.11498133508994\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 308\n",
+      "  episodes_total: 3312\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5061,80 +6338,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
+      "        entropy: 0.8602482428153356\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
+      "        kl: 0.006070932140573859\n",
       "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
+      "        policy_loss: -0.009451528991727779\n",
+      "        total_loss: 13.428233623504639\n",
+      "        vf_explained_var: 0.981722891330719\n",
+      "        vf_loss: 13.437508344650269\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
+      "    cpu_util_percent: 29.77692307692308\n",
+      "    gpu_util_percent0: 0.40192307692307705\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
+      "    ram_util_percent: 3.757692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
+      "    mean_action_processing_ms: 0.1523316783764433\n",
+      "    mean_env_wait_ms: 1.197482520364091\n",
+      "    mean_inference_ms: 4.630753591799989\n",
+      "    mean_raw_obs_processing_ms: 0.39506937213176363\n",
+      "  time_since_restore: 373.392630815506\n",
+      "  time_this_iter_s: 21.62122941017151\n",
+      "  time_total_s: 373.392630815506\n",
       "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
+      "    learn_throughput: 11067.625\n",
+      "    learn_time_ms: 14618.493\n",
+      "    sample_throughput: 23078.296\n",
+      "    sample_time_ms: 7010.57\n",
+      "    update_time_ms: 35.004\n",
+      "  timestamp: 1602490969\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     17 |          373.393 | 2750464 |  242.115 |              290.414 |              118.596 |            823.801 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3455.939385150812\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-23-11\n",
       "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 822.9513808975835\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 242.9883733770384\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 164\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5143,80 +6420,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
+      "        entropy: 0.8480297277371088\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
+      "        kl: 0.005980685236863792\n",
       "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
+      "        policy_loss: -0.009295757947256789\n",
+      "        total_loss: 8.385785063107809\n",
+      "        vf_explained_var: 0.98355633020401\n",
+      "        vf_loss: 8.394906878471375\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
+      "    cpu_util_percent: 29.719230769230762\n",
+      "    gpu_util_percent0: 0.38961538461538464\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
+      "    ram_util_percent: 3.776923076923077\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
+      "    mean_action_processing_ms: 0.15216380576721844\n",
+      "    mean_env_wait_ms: 1.198240484170083\n",
+      "    mean_inference_ms: 4.619870814820799\n",
+      "    mean_raw_obs_processing_ms: 0.39451138085377374\n",
+      "  time_since_restore: 394.9590709209442\n",
+      "  time_this_iter_s: 21.566440105438232\n",
+      "  time_total_s: 394.9590709209442\n",
       "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
+      "    learn_throughput: 11083.274\n",
+      "    learn_time_ms: 14597.852\n",
+      "    sample_throughput: 23126.733\n",
+      "    sample_time_ms: 6995.887\n",
+      "    update_time_ms: 33.651\n",
+      "  timestamp: 1602490991\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     18 |          394.959 | 2912256 |  242.988 |              290.414 |              118.596 |            822.951 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3450.849694952856\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-23-32\n",
       "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 822.1293340671436\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 243.76256789135152\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5225,80 +6502,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
+      "        entropy: 0.8463053901990255\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
+      "        kl: 0.005816654340984921\n",
       "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
+      "        policy_loss: -0.008370639804828292\n",
+      "        total_loss: 9.871557076772055\n",
+      "        vf_explained_var: 0.9790952801704407\n",
+      "        vf_loss: 9.879769563674927\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
+      "    cpu_util_percent: 29.973076923076924\n",
+      "    gpu_util_percent0: 0.4196153846153846\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
+      "    ram_util_percent: 3.776923076923077\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
+      "    mean_action_processing_ms: 0.15201376411298773\n",
+      "    mean_env_wait_ms: 1.1989255429744285\n",
+      "    mean_inference_ms: 4.61002629957187\n",
+      "    mean_raw_obs_processing_ms: 0.39400633263886187\n",
+      "  time_since_restore: 416.5034601688385\n",
+      "  time_this_iter_s: 21.544389247894287\n",
+      "  time_total_s: 416.5034601688385\n",
       "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
+      "    learn_throughput: 11104.878\n",
+      "    learn_time_ms: 14569.453\n",
+      "    sample_throughput: 23182.323\n",
+      "    sample_time_ms: 6979.111\n",
+      "    update_time_ms: 32.143\n",
+      "  timestamp: 1602491012\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     19 |          416.503 | 3074048 |  243.763 |              290.414 |              118.596 |            822.129 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3444.7242281527997\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-23-54\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 820.728051948052\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 244.5843499934408\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 216\n",
+      "  episodes_total: 3850\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5307,671 +6584,753 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
+      "        entropy: 0.8126419484615326\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
+      "        kl: 0.005857201875187457\n",
       "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
+      "        policy_loss: -0.00785230855884341\n",
+      "        total_loss: 12.330925305684408\n",
+      "        vf_explained_var: 0.9810908436775208\n",
+      "        vf_loss: 12.338598330815634\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.684\n",
+      "    gpu_util_percent0: 0.3696\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.756\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15182597036787565\n",
+      "    mean_env_wait_ms: 1.1998648566925316\n",
+      "    mean_inference_ms: 4.59769219767983\n",
+      "    mean_raw_obs_processing_ms: 0.3933754930031549\n",
+      "  time_since_restore: 437.9918293952942\n",
+      "  time_this_iter_s: 21.48836922645569\n",
+      "  time_total_s: 437.9918293952942\n",
+      "  timers:\n",
+      "    learn_throughput: 11114.896\n",
+      "    learn_time_ms: 14556.322\n",
+      "    sample_throughput: 23172.677\n",
+      "    sample_time_ms: 6982.016\n",
+      "    update_time_ms: 32.369\n",
+      "  timestamp: 1602491034\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     20 |          437.992 | 3235840 |  244.584 |              290.414 |              118.596 |            820.728 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3437.690441176471\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-24-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 819.2585199610517\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 245.53567072870865\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 258\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7962117195129395\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004699128757541378\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007990811747731641\n",
+      "        total_loss: 10.702264308929443\n",
+      "        vf_explained_var: 0.9830734729766846\n",
+      "        vf_loss: 10.710183302561441\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
+      "    cpu_util_percent: 28.366666666666667\n",
+      "    gpu_util_percent0: 0.29074074074074074\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
+      "    mean_action_processing_ms: 0.15161483382226207\n",
+      "    mean_env_wait_ms: 1.2008228195208275\n",
+      "    mean_inference_ms: 4.584031516371675\n",
+      "    mean_raw_obs_processing_ms: 0.392688806021127\n",
+      "  time_since_restore: 459.91959524154663\n",
+      "  time_this_iter_s: 21.92776584625244\n",
+      "  time_total_s: 459.91959524154663\n",
       "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
+      "    learn_throughput: 11108.902\n",
+      "    learn_time_ms: 14564.176\n",
+      "    sample_throughput: 23146.475\n",
+      "    sample_time_ms: 6989.919\n",
+      "    update_time_ms: 31.574\n",
+      "  timestamp: 1602491056\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     21 |           459.92 | 3397632 |  245.536 |              290.414 |              118.596 |            819.259 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3433.871165644172\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-24-38\n",
       "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 818.1823722456634\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 246.1614527838156\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
+      "        entropy: 0.7922417124112447\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
+      "        kl: 0.006179819426809748\n",
       "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
+      "        policy_loss: -0.010333442517245809\n",
+      "        total_loss: 7.185657620429993\n",
+      "        vf_explained_var: 0.9850761890411377\n",
+      "        vf_loss: 7.1960781415303545\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
+      "    cpu_util_percent: 29.17307692307692\n",
+      "    gpu_util_percent0: 0.41423076923076924\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
+      "    ram_util_percent: 3.7807692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
+      "    mean_action_processing_ms: 0.15149682416537705\n",
+      "    mean_env_wait_ms: 1.201374445162289\n",
+      "    mean_inference_ms: 4.576403214104389\n",
+      "    mean_raw_obs_processing_ms: 0.39230323446183507\n",
+      "  time_since_restore: 481.6516396999359\n",
+      "  time_this_iter_s: 21.732044458389282\n",
+      "  time_total_s: 481.6516396999359\n",
       "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
+      "    learn_throughput: 11106.817\n",
+      "    learn_time_ms: 14566.909\n",
+      "    sample_throughput: 23172.025\n",
+      "    sample_time_ms: 6982.212\n",
+      "    update_time_ms: 31.216\n",
+      "  timestamp: 1602491078\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     22 |          481.652 | 3559424 |  246.161 |              293.899 |              118.596 |            818.182 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3429.85662349466\n",
+      "    time_step_min: 3135\n",
+      "  date: 2020-10-12_08-25-00\n",
       "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 817.115601715963\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 246.75540457635734\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 4429\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
+      "        entropy: 0.7696222414573034\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
+      "        kl: 0.006637000245973468\n",
       "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
+      "        policy_loss: -0.008142252181035778\n",
+      "        total_loss: 9.046889623006185\n",
+      "        vf_explained_var: 0.9829367995262146\n",
+      "        vf_loss: 9.055085023244223\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
+      "    cpu_util_percent: 29.426923076923078\n",
+      "    gpu_util_percent0: 0.32230769230769235\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
+      "    ram_util_percent: 3.7807692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
+      "    mean_action_processing_ms: 0.15138571915254828\n",
+      "    mean_env_wait_ms: 1.2019350771701267\n",
+      "    mean_inference_ms: 4.569002703077179\n",
+      "    mean_raw_obs_processing_ms: 0.3919233349017119\n",
+      "  time_since_restore: 503.2853772640228\n",
+      "  time_this_iter_s: 21.633737564086914\n",
+      "  time_total_s: 503.2853772640228\n",
       "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
+      "    learn_throughput: 11104.524\n",
+      "    learn_time_ms: 14569.917\n",
+      "    sample_throughput: 23231.381\n",
+      "    sample_time_ms: 6964.373\n",
+      "    update_time_ms: 29.524\n",
+      "  timestamp: 1602491100\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     23 |          503.285 | 3721216 |  246.755 |              293.899 |              118.596 |            817.116 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3423.16099532114\n",
+      "    time_step_min: 3135\n",
+      "  date: 2020-10-12_08-25-21\n",
       "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 815.1300211416491\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 247.74651376342703\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 301\n",
+      "  episodes_total: 4730\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
+      "        entropy: 0.7392598738272985\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
+      "        kl: 0.005826210797143479\n",
       "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
+      "        policy_loss: -0.009122005936660571\n",
+      "        total_loss: 10.013187249501547\n",
+      "        vf_explained_var: 0.9857361912727356\n",
+      "        vf_loss: 10.022387663523356\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
+      "    cpu_util_percent: 29.756\n",
+      "    gpu_util_percent0: 0.36560000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
+      "    ram_util_percent: 3.7640000000000002\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
+      "    mean_action_processing_ms: 0.15118670580087262\n",
+      "    mean_env_wait_ms: 1.2029626221917573\n",
+      "    mean_inference_ms: 4.556226465372887\n",
+      "    mean_raw_obs_processing_ms: 0.391288705553902\n",
+      "  time_since_restore: 524.8132407665253\n",
+      "  time_this_iter_s: 21.52786350250244\n",
+      "  time_total_s: 524.8132407665253\n",
       "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
+      "    learn_throughput: 11072.325\n",
+      "    learn_time_ms: 14612.288\n",
+      "    sample_throughput: 23276.561\n",
+      "    sample_time_ms: 6950.855\n",
+      "    update_time_ms: 29.333\n",
+      "  timestamp: 1602491121\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     24 |          524.813 | 3883008 |  247.747 |              293.899 |              118.596 |             815.13 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3419.282751540041\n",
+      "    time_step_min: 3135\n",
+      "  date: 2020-10-12_08-25-43\n",
       "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 814.100653327889\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 248.32132678355623\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 168\n",
+      "  episodes_total: 4898\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
+      "        entropy: 0.7336608171463013\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
+      "        kl: 0.006113760716592272\n",
       "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
+      "        policy_loss: -0.009550909734874343\n",
+      "        total_loss: 6.576909343401591\n",
+      "        vf_explained_var: 0.9865676760673523\n",
+      "        vf_loss: 6.58652130762736\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
+      "    cpu_util_percent: 28.73076923076923\n",
+      "    gpu_util_percent0: 0.32346153846153847\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
+      "    ram_util_percent: 3.776923076923077\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
+      "    mean_action_processing_ms: 0.15108537890214208\n",
+      "    mean_env_wait_ms: 1.2034634470979062\n",
+      "    mean_inference_ms: 4.549592354974739\n",
+      "    mean_raw_obs_processing_ms: 0.3909562190733837\n",
+      "  time_since_restore: 546.2893211841583\n",
+      "  time_this_iter_s: 21.476080417633057\n",
+      "  time_total_s: 546.2893211841583\n",
       "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
+      "    learn_throughput: 11081.383\n",
+      "    learn_time_ms: 14600.343\n",
+      "    sample_throughput: 23282.075\n",
+      "    sample_time_ms: 6949.209\n",
+      "    update_time_ms: 27.926\n",
+      "  timestamp: 1602491143\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     25 |          546.289 | 4044800 |  248.321 |              293.899 |              118.596 |            814.101 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3415.8178564326904\n",
+      "    time_step_min: 3128\n",
+      "  date: 2020-10-12_08-26-05\n",
       "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 813.1633379473997\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 248.8292395978771\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 5057\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
+      "        entropy: 0.7295501778523127\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
+      "        kl: 0.005874564366725584\n",
       "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.008493003813782707\n",
+      "        total_loss: 7.950014750162761\n",
+      "        vf_explained_var: 0.983363151550293\n",
+      "        vf_loss: 7.958578626314799\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
+      "    cpu_util_percent: 29.542307692307695\n",
+      "    gpu_util_percent0: 0.3719230769230769\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
+      "    ram_util_percent: 3.7884615384615383\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
+      "    mean_action_processing_ms: 0.1509959980043755\n",
+      "    mean_env_wait_ms: 1.2039438535670208\n",
+      "    mean_inference_ms: 4.543643745260567\n",
+      "    mean_raw_obs_processing_ms: 0.39065745577815003\n",
+      "  time_since_restore: 567.7602591514587\n",
+      "  time_this_iter_s: 21.470937967300415\n",
+      "  time_total_s: 567.7602591514587\n",
       "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
+      "    learn_throughput: 11102.74\n",
+      "    learn_time_ms: 14572.258\n",
+      "    sample_throughput: 23346.655\n",
+      "    sample_time_ms: 6929.986\n",
+      "    update_time_ms: 25.614\n",
+      "  timestamp: 1602491165\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     26 |           567.76 | 4206592 |  248.829 |              293.899 |              118.596 |            813.163 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3409.7600677455775\n",
+      "    time_step_min: 3128\n",
+      "  date: 2020-10-12_08-26-26\n",
       "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 811.4490827405466\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 249.6970396590389\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 285\n",
+      "  episodes_total: 5342\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
+      "        entropy: 0.6967413127422333\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
+      "        kl: 0.006306514337969323\n",
       "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.009041692143606875\n",
+      "        total_loss: 9.368427356084188\n",
+      "        vf_explained_var: 0.9863912463188171\n",
+      "        vf_loss: 9.377501646677652\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
+      "    cpu_util_percent: 29.844\n",
+      "    gpu_util_percent0: 0.3772\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
+      "    ram_util_percent: 3.7599999999999993\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
+      "    mean_action_processing_ms: 0.15084418754751167\n",
+      "    mean_env_wait_ms: 1.204832560302368\n",
+      "    mean_inference_ms: 4.533798639536211\n",
+      "    mean_raw_obs_processing_ms: 0.3901641161662921\n",
+      "  time_since_restore: 589.397045135498\n",
+      "  time_this_iter_s: 21.636785984039307\n",
+      "  time_total_s: 589.397045135498\n",
       "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
+      "    learn_throughput: 11092.25\n",
+      "    learn_time_ms: 14586.04\n",
+      "    sample_throughput: 23395.212\n",
+      "    sample_time_ms: 6915.603\n",
+      "    update_time_ms: 27.344\n",
+      "  timestamp: 1602491186\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     27 |          589.397 | 4368384 |  249.697 |              293.899 |              118.596 |            811.449 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3405.737549981825\n",
+      "    time_step_min: 3128\n",
+      "  date: 2020-10-12_08-26-48\n",
       "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 810.4667269439421\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 250.2915045573273\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 188\n",
+      "  episodes_total: 5530\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
+      "        entropy: 0.675686240196228\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
+      "        kl: 0.005107206680501501\n",
       "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.00786691315685554\n",
+      "        total_loss: 7.04692538579305\n",
+      "        vf_explained_var: 0.9860422015190125\n",
+      "        vf_loss: 7.054874618848165\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
+      "    cpu_util_percent: 29.199999999999996\n",
+      "    gpu_util_percent0: 0.33692307692307694\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
+      "    ram_util_percent: 3.780769230769231\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
+      "    mean_action_processing_ms: 0.15074896499452803\n",
+      "    mean_env_wait_ms: 1.2053334662527855\n",
+      "    mean_inference_ms: 4.527474043839373\n",
+      "    mean_raw_obs_processing_ms: 0.3898601834278142\n",
+      "  time_since_restore: 610.9207043647766\n",
+      "  time_this_iter_s: 21.523659229278564\n",
+      "  time_total_s: 610.9207043647766\n",
       "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
+      "    learn_throughput: 11086.727\n",
+      "    learn_time_ms: 14593.306\n",
+      "    sample_throughput: 23437.181\n",
+      "    sample_time_ms: 6903.219\n",
+      "    update_time_ms: 27.218\n",
+      "  timestamp: 1602491208\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
+      "| PPO_jss_env_39cc5_00000 | TERMINATED |       |     28 |          610.921 | 4530176 |  250.292 |              293.899 |              118.596 |            810.467 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
+      "| PPO_jss_env_39cc5_00000 | TERMINATED |       |     28 |          610.921 | 4530176 |  250.292 |              293.899 |              118.596 |            810.467 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24616\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_081622-6nvy6bhw/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_081622-6nvy6bhw/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3128\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602491208\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4134\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3405.73755\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 293.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 118.59596\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 250.2915\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5530\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
@@ -5987,449 +7346,20 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mazure-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/6nvy6bhw\u001b[0m\n",
+      "2020-10-12 08:26:56,087 - wandb.wandb_agent - INFO - Cleaning up finished run: 6nvy6bhw\n",
+      "2020-10-12 08:26:56,400 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:26:56,400 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
       "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
       "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
-      "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
-      "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
-      "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n"
+      "2020-10-12 08:26:56,403 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent q78e25ms"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index ac81b03..0ea65b2 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 8ee10cb..07c0b41 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug-internal.log
\ No newline at end of file
+run-20201012_082658-q0jbd5ol/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4f3bf3b..d49d805 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug.log
\ No newline at end of file
+run-20201012_082658-q0jbd5ol/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 8be457f..4eacc77 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201012_023117-p62mhra8
\ No newline at end of file
+run-20201012_082658-q0jbd5ol
\ No newline at end of file
