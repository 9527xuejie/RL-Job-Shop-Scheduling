2020-10-12 08:27:02,632	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b50e2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=56858)[0m 2020-10-12 08:27:05,402	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=56824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56796)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_08-27-38
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1851047078768413
        entropy_coeff: 0.0005000000000000001
        kl: 0.004071502441850801
        model: {}
        policy_loss: -0.00785889983914482
        total_loss: 507.07567087809247
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.634375
    gpu_util_percent0: 0.26875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5718750000000004
    vram_util_percent0: 0.08698036241390619
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16685353344183862
    mean_env_wait_ms: 1.1679478021417367
    mean_inference_ms: 5.432594445944936
    mean_raw_obs_processing_ms: 0.4397812019199749
  time_since_restore: 27.773663997650146
  time_this_iter_s: 27.773663997650146
  time_total_s: 27.773663997650146
  timers:
    learn_throughput: 8530.856
    learn_time_ms: 18965.507
    sample_throughput: 18503.321
    sample_time_ms: 8743.944
    update_time_ms: 28.446
  timestamp: 1602491258
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      1 |          27.7737 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3614.4305555555557
    time_step_min: 3250
  date: 2020-10-12_08-28-05
  done: false
  episode_len_mean: 890.8607594936709
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.6365234624726
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1561074058214824
        entropy_coeff: 0.0005000000000000001
        kl: 0.007923512797181806
        model: {}
        policy_loss: -0.010965243893830726
        total_loss: 127.46906661987305
        vf_explained_var: 0.8076093792915344
        vf_loss: 127.47981770833333
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.76774193548387
    gpu_util_percent0: 0.25387096774193546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7483870967741932
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16356765459772646
    mean_env_wait_ms: 1.1668320901532692
    mean_inference_ms: 5.292065685229201
    mean_raw_obs_processing_ms: 0.43211279746919895
  time_since_restore: 54.347506284713745
  time_this_iter_s: 26.5738422870636
  time_total_s: 54.347506284713745
  timers:
    learn_throughput: 8594.957
    learn_time_ms: 18824.062
    sample_throughput: 19561.031
    sample_time_ms: 8271.139
    update_time_ms: 36.678
  timestamp: 1602491285
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      2 |          54.3475 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.8677130044844
    time_step_min: 3250
  date: 2020-10-12_08-28-31
  done: false
  episode_len_mean: 885.132911392405
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 219.87009333844756
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1456398169199626
        entropy_coeff: 0.0005000000000000001
        kl: 0.008224547879459957
        model: {}
        policy_loss: -0.013529085864623388
        total_loss: 61.275455474853516
        vf_explained_var: 0.8916645646095276
        vf_loss: 61.28873507181803
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.589999999999996
    gpu_util_percent0: 0.4183333333333332
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16107501960595214
    mean_env_wait_ms: 1.1671126318189669
    mean_inference_ms: 5.153129934027859
    mean_raw_obs_processing_ms: 0.42528733449335054
  time_since_restore: 80.20835757255554
  time_this_iter_s: 25.860851287841797
  time_total_s: 80.20835757255554
  timers:
    learn_throughput: 8612.207
    learn_time_ms: 18786.357
    sample_throughput: 20559.193
    sample_time_ms: 7869.57
    update_time_ms: 35.435
  timestamp: 1602491311
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      3 |          80.2084 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3596.0099337748343
    time_step_min: 3231
  date: 2020-10-12_08-28-56
  done: false
  episode_len_mean: 878.7689873417721
  episode_reward_max: 276.47474747474763
  episode_reward_mean: 220.6047340493541
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1263898611068726
        entropy_coeff: 0.0005000000000000001
        kl: 0.008100568510902425
        model: {}
        policy_loss: -0.013406771836647144
        total_loss: 47.16934140523275
        vf_explained_var: 0.9198758602142334
        vf_loss: 47.18250052134196
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.160000000000004
    gpu_util_percent0: 0.3093333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15927669885835546
    mean_env_wait_ms: 1.1684658072392184
    mean_inference_ms: 5.047141820534734
    mean_raw_obs_processing_ms: 0.41967187543535894
  time_since_restore: 105.9318573474884
  time_this_iter_s: 25.72349977493286
  time_total_s: 105.9318573474884
  timers:
    learn_throughput: 8619.167
    learn_time_ms: 18771.187
    sample_throughput: 21195.516
    sample_time_ms: 7633.313
    update_time_ms: 31.747
  timestamp: 1602491336
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      4 |          105.932 | 647168 |  220.605 |              276.475 |              145.717 |            878.769 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3581.6985583224114
    time_step_min: 3204
  date: 2020-10-12_08-29-22
  done: false
  episode_len_mean: 872.4867256637168
  episode_reward_max: 280.5656565656565
  episode_reward_mean: 222.48133675567283
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 159
  episodes_total: 791
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0873714486757915
        entropy_coeff: 0.0005000000000000001
        kl: 0.006956188706681132
        model: {}
        policy_loss: -0.011262792395427823
        total_loss: 34.19948164621989
        vf_explained_var: 0.9459590911865234
        vf_loss: 34.2105925877889
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.229032258064517
    gpu_util_percent0: 0.36677419354838714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15788454068385543
    mean_env_wait_ms: 1.1707007939199836
    mean_inference_ms: 4.964668926523751
    mean_raw_obs_processing_ms: 0.4151380720341482
  time_since_restore: 131.79730200767517
  time_this_iter_s: 25.865444660186768
  time_total_s: 131.79730200767517
  timers:
    learn_throughput: 8618.29
    learn_time_ms: 18773.099
    sample_throughput: 21581.782
    sample_time_ms: 7496.693
    update_time_ms: 29.37
  timestamp: 1602491362
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      5 |          131.797 | 808960 |  222.481 |              280.566 |              145.717 |            872.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3564.887755102041
    time_step_min: 3204
  date: 2020-10-12_08-29-48
  done: false
  episode_len_mean: 860.6943942133815
  episode_reward_max: 280.5656565656565
  episode_reward_mean: 225.7112809834327
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 315
  episodes_total: 1106
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0886386533578236
        entropy_coeff: 0.0005000000000000001
        kl: 0.007588425030310948
        model: {}
        policy_loss: -0.01092883839737624
        total_loss: 30.730765342712402
        vf_explained_var: 0.9611188769340515
        vf_loss: 30.741480032602947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.956666666666667
    gpu_util_percent0: 0.405
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7566666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15599735271528273
    mean_env_wait_ms: 1.1757357125865684
    mean_inference_ms: 4.853323471533123
    mean_raw_obs_processing_ms: 0.40931598209773395
  time_since_restore: 157.56571769714355
  time_this_iter_s: 25.768415689468384
  time_total_s: 157.56571769714355
  timers:
    learn_throughput: 8617.26
    learn_time_ms: 18775.341
    sample_throughput: 21904.527
    sample_time_ms: 7386.236
    update_time_ms: 29.208
  timestamp: 1602491388
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      6 |          157.566 | 970752 |  225.711 |              280.566 |              145.717 |            860.694 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3552.704692556634
    time_step_min: 3179
  date: 2020-10-12_08-30-14
  done: false
  episode_len_mean: 855.0387658227849
  episode_reward_max: 284.35353535353545
  episode_reward_mean: 227.46978487405684
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0706470410029094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007387861027382314
        model: {}
        policy_loss: -0.013462736414415607
        total_loss: 19.742233912150066
        vf_explained_var: 0.9632093906402588
        vf_loss: 19.75549300511678
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.49666666666667
    gpu_util_percent0: 0.29433333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15530080693050297
    mean_env_wait_ms: 1.1778749831186706
    mean_inference_ms: 4.812541661631387
    mean_raw_obs_processing_ms: 0.40715848313222897
  time_since_restore: 183.37474465370178
  time_this_iter_s: 25.809026956558228
  time_total_s: 183.37474465370178
  timers:
    learn_throughput: 8610.851
    learn_time_ms: 18789.315
    sample_throughput: 22137.639
    sample_time_ms: 7308.458
    update_time_ms: 29.392
  timestamp: 1602491414
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      7 |          183.375 | 1132544 |   227.47 |              284.354 |              145.717 |            855.039 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3540.6398852223815
    time_step_min: 3179
  date: 2020-10-12_08-30-40
  done: false
  episode_len_mean: 850.7552742616034
  episode_reward_max: 284.35353535353545
  episode_reward_mean: 229.23441162681647
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0475670397281647
        entropy_coeff: 0.0005000000000000001
        kl: 0.007399068369219701
        model: {}
        policy_loss: -0.009183195322596779
        total_loss: 16.652963479359943
        vf_explained_var: 0.9667003154754639
        vf_loss: 16.661930561065674
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.59
    gpu_util_percent0: 0.3423333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546926297232668
    mean_env_wait_ms: 1.179701493934929
    mean_inference_ms: 4.776937228752141
    mean_raw_obs_processing_ms: 0.40521504870584935
  time_since_restore: 209.05934143066406
  time_this_iter_s: 25.68459677696228
  time_total_s: 209.05934143066406
  timers:
    learn_throughput: 8621.673
    learn_time_ms: 18765.73
    sample_throughput: 22252.654
    sample_time_ms: 7270.683
    update_time_ms: 28.796
  timestamp: 1602491440
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      8 |          209.059 | 1294336 |  229.234 |              284.354 |              145.717 |            850.755 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3526.8721374045804
    time_step_min: 3179
  date: 2020-10-12_08-31-06
  done: false
  episode_len_mean: 845.9875
  episode_reward_max: 285.7171717171716
  episode_reward_mean: 231.28724747474732
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 178
  episodes_total: 1600
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9999773452679316
        entropy_coeff: 0.0005000000000000001
        kl: 0.007928823702968657
        model: {}
        policy_loss: -0.011458211791856835
        total_loss: 16.58501172065735
        vf_explained_var: 0.9729644656181335
        vf_loss: 16.596176783243816
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.06333333333334
    gpu_util_percent0: 0.36433333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541003441512452
    mean_env_wait_ms: 1.1818521863514695
    mean_inference_ms: 4.742016009185261
    mean_raw_obs_processing_ms: 0.40328170614028436
  time_since_restore: 234.73203349113464
  time_this_iter_s: 25.67269206047058
  time_total_s: 234.73203349113464
  timers:
    learn_throughput: 8623.109
    learn_time_ms: 18762.607
    sample_throughput: 22401.496
    sample_time_ms: 7222.375
    update_time_ms: 29.742
  timestamp: 1602491466
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      9 |          234.732 | 1456128 |  231.287 |              285.717 |              145.717 |            845.987 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3508.0337259100643
    time_step_min: 3173
  date: 2020-10-12_08-31-32
  done: false
  episode_len_mean: 839.0052742616034
  episode_reward_max: 285.7171717171716
  episode_reward_mean: 234.27066551591852
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 296
  episodes_total: 1896
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9948871235052744
        entropy_coeff: 0.0005000000000000001
        kl: 0.006681857941051324
        model: {}
        policy_loss: -0.011002168253374597
        total_loss: 15.828110535939535
        vf_explained_var: 0.9757750630378723
        vf_loss: 15.838941733042398
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.21666666666666
    gpu_util_percent0: 0.2816666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15330418781933425
    mean_env_wait_ms: 1.185126611501359
    mean_inference_ms: 4.695157746382897
    mean_raw_obs_processing_ms: 0.40072338771829985
  time_since_restore: 260.7745864391327
  time_this_iter_s: 26.042552947998047
  time_total_s: 260.7745864391327
  timers:
    learn_throughput: 8621.363
    learn_time_ms: 18766.406
    sample_throughput: 22420.449
    sample_time_ms: 7216.269
    update_time_ms: 29.275
  timestamp: 1602491492
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     10 |          260.775 | 1617920 |  234.271 |              285.717 |              145.717 |            839.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3499.19842053307
    time_step_min: 3171
  date: 2020-10-12_08-31-58
  done: false
  episode_len_mean: 835.7263875365142
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 235.87525203347977
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.975288137793541
        entropy_coeff: 0.0005000000000000001
        kl: 0.007294710182274382
        model: {}
        policy_loss: -0.012727556153549813
        total_loss: 11.962000767389933
        vf_explained_var: 0.9750909805297852
        vf_loss: 11.974486589431763
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.1448275862069
    gpu_util_percent0: 0.3741379310344828
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15294883238989318
    mean_env_wait_ms: 1.1866395067793458
    mean_inference_ms: 4.674182125426418
    mean_raw_obs_processing_ms: 0.3995715385731446
  time_since_restore: 286.4323949813843
  time_this_iter_s: 25.657808542251587
  time_total_s: 286.4323949813843
  timers:
    learn_throughput: 8628.498
    learn_time_ms: 18750.889
    sample_throughput: 23057.659
    sample_time_ms: 7016.844
    update_time_ms: 30.392
  timestamp: 1602491518
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     11 |          286.432 | 1779712 |  235.875 |              294.202 |              145.717 |            835.726 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3490.923534798535
    time_step_min: 3159
  date: 2020-10-12_08-32-24
  done: false
  episode_len_mean: 832.6595840867993
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 237.1319752680511
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9521185209353765
        entropy_coeff: 0.0005000000000000001
        kl: 0.006661186693236232
        model: {}
        policy_loss: -0.013089668517447231
        total_loss: 12.603836615880331
        vf_explained_var: 0.9737562537193298
        vf_loss: 12.61673672993978
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.0
    gpu_util_percent0: 0.2946666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15262553899195727
    mean_env_wait_ms: 1.1880384910499628
    mean_inference_ms: 4.655044930723983
    mean_raw_obs_processing_ms: 0.3984844650888046
  time_since_restore: 312.2770745754242
  time_this_iter_s: 25.844679594039917
  time_total_s: 312.2770745754242
  timers:
    learn_throughput: 8616.967
    learn_time_ms: 18775.98
    sample_throughput: 23381.461
    sample_time_ms: 6919.67
    update_time_ms: 28.839
  timestamp: 1602491544
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     12 |          312.277 | 1941504 |  237.132 |              294.202 |              145.717 |             832.66 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3477.030998389694
    time_step_min: 3151
  date: 2020-10-12_08-32-49
  done: false
  episode_len_mean: 827.7671178343949
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 239.24816235604442
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 300
  episodes_total: 2512
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9211943199237188
        entropy_coeff: 0.0005000000000000001
        kl: 0.0069003046955913305
        model: {}
        policy_loss: -0.011187698284629732
        total_loss: 15.527917702992758
        vf_explained_var: 0.9792836308479309
        vf_loss: 15.538876056671143
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.96000000000001
    gpu_util_percent0: 0.30400000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15209830857560627
    mean_env_wait_ms: 1.1906489993121385
    mean_inference_ms: 4.623501466732292
    mean_raw_obs_processing_ms: 0.39672878573513676
  time_since_restore: 337.9526643753052
  time_this_iter_s: 25.67558979988098
  time_total_s: 337.9526643753052
  timers:
    learn_throughput: 8613.011
    learn_time_ms: 18784.604
    sample_throughput: 23471.819
    sample_time_ms: 6893.032
    update_time_ms: 27.674
  timestamp: 1602491569
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     13 |          337.953 | 2103296 |  239.248 |              294.202 |              145.717 |            827.767 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3468.7953348382243
    time_step_min: 3151
  date: 2020-10-12_08-33-15
  done: false
  episode_len_mean: 825.1623231571109
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 240.4743300465563
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 174
  episodes_total: 2686
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9143994450569153
        entropy_coeff: 0.0005000000000000001
        kl: 0.0060155229875817895
        model: {}
        policy_loss: -0.012139652118397256
        total_loss: 10.54153060913086
        vf_explained_var: 0.979185163974762
        vf_loss: 10.553526004155477
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.93666666666667
    gpu_util_percent0: 0.36566666666666675
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518304432787989
    mean_env_wait_ms: 1.1919773745862008
    mean_inference_ms: 4.607832873092171
    mean_raw_obs_processing_ms: 0.39585667669054664
  time_since_restore: 363.7148759365082
  time_this_iter_s: 25.762211561203003
  time_total_s: 363.7148759365082
  timers:
    learn_throughput: 8609.094
    learn_time_ms: 18793.15
    sample_throughput: 23519.949
    sample_time_ms: 6878.926
    update_time_ms: 28.481
  timestamp: 1602491595
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     14 |          363.715 | 2265088 |  240.474 |              294.202 |              145.717 |            825.162 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3462.4602272727275
    time_step_min: 3131
  date: 2020-10-12_08-33-41
  done: false
  episode_len_mean: 822.9542897327707
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 241.45540851553497
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9019962549209595
        entropy_coeff: 0.0005000000000000001
        kl: 0.006133316123547654
        model: {}
        policy_loss: -0.012229806568939239
        total_loss: 9.555021127065023
        vf_explained_var: 0.9795403480529785
        vf_loss: 9.567088762919107
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.172413793103452
    gpu_util_percent0: 0.37551724137931036
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.786206896551724
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151607687655734
    mean_env_wait_ms: 1.193090286434833
    mean_inference_ms: 4.5946463140143115
    mean_raw_obs_processing_ms: 0.3950969402364921
  time_since_restore: 389.2473704814911
  time_this_iter_s: 25.53249454498291
  time_total_s: 389.2473704814911
  timers:
    learn_throughput: 8613.956
    learn_time_ms: 18782.543
    sample_throughput: 23577.838
    sample_time_ms: 6862.037
    update_time_ms: 28.54
  timestamp: 1602491621
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     15 |          389.247 | 2426880 |  241.455 |              294.202 |              145.717 |            822.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3453.8821989528797
    time_step_min: 3083
  date: 2020-10-12_08-34-07
  done: false
  episode_len_mean: 819.9792477302204
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 242.75903981448718
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 240
  episodes_total: 3084
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8659086326758066
        entropy_coeff: 0.0005000000000000001
        kl: 0.00634678197093308
        model: {}
        policy_loss: -0.012134946203635385
        total_loss: 13.195513248443604
        vf_explained_var: 0.980156421661377
        vf_loss: 13.207446098327637
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.230000000000004
    gpu_util_percent0: 0.3093333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130438922280068
    mean_env_wait_ms: 1.1947834234298744
    mean_inference_ms: 4.576700910735796
    mean_raw_obs_processing_ms: 0.3940516625903479
  time_since_restore: 414.89031171798706
  time_this_iter_s: 25.64294123649597
  time_total_s: 414.89031171798706
  timers:
    learn_throughput: 8611.981
    learn_time_ms: 18786.851
    sample_throughput: 23612.567
    sample_time_ms: 6851.944
    update_time_ms: 27.668
  timestamp: 1602491647
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     16 |           414.89 | 2588672 |  242.759 |              298.899 |              145.717 |            819.979 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3445.377811550152
    time_step_min: 3083
  date: 2020-10-12_08-34-32
  done: false
  episode_len_mean: 817.4445449065702
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 243.9846110289147
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 234
  episodes_total: 3318
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8606445689996084
        entropy_coeff: 0.0005000000000000001
        kl: 0.005582816433161497
        model: {}
        policy_loss: -0.011729711521184072
        total_loss: 9.780861934026083
        vf_explained_var: 0.9827695488929749
        vf_loss: 9.792463779449463
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.09310344827587
    gpu_util_percent0: 0.32931034482758625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7655172413793094
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15103882590583312
    mean_env_wait_ms: 1.1962458333454598
    mean_inference_ms: 4.560733127331646
    mean_raw_obs_processing_ms: 0.3931480643656643
  time_since_restore: 440.4795105457306
  time_this_iter_s: 25.58919882774353
  time_total_s: 440.4795105457306
  timers:
    learn_throughput: 8617.68
    learn_time_ms: 18774.427
    sample_throughput: 23645.985
    sample_time_ms: 6842.261
    update_time_ms: 28.37
  timestamp: 1602491672
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     17 |           440.48 | 2750464 |  243.985 |              298.899 |              145.717 |            817.445 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3440.181554524362
    time_step_min: 3083
  date: 2020-10-12_08-34-58
  done: false
  episode_len_mean: 815.873417721519
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 244.73267194383405
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8570553759733835
        entropy_coeff: 0.0005000000000000001
        kl: 0.00693794801676025
        model: {}
        policy_loss: -0.012595690621916825
        total_loss: 9.302302360534668
        vf_explained_var: 0.9800246357917786
        vf_loss: 9.314632733662924
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.483333333333334
    gpu_util_percent0: 0.32566666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15087560837473593
    mean_env_wait_ms: 1.1971604614135072
    mean_inference_ms: 4.550998984301916
    mean_raw_obs_processing_ms: 0.3925846015008058
  time_since_restore: 466.1001446247101
  time_this_iter_s: 25.620634078979492
  time_total_s: 466.1001446247101
  timers:
    learn_throughput: 8609.563
    learn_time_ms: 18792.127
    sample_throughput: 23733.558
    sample_time_ms: 6817.014
    update_time_ms: 28.365
  timestamp: 1602491698
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     18 |            466.1 | 2912256 |  244.733 |              298.899 |              145.717 |            815.873 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3435.160891089109
    time_step_min: 3083
  date: 2020-10-12_08-35-24
  done: false
  episode_len_mean: 814.1853165938865
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 245.55176216311577
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 188
  episodes_total: 3664
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8260929683844248
        entropy_coeff: 0.0005000000000000001
        kl: 0.00627721450291574
        model: {}
        policy_loss: -0.010709817167177485
        total_loss: 11.524338483810425
        vf_explained_var: 0.9801642894744873
        vf_loss: 11.534833749135336
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.67666666666667
    gpu_util_percent0: 0.3486666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15069873153236457
    mean_env_wait_ms: 1.1982064856230281
    mean_inference_ms: 4.5401690055796
    mean_raw_obs_processing_ms: 0.3919602176683018
  time_since_restore: 491.7349843978882
  time_this_iter_s: 25.6348397731781
  time_total_s: 491.7349843978882
  timers:
    learn_throughput: 8607.873
    learn_time_ms: 18795.816
    sample_throughput: 23758.107
    sample_time_ms: 6809.97
    update_time_ms: 27.774
  timestamp: 1602491724
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     19 |          491.735 | 3074048 |  245.552 |              298.899 |              145.717 |            814.185 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3428.4441611422744
    time_step_min: 3083
  date: 2020-10-12_08-35-50
  done: false
  episode_len_mean: 812.0630379746835
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 246.60976857179378
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 286
  episodes_total: 3950
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8063790599505106
        entropy_coeff: 0.0005000000000000001
        kl: 0.00581474454763035
        model: {}
        policy_loss: -0.010059737542178482
        total_loss: 10.378987232844034
        vf_explained_var: 0.9842923283576965
        vf_loss: 10.388868490854898
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.07241379310345
    gpu_util_percent0: 0.3334482758620689
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15045825954287506
    mean_env_wait_ms: 1.1998160099735846
    mean_inference_ms: 4.525558072261089
    mean_raw_obs_processing_ms: 0.39113303459812954
  time_since_restore: 517.4642984867096
  time_this_iter_s: 25.72931408882141
  time_total_s: 517.4642984867096
  timers:
    learn_throughput: 8607.09
    learn_time_ms: 18797.525
    sample_throughput: 23881.611
    sample_time_ms: 6774.752
    update_time_ms: 29.275
  timestamp: 1602491750
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     20 |          517.464 | 3235840 |   246.61 |              298.899 |              145.717 |            812.063 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3424.633333333333
    time_step_min: 3083
  date: 2020-10-12_08-36-16
  done: false
  episode_len_mean: 811.1747809152872
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 247.171761431255
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8050975054502487
        entropy_coeff: 0.0005000000000000001
        kl: 0.006411496355819206
        model: {}
        policy_loss: -0.0109325938198405
        total_loss: 8.397321462631226
        vf_explained_var: 0.9822394847869873
        vf_loss: 8.408015330632528
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.076666666666668
    gpu_util_percent0: 0.3436666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15033854121740725
    mean_env_wait_ms: 1.200601038893896
    mean_inference_ms: 4.518158834825987
    mean_raw_obs_processing_ms: 0.39071788216336256
  time_since_restore: 543.27952003479
  time_this_iter_s: 25.815221548080444
  time_total_s: 543.27952003479
  timers:
    learn_throughput: 8602.003
    learn_time_ms: 18808.644
    sample_throughput: 23862.737
    sample_time_ms: 6780.111
    update_time_ms: 28.171
  timestamp: 1602491776
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     21 |           543.28 | 3397632 |  247.172 |              298.899 |              145.717 |            811.175 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3421.5082547169814
    time_step_min: 3083
  date: 2020-10-12_08-36-42
  done: false
  episode_len_mean: 810.3659793814433
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 247.6299262541061
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 160
  episodes_total: 4268
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7943403224150339
        entropy_coeff: 0.0005000000000000001
        kl: 0.006092905105712513
        model: {}
        policy_loss: -0.012508889408006022
        total_loss: 10.069480101267496
        vf_explained_var: 0.9799533486366272
        vf_loss: 10.08177661895752
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.833333333333336
    gpu_util_percent0: 0.38999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15022548822104212
    mean_env_wait_ms: 1.2013670024852496
    mean_inference_ms: 4.5111048698298655
    mean_raw_obs_processing_ms: 0.39031940877553956
  time_since_restore: 568.987156867981
  time_this_iter_s: 25.707636833190918
  time_total_s: 568.987156867981
  timers:
    learn_throughput: 8608.305
    learn_time_ms: 18794.874
    sample_throughput: 23897.151
    sample_time_ms: 6770.347
    update_time_ms: 29.144
  timestamp: 1602491802
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     22 |          568.987 | 3559424 |   247.63 |              298.899 |              145.717 |            810.366 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3415.407570422535
    time_step_min: 3083
  date: 2020-10-12_08-37-08
  done: false
  episode_len_mean: 808.5879265091863
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 248.62850287653427
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 304
  episodes_total: 4572
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7644506990909576
        entropy_coeff: 0.0005000000000000001
        kl: 0.005771325357879202
        model: {}
        policy_loss: -0.009549629636846172
        total_loss: 10.615382512410482
        vf_explained_var: 0.9846494197845459
        vf_loss: 10.624737024307251
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.216666666666665
    gpu_util_percent0: 0.4233333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15002868087968005
    mean_env_wait_ms: 1.20278776735838
    mean_inference_ms: 4.498766578182944
    mean_raw_obs_processing_ms: 0.3896344622864878
  time_since_restore: 595.0535960197449
  time_this_iter_s: 26.066439151763916
  time_total_s: 595.0535960197449
  timers:
    learn_throughput: 8596.051
    learn_time_ms: 18821.665
    sample_throughput: 23867.567
    sample_time_ms: 6778.739
    update_time_ms: 32.329
  timestamp: 1602491828
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     23 |          595.054 | 3721216 |  248.629 |              298.899 |              145.717 |            808.588 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b50e2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3412.3495331069607
    time_step_min: 3083
  date: 2020-10-12_08-37-34
  done: true
  episode_len_mean: 807.6881856540084
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 249.11699271192933
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 168
  episodes_total: 4740
  experiment_id: 159fbc592ed142b4b7741b1a94933f93
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7512289037307104
        entropy_coeff: 0.0005000000000000001
        kl: 0.006618439607943098
        model: {}
        policy_loss: -0.011942399355272451
        total_loss: 7.106495062510173
        vf_explained_var: 0.9852812886238098
        vf_loss: 7.118151148160298
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.51379310344828
    gpu_util_percent0: 0.28172413793103457
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7896551724137932
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56858
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14993006395150182
    mean_env_wait_ms: 1.2035070901630875
    mean_inference_ms: 4.492612595979025
    mean_raw_obs_processing_ms: 0.3892858976989751
  time_since_restore: 620.7819950580597
  time_this_iter_s: 25.72839903831482
  time_total_s: 620.7819950580597
  timers:
    learn_throughput: 8597.125
    learn_time_ms: 18819.315
    sample_throughput: 23842.836
    sample_time_ms: 6785.77
    update_time_ms: 31.534
  timestamp: 1602491854
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: b50e2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | TERMINATED |       |     24 |          620.782 | 3883008 |  249.117 |              298.899 |              145.717 |            807.688 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b50e2_00000 | TERMINATED |       |     24 |          620.782 | 3883008 |  249.117 |              298.899 |              145.717 |            807.688 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


