diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index d0ca168..b144024 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
@@ -14,9 +14,8 @@
     }
    ],
    "source": [
-    "##### import os\n",
+    "import os\n",
     "import multiprocessing as mp\n",
-    "\n",
     "import plotly.io as pio\n",
     "import ray\n",
     "from ray import tune\n",
@@ -29,7 +28,7 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "2\n",
+    "\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
@@ -60,21 +59,14 @@
     "        'program': 'train.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
-    "            'name': 'time_step_mean',\n",
+    "            'name': 'time_step_min',\n",
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'clip_param': {\n",
-    "                'values': [0.3, 0.5]\n",
-    "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
-    "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
-    "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "            'instance_path': {\n",
+    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
+    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
+    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +74,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: pu0gldb1\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/pu0gldb1\n"
      ]
     }
    ],
@@ -108,203 +100,200 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "2020-10-12 12:30:07,031 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 12:30:07,347 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 12:30:07,348 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
+      "2020-10-12 12:30:07,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta51\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/pu0gldb1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/otkmv5te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_123009-otkmv5te\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 12:30:12,362 - wandb.wandb_agent - INFO - Running runs: ['otkmv5te']\n",
+      "2020-10-12 12:30:12,909\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=57679)\u001b[0m 2020-10-12 12:30:15,608\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=57592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57644)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57644)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57637)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57637)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57659)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57659)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57672)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57672)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57577)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57577)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57575)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57575)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57658)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57658)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57651)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57651)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57655)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57655)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57647)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57647)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57661)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57661)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57652)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57652)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57663)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57663)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57578)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57578)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57665)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57665)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57571)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57571)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57632)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57632)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57645)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57645)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57657)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57657)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57630)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57630)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57656)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57656)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57627)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57627)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57634)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57634)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57654)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57654)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_12-30-49\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,21 +301,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
+      "        entropy: 1.1823383669058483\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        kl: 0.006917016425480445\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
+      "        policy_loss: -0.009157503198366612\n",
+      "        total_loss: 507.07493591308594\n",
       "        vf_explained_var: 0.540532648563385\n",
       "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
@@ -336,81 +325,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 27.593939393939394\n",
+      "    gpu_util_percent0: 0.28818181818181815\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.563636363636364\n",
+      "    vram_util_percent0: 0.08736346740610434\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.16890503735261111\n",
+      "    mean_env_wait_ms: 1.1702247577230296\n",
+      "    mean_inference_ms: 5.661956237105169\n",
+      "    mean_raw_obs_processing_ms: 0.4499529408392769\n",
+      "  time_since_restore: 28.237815141677856\n",
+      "  time_this_iter_s: 28.237815141677856\n",
+      "  time_total_s: 28.237815141677856\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 8559.016\n",
+      "    learn_time_ms: 18903.107\n",
+      "    sample_throughput: 17589.407\n",
+      "    sample_time_ms: 9198.263\n",
+      "    update_time_ms: 98.214\n",
+      "  timestamp: 1602505849\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      1 |          28.2378 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3614.2256944444443\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_12-31-15\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 892.4873417721519\n",
+      "  episode_reward_max: 264.3535353535352\n",
+      "  episode_reward_mean: 217.54734049354283\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
+      "        entropy: 1.149937113126119\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        kl: 0.007523950111741821\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.00998671705989788\n",
+      "        total_loss: 126.33550771077473\n",
+      "        vf_explained_var: 0.8110877871513367\n",
+      "        vf_loss: 126.34455998738606\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,81 +407,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 27.38709677419354\n",
+      "    gpu_util_percent0: 0.33709677419354844\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
+      "    ram_util_percent: 3.751612903225806\n",
       "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.16522538421298727\n",
+      "    mean_env_wait_ms: 1.166785318106883\n",
+      "    mean_inference_ms: 5.478239392992289\n",
+      "    mean_raw_obs_processing_ms: 0.44201243673943585\n",
+      "  time_since_restore: 54.568071365356445\n",
+      "  time_this_iter_s: 26.33025622367859\n",
+      "  time_total_s: 54.568071365356445\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 8650.173\n",
+      "    learn_time_ms: 18703.904\n",
+      "    sample_throughput: 19174.478\n",
+      "    sample_time_ms: 8437.883\n",
+      "    update_time_ms: 65.669\n",
+      "  timestamp: 1602505875\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      2 |          54.5681 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3605.479820627803\n",
+      "    time_step_min: 3310\n",
+      "  date: 2020-10-12_12-31-41\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 888.5801687763714\n",
+      "  episode_reward_max: 264.50505050505006\n",
+      "  episode_reward_mean: 219.20585602864062\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
+      "        entropy: 1.1411352157592773\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        kl: 0.010440803055341044\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.013970387983135879\n",
+      "        total_loss: 54.93683338165283\n",
+      "        vf_explained_var: 0.8966913819313049\n",
+      "        vf_loss: 54.94928582509359\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,81 +489,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 25.876666666666665\n",
+      "    gpu_util_percent0: 0.3706666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
+      "    ram_util_percent: 3.769999999999999\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16260294589169655\n",
+      "    mean_env_wait_ms: 1.1663843852803522\n",
+      "    mean_inference_ms: 5.317580712460233\n",
+      "    mean_raw_obs_processing_ms: 0.4346313705797556\n",
+      "  time_since_restore: 80.45094752311707\n",
+      "  time_this_iter_s: 25.88287615776062\n",
+      "  time_total_s: 80.45094752311707\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 8664.155\n",
+      "    learn_time_ms: 18673.719\n",
+      "    sample_throughput: 20162.774\n",
+      "    sample_time_ms: 8024.293\n",
+      "    update_time_ms: 51.182\n",
+      "  timestamp: 1602505901\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      3 |          80.4509 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3591.1639072847684\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_12-32-07\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 885.4873417721519\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 221.420326684567\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
+      "        entropy: 1.1191200812657673\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        kl: 0.011468215147033334\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.013862663588952273\n",
+      "        total_loss: 39.326786041259766\n",
+      "        vf_explained_var: 0.9241357445716858\n",
+      "        vf_loss: 39.33891359965006\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,81 +571,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 25.43333333333333\n",
+      "    gpu_util_percent0: 0.37566666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
+      "    ram_util_percent: 3.77\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.1607462757833792\n",
+      "    mean_env_wait_ms: 1.1666065594299164\n",
+      "    mean_inference_ms: 5.19759320615125\n",
+      "    mean_raw_obs_processing_ms: 0.42884899221182987\n",
+      "  time_since_restore: 106.41191577911377\n",
+      "  time_this_iter_s: 25.960968255996704\n",
+      "  time_total_s: 106.41191577911377\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 8645.902\n",
+      "    learn_time_ms: 18713.143\n",
+      "    sample_throughput: 20794.811\n",
+      "    sample_time_ms: 7780.403\n",
+      "    update_time_ms: 46.964\n",
+      "  timestamp: 1602505927\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      4 |          106.412 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3577.469816272966\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_12-32-33\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 882.6164556962025\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 223.37348165196246\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
+      "        entropy: 1.0904998779296875\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        kl: 0.010465693194419146\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.013936646308138734\n",
+      "        total_loss: 29.070746898651123\n",
+      "        vf_explained_var: 0.9454066157341003\n",
+      "        vf_loss: 29.0831356048584\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,81 +653,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 25.55333333333333\n",
+      "    gpu_util_percent0: 0.4026666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
+      "    ram_util_percent: 3.7633333333333328\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.15932651553390745\n",
+      "    mean_env_wait_ms: 1.167247236922676\n",
+      "    mean_inference_ms: 5.105156955761531\n",
+      "    mean_raw_obs_processing_ms: 0.4241619853874412\n",
+      "  time_since_restore: 132.39279627799988\n",
+      "  time_this_iter_s: 25.98088049888611\n",
+      "  time_total_s: 132.39279627799988\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 8644.99\n",
+      "    learn_time_ms: 18715.117\n",
+      "    sample_throughput: 21124.511\n",
+      "    sample_time_ms: 7658.97\n",
+      "    update_time_ms: 44.841\n",
+      "  timestamp: 1602505953\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      5 |          132.393 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3562.2380487804876\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-32-59\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 875.4055080721747\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 225.90998302109395\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 263\n",
+      "  episodes_total: 1053\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
+      "        entropy: 1.0669801433881123\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        kl: 0.010119187956055006\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.014624884177464992\n",
+      "        total_loss: 30.67037757237752\n",
+      "        vf_explained_var: 0.9617660641670227\n",
+      "        vf_loss: 30.683512210845947\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,81 +735,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 24.896774193548392\n",
+      "    gpu_util_percent0: 0.4380645161290322\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7645161290322577\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15758373732759218\n",
+      "    mean_env_wait_ms: 1.1697938862862185\n",
+      "    mean_inference_ms: 4.993265760954177\n",
+      "    mean_raw_obs_processing_ms: 0.41869440795286283\n",
+      "  time_since_restore: 158.20772171020508\n",
+      "  time_this_iter_s: 25.8149254322052\n",
+      "  time_total_s: 158.20772171020508\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 8650.438\n",
+      "    learn_time_ms: 18703.33\n",
+      "    sample_throughput: 21428.196\n",
+      "    sample_time_ms: 7550.426\n",
+      "    update_time_ms: 54.438\n",
+      "  timestamp: 1602505979\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      6 |          158.208 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3547.7540453074434\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-33-25\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 868.5514240506329\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 228.15807601329732\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 211\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
+      "        entropy: 1.0668786863485973\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        kl: 0.012256689059237639\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.01610318278350557\n",
+      "        total_loss: 20.370780150095623\n",
+      "        vf_explained_var: 0.963979959487915\n",
+      "        vf_loss: 20.384966214497883\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,81 +817,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 24.853333333333335\n",
+      "    gpu_util_percent0: 0.34933333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
+      "    ram_util_percent: 3.766666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.15657329873395373\n",
+      "    mean_env_wait_ms: 1.1718041449096683\n",
+      "    mean_inference_ms: 4.928618743314384\n",
+      "    mean_raw_obs_processing_ms: 0.4154075703104024\n",
+      "  time_since_restore: 184.31369256973267\n",
+      "  time_this_iter_s: 26.105970859527588\n",
+      "  time_total_s: 184.31369256973267\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 8635.087\n",
+      "    learn_time_ms: 18736.58\n",
+      "    sample_throughput: 21626.365\n",
+      "    sample_time_ms: 7481.239\n",
+      "    update_time_ms: 52.288\n",
+      "  timestamp: 1602506005\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      7 |          184.314 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3536.647776183644\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-33-51\n",
       "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 862.704641350211\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 229.98016025231198\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
+      "        entropy: 1.0334690809249878\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
+      "        kl: 0.010793289790550867\n",
       "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
+      "        policy_loss: -0.015747709141578525\n",
+      "        total_loss: 15.715624650319418\n",
+      "        vf_explained_var: 0.969296395778656\n",
+      "        vf_loss: 15.729730685551962\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -910,81 +899,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
+      "    cpu_util_percent: 25.253333333333334\n",
+      "    gpu_util_percent0: 0.391\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
+      "    ram_util_percent: 3.776666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
+      "    mean_action_processing_ms: 0.1559479711492542\n",
+      "    mean_env_wait_ms: 1.1733561902991976\n",
+      "    mean_inference_ms: 4.888176842818723\n",
+      "    mean_raw_obs_processing_ms: 0.4133021243199457\n",
+      "  time_since_restore: 210.29469919204712\n",
+      "  time_this_iter_s: 25.981006622314453\n",
+      "  time_total_s: 210.29469919204712\n",
       "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
+      "    learn_throughput: 8632.364\n",
+      "    learn_time_ms: 18742.491\n",
+      "    sample_throughput: 21765.348\n",
+      "    sample_time_ms: 7433.467\n",
+      "    update_time_ms: 49.493\n",
+      "  timestamp: 1602506031\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      8 |          210.295 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3525.568943298969\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-34-17\n",
       "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 857.1208860759493\n",
+      "  episode_reward_max: 279.3535353535359\n",
+      "  episode_reward_mean: 231.70662319396482\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
+      "        entropy: 1.0033017992973328\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
+      "        kl: 0.010770521514738599\n",
       "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
+      "        policy_loss: -0.015525121105990062\n",
+      "        total_loss: 16.273523728052776\n",
+      "        vf_explained_var: 0.9674468040466309\n",
+      "        vf_loss: 16.28739635149638\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -992,81 +981,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
+      "    cpu_util_percent: 24.610000000000003\n",
+      "    gpu_util_percent0: 0.27566666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
+      "    ram_util_percent: 3.77\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
+      "    mean_action_processing_ms: 0.15539724462957527\n",
+      "    mean_env_wait_ms: 1.175024142163589\n",
+      "    mean_inference_ms: 4.852607294414321\n",
+      "    mean_raw_obs_processing_ms: 0.41139122673210116\n",
+      "  time_since_restore: 236.31488513946533\n",
+      "  time_this_iter_s: 26.020185947418213\n",
+      "  time_total_s: 236.31488513946533\n",
       "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
+      "    learn_throughput: 8625.483\n",
+      "    learn_time_ms: 18757.443\n",
+      "    sample_throughput: 21885.114\n",
+      "    sample_time_ms: 7392.787\n",
+      "    update_time_ms: 46.251\n",
+      "  timestamp: 1602506057\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      9 |          236.315 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3504.7218934911243\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_12-34-43\n",
       "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 847.3826179120297\n",
+      "  episode_reward_max: 284.0505050505049\n",
+      "  episode_reward_mean: 234.9192882722293\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1887\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
+      "        entropy: 0.9698180854320526\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
+      "        kl: 0.008762541770314177\n",
       "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
+      "        policy_loss: -0.011754670903125467\n",
+      "        total_loss: 22.15676514307658\n",
+      "        vf_explained_var: 0.9699413776397705\n",
+      "        vf_loss: 22.167253017425537\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -1074,81 +1063,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
+      "    cpu_util_percent: 24.686666666666667\n",
+      "    gpu_util_percent0: 0.25466666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.763333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
+      "    mean_action_processing_ms: 0.15453766769147795\n",
+      "    mean_env_wait_ms: 1.1787124191264264\n",
+      "    mean_inference_ms: 4.796413184950241\n",
+      "    mean_raw_obs_processing_ms: 0.40843775652716663\n",
+      "  time_since_restore: 262.18814992904663\n",
+      "  time_this_iter_s: 25.8732647895813\n",
+      "  time_total_s: 262.18814992904663\n",
       "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
+      "    learn_throughput: 8627.415\n",
+      "    learn_time_ms: 18753.242\n",
+      "    sample_throughput: 21977.845\n",
+      "    sample_time_ms: 7361.595\n",
+      "    update_time_ms: 44.093\n",
+      "  timestamp: 1602506083\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     10 |          262.188 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3494.990128331688\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_12-35-09\n",
       "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
+      "  episode_len_mean: 842.626582278481\n",
+      "  episode_reward_max: 287.38383838383817\n",
+      "  episode_reward_mean: 236.53693212553955\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
+      "        entropy: 0.959399938583374\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
+      "        kl: 0.009050344349816442\n",
       "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
+      "        policy_loss: -0.014448691198291877\n",
+      "        total_loss: 14.143741130828857\n",
+      "        vf_explained_var: 0.9704552292823792\n",
+      "        vf_loss: 14.156859795252482\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -1156,81 +1145,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
+      "    cpu_util_percent: 24.470000000000006\n",
+      "    gpu_util_percent0: 0.31033333333333335\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
+      "    ram_util_percent: 3.7766666666666664\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
+      "    mean_action_processing_ms: 0.1541531067576189\n",
+      "    mean_env_wait_ms: 1.180539782661793\n",
+      "    mean_inference_ms: 4.7710904173214255\n",
+      "    mean_raw_obs_processing_ms: 0.40708730490687545\n",
+      "  time_since_restore: 288.0478582382202\n",
+      "  time_this_iter_s: 25.859708309173584\n",
+      "  time_total_s: 288.0478582382202\n",
       "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
+      "    learn_throughput: 8633.513\n",
+      "    learn_time_ms: 18739.996\n",
+      "    sample_throughput: 22654.324\n",
+      "    sample_time_ms: 7141.771\n",
+      "    update_time_ms: 37.934\n",
+      "  timestamp: 1602506109\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     11 |          288.048 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3486.236721611722\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-35-35\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 839.50226039783\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 237.80845069136197\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
+      "        entropy: 0.9463174144426981\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
+      "        kl: 0.009074758971109986\n",
       "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
+      "        policy_loss: -0.014368217787705362\n",
+      "        total_loss: 10.841783205668131\n",
+      "        vf_explained_var: 0.9763579368591309\n",
+      "        vf_loss: 10.854809761047363\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -1238,81 +1227,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
+      "    cpu_util_percent: 24.709999999999997\n",
+      "    gpu_util_percent0: 0.304\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
+      "    ram_util_percent: 3.7766666666666664\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
+      "    mean_action_processing_ms: 0.15382456786108878\n",
+      "    mean_env_wait_ms: 1.1821934851322788\n",
+      "    mean_inference_ms: 4.749452794942857\n",
+      "    mean_raw_obs_processing_ms: 0.40591959145529394\n",
+      "  time_since_restore: 314.2713918685913\n",
+      "  time_this_iter_s: 26.223533630371094\n",
+      "  time_total_s: 314.2713918685913\n",
       "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
+      "    learn_throughput: 8608.293\n",
+      "    learn_time_ms: 18794.898\n",
+      "    sample_throughput: 22846.513\n",
+      "    sample_time_ms: 7081.693\n",
+      "    update_time_ms: 38.592\n",
+      "  timestamp: 1602506135\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     12 |          314.271 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3477.1867900715188\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-36-01\n",
       "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 836.276923076923\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 239.12358512358495\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 193\n",
+      "  episodes_total: 2405\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
+      "        entropy: 0.9069925745328268\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
+      "        kl: 0.009530291194096208\n",
       "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
+      "        policy_loss: -0.014515867456793785\n",
+      "        total_loss: 15.319237470626831\n",
+      "        vf_explained_var: 0.9747470021247864\n",
+      "        vf_loss: 15.332300901412964\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -1320,81 +1309,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
+      "    cpu_util_percent: 24.57333333333333\n",
+      "    gpu_util_percent0: 0.26733333333333337\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
+      "    ram_util_percent: 3.766666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
+      "    mean_action_processing_ms: 0.15346836889333854\n",
+      "    mean_env_wait_ms: 1.184240944593027\n",
+      "    mean_inference_ms: 4.725537933532759\n",
+      "    mean_raw_obs_processing_ms: 0.40463245423111577\n",
+      "  time_since_restore: 340.12329864501953\n",
+      "  time_this_iter_s: 25.851906776428223\n",
+      "  time_total_s: 340.12329864501953\n",
       "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
+      "    learn_throughput: 8602.467\n",
+      "    learn_time_ms: 18807.627\n",
+      "    sample_throughput: 22905.641\n",
+      "    sample_time_ms: 7063.413\n",
+      "    update_time_ms: 40.411\n",
+      "  timestamp: 1602506161\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     13 |          340.123 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3465.9672686230247\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-36-27\n",
       "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 832.3082650781831\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 240.80178553968565\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 281\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
+      "        entropy: 0.9011691262324651\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
+      "        kl: 0.010886709050585827\n",
       "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
+      "        policy_loss: -0.01605825025762897\n",
+      "        total_loss: 13.799258867899576\n",
+      "        vf_explained_var: 0.9779562950134277\n",
+      "        vf_loss: 13.813590288162231\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -1402,81 +1391,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
+      "    cpu_util_percent: 25.203333333333333\n",
+      "    gpu_util_percent0: 0.39166666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
+      "    ram_util_percent: 3.769999999999999\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
+      "    mean_action_processing_ms: 0.15301494054162276\n",
+      "    mean_env_wait_ms: 1.1868015832357257\n",
+      "    mean_inference_ms: 4.695915855449172\n",
+      "    mean_raw_obs_processing_ms: 0.4030395525153571\n",
+      "  time_since_restore: 365.95724272727966\n",
+      "  time_this_iter_s: 25.833944082260132\n",
+      "  time_total_s: 365.95724272727966\n",
       "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
+      "    learn_throughput: 8610.589\n",
+      "    learn_time_ms: 18789.887\n",
+      "    sample_throughput: 22889.673\n",
+      "    sample_time_ms: 7068.34\n",
+      "    update_time_ms: 39.225\n",
+      "  timestamp: 1602506187\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     14 |          365.957 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3459.754971590909\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-36-53\n",
       "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 830.3291139240506\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 241.694508374888\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
+      "        entropy: 0.8705271085103353\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
+      "        kl: 0.010132285223032037\n",
       "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
+      "        policy_loss: -0.01209646585630253\n",
+      "        total_loss: 9.354986588160196\n",
+      "        vf_explained_var: 0.9806396961212158\n",
+      "        vf_loss: 9.36549154917399\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -1484,81 +1473,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
+      "    cpu_util_percent: 24.339999999999996\n",
+      "    gpu_util_percent0: 0.354\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
+      "    ram_util_percent: 3.7733333333333334\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
+      "    mean_action_processing_ms: 0.15279157288304182\n",
+      "    mean_env_wait_ms: 1.188104613473158\n",
+      "    mean_inference_ms: 4.681133757261421\n",
+      "    mean_raw_obs_processing_ms: 0.4022444482464537\n",
+      "  time_since_restore: 391.6302752494812\n",
+      "  time_this_iter_s: 25.673032522201538\n",
+      "  time_total_s: 391.6302752494812\n",
       "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
+      "    learn_throughput: 8614.25\n",
+      "    learn_time_ms: 18781.902\n",
+      "    sample_throughput: 22961.178\n",
+      "    sample_time_ms: 7046.328\n",
+      "    update_time_ms: 37.541\n",
+      "  timestamp: 1602506213\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     15 |           391.63 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3454.032279757902\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-37-19\n",
       "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 828.5073284477015\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 242.50461645098542\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
+      "        entropy: 0.8471738596757253\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
+      "        kl: 0.009305963292717934\n",
       "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
+      "        policy_loss: -0.01094130908313673\n",
+      "        total_loss: 10.646601835886637\n",
+      "        vf_explained_var: 0.9784726500511169\n",
+      "        vf_loss: 10.656105756759644\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -1566,81 +1555,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
+      "    cpu_util_percent: 25.168965517241375\n",
+      "    gpu_util_percent0: 0.37931034482758613\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
+      "    ram_util_percent: 3.772413793103448\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
+      "    mean_action_processing_ms: 0.15258489228875483\n",
+      "    mean_env_wait_ms: 1.189348100743969\n",
+      "    mean_inference_ms: 4.667388374821382\n",
+      "    mean_raw_obs_processing_ms: 0.4014845687165312\n",
+      "  time_since_restore: 417.28298902511597\n",
+      "  time_this_iter_s: 25.652713775634766\n",
+      "  time_total_s: 417.28298902511597\n",
       "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
+      "    learn_throughput: 8611.392\n",
+      "    learn_time_ms: 18788.135\n",
+      "    sample_throughput: 23005.777\n",
+      "    sample_time_ms: 7032.669\n",
+      "    update_time_ms: 29.153\n",
+      "  timestamp: 1602506239\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     16 |          417.283 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3446.2361408882084\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-37-45\n",
       "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 825.9881566960219\n",
+      "  episode_reward_max: 289.9595959595964\n",
+      "  episode_reward_mean: 243.72948433622582\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 291\n",
+      "  episodes_total: 3293\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
+      "        entropy: 0.8250234176715215\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
+      "        kl: 0.008491925351942578\n",
       "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
+      "        policy_loss: -0.014777651784243062\n",
+      "        total_loss: 15.209494908650717\n",
+      "        vf_explained_var: 0.9786728024482727\n",
+      "        vf_loss: 15.222986777623495\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -1648,81 +1637,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
+      "    cpu_util_percent: 23.81666666666667\n",
+      "    gpu_util_percent0: 0.405\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
+      "    ram_util_percent: 3.7599999999999993\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
+      "    mean_action_processing_ms: 0.15225128410563682\n",
+      "    mean_env_wait_ms: 1.191534804694793\n",
+      "    mean_inference_ms: 4.644749359521727\n",
+      "    mean_raw_obs_processing_ms: 0.4002669504773126\n",
+      "  time_since_restore: 442.85631251335144\n",
+      "  time_this_iter_s: 25.573323488235474\n",
+      "  time_total_s: 442.85631251335144\n",
       "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
+      "    learn_throughput: 8621.52\n",
+      "    learn_time_ms: 18766.065\n",
+      "    sample_throughput: 23099.783\n",
+      "    sample_time_ms: 7004.049\n",
+      "    update_time_ms: 27.27\n",
+      "  timestamp: 1602506265\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     17 |          442.856 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3440.9040023201856\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-38-10\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.563003452244\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 244.5732671943833\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 183\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
+      "        entropy: 0.8241499215364456\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
+      "        kl: 0.007864817045629025\n",
       "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
+      "        policy_loss: -0.01140341673938868\n",
+      "        total_loss: 8.79675587018331\n",
+      "        vf_explained_var: 0.9828992486000061\n",
+      "        vf_loss: 8.806998491287231\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -1730,81 +1719,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
+      "    cpu_util_percent: 25.268965517241377\n",
+      "    gpu_util_percent0: 0.32137931034482753\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
+      "    ram_util_percent: 3.772413793103448\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
+      "    mean_action_processing_ms: 0.152057784099256\n",
+      "    mean_env_wait_ms: 1.1927444276404982\n",
+      "    mean_inference_ms: 4.631954197589499\n",
+      "    mean_raw_obs_processing_ms: 0.3995722632347076\n",
+      "  time_since_restore: 468.4573698043823\n",
+      "  time_this_iter_s: 25.601057291030884\n",
+      "  time_total_s: 468.4573698043823\n",
       "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
+      "    learn_throughput: 8625.27\n",
+      "    learn_time_ms: 18757.906\n",
+      "    sample_throughput: 23193.06\n",
+      "    sample_time_ms: 6975.88\n",
+      "    update_time_ms: 26.475\n",
+      "  timestamp: 1602506290\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     18 |          468.457 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3436.840266222962\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-38-36\n",
       "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
+      "  episode_len_mean: 823.8428728673638\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.09397497262097\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
+      "        entropy: 0.8113949745893478\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
+      "        kl: 0.008743428780386845\n",
       "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
+      "        policy_loss: -0.012751462903300611\n",
+      "        total_loss: 8.8964794476827\n",
+      "        vf_explained_var: 0.9816879630088806\n",
+      "        vf_loss: 8.907887935638428\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -1812,81 +1801,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    cpu_util_percent: 24.160000000000004\n",
+      "    gpu_util_percent0: 0.31700000000000006\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
+      "    ram_util_percent: 3.773333333333333\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
+      "    mean_action_processing_ms: 0.15190300447660146\n",
+      "    mean_env_wait_ms: 1.1937104261191516\n",
+      "    mean_inference_ms: 4.621606530580184\n",
+      "    mean_raw_obs_processing_ms: 0.3990076443002664\n",
+      "  time_since_restore: 494.1212737560272\n",
+      "  time_this_iter_s: 25.663903951644897\n",
+      "  time_total_s: 494.1212737560272\n",
       "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
+      "    learn_throughput: 8633.094\n",
+      "    learn_time_ms: 18740.905\n",
+      "    sample_throughput: 23256.792\n",
+      "    sample_time_ms: 6956.763\n",
+      "    update_time_ms: 26.349\n",
+      "  timestamp: 1602506316\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     19 |          494.121 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3432.525217850541\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-39-02\n",
       "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 823.0579292267365\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.79004990931585\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 181\n",
+      "  episodes_total: 3815\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
+      "        entropy: 0.7609985868136088\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
+      "        kl: 0.00916624628007412\n",
       "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
+      "        policy_loss: -0.012107667707217237\n",
+      "        total_loss: 10.657151778539022\n",
+      "        vf_explained_var: 0.9814252257347107\n",
+      "        vf_loss: 10.66780686378479\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -1894,81 +1883,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
+      "    cpu_util_percent: 25.175862068965515\n",
+      "    gpu_util_percent0: 0.36344827586206896\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
+      "    ram_util_percent: 3.76551724137931\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
+      "    mean_action_processing_ms: 0.15173262102728452\n",
+      "    mean_env_wait_ms: 1.194739519238314\n",
+      "    mean_inference_ms: 4.6104790880218705\n",
+      "    mean_raw_obs_processing_ms: 0.3983916300855253\n",
+      "  time_since_restore: 519.5943777561188\n",
+      "  time_this_iter_s: 25.473104000091553\n",
+      "  time_total_s: 519.5943777561188\n",
       "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
+      "    learn_throughput: 8634.98\n",
+      "    learn_time_ms: 18736.812\n",
+      "    sample_throughput: 23382.066\n",
+      "    sample_time_ms: 6919.491\n",
+      "    update_time_ms: 26.922\n",
+      "  timestamp: 1602506342\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     20 |          519.594 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3425.473593711619\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-39-28\n",
       "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 821.8972920224445\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 246.80025184758034\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4099\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
+      "        entropy: 0.7578712403774261\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
+      "        kl: 0.0086368964985013\n",
       "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
+      "        policy_loss: -0.011422600480727851\n",
+      "        total_loss: 10.725571791330973\n",
+      "        vf_explained_var: 0.9839944839477539\n",
+      "        vf_loss: 10.735645691553751\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -1976,81 +1965,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
+      "    cpu_util_percent: 24.413333333333338\n",
+      "    gpu_util_percent0: 0.36233333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
+      "    ram_util_percent: 3.763333333333333\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
+      "    mean_action_processing_ms: 0.15149336115425896\n",
+      "    mean_env_wait_ms: 1.196135945498552\n",
+      "    mean_inference_ms: 4.5943737192150405\n",
+      "    mean_raw_obs_processing_ms: 0.39750761177887367\n",
+      "  time_since_restore: 545.1678259372711\n",
+      "  time_this_iter_s: 25.573448181152344\n",
+      "  time_total_s: 545.1678259372711\n",
       "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
+      "    learn_throughput: 8638.164\n",
+      "    learn_time_ms: 18729.907\n",
+      "    sample_throughput: 23454.768\n",
+      "    sample_time_ms: 6898.043\n",
+      "    update_time_ms: 25.122\n",
+      "  timestamp: 1602506368\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     21 |          545.168 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3421.670599339311\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-39-54\n",
       "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 821.5065635255509\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 247.35105627299706\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
+      "        entropy: 0.7521579414606094\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
+      "        kl: 0.007824398732433716\n",
       "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
+      "        policy_loss: -0.01322558480508936\n",
+      "        total_loss: 7.959930698076884\n",
+      "        vf_explained_var: 0.9843184947967529\n",
+      "        vf_loss: 7.971967538197835\n",
       "    num_steps_sampled: 3559424\n",
       "    num_steps_trained: 3559424\n",
       "  iterations_since_restore: 22\n",
@@ -2058,81 +2047,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
+      "    cpu_util_percent: 24.103333333333335\n",
+      "    gpu_util_percent0: 0.3143333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
+      "    ram_util_percent: 3.7866666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
+      "    mean_action_processing_ms: 0.15135817854915368\n",
+      "    mean_env_wait_ms: 1.1968631050270366\n",
+      "    mean_inference_ms: 4.58570350856658\n",
+      "    mean_raw_obs_processing_ms: 0.3970226544952488\n",
+      "  time_since_restore: 570.9309539794922\n",
+      "  time_this_iter_s: 25.76312804222107\n",
+      "  time_total_s: 570.9309539794922\n",
       "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
+      "    learn_throughput: 8645.196\n",
+      "    learn_time_ms: 18714.67\n",
+      "    sample_throughput: 23563.448\n",
+      "    sample_time_ms: 6866.228\n",
+      "    update_time_ms: 24.993\n",
+      "  timestamp: 1602506394\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3559424\n",
       "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     22 |          570.931 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3418.63762511374\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-40-20\n",
       "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
+      "  episode_len_mean: 821.0913200723327\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 247.84626098233684\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
+      "        entropy: 0.739922359585762\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
+      "        kl: 0.008788479414458076\n",
       "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
+      "        policy_loss: -0.013709326779159406\n",
+      "        total_loss: 7.252472162246704\n",
+      "        vf_explained_var: 0.9847645163536072\n",
+      "        vf_loss: 7.264793713887532\n",
       "    num_steps_sampled: 3721216\n",
       "    num_steps_trained: 3721216\n",
       "  iterations_since_restore: 23\n",
@@ -2140,81 +2129,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
+      "    cpu_util_percent: 24.030000000000005\n",
+      "    gpu_util_percent0: 0.41166666666666674\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
+      "    ram_util_percent: 3.77\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
+      "    mean_action_processing_ms: 0.15123807745980236\n",
+      "    mean_env_wait_ms: 1.1974930413341178\n",
+      "    mean_inference_ms: 4.577881618246516\n",
+      "    mean_raw_obs_processing_ms: 0.3965811523986444\n",
+      "  time_since_restore: 596.7764484882355\n",
+      "  time_this_iter_s: 25.845494508743286\n",
+      "  time_total_s: 596.7764484882355\n",
       "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
+      "    learn_throughput: 8638.437\n",
+      "    learn_time_ms: 18729.313\n",
+      "    sample_throughput: 23647.317\n",
+      "    sample_time_ms: 6841.875\n",
+      "    update_time_ms: 25.27\n",
+      "  timestamp: 1602506420\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3721216\n",
       "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     23 |          596.776 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3414.4957691473205\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-40-45\n",
       "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 820.656243260729\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 248.46065137029112\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 4637\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
+      "        entropy: 0.7039715051651001\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
+      "        kl: 0.007829503583100935\n",
       "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
+      "        policy_loss: -0.010663946062171211\n",
+      "        total_loss: 8.341045339902243\n",
+      "        vf_explained_var: 0.9864241480827332\n",
+      "        vf_loss: 8.350495417912802\n",
       "    num_steps_sampled: 3883008\n",
       "    num_steps_trained: 3883008\n",
       "  iterations_since_restore: 24\n",
@@ -2222,81 +2211,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
+      "    cpu_util_percent: 24.83448275862069\n",
+      "    gpu_util_percent0: 0.3296551724137931\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
+      "    ram_util_percent: 3.7655172413793094\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
+      "    mean_action_processing_ms: 0.1510830566654544\n",
+      "    mean_env_wait_ms: 1.1982758128961588\n",
+      "    mean_inference_ms: 4.567927674219303\n",
+      "    mean_raw_obs_processing_ms: 0.3960149133084128\n",
+      "  time_since_restore: 622.3432440757751\n",
+      "  time_this_iter_s: 25.566795587539673\n",
+      "  time_total_s: 622.3432440757751\n",
       "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
+      "    learn_throughput: 8634.993\n",
+      "    learn_time_ms: 18736.783\n",
+      "    sample_throughput: 23768.17\n",
+      "    sample_time_ms: 6807.087\n",
+      "    update_time_ms: 25.138\n",
+      "  timestamp: 1602506445\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3883008\n",
       "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
+      "| PPO_jss_env_ad858_00000 | TERMINATED |       |     24 |          622.343 | 3883008 |  248.461 |              296.626 |              133.899 |            820.656 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
+      "| PPO_jss_env_ad858_00000 | TERMINATED |       |     24 |          622.343 | 3883008 |  248.461 |              296.626 |              133.899 |            820.656 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57425\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_123009-otkmv5te/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_123009-otkmv5te/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3098\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 637\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602506446\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4172\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3414.49577\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 296.62626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 133.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 248.46065\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4637\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
@@ -2313,228 +2302,225 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrich-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/otkmv5te\u001b[0m\n",
+      "2020-10-12 12:40:53,918 - wandb.wandb_agent - INFO - Cleaning up finished run: otkmv5te\n",
+      "2020-10-12 12:40:54,244 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 12:40:54,245 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
+      "2020-10-12 12:40:54,247 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta52\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
+      "2020-10-12 12:40:59,262 - wandb.wandb_agent - INFO - Running runs: ['y1n2drlw']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrue-sweep-2\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/pu0gldb1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/y1n2drlw\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_124056-y1n2drlw\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 12:41:00,037\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
+      "\u001b[2m\u001b[36m(pid=3607)\u001b[0m 2020-10-12 12:41:02,820\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=3517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3571)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3571)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3589)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3589)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3575)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3575)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3604)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3604)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3501)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3501)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3578)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3578)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3541)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3541)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3538)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3538)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3532)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3532)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3543)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3543)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3547)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3547)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3594)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3594)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=3485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=3485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3616.3166666666666\n",
+      "    time_step_min: 3355\n",
+      "  date: 2020-10-12_12-41-36\n",
       "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 904.8481012658228\n",
+      "  episode_reward_max: 246.595959595959\n",
+      "  episode_reward_mean: 201.8721391126452\n",
+      "  episode_reward_min: 106.74747474747424\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
+      "        entropy: 1.1660849452018738\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
+      "        kl: 0.007487039663828909\n",
       "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
-      "        vf_explained_var: 0.5664147734642029\n",
-      "        vf_loss: 502.24672444661456\n",
+      "        policy_loss: -0.009705218815118618\n",
+      "        total_loss: 369.24190012613934\n",
+      "        vf_explained_var: 0.588043749332428\n",
+      "        vf_loss: 369.2507044474284\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -2542,81 +2528,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
+      "    cpu_util_percent: 30.439999999999998\n",
+      "    gpu_util_percent0: 0.34828571428571425\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
+      "    ram_util_percent: 3.5514285714285716\n",
+      "    vram_util_percent0: 0.08515906854706463\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
+      "    mean_action_processing_ms: 0.16766784587882486\n",
+      "    mean_env_wait_ms: 1.1779018683579277\n",
+      "    mean_inference_ms: 6.1455708986890665\n",
+      "    mean_raw_obs_processing_ms: 0.4561936336374828\n",
+      "  time_since_restore: 28.484970092773438\n",
+      "  time_this_iter_s: 28.484970092773438\n",
+      "  time_total_s: 28.484970092773438\n",
       "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
+      "    learn_throughput: 8744.933\n",
+      "    learn_time_ms: 18501.228\n",
+      "    sample_throughput: 16339.015\n",
+      "    sample_time_ms: 9902.188\n",
+      "    update_time_ms: 44.878\n",
+      "  timestamp: 1602506496\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      1 |           28.485 | 161792 |  201.872 |              246.596 |              106.747 |            904.848 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3625.2374100719426\n",
+      "    time_step_min: 3339\n",
+      "  date: 2020-10-12_12-42-02\n",
       "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
+      "  episode_len_mean: 904.4556962025316\n",
+      "  episode_reward_max: 246.595959595959\n",
+      "  episode_reward_mean: 199.3687827643521\n",
+      "  episode_reward_min: 106.74747474747424\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
+      "        entropy: 1.135809987783432\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
+      "        kl: 0.010140993477155765\n",
       "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
+      "        policy_loss: -0.011478722333170785\n",
+      "        total_loss: 95.7723019917806\n",
+      "        vf_explained_var: 0.8307454586029053\n",
+      "        vf_loss: 95.78232320149739\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -2624,81 +2610,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
+      "    cpu_util_percent: 27.345161290322583\n",
+      "    gpu_util_percent0: 0.33032258064516135\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.751612903225806\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
+      "    mean_action_processing_ms: 0.1637749172129011\n",
+      "    mean_env_wait_ms: 1.175515161566294\n",
+      "    mean_inference_ms: 5.808114322059557\n",
+      "    mean_raw_obs_processing_ms: 0.44289364338056286\n",
+      "  time_since_restore: 54.45203757286072\n",
+      "  time_this_iter_s: 25.96706748008728\n",
+      "  time_total_s: 54.45203757286072\n",
       "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
+      "    learn_throughput: 8856.737\n",
+      "    learn_time_ms: 18267.676\n",
+      "    sample_throughput: 18216.5\n",
+      "    sample_time_ms: 8881.618\n",
+      "    update_time_ms: 33.458\n",
+      "  timestamp: 1602506522\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      2 |           54.452 | 323584 |  199.369 |              246.596 |              106.747 |            904.456 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3631.1490825688074\n",
+      "    time_step_min: 3328\n",
+      "  date: 2020-10-12_12-42-28\n",
       "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 902.246835443038\n",
+      "  episode_reward_max: 246.595959595959\n",
+      "  episode_reward_mean: 199.6703746323997\n",
+      "  episode_reward_min: 106.74747474747424\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
+      "        entropy: 1.125467707713445\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
+      "        kl: 0.010452566435560584\n",
       "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
+      "        policy_loss: -0.013522157406744858\n",
+      "        total_loss: 49.543551445007324\n",
+      "        vf_explained_var: 0.899634599685669\n",
+      "        vf_loss: 49.555545806884766\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -2706,81 +2692,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
+      "    cpu_util_percent: 25.677419354838705\n",
+      "    gpu_util_percent0: 0.31225806451612903\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7645161290322573\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
+      "    mean_action_processing_ms: 0.1610122614239026\n",
+      "    mean_env_wait_ms: 1.1752129850381983\n",
+      "    mean_inference_ms: 5.566328896160028\n",
+      "    mean_raw_obs_processing_ms: 0.43357261225894383\n",
+      "  time_since_restore: 80.04528307914734\n",
+      "  time_this_iter_s: 25.59324550628662\n",
+      "  time_total_s: 80.04528307914734\n",
       "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
+      "    learn_throughput: 8834.464\n",
+      "    learn_time_ms: 18313.732\n",
+      "    sample_throughput: 19524.707\n",
+      "    sample_time_ms: 8286.526\n",
+      "    update_time_ms: 35.094\n",
+      "  timestamp: 1602506548\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      3 |          80.0453 | 485376 |   199.67 |              246.596 |              106.747 |            902.247 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3626.96632996633\n",
+      "    time_step_min: 3328\n",
+      "  date: 2020-10-12_12-42-53\n",
       "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 897.6582278481013\n",
+      "  episode_reward_max: 253.71717171717134\n",
+      "  episode_reward_mean: 200.85348740570234\n",
+      "  episode_reward_min: 106.74747474747424\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
+      "        entropy: 1.1046620110670726\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
+      "        kl: 0.01121117314323783\n",
       "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
+      "        policy_loss: -0.014733990072272718\n",
+      "        total_loss: 36.47766558329264\n",
+      "        vf_explained_var: 0.924907922744751\n",
+      "        vf_loss: 36.49070962270101\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -2788,81 +2774,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
+      "    cpu_util_percent: 25.554838709677416\n",
+      "    gpu_util_percent0: 0.3461290322580645\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
+      "    mean_action_processing_ms: 0.15902557874431109\n",
+      "    mean_env_wait_ms: 1.1761492975958119\n",
+      "    mean_inference_ms: 5.3938636303115555\n",
+      "    mean_raw_obs_processing_ms: 0.4266225682217487\n",
+      "  time_since_restore: 105.31522297859192\n",
+      "  time_this_iter_s: 25.26993989944458\n",
+      "  time_total_s: 105.31522297859192\n",
       "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
+      "    learn_throughput: 8834.02\n",
+      "    learn_time_ms: 18314.652\n",
+      "    sample_throughput: 20391.969\n",
+      "    sample_time_ms: 7934.104\n",
+      "    update_time_ms: 31.737\n",
+      "  timestamp: 1602506573\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      4 |          105.315 | 647168 |  200.853 |              253.717 |              106.747 |            897.658 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3620.130319148936\n",
+      "    time_step_min: 3328\n",
+      "  date: 2020-10-12_12-43-18\n",
       "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 894.2341772151899\n",
+      "  episode_reward_max: 253.71717171717134\n",
+      "  episode_reward_mean: 201.7969569108807\n",
+      "  episode_reward_min: 106.74747474747424\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
+      "        entropy: 1.0741320550441742\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
+      "        kl: 0.010659902356564999\n",
       "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
+      "        policy_loss: -0.011991073998312155\n",
+      "        total_loss: 29.64512062072754\n",
+      "        vf_explained_var: 0.9406320452690125\n",
+      "        vf_loss: 29.655516147613525\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -2870,81 +2856,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
+      "    cpu_util_percent: 25.776666666666667\n",
+      "    gpu_util_percent0: 0.4046666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
+      "    mean_action_processing_ms: 0.15753872962615612\n",
+      "    mean_env_wait_ms: 1.1772916063340257\n",
+      "    mean_inference_ms: 5.2647729361155635\n",
+      "    mean_raw_obs_processing_ms: 0.421179650515422\n",
+      "  time_since_restore: 130.2804799079895\n",
+      "  time_this_iter_s: 24.965256929397583\n",
+      "  time_total_s: 130.2804799079895\n",
       "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
+      "    learn_throughput: 8863.013\n",
+      "    learn_time_ms: 18254.74\n",
+      "    sample_throughput: 20949.572\n",
+      "    sample_time_ms: 7722.926\n",
+      "    update_time_ms: 29.383\n",
+      "  timestamp: 1602506598\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      5 |           130.28 | 808960 |  201.797 |              253.717 |              106.747 |            894.234 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3613.8930131004367\n",
+      "    time_step_min: 3280\n",
+      "  date: 2020-10-12_12-43-44\n",
       "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 890.5723270440252\n",
+      "  episode_reward_max: 258.868686868687\n",
+      "  episode_reward_mean: 202.77139317705334\n",
+      "  episode_reward_min: 106.74747474747424\n",
+      "  episodes_this_iter: 164\n",
+      "  episodes_total: 954\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
+      "        entropy: 1.0176733334859211\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
+      "        kl: 0.01112077998307844\n",
       "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
+      "        policy_loss: -0.01367081212811172\n",
+      "        total_loss: 28.44929854075114\n",
+      "        vf_explained_var: 0.9561074376106262\n",
+      "        vf_loss: 28.461254119873047\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -2952,81 +2938,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
+      "    cpu_util_percent: 25.986666666666665\n",
+      "    gpu_util_percent0: 0.394\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7533333333333325\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
+      "    mean_action_processing_ms: 0.1563283776266907\n",
+      "    mean_env_wait_ms: 1.1787037140608163\n",
+      "    mean_inference_ms: 5.161306142094558\n",
+      "    mean_raw_obs_processing_ms: 0.4166823689177291\n",
+      "  time_since_restore: 155.60316634178162\n",
+      "  time_this_iter_s: 25.322686433792114\n",
+      "  time_total_s: 155.60316634178162\n",
       "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
+      "    learn_throughput: 8861.524\n",
+      "    learn_time_ms: 18257.807\n",
+      "    sample_throughput: 21306.62\n",
+      "    sample_time_ms: 7593.509\n",
+      "    update_time_ms: 30.4\n",
+      "  timestamp: 1602506624\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      6 |          155.603 | 970752 |  202.771 |              258.869 |              106.747 |            890.572 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3603.3406862745096\n",
+      "    time_step_min: 3264\n",
+      "  date: 2020-10-12_12-44-09\n",
       "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 883.7662440570523\n",
+      "  episode_reward_max: 258.868686868687\n",
+      "  episode_reward_mean: 204.31626886935896\n",
+      "  episode_reward_min: 106.74747474747424\n",
+      "  episodes_this_iter: 308\n",
+      "  episodes_total: 1262\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
+      "        entropy: 1.0213659306367238\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
+      "        kl: 0.009701167543729147\n",
       "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
+      "        policy_loss: -0.010542363626882434\n",
+      "        total_loss: 30.853121121724445\n",
+      "        vf_explained_var: 0.9592533111572266\n",
+      "        vf_loss: 30.862233479817707\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -3034,81 +3020,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
+      "    cpu_util_percent: 25.703333333333337\n",
+      "    gpu_util_percent0: 0.3773333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7599999999999993\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
+      "    mean_action_processing_ms: 0.15473377617903775\n",
+      "    mean_env_wait_ms: 1.1810367532901567\n",
+      "    mean_inference_ms: 5.024348698010241\n",
+      "    mean_raw_obs_processing_ms: 0.4108852518846039\n",
+      "  time_since_restore: 180.50350046157837\n",
+      "  time_this_iter_s: 24.900334119796753\n",
+      "  time_total_s: 180.50350046157837\n",
       "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
+      "    learn_throughput: 8876.571\n",
+      "    learn_time_ms: 18226.857\n",
+      "    sample_throughput: 21638.256\n",
+      "    sample_time_ms: 7477.128\n",
+      "    update_time_ms: 29.74\n",
+      "  timestamp: 1602506649\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      7 |          180.504 | 1132544 |  204.316 |              258.869 |              106.747 |            883.766 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_2f54c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
+      "    time_step_max: 4248\n",
+      "    time_step_mean: 3596.635838150289\n",
+      "    time_step_min: 3264\n",
+      "  date: 2020-10-12_12-44-34\n",
       "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
+      "  episode_len_mean: 880.6427566807314\n",
+      "  episode_reward_max: 265.98989898989885\n",
+      "  episode_reward_mean: 205.24681413288985\n",
+      "  episode_reward_min: 103.86868686868668\n",
+      "  episodes_this_iter: 160\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
+      "        entropy: 1.0055027554432552\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
+      "        kl: 0.009654009947553277\n",
       "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
+      "        policy_loss: -0.011977127088660685\n",
+      "        total_loss: 21.057878653208416\n",
+      "        vf_explained_var: 0.9642793536186218\n",
+      "        vf_loss: 21.068427403767902\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -3116,3320 +3102,56 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
+      "    cpu_util_percent: 25.467741935483875\n",
+      "    gpu_util_percent0: 0.2916129032258064\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.774193548387097\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 3607\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
+      "    mean_action_processing_ms: 0.15411860827672585\n",
+      "    mean_env_wait_ms: 1.1819827185557858\n",
+      "    mean_inference_ms: 4.97131117082984\n",
+      "    mean_raw_obs_processing_ms: 0.4086455750448838\n",
+      "  time_since_restore: 205.72761225700378\n",
+      "  time_this_iter_s: 25.224111795425415\n",
+      "  time_total_s: 205.72761225700378\n",
       "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
+      "    learn_throughput: 8870.705\n",
+      "    learn_time_ms: 18238.911\n",
+      "    sample_throughput: 21886.024\n",
+      "    sample_time_ms: 7392.48\n",
+      "    update_time_ms: 30.869\n",
+      "  timestamp: 1602506674\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: 2f54c_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
-      "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
-      "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
-      "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
-      "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
-      "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285714\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
-      "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
-      "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
-      "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
-      "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
-      "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
-      "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
-      "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
-      "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
-      "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
-      "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
-      "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
-      "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
-      "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
-      "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
-      "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
-      "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
-      "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
-      "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
-      "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
-      "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
-      "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
-      "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
-      "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      8 |          205.728 | 1294336 |  205.247 |               265.99 |              103.869 |            880.643 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent pu0gldb1"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index 0786a30..4729210 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -21,7 +21,7 @@ default_config = {
     'clip_param': 0.3,
     'vf_clip_param': 10.0,
     'kl_target': 0.01,
-    'num_sgd_iter': 30,
+    'num_sgd_iter': 25,
     'lambda': 1.0,
     "use_critic": True,
     "use_gae": True,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 1e-4,
+    "entropy_coeff": 5e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index d0ca168..6646acb 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [
     {
@@ -14,9 +14,8 @@
     }
    ],
    "source": [
-    "##### import os\n",
+    "import os\n",
     "import multiprocessing as mp\n",
-    "\n",
     "import plotly.io as pio\n",
     "import ray\n",
     "from ray import tune\n",
@@ -29,7 +28,7 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "2\n",
+    "\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
@@ -60,21 +59,14 @@
     "        'program': 'train.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
-    "            'name': 'time_step_mean',\n",
+    "            'name': 'time_step_min',\n",
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'clip_param': {\n",
-    "                'values': [0.3, 0.5]\n",
-    "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
-    "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
-    "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "            'instance_path': {\n",
+    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
+    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
+    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +74,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: u34ll0uk\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/u34ll0uk\n"
      ]
     }
    ],
@@ -108,203 +100,200 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "2020-10-12 14:18:04,700 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 14:18:05,135 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 14:18:05,136 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
+      "2020-10-12 14:18:05,137 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta51\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 14:18:10,153 - wandb.wandb_agent - INFO - Running runs: ['ghl8l9jj']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrim-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/u34ll0uk\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ghl8l9jj\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_141806-ghl8l9jj\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 14:18:10,755\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=70054)\u001b[0m 2020-10-12 14:18:13,502\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=70052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70019)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70019)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69979)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69979)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69945)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69945)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70016)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70016)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69946)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69946)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69950)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69950)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69947)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69947)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70018)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70018)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70010)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70010)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69949)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69949)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70021)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70021)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70072)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70072)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69951)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69951)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70015)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70015)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69954)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69954)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70022)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70022)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=70013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=70013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_14-18-46\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,21 +301,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
+      "        entropy: 1.1851047078768413\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        kl: 0.004071502441850801\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
+      "        policy_loss: -0.00785889983914482\n",
+      "        total_loss: 507.07567087809247\n",
       "        vf_explained_var: 0.540532648563385\n",
       "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
@@ -336,65 +325,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 29.659374999999997\n",
+      "    gpu_util_percent0: 0.24875000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.55625\n",
+      "    vram_util_percent0: 0.08526873565103313\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.16994892060296626\n",
+      "    mean_env_wait_ms: 1.169091189632669\n",
+      "    mean_inference_ms: 5.872200097004254\n",
+      "    mean_raw_obs_processing_ms: 0.45335577092961277\n",
+      "  time_since_restore: 27.71648859977722\n",
+      "  time_this_iter_s: 27.71648859977722\n",
+      "  time_total_s: 27.71648859977722\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 8874.446\n",
+      "    learn_time_ms: 18231.223\n",
+      "    sample_throughput: 17216.996\n",
+      "    sample_time_ms: 9397.226\n",
+      "    update_time_ms: 45.065\n",
+      "  timestamp: 1602512326\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      1 |          27.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_mean: 3614.4305555555557\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_14-19-13\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
+      "  episode_len_mean: 890.8607594936709\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.6365234624726\n",
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -403,14 +392,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
+      "        entropy: 1.1561074058214824\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        kl: 0.007923512797181806\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.010965243893830726\n",
+      "        total_loss: 127.46906661987305\n",
+      "        vf_explained_var: 0.8076093792915344\n",
+      "        vf_loss: 127.47981770833333\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,65 +407,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 25.34193548387097\n",
+      "    gpu_util_percent0: 0.3187096774193548\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
+      "    ram_util_percent: 3.748387096774193\n",
       "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.16561765606620044\n",
+      "    mean_env_wait_ms: 1.165680428994888\n",
+      "    mean_inference_ms: 5.6226371336530185\n",
+      "    mean_raw_obs_processing_ms: 0.4413906555255206\n",
+      "  time_since_restore: 54.19657015800476\n",
+      "  time_this_iter_s: 26.48008155822754\n",
+      "  time_total_s: 54.19657015800476\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 8799.877\n",
+      "    learn_time_ms: 18385.711\n",
+      "    sample_throughput: 18754.589\n",
+      "    sample_time_ms: 8626.795\n",
+      "    update_time_ms: 41.168\n",
+      "  timestamp: 1602512353\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      2 |          54.1966 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3601.8677130044844\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_14-19-39\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 885.132911392405\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 219.87009333844756\n",
+      "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -485,14 +474,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
+      "        entropy: 1.1456398169199626\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        kl: 0.008224547879459957\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.013529085864623388\n",
+      "        total_loss: 61.275455474853516\n",
+      "        vf_explained_var: 0.8916645646095276\n",
+      "        vf_loss: 61.28873507181803\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,65 +489,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 24.036666666666665\n",
+      "    gpu_util_percent0: 0.4583333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
+      "    ram_util_percent: 3.766666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16292763164001656\n",
+      "    mean_env_wait_ms: 1.1660419208572714\n",
+      "    mean_inference_ms: 5.433839896911039\n",
+      "    mean_raw_obs_processing_ms: 0.4330986534385022\n",
+      "  time_since_restore: 80.38152575492859\n",
+      "  time_this_iter_s: 26.184955596923828\n",
+      "  time_total_s: 80.38152575492859\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 8760.554\n",
+      "    learn_time_ms: 18468.239\n",
+      "    sample_throughput: 19699.668\n",
+      "    sample_time_ms: 8212.93\n",
+      "    update_time_ms: 40.926\n",
+      "  timestamp: 1602512379\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      3 |          80.3815 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3596.0099337748343\n",
+      "    time_step_min: 3231\n",
+      "  date: 2020-10-12_14-20-04\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 878.7689873417721\n",
+      "  episode_reward_max: 276.47474747474763\n",
+      "  episode_reward_mean: 220.6047340493541\n",
+      "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -567,14 +556,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
+      "        entropy: 1.1263898611068726\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        kl: 0.008100568510902425\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.013406771836647144\n",
+      "        total_loss: 47.16934140523275\n",
+      "        vf_explained_var: 0.9198758602142334\n",
+      "        vf_loss: 47.18250052134196\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,65 +571,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 25.53103448275862\n",
+      "    gpu_util_percent0: 0.2900000000000001\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
+      "    ram_util_percent: 3.768965517241379\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.16094661920745734\n",
+      "    mean_env_wait_ms: 1.167455903288604\n",
+      "    mean_inference_ms: 5.2910087094709635\n",
+      "    mean_raw_obs_processing_ms: 0.42653092723086955\n",
+      "  time_since_restore: 105.78936982154846\n",
+      "  time_this_iter_s: 25.407844066619873\n",
+      "  time_total_s: 105.78936982154846\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 8772.696\n",
+      "    learn_time_ms: 18442.677\n",
+      "    sample_throughput: 20485.045\n",
+      "    sample_time_ms: 7898.054\n",
+      "    update_time_ms: 40.294\n",
+      "  timestamp: 1602512404\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      4 |          105.789 | 647168 |  220.605 |              276.475 |              145.717 |            878.769 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3581.6985583224114\n",
+      "    time_step_min: 3204\n",
+      "  date: 2020-10-12_14-20-30\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 872.4867256637168\n",
+      "  episode_reward_max: 280.5656565656565\n",
+      "  episode_reward_mean: 222.48133675567283\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 791\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -649,14 +638,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
+      "        entropy: 1.0873714486757915\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        kl: 0.006956188706681132\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.011262792395427823\n",
+      "        total_loss: 34.19948164621989\n",
+      "        vf_explained_var: 0.9459590911865234\n",
+      "        vf_loss: 34.2105925877889\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,65 +653,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 24.066666666666663\n",
+      "    gpu_util_percent0: 0.43766666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
+      "    ram_util_percent: 3.7666666666666657\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.15940651242537818\n",
+      "    mean_env_wait_ms: 1.169971635752512\n",
+      "    mean_inference_ms: 5.180106083655211\n",
+      "    mean_raw_obs_processing_ms: 0.4212780660858121\n",
+      "  time_since_restore: 131.2926995754242\n",
+      "  time_this_iter_s: 25.503329753875732\n",
+      "  time_total_s: 131.2926995754242\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 8760.483\n",
+      "    learn_time_ms: 18468.388\n",
+      "    sample_throughput: 21079.592\n",
+      "    sample_time_ms: 7675.291\n",
+      "    update_time_ms: 36.471\n",
+      "  timestamp: 1602512430\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      5 |          131.293 | 808960 |  222.481 |              280.566 |              145.717 |            872.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3564.887755102041\n",
+      "    time_step_min: 3204\n",
+      "  date: 2020-10-12_14-20-56\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 860.6943942133815\n",
+      "  episode_reward_max: 280.5656565656565\n",
+      "  episode_reward_mean: 225.7112809834327\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 315\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -731,14 +720,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
+      "        entropy: 1.0886386533578236\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        kl: 0.007588425030310948\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.01092883839737624\n",
+      "        total_loss: 30.730765342712402\n",
+      "        vf_explained_var: 0.9611188769340515\n",
+      "        vf_loss: 30.741480032602947\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,65 +735,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 25.18965517241379\n",
+      "    gpu_util_percent0: 0.2837931034482758\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
+      "    ram_util_percent: 3.7620689655172406\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15734562235197594\n",
+      "    mean_env_wait_ms: 1.1756497799942263\n",
+      "    mean_inference_ms: 5.0326967604555675\n",
+      "    mean_raw_obs_processing_ms: 0.41464838863890185\n",
+      "  time_since_restore: 156.71548414230347\n",
+      "  time_this_iter_s: 25.422784566879272\n",
+      "  time_total_s: 156.71548414230347\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 8759.305\n",
+      "    learn_time_ms: 18470.871\n",
+      "    sample_throughput: 21462.045\n",
+      "    sample_time_ms: 7538.517\n",
+      "    update_time_ms: 36.673\n",
+      "  timestamp: 1602512456\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      6 |          156.715 | 970752 |  225.711 |              280.566 |              145.717 |            860.694 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_c29f8_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3552.704692556634\n",
+      "    time_step_min: 3179\n",
+      "  date: 2020-10-12_14-21-21\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 855.0387658227849\n",
+      "  episode_reward_max: 284.35353535353545\n",
+      "  episode_reward_mean: 227.46978487405684\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -813,14 +802,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
+      "        entropy: 1.0706470410029094\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        kl: 0.007387861027382314\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.013462736414415607\n",
+      "        total_loss: 19.742233912150066\n",
+      "        vf_explained_var: 0.9632093906402588\n",
+      "        vf_loss: 19.75549300511678\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,5608 +817,56 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 25.182758620689658\n",
+      "    gpu_util_percent0: 0.30241379310344835\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
+      "    ram_util_percent: 3.775862068965517\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 70054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.15659944710447274\n",
+      "    mean_env_wait_ms: 1.1781296386862312\n",
+      "    mean_inference_ms: 4.979102261022608\n",
+      "    mean_raw_obs_processing_ms: 0.41223103840983283\n",
+      "  time_since_restore: 182.10720825195312\n",
+      "  time_this_iter_s: 25.391724109649658\n",
+      "  time_total_s: 182.10720825195312\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 8762.399\n",
+      "    learn_time_ms: 18464.35\n",
+      "    sample_throughput: 21732.82\n",
+      "    sample_time_ms: 7444.593\n",
+      "    update_time_ms: 36.744\n",
+      "  timestamp: 1602512481\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
-      "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
-      "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: c29f8_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
-      "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
+      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      7 |          182.107 | 1132544 |   227.47 |              284.354 |              145.717 |            855.039 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
-      "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
-      "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
-      "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
-      "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
-      "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
-      "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
-      "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
-      "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
-      "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
-      "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
-      "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
-      "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
-      "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
-      "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
-      "        vf_explained_var: 0.5664147734642029\n",
-      "        vf_loss: 502.24672444661456\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
-      "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
-      "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
-      "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
-      "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
-      "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
-      "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
-      "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
-      "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
-      "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
-      "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
-      "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
-      "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
-      "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285714\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
-      "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
-      "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
-      "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
-      "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
-      "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
-      "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
-      "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
-      "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
-      "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
-      "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
-      "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
-      "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
-      "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
-      "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
-      "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
-      "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
-      "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
-      "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
-      "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
-      "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
-      "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
-      "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
-      "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent u34ll0uk"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index ac81b03..2f0e0dc 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index 0786a30..4729210 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -21,7 +21,7 @@ default_config = {
     'clip_param': 0.3,
     'vf_clip_param': 10.0,
     'kl_target': 0.01,
-    'num_sgd_iter': 30,
+    'num_sgd_iter': 25,
     'lambda': 1.0,
     "use_critic": True,
     "use_gae": True,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 1e-4,
+    "entropy_coeff": 5e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 8ee10cb..4404ee3 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug-internal.log
\ No newline at end of file
+run-20201012_153307-w1uw7m4j/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4f3bf3b..c3711bd 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug.log
\ No newline at end of file
+run-20201012_153307-w1uw7m4j/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 8be457f..3df25c5 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201012_023117-p62mhra8
\ No newline at end of file
+run-20201012_153307-w1uw7m4j
\ No newline at end of file
