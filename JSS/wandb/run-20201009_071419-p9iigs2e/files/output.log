2020-10-09 07:14:21,706	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_0e966_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=48367)[0m 2020-10-09 07:14:24,723	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=48287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48249)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-09_07-14-57
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1640265882015228
        entropy_coeff: 0.0
        kl: 0.0028357502771541475
        model: {}
        policy_loss: -0.009348569472786039
        total_loss: 493.98447875976564
        vf_explained_var: 0.5632375478744507
        vf_loss: 493.9932662963867
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.620000000000005
    gpu_util_percent0: 0.04466666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003333333333333333
    ram_util_percent: 9.549999999999999
    vram_util_percent0: 0.2567781786378047
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17463686143074852
    mean_env_wait_ms: 1.6403666216858228
    mean_inference_ms: 5.586467591580433
    mean_raw_obs_processing_ms: 0.472613938541536
  time_since_restore: 26.50930643081665
  time_this_iter_s: 26.50930643081665
  time_total_s: 26.50930643081665
  timers:
    learn_throughput: 9597.811
    learn_time_ms: 16857.177
    sample_throughput: 16899.086
    sample_time_ms: 9574.009
    update_time_ms: 47.374
  timestamp: 1602227697
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      1 |          26.5093 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3243.0
  date: 2020-10-09_07-15-22
  done: false
  episode_len_mean: 875.8892405063291
  episode_reward_max: 277.6969696969693
  episode_reward_mean: 227.75489067894108
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1405592024326325
        entropy_coeff: 0.0
        kl: 0.003963828808628023
        model: {}
        policy_loss: -0.009683768078684808
        total_loss: 112.75638694763184
        vf_explained_var: 0.8139449954032898
        vf_loss: 112.76567344665527
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.36785714285714
    gpu_util_percent0: 0.16142857142857142
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74642857142857
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17050721624806217
    mean_env_wait_ms: 1.636370874639753
    mean_inference_ms: 5.377943849545443
    mean_raw_obs_processing_ms: 0.4614864638634708
  time_since_restore: 51.477715492248535
  time_this_iter_s: 24.968409061431885
  time_total_s: 51.477715492248535
  timers:
    learn_throughput: 9671.12
    learn_time_ms: 16729.397
    sample_throughput: 18129.801
    sample_time_ms: 8924.091
    update_time_ms: 44.586
  timestamp: 1602227722
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      2 |          51.4777 | 323584 |  227.755 |              277.697 |              115.788 |            875.889 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3243.0
  date: 2020-10-09_07-15-47
  done: false
  episode_len_mean: 873.4409282700421
  episode_reward_max: 278.12121212121184
  episode_reward_mean: 228.45058176703725
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 1.1322518289089203
        entropy_coeff: 0.0
        kl: 0.00506454105488956
        model: {}
        policy_loss: -0.011438605771400035
        total_loss: 47.14689064025879
        vf_explained_var: 0.9070607423782349
        vf_loss: 47.15807628631592
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.625
    gpu_util_percent0: 0.06214285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.789285714285715
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1676968647818221
    mean_env_wait_ms: 1.635201127812432
    mean_inference_ms: 5.254846718194445
    mean_raw_obs_processing_ms: 0.45264530144783727
  time_since_restore: 76.2107138633728
  time_this_iter_s: 24.732998371124268
  time_total_s: 76.2107138633728
  timers:
    learn_throughput: 9687.066
    learn_time_ms: 16701.858
    sample_throughput: 18774.758
    sample_time_ms: 8617.528
    update_time_ms: 38.348
  timestamp: 1602227747
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      3 |          76.2107 | 485376 |  228.451 |              278.121 |              115.788 |            873.441 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3243.0
  date: 2020-10-09_07-16-12
  done: false
  episode_len_mean: 870.1946202531645
  episode_reward_max: 287.4444444444444
  episode_reward_mean: 230.0844041682647
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 1.1200319826602936
        entropy_coeff: 0.0
        kl: 0.0044023396214470266
        model: {}
        policy_loss: -0.01159109640866518
        total_loss: 34.55885772705078
        vf_explained_var: 0.9278494119644165
        vf_loss: 34.57022714614868
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.153571428571436
    gpu_util_percent0: 0.00035714285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.803571428571427
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16581527685855654
    mean_env_wait_ms: 1.6351770484879833
    mean_inference_ms: 5.161821998940865
    mean_raw_obs_processing_ms: 0.4463177272127474
  time_since_restore: 101.1593599319458
  time_this_iter_s: 24.948646068572998
  time_total_s: 101.1593599319458
  timers:
    learn_throughput: 9681.599
    learn_time_ms: 16711.29
    sample_throughput: 19058.958
    sample_time_ms: 8489.026
    update_time_ms: 38.669
  timestamp: 1602227772
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      4 |          101.159 | 647168 |  230.084 |              287.444 |              110.798 |            870.195 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3232.0
  date: 2020-10-09_07-16-36
  done: false
  episode_len_mean: 867.2575757575758
  episode_reward_max: 290.191919191919
  episode_reward_mean: 231.36863585348416
  episode_reward_min: 110.79797979798
  episodes_this_iter: 160
  episodes_total: 792
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 1.0877218842506409
        entropy_coeff: 0.0
        kl: 0.005004563950933516
        model: {}
        policy_loss: -0.011946538183838128
        total_loss: 29.39444570541382
        vf_explained_var: 0.94978266954422
        vf_loss: 29.406267166137695
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.31785714285714
    gpu_util_percent0: 0.40642857142857153
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75357142857143
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16446271662943718
    mean_env_wait_ms: 1.6363865174519043
    mean_inference_ms: 5.0880504399418705
    mean_raw_obs_processing_ms: 0.44138367058292655
  time_since_restore: 125.59317994117737
  time_this_iter_s: 24.433820009231567
  time_total_s: 125.59317994117737
  timers:
    learn_throughput: 9699.741
    learn_time_ms: 16680.033
    sample_throughput: 19376.534
    sample_time_ms: 8349.894
    update_time_ms: 38.069
  timestamp: 1602227796
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      5 |          125.593 | 808960 |  231.369 |              290.192 |              110.798 |            867.258 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3144.0
  date: 2020-10-09_07-17-01
  done: false
  episode_len_mean: 861.7649186256781
  episode_reward_max: 290.191919191919
  episode_reward_mean: 233.73055144574113
  episode_reward_min: 110.79797979798
  episodes_this_iter: 314
  episodes_total: 1106
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 1.1087872564792634
        entropy_coeff: 0.0
        kl: 0.004968288983218372
        model: {}
        policy_loss: -0.010600300226360559
        total_loss: 30.008597946166994
        vf_explained_var: 0.9554424285888672
        vf_loss: 30.019073963165283
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.13333333333333
    gpu_util_percent0: 0.22666666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76296296296296
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16270859150728867
    mean_env_wait_ms: 1.639132746557686
    mean_inference_ms: 4.989275565338716
    mean_raw_obs_processing_ms: 0.4353139565030795
  time_since_restore: 149.97633266448975
  time_this_iter_s: 24.383152723312378
  time_total_s: 149.97633266448975
  timers:
    learn_throughput: 9716.686
    learn_time_ms: 16650.944
    sample_throughput: 19594.019
    sample_time_ms: 8257.214
    update_time_ms: 37.144
  timestamp: 1602227821
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      6 |          149.976 | 970752 |  233.731 |              290.192 |              110.798 |            861.765 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3144.0
  date: 2020-10-09_07-17-25
  done: false
  episode_len_mean: 859.1115506329114
  episode_reward_max: 290.191919191919
  episode_reward_mean: 234.5163262370539
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 1.0938330292701721
        entropy_coeff: 0.0
        kl: 0.005224581435322761
        model: {}
        policy_loss: -0.012242387142032385
        total_loss: 17.812509727478027
        vf_explained_var: 0.9656338691711426
        vf_loss: 17.824687194824218
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.603571428571428
    gpu_util_percent0: 0.5325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1620799961319486
    mean_env_wait_ms: 1.6404863383172
    mean_inference_ms: 4.953015583272775
    mean_raw_obs_processing_ms: 0.43310100509925725
  time_since_restore: 174.5643343925476
  time_this_iter_s: 24.58800172805786
  time_total_s: 174.5643343925476
  timers:
    learn_throughput: 9705.282
    learn_time_ms: 16670.509
    sample_throughput: 19782.772
    sample_time_ms: 8178.429
    update_time_ms: 37.52
  timestamp: 1602227845
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      7 |          174.564 | 1132544 |  234.516 |              290.192 |              110.798 |            859.112 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3144.0
  date: 2020-10-09_07-17-50
  done: false
  episode_len_mean: 856.5239099859353
  episode_reward_max: 290.191919191919
  episode_reward_mean: 235.52299364957577
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 1.078421276807785
        entropy_coeff: 0.0
        kl: 0.005420685536228121
        model: {}
        policy_loss: -0.01284004000481218
        total_loss: 17.272067022323608
        vf_explained_var: 0.9650015830993652
        vf_loss: 17.284838819503783
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.68888888888889
    gpu_util_percent0: 0.39740740740740743
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16154635715889593
    mean_env_wait_ms: 1.6417923902651794
    mean_inference_ms: 4.921473504064219
    mean_raw_obs_processing_ms: 0.4312080203566676
  time_since_restore: 198.93187761306763
  time_this_iter_s: 24.36754322052002
  time_total_s: 198.93187761306763
  timers:
    learn_throughput: 9722.518
    learn_time_ms: 16640.956
    sample_throughput: 19879.589
    sample_time_ms: 8138.599
    update_time_ms: 35.422
  timestamp: 1602227870
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      8 |          198.932 | 1294336 |  235.523 |              290.192 |              110.798 |            856.524 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3144.0
  date: 2020-10-09_07-18-14
  done: false
  episode_len_mean: 854.0335443037975
  episode_reward_max: 290.46464646464625
  episode_reward_mean: 236.51258151131555
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 1.0531862735748292
        entropy_coeff: 0.0
        kl: 0.0052449502749368545
        model: {}
        policy_loss: -0.012520163576118648
        total_loss: 15.421020460128783
        vf_explained_var: 0.9687449336051941
        vf_loss: 15.433475112915039
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.935714285714287
    gpu_util_percent0: 0.03214285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.817857142857145
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1610798613576855
    mean_env_wait_ms: 1.6430634873570016
    mean_inference_ms: 4.893778368674666
    mean_raw_obs_processing_ms: 0.42946828514155205
  time_since_restore: 223.56012344360352
  time_this_iter_s: 24.62824583053589
  time_total_s: 223.56012344360352
  timers:
    learn_throughput: 9716.534
    learn_time_ms: 16651.206
    sample_throughput: 19973.928
    sample_time_ms: 8100.159
    update_time_ms: 36.634
  timestamp: 1602227894
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |      9 |           223.56 | 1456128 |  236.513 |              290.465 |              110.798 |            854.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3115.0
  date: 2020-10-09_07-18-39
  done: false
  episode_len_mean: 849.0339702760085
  episode_reward_max: 291.8181818181812
  episode_reward_mean: 238.96458748847266
  episode_reward_min: 110.79797979798
  episodes_this_iter: 304
  episodes_total: 1884
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 1.0347528219223023
        entropy_coeff: 0.0
        kl: 0.004849956254474819
        model: {}
        policy_loss: -0.011472697323188185
        total_loss: 22.35040855407715
        vf_explained_var: 0.9689149856567383
        vf_loss: 22.36182098388672
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.86785714285714
    gpu_util_percent0: 0.2871428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16034888262152874
    mean_env_wait_ms: 1.6457249235741012
    mean_inference_ms: 4.850055461029211
    mean_raw_obs_processing_ms: 0.42677150489620397
  time_since_restore: 248.17753267288208
  time_this_iter_s: 24.617409229278564
  time_total_s: 248.17753267288208
  timers:
    learn_throughput: 9717.316
    learn_time_ms: 16649.864
    sample_throughput: 20025.563
    sample_time_ms: 8079.273
    update_time_ms: 36.371
  timestamp: 1602227919
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     10 |          248.178 | 1617920 |  238.965 |              291.818 |              110.798 |            849.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3115.0
  date: 2020-10-09_07-19-04
  done: false
  episode_len_mean: 846.4230769230769
  episode_reward_max: 291.8181818181812
  episode_reward_mean: 240.04273996046132
  episode_reward_min: 110.79797979798
  episodes_this_iter: 170
  episodes_total: 2054
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.0e-05
        entropy: 1.0367805242538453
        entropy_coeff: 0.0
        kl: 0.005108644720166922
        model: {}
        policy_loss: -0.011513726029079407
        total_loss: 14.326866722106933
        vf_explained_var: 0.9715536832809448
        vf_loss: 14.338348531723023
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.221428571428575
    gpu_util_percent0: 0.4250000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16001688757455426
    mean_env_wait_ms: 1.6469832035532905
    mean_inference_ms: 4.829970747825276
    mean_raw_obs_processing_ms: 0.42551507762086455
  time_since_restore: 272.65007996559143
  time_this_iter_s: 24.47254729270935
  time_total_s: 272.65007996559143
  timers:
    learn_throughput: 9743.325
    learn_time_ms: 16605.419
    sample_throughput: 20438.146
    sample_time_ms: 7916.178
    update_time_ms: 36.422
  timestamp: 1602227944
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     11 |           272.65 | 1779712 |  240.043 |              291.818 |              110.798 |            846.423 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3115.0
  date: 2020-10-09_07-19-29
  done: false
  episode_len_mean: 844.3182640144665
  episode_reward_max: 292.1212121212122
  episode_reward_mean: 240.86200157086216
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.0e-05
        entropy: 1.0289155066013336
        entropy_coeff: 0.0
        kl: 0.004698231723159552
        model: {}
        policy_loss: -0.011500532634090632
        total_loss: 15.446291065216064
        vf_explained_var: 0.9684388041496277
        vf_loss: 15.457762241363525
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.328571428571426
    gpu_util_percent0: 0.44857142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.767857142857144
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15973366011127318
    mean_env_wait_ms: 1.6481865592334555
    mean_inference_ms: 4.812976996289823
    mean_raw_obs_processing_ms: 0.4244910976457299
  time_since_restore: 297.62342166900635
  time_this_iter_s: 24.973341703414917
  time_total_s: 297.62342166900635
  timers:
    learn_throughput: 9736.56
    learn_time_ms: 16616.957
    sample_throughput: 20485.102
    sample_time_ms: 7898.033
    update_time_ms: 42.566
  timestamp: 1602227969
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     12 |          297.623 | 1941504 |  240.862 |              292.121 |              110.798 |            844.318 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3115.0
  date: 2020-10-09_07-19-53
  done: false
  episode_len_mean: 842.07805907173
  episode_reward_max: 292.9898989898988
  episode_reward_mean: 241.80551506627444
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 5.0e-05
        entropy: 0.9957593947649002
        entropy_coeff: 0.0
        kl: 0.004901725705713034
        model: {}
        policy_loss: -0.01176951372763142
        total_loss: 13.699395942687989
        vf_explained_var: 0.9720869064331055
        vf_loss: 13.711150217056275
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.68518518518518
    gpu_util_percent0: 0.26333333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.785185185185185
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15947060615472364
    mean_env_wait_ms: 1.6493961058276012
    mean_inference_ms: 4.797449374893619
    mean_raw_obs_processing_ms: 0.4235450211647434
  time_since_restore: 322.1290500164032
  time_this_iter_s: 24.50562834739685
  time_total_s: 322.1290500164032
  timers:
    learn_throughput: 9747.348
    learn_time_ms: 16598.567
    sample_throughput: 20503.181
    sample_time_ms: 7891.068
    update_time_ms: 44.577
  timestamp: 1602227993
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     13 |          322.129 | 2103296 |  241.806 |               292.99 |              110.798 |            842.078 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-20-18
  done: false
  episode_len_mean: 838.288648244959
  episode_reward_max: 296.44444444444457
  episode_reward_mean: 243.35786920738363
  episode_reward_min: 110.79797979798
  episodes_this_iter: 308
  episodes_total: 2678
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 5.0e-05
        entropy: 0.97830990254879
        entropy_coeff: 0.0
        kl: 0.004749645246192813
        model: {}
        policy_loss: -0.01113577876240015
        total_loss: 21.112703227996825
        vf_explained_var: 0.9704862833023071
        vf_loss: 21.123831844329835
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.232142857142854
    gpu_util_percent0: 0.05535714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.767857142857142
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15902577189393574
    mean_env_wait_ms: 1.6517612314968997
    mean_inference_ms: 4.771103934752193
    mean_raw_obs_processing_ms: 0.4219883207475376
  time_since_restore: 346.6096725463867
  time_this_iter_s: 24.48062252998352
  time_total_s: 346.6096725463867
  timers:
    learn_throughput: 9761.054
    learn_time_ms: 16575.26
    sample_throughput: 20563.351
    sample_time_ms: 7867.978
    update_time_ms: 44.544
  timestamp: 1602228018
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     14 |           346.61 | 2265088 |  243.358 |              296.444 |              110.798 |            838.289 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-20-43
  done: false
  episode_len_mean: 836.601617440225
  episode_reward_max: 296.44444444444457
  episode_reward_mean: 244.13699938910898
  episode_reward_min: 110.79797979798
  episodes_this_iter: 166
  episodes_total: 2844
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 5.0e-05
        entropy: 0.9687725365161896
        entropy_coeff: 0.0
        kl: 0.004767898167483508
        model: {}
        policy_loss: -0.0114263822324574
        total_loss: 12.084120798110963
        vf_explained_var: 0.9757186770439148
        vf_loss: 12.095543432235718
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.896428571428572
    gpu_util_percent0: 0.33928571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15881528370044373
    mean_env_wait_ms: 1.6529149459348502
    mean_inference_ms: 4.758762916116475
    mean_raw_obs_processing_ms: 0.4212274900572751
  time_since_restore: 371.12758445739746
  time_this_iter_s: 24.517911911010742
  time_total_s: 371.12758445739746
  timers:
    learn_throughput: 9766.003
    learn_time_ms: 16566.859
    sample_throughput: 20524.769
    sample_time_ms: 7882.768
    update_time_ms: 44.98
  timestamp: 1602228043
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     15 |          371.128 | 2426880 |  244.137 |              296.444 |              110.798 |            836.602 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-21-07
  done: false
  episode_len_mean: 835.1005996002665
  episode_reward_max: 296.44444444444457
  episode_reward_mean: 244.90833047328704
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 5.0e-05
        entropy: 0.9697494626045227
        entropy_coeff: 0.0
        kl: 0.004601132241077721
        model: {}
        policy_loss: -0.01233454094035551
        total_loss: 10.331189441680909
        vf_explained_var: 0.9766246676445007
        vf_loss: 10.343522310256958
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.39285714285714
    gpu_util_percent0: 0.4189285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15863115991127297
    mean_env_wait_ms: 1.653989254100703
    mean_inference_ms: 4.747839953358332
    mean_raw_obs_processing_ms: 0.42055036707201365
  time_since_restore: 395.8954920768738
  time_this_iter_s: 24.76790761947632
  time_total_s: 395.8954920768738
  timers:
    learn_throughput: 9760.264
    learn_time_ms: 16576.601
    sample_throughput: 20460.644
    sample_time_ms: 7907.474
    update_time_ms: 46.194
  timestamp: 1602228067
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     16 |          395.895 | 2588672 |  244.908 |              296.444 |              110.798 |            835.101 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-21-32
  done: false
  episode_len_mean: 833.635101010101
  episode_reward_max: 296.44444444444457
  episode_reward_mean: 245.63522535965706
  episode_reward_min: 110.79797979798
  episodes_this_iter: 166
  episodes_total: 3168
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 5.0e-05
        entropy: 0.9329240083694458
        entropy_coeff: 0.0
        kl: 0.004962193476967513
        model: {}
        policy_loss: -0.011875637667253613
        total_loss: 12.53795928955078
        vf_explained_var: 0.9776097536087036
        vf_loss: 12.54983434677124
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.607407407407408
    gpu_util_percent0: 0.4103703703703704
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15845011378747978
    mean_env_wait_ms: 1.6550763729980544
    mean_inference_ms: 4.737145283753431
    mean_raw_obs_processing_ms: 0.4198699682257555
  time_since_restore: 420.19782996177673
  time_this_iter_s: 24.302337884902954
  time_total_s: 420.19782996177673
  timers:
    learn_throughput: 9782.757
    learn_time_ms: 16538.487
    sample_throughput: 20455.653
    sample_time_ms: 7909.403
    update_time_ms: 52.077
  timestamp: 1602228092
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     17 |          420.198 | 2750464 |  245.635 |              296.444 |              110.798 |            833.635 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-21-57
  done: false
  episode_len_mean: 831.4149640287769
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 246.81079282028912
  episode_reward_min: 110.79797979798
  episodes_this_iter: 307
  episodes_total: 3475
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 5.0e-05
        entropy: 0.9232602834701538
        entropy_coeff: 0.0
        kl: 0.0046374156372621655
        model: {}
        policy_loss: -0.011063570086844266
        total_loss: 16.395332050323486
        vf_explained_var: 0.9757033586502075
        vf_loss: 16.406394958496094
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.65185185185185
    gpu_util_percent0: 0.008888888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15815426363061122
    mean_env_wait_ms: 1.6570084199453134
    mean_inference_ms: 4.719748136053731
    mean_raw_obs_processing_ms: 0.41878339871528697
  time_since_restore: 444.77306509017944
  time_this_iter_s: 24.57523512840271
  time_total_s: 444.77306509017944
  timers:
    learn_throughput: 9766.887
    learn_time_ms: 16565.36
    sample_throughput: 20482.932
    sample_time_ms: 7898.869
    update_time_ms: 54.057
  timestamp: 1602228117
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     18 |          444.773 | 2912256 |  246.811 |              299.121 |              110.798 |            831.415 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-22-21
  done: false
  episode_len_mean: 830.4201981287837
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 247.37766214706215
  episode_reward_min: 110.79797979798
  episodes_this_iter: 159
  episodes_total: 3634
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 5.0e-05
        entropy: 0.9201890617609024
        entropy_coeff: 0.0
        kl: 0.004413552326150238
        model: {}
        policy_loss: -0.012228489469271154
        total_loss: 10.372993803024292
        vf_explained_var: 0.979202389717102
        vf_loss: 10.385222101211548
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.71785714285715
    gpu_util_percent0: 0.41071428571428564
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15801908430894415
    mean_env_wait_ms: 1.6579108449195785
    mean_inference_ms: 4.711608438282421
    mean_raw_obs_processing_ms: 0.4182761961590881
  time_since_restore: 469.1063916683197
  time_this_iter_s: 24.33332657814026
  time_total_s: 469.1063916683197
  timers:
    learn_throughput: 9783.952
    learn_time_ms: 16536.467
    sample_throughput: 20480.743
    sample_time_ms: 7899.713
    update_time_ms: 51.745
  timestamp: 1602228141
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     19 |          469.106 | 3074048 |  247.378 |              299.121 |              110.798 |             830.42 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-22-46
  done: false
  episode_len_mean: 829.4351265822785
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 247.82955078208232
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 5.0e-05
        entropy: 0.9197682678699494
        entropy_coeff: 0.0
        kl: 0.004512415430508554
        model: {}
        policy_loss: -0.01183155617909506
        total_loss: 11.920797729492188
        vf_explained_var: 0.9747611284255981
        vf_loss: 11.93262939453125
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.542857142857144
    gpu_util_percent0: 0.15357142857142855
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.775000000000002
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15789257649463492
    mean_env_wait_ms: 1.658783200660992
    mean_inference_ms: 4.704045076198331
    mean_raw_obs_processing_ms: 0.41779564297759786
  time_since_restore: 493.70829486846924
  time_this_iter_s: 24.601903200149536
  time_total_s: 493.70829486846924
  timers:
    learn_throughput: 9785.549
    learn_time_ms: 16533.769
    sample_throughput: 20503.548
    sample_time_ms: 7890.927
    update_time_ms: 52.337
  timestamp: 1602228166
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     20 |          493.708 | 3235840 |   247.83 |              299.121 |              110.798 |            829.435 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-23-10
  done: false
  episode_len_mean: 828.0447872605125
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 248.63675320007732
  episode_reward_min: 110.79797979798
  episodes_this_iter: 227
  episodes_total: 4019
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.2207031250000002e-05
        cur_lr: 5.0e-05
        entropy: 0.8794618248939514
        entropy_coeff: 0.0
        kl: 0.004830943769775331
        model: {}
        policy_loss: -0.011574837641092017
        total_loss: 12.576652002334594
        vf_explained_var: 0.9803616404533386
        vf_loss: 12.588226747512817
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.60740740740741
    gpu_util_percent0: 0.12222222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.774074074074075
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15771762768922032
    mean_env_wait_ms: 1.6599721425519196
    mean_inference_ms: 4.693824998820056
    mean_raw_obs_processing_ms: 0.4171388212847423
  time_since_restore: 518.1190102100372
  time_this_iter_s: 24.410715341567993
  time_total_s: 518.1190102100372
  timers:
    learn_throughput: 9786.453
    learn_time_ms: 16532.241
    sample_throughput: 20516.386
    sample_time_ms: 7885.989
    update_time_ms: 51.316
  timestamp: 1602228190
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     21 |          518.119 | 3397632 |  248.637 |              299.121 |              110.798 |            828.045 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-23-35
  done: false
  episode_len_mean: 826.5304735114862
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 249.42780358673463
  episode_reward_min: 110.79797979798
  episodes_this_iter: 247
  episodes_total: 4266
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625000001e-06
        cur_lr: 5.0e-05
        entropy: 0.8742325663566589
        entropy_coeff: 0.0
        kl: 0.004326233500614762
        model: {}
        policy_loss: -0.011729187925811856
        total_loss: 11.734823608398438
        vf_explained_var: 0.9793536067008972
        vf_loss: 11.74655270576477
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.03214285714286
    gpu_util_percent0: 0.06142857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.8
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15754554607894655
    mean_env_wait_ms: 1.6612544682303985
    mean_inference_ms: 4.683949618171246
    mean_raw_obs_processing_ms: 0.4165218857860539
  time_since_restore: 542.8675689697266
  time_this_iter_s: 24.74855875968933
  time_total_s: 542.8675689697266
  timers:
    learn_throughput: 9784.738
    learn_time_ms: 16535.139
    sample_throughput: 20566.123
    sample_time_ms: 7866.918
    update_time_ms: 44.585
  timestamp: 1602228215
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     22 |          542.868 | 3559424 |  249.428 |              299.121 |              110.798 |             826.53 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-24-00
  done: false
  episode_len_mean: 825.5768535262206
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 249.93269265895844
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125000006e-06
        cur_lr: 5.0e-05
        entropy: 0.8745293319225311
        entropy_coeff: 0.0
        kl: 0.004582717339508236
        model: {}
        policy_loss: -0.012877877103164792
        total_loss: 8.58986005783081
        vf_explained_var: 0.9813207387924194
        vf_loss: 8.60273802280426
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.714285714285715
    gpu_util_percent0: 0.08214285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.782142857142857
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15744042469839561
    mean_env_wait_ms: 1.6620273043560736
    mean_inference_ms: 4.67800356733732
    mean_raw_obs_processing_ms: 0.4161481277396671
  time_since_restore: 567.3511288166046
  time_this_iter_s: 24.48355984687805
  time_total_s: 567.3511288166046
  timers:
    learn_throughput: 9784.191
    learn_time_ms: 16536.063
    sample_throughput: 20573.74
    sample_time_ms: 7864.005
    update_time_ms: 43.578
  timestamp: 1602228240
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     23 |          567.351 | 3721216 |  249.933 |              299.121 |              110.798 |            825.577 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-24-25
  done: false
  episode_len_mean: 824.6549541684853
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 250.413480064724
  episode_reward_min: 110.79797979798
  episodes_this_iter: 158
  episodes_total: 4582
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.5258789062500003e-06
        cur_lr: 5.0e-05
        entropy: 0.861202847957611
        entropy_coeff: 0.0
        kl: 0.004780444619245827
        model: {}
        policy_loss: -0.01290580842178315
        total_loss: 8.991027688980102
        vf_explained_var: 0.9811282157897949
        vf_loss: 9.003933238983155
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.653571428571432
    gpu_util_percent0: 0.0007142857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.807142857142855
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15734128709592088
    mean_env_wait_ms: 1.6627920812548644
    mean_inference_ms: 4.672370066841132
    mean_raw_obs_processing_ms: 0.41579229815131885
  time_since_restore: 592.1025874614716
  time_this_iter_s: 24.751458644866943
  time_total_s: 592.1025874614716
  timers:
    learn_throughput: 9776.533
    learn_time_ms: 16549.016
    sample_throughput: 20537.982
    sample_time_ms: 7877.697
    update_time_ms: 43.512
  timestamp: 1602228265
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | RUNNING  | 172.17.0.4:48367 |     24 |          592.103 | 3883008 |  250.413 |              299.121 |              110.798 |            824.655 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0e966_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3087.0
  date: 2020-10-09_07-24-50
  done: true
  episode_len_mean: 823.0118633667416
  episode_reward_max: 299.1212121212118
  episode_reward_mean: 251.20142930635868
  episode_reward_min: 110.79797979798
  episodes_this_iter: 307
  episodes_total: 4889
  experiment_id: 6cbf7a057a934fb0a3582294fd1d319a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.629394531250001e-07
        cur_lr: 5.0e-05
        entropy: 0.8270130187273026
        entropy_coeff: 0.0
        kl: 0.004464933113195002
        model: {}
        policy_loss: -0.010773738974239676
        total_loss: 15.284658527374267
        vf_explained_var: 0.9783425331115723
        vf_loss: 15.29543228149414
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.050000000000004
    gpu_util_percent0: 0.0
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.825
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48367
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15715803150877047
    mean_env_wait_ms: 1.664251666631536
    mean_inference_ms: 4.662249119837573
    mean_raw_obs_processing_ms: 0.4151705664376715
  time_since_restore: 616.7583134174347
  time_this_iter_s: 24.655725955963135
  time_total_s: 616.7583134174347
  timers:
    learn_throughput: 9762.291
    learn_time_ms: 16573.158
    sample_throughput: 20562.263
    sample_time_ms: 7868.395
    update_time_ms: 41.669
  timestamp: 1602228290
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 0e966_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | TERMINATED |       |     25 |          616.758 | 4044800 |  251.201 |              299.121 |              110.798 |            823.012 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0e966_00000 | TERMINATED |       |     25 |          616.758 | 4044800 |  251.201 |              299.121 |              110.798 |            823.012 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


