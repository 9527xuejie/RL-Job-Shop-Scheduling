2020-10-12 01:17:01,769	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a2898_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=33214)[0m 2020-10-12 01:17:04,487	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=33153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33110)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_01-17-42
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1748726467291515
        entropy_coeff: 0.0001
        kl: 0.014984360507999858
        model: {}
        policy_loss: -0.012841334100812674
        total_loss: 502.23527272542316
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.471794871794874
    gpu_util_percent0: 0.398974358974359
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.576923076923076
    vram_util_percent0: 0.08867766649006405
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17280439345620968
    mean_env_wait_ms: 1.180237298690452
    mean_inference_ms: 6.092366553928131
    mean_raw_obs_processing_ms: 0.46567088625025466
  time_since_restore: 32.97260785102844
  time_this_iter_s: 32.97260785102844
  time_total_s: 32.97260785102844
  timers:
    learn_throughput: 6940.624
    learn_time_ms: 23310.871
    sample_throughput: 16973.976
    sample_time_ms: 9531.768
    update_time_ms: 92.346
  timestamp: 1602465462
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      1 |          32.9726 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3617.815972222222
    time_step_min: 3331
  date: 2020-10-12_01-18-14
  done: false
  episode_len_mean: 887.9367088607595
  episode_reward_max: 261.323232323232
  episode_reward_mean: 216.60660401483165
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.136822024981181
        entropy_coeff: 0.0001
        kl: 0.01715827500447631
        model: {}
        policy_loss: -0.012902510313627621
        total_loss: 124.1578820546468
        vf_explained_var: 0.8215093612670898
        vf_loss: 124.16918563842773
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.902777777777782
    gpu_util_percent0: 0.30972222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761111111111111
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16703598439208753
    mean_env_wait_ms: 1.1742109971324466
    mean_inference_ms: 5.745245095242495
    mean_raw_obs_processing_ms: 0.4487436141978659
  time_since_restore: 64.03854560852051
  time_this_iter_s: 31.065937757492065
  time_total_s: 64.03854560852051
  timers:
    learn_throughput: 6935.408
    learn_time_ms: 23328.403
    sample_throughput: 18856.113
    sample_time_ms: 8580.347
    update_time_ms: 67.232
  timestamp: 1602465494
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      2 |          64.0385 | 323584 |  216.607 |              261.323 |              144.202 |            887.937 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3613.784753363229
    time_step_min: 3320
  date: 2020-10-12_01-18-44
  done: false
  episode_len_mean: 881.0042194092827
  episode_reward_max: 262.9898989898987
  episode_reward_mean: 218.115841963943
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1223203937212627
        entropy_coeff: 0.0001
        kl: 0.018799157968411844
        model: {}
        policy_loss: -0.016793193179182708
        total_loss: 51.39241409301758
        vf_explained_var: 0.9113974571228027
        vf_loss: 51.407439867655434
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.483333333333334
    gpu_util_percent0: 0.37388888888888894
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16361782098501088
    mean_env_wait_ms: 1.1727799543980046
    mean_inference_ms: 5.519250313593537
    mean_raw_obs_processing_ms: 0.4379853498338707
  time_since_restore: 94.76569247245789
  time_this_iter_s: 30.727146863937378
  time_total_s: 94.76569247245789
  timers:
    learn_throughput: 6933.784
    learn_time_ms: 23333.868
    sample_throughput: 19831.86
    sample_time_ms: 8158.186
    update_time_ms: 51.228
  timestamp: 1602465524
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      3 |          94.7657 | 485376 |  218.116 |               262.99 |              144.202 |            881.004 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3604.427152317881
    time_step_min: 3320
  date: 2020-10-12_01-19-15
  done: false
  episode_len_mean: 873.0490506329114
  episode_reward_max: 262.9898989898987
  episode_reward_mean: 219.81695115714083
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0750902990500133
        entropy_coeff: 0.0001
        kl: 0.01878150102371971
        model: {}
        policy_loss: -0.017924356119086344
        total_loss: 36.24767621358236
        vf_explained_var: 0.9328387379646301
        vf_loss: 36.26382954915365
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.630555555555553
    gpu_util_percent0: 0.35611111111111104
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555563
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16128176617762832
    mean_env_wait_ms: 1.1732860893243198
    mean_inference_ms: 5.361311096660793
    mean_raw_obs_processing_ms: 0.4303900169603369
  time_since_restore: 125.57035517692566
  time_this_iter_s: 30.804662704467773
  time_total_s: 125.57035517692566
  timers:
    learn_throughput: 6921.794
    learn_time_ms: 23374.287
    sample_throughput: 20420.368
    sample_time_ms: 7923.07
    update_time_ms: 47.947
  timestamp: 1602465555
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      4 |           125.57 | 647168 |  219.817 |               262.99 |              144.202 |            873.049 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3583.159090909091
    time_step_min: 3229
  date: 2020-10-12_01-19-46
  done: false
  episode_len_mean: 863.2560975609756
  episode_reward_max: 278.2929292929289
  episode_reward_mean: 222.9198694259668
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 188
  episodes_total: 820
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0202479163805644
        entropy_coeff: 0.0001
        kl: 0.018400403981407482
        model: {}
        policy_loss: -0.01651181447474907
        total_loss: 31.818137168884277
        vf_explained_var: 0.9564892649650574
        vf_loss: 31.832910696665447
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.025000000000006
    gpu_util_percent0: 0.32833333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7638888888888897
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1593718817262854
    mean_env_wait_ms: 1.1765707097676537
    mean_inference_ms: 5.226894107438743
    mean_raw_obs_processing_ms: 0.42394162988989126
  time_since_restore: 156.27751088142395
  time_this_iter_s: 30.70715570449829
  time_total_s: 156.27751088142395
  timers:
    learn_throughput: 6924.579
    learn_time_ms: 23364.886
    sample_throughput: 20791.051
    sample_time_ms: 7781.81
    update_time_ms: 60.16
  timestamp: 1602465586
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      5 |          156.278 | 808960 |   222.92 |              278.293 |              144.202 |            863.256 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3556.359925788497
    time_step_min: 3151
  date: 2020-10-12_01-20-17
  done: false
  episode_len_mean: 852.4330922242315
  episode_reward_max: 288.5959595959595
  episode_reward_mean: 227.62987926279047
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 286
  episodes_total: 1106
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0240679879983265
        entropy_coeff: 0.0001
        kl: 0.017185148550197482
        model: {}
        policy_loss: -0.014114591894516101
        total_loss: 21.468740940093994
        vf_explained_var: 0.9657241702079773
        vf_loss: 21.481239795684814
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.054285714285715
    gpu_util_percent0: 0.37314285714285716
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573948794718402
    mean_env_wait_ms: 1.180626294620287
    mean_inference_ms: 5.090205823808286
    mean_raw_obs_processing_ms: 0.4174949573678648
  time_since_restore: 186.8310387134552
  time_this_iter_s: 30.55352783203125
  time_total_s: 186.8310387134552
  timers:
    learn_throughput: 6931.678
    learn_time_ms: 23340.956
    sample_throughput: 21025.481
    sample_time_ms: 7695.044
    update_time_ms: 53.697
  timestamp: 1602465617
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      6 |          186.831 | 970752 |   227.63 |              288.596 |              144.202 |            852.433 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3539.9967637540453
    time_step_min: 3151
  date: 2020-10-12_01-20-48
  done: false
  episode_len_mean: 848.7824367088608
  episode_reward_max: 288.5959595959595
  episode_reward_mean: 229.62468034778146
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9850030193726221
        entropy_coeff: 0.0001
        kl: 0.01691041871284445
        model: {}
        policy_loss: -0.01699635791495287
        total_loss: 16.763437747955322
        vf_explained_var: 0.9689126014709473
        vf_loss: 16.778841336568195
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.652777777777775
    gpu_util_percent0: 0.3361111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788888888888889
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15659992975965603
    mean_env_wait_ms: 1.1822187885313307
    mean_inference_ms: 5.0344704759852315
    mean_raw_obs_processing_ms: 0.41483327810958864
  time_since_restore: 217.54653692245483
  time_this_iter_s: 30.715498208999634
  time_total_s: 217.54653692245483
  timers:
    learn_throughput: 6923.747
    learn_time_ms: 23367.694
    sample_throughput: 21262.438
    sample_time_ms: 7609.287
    update_time_ms: 51.875
  timestamp: 1602465648
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      7 |          217.547 | 1132544 |  229.625 |              288.596 |              144.202 |            848.782 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3526.442611190818
    time_step_min: 3151
  date: 2020-10-12_01-21-18
  done: false
  episode_len_mean: 845.2665260196906
  episode_reward_max: 288.5959595959595
  episode_reward_mean: 231.6288198440096
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9404801925023397
        entropy_coeff: 0.0001
        kl: 0.01687920861877501
        model: {}
        policy_loss: -0.015691090763236087
        total_loss: 15.117162863413492
        vf_explained_var: 0.9690518379211426
        vf_loss: 15.131259759267172
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.616666666666664
    gpu_util_percent0: 0.3775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7888888888888896
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15592822936342657
    mean_env_wait_ms: 1.1836209348736244
    mean_inference_ms: 4.986578552029442
    mean_raw_obs_processing_ms: 0.41248042630766374
  time_since_restore: 248.09509801864624
  time_this_iter_s: 30.548561096191406
  time_total_s: 248.09509801864624
  timers:
    learn_throughput: 6920.835
    learn_time_ms: 23377.524
    sample_throughput: 21473.271
    sample_time_ms: 7534.577
    update_time_ms: 50.477
  timestamp: 1602465678
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      8 |          248.095 | 1294336 |  231.629 |              288.596 |              144.202 |            845.267 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3510.4248284466626
    time_step_min: 3151
  date: 2020-10-12_01-21-49
  done: false
  episode_len_mean: 841.8859595340282
  episode_reward_max: 288.5959595959595
  episode_reward_mean: 234.03043927936622
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 209
  episodes_total: 1631
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8966551373402277
        entropy_coeff: 0.0001
        kl: 0.014243030066912373
        model: {}
        policy_loss: -0.015340741180504361
        total_loss: 16.086894035339355
        vf_explained_var: 0.975477933883667
        vf_loss: 16.100900252660114
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.63888888888889
    gpu_util_percent0: 0.3727777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551739038804288
    mean_env_wait_ms: 1.185234473769692
    mean_inference_ms: 4.933261633771936
    mean_raw_obs_processing_ms: 0.4098073439333437
  time_since_restore: 278.9005649089813
  time_this_iter_s: 30.805466890335083
  time_total_s: 278.9005649089813
  timers:
    learn_throughput: 6915.267
    learn_time_ms: 23396.35
    sample_throughput: 21588.479
    sample_time_ms: 7494.368
    update_time_ms: 48.696
  timestamp: 1602465709
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |      9 |          278.901 | 1456128 |   234.03 |              288.596 |              144.202 |            841.886 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3492.928265524625
    time_step_min: 3151
  date: 2020-10-12_01-22-19
  done: false
  episode_len_mean: 838.0791139240506
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 236.8178941311852
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 265
  episodes_total: 1896
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.902370939652125
        entropy_coeff: 0.0001
        kl: 0.012971641806264719
        model: {}
        policy_loss: -0.01420637356932275
        total_loss: 14.944888671239218
        vf_explained_var: 0.9759809374809265
        vf_loss: 14.957888205846151
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.48857142857143
    gpu_util_percent0: 0.32485714285714284
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15441204298875935
    mean_env_wait_ms: 1.1871043041224436
    mean_inference_ms: 4.87828601352969
    mean_raw_obs_processing_ms: 0.4071621300277108
  time_since_restore: 309.2622129917145
  time_this_iter_s: 30.361648082733154
  time_total_s: 309.2622129917145
  timers:
    learn_throughput: 6914.81
    learn_time_ms: 23397.896
    sample_throughput: 21769.668
    sample_time_ms: 7431.992
    update_time_ms: 46.126
  timestamp: 1602465739
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     10 |          309.262 | 1617920 |  236.818 |              293.141 |              144.202 |            838.079 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3484.319842053307
    time_step_min: 3151
  date: 2020-10-12_01-22-50
  done: false
  episode_len_mean: 836.0326192794547
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 238.16745350289645
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8755829135576884
        entropy_coeff: 0.0001
        kl: 0.01378366087252895
        model: {}
        policy_loss: -0.014177696168189868
        total_loss: 12.160890738169352
        vf_explained_var: 0.9767784476280212
        vf_loss: 12.17377789815267
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.308333333333334
    gpu_util_percent0: 0.3288888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540248799838678
    mean_env_wait_ms: 1.1879856670504698
    mean_inference_ms: 4.850337433152704
    mean_raw_obs_processing_ms: 0.4057823535584076
  time_since_restore: 339.6035363674164
  time_this_iter_s: 30.341323375701904
  time_total_s: 339.6035363674164
  timers:
    learn_throughput: 6912.267
    learn_time_ms: 23406.502
    sample_throughput: 22578.316
    sample_time_ms: 7165.813
    update_time_ms: 38.77
  timestamp: 1602465770
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     11 |          339.604 | 1779712 |  238.167 |              293.141 |              144.202 |            836.033 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3476.6565934065934
    time_step_min: 3151
  date: 2020-10-12_01-23-21
  done: false
  episode_len_mean: 834.3010849909584
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 239.23113138619456
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8411885350942612
        entropy_coeff: 0.0001
        kl: 0.011767114590232572
        model: {}
        policy_loss: -0.013000590765538314
        total_loss: 12.302385648091635
        vf_explained_var: 0.9761373400688171
        vf_loss: 12.31429386138916
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.63142857142857
    gpu_util_percent0: 0.3474285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857144
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15367201902439495
    mean_env_wait_ms: 1.188785004198987
    mean_inference_ms: 4.824838238366847
    mean_raw_obs_processing_ms: 0.40450607186857657
  time_since_restore: 370.2225749492645
  time_this_iter_s: 30.619038581848145
  time_total_s: 370.2225749492645
  timers:
    learn_throughput: 6912.168
    learn_time_ms: 23406.837
    sample_throughput: 22720.659
    sample_time_ms: 7120.92
    update_time_ms: 38.228
  timestamp: 1602465801
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     12 |          370.223 | 1941504 |  239.231 |              293.141 |              144.202 |            834.301 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3463.4942386831276
    time_step_min: 3140
  date: 2020-10-12_01-23-51
  done: false
  episode_len_mean: 831.7127746135069
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 241.0744466635434
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 246
  episodes_total: 2458
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7920639216899872
        entropy_coeff: 0.0001
        kl: 0.01213868559959034
        model: {}
        policy_loss: -0.013442033300331483
        total_loss: 14.49018128712972
        vf_explained_var: 0.9792584776878357
        vf_loss: 14.502488772074381
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.605555555555558
    gpu_util_percent0: 0.31611111111111106
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15319192658926487
    mean_env_wait_ms: 1.1899624100443307
    mean_inference_ms: 4.789792908314652
    mean_raw_obs_processing_ms: 0.40276274672434303
  time_since_restore: 400.59848737716675
  time_this_iter_s: 30.37591242790222
  time_total_s: 400.59848737716675
  timers:
    learn_throughput: 6913.862
    learn_time_ms: 23401.105
    sample_throughput: 22818.514
    sample_time_ms: 7090.383
    update_time_ms: 38.735
  timestamp: 1602465831
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     13 |          400.598 | 2103296 |  241.074 |              293.141 |              144.202 |            831.713 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3454.7053067369216
    time_step_min: 3140
  date: 2020-10-12_01-24-21
  done: false
  episode_len_mean: 829.5180633147114
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 242.3964787540206
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 227
  episodes_total: 2685
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7907427052656809
        entropy_coeff: 0.0001
        kl: 0.011492713664968809
        model: {}
        policy_loss: -0.014609491108179403
        total_loss: 11.160450379053751
        vf_explained_var: 0.9812641143798828
        vf_loss: 11.173989534378052
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.56857142857143
    gpu_util_percent0: 0.33371428571428574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15280084842049332
    mean_env_wait_ms: 1.1909560794391547
    mean_inference_ms: 4.761700477979083
    mean_raw_obs_processing_ms: 0.4013850737154691
  time_since_restore: 430.8080036640167
  time_this_iter_s: 30.209516286849976
  time_total_s: 430.8080036640167
  timers:
    learn_throughput: 6925.27
    learn_time_ms: 23362.555
    sample_throughput: 22885.513
    sample_time_ms: 7069.625
    update_time_ms: 38.617
  timestamp: 1602465861
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     14 |          430.808 | 2265088 |  242.396 |              293.141 |              144.202 |            829.518 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3448.732599431818
    time_step_min: 3140
  date: 2020-10-12_01-24-51
  done: false
  episode_len_mean: 828.2630098452884
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 243.3823786387077
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7721695005893707
        entropy_coeff: 0.0001
        kl: 0.012290968326851726
        model: {}
        policy_loss: -0.013933065405581146
        total_loss: 8.474902391433716
        vf_explained_var: 0.9825029969215393
        vf_loss: 8.487683455149332
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.914285714285715
    gpu_util_percent0: 0.39314285714285707
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857144
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15255946278887905
    mean_env_wait_ms: 1.1915667214047891
    mean_inference_ms: 4.744052522452856
    mean_raw_obs_processing_ms: 0.40051762082840253
  time_since_restore: 460.7197630405426
  time_this_iter_s: 29.91175937652588
  time_total_s: 460.7197630405426
  timers:
    learn_throughput: 6935.935
    learn_time_ms: 23326.631
    sample_throughput: 23004.606
    sample_time_ms: 7033.026
    update_time_ms: 31.19
  timestamp: 1602465891
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     15 |           460.72 | 2426880 |  243.382 |              293.141 |              144.202 |            828.263 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3442.872611464968
    time_step_min: 3140
  date: 2020-10-12_01-25-22
  done: false
  episode_len_mean: 827.0162736632348
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 244.22813656324112
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 167
  episodes_total: 3011
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7404458671808243
        entropy_coeff: 0.0001
        kl: 0.012412261916324496
        model: {}
        policy_loss: -0.015297051325129965
        total_loss: 9.845894654591879
        vf_explained_var: 0.9812369346618652
        vf_loss: 9.860024213790894
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.4
    gpu_util_percent0: 0.34138888888888885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15232578337007877
    mean_env_wait_ms: 1.192199782033134
    mean_inference_ms: 4.726653974570713
    mean_raw_obs_processing_ms: 0.3996673495723884
  time_since_restore: 490.9017560482025
  time_this_iter_s: 30.181993007659912
  time_total_s: 490.9017560482025
  timers:
    learn_throughput: 6942.679
    learn_time_ms: 23303.972
    sample_throughput: 23080.52
    sample_time_ms: 7009.894
    update_time_ms: 31.036
  timestamp: 1602465922
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     16 |          490.902 | 2588672 |  244.228 |              293.141 |              144.202 |            827.016 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3435.6458333333335
    time_step_min: 3140
  date: 2020-10-12_01-25-52
  done: false
  episode_len_mean: 825.28219927096
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 245.41855983897293
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 281
  episodes_total: 3292
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7087905208269755
        entropy_coeff: 0.0001
        kl: 0.012811542022973299
        model: {}
        policy_loss: -0.015185093526573231
        total_loss: 10.511377334594727
        vf_explained_var: 0.9850895404815674
        vf_loss: 10.525351921717325
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.68285714285714
    gpu_util_percent0: 0.3554285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15196949624282152
    mean_env_wait_ms: 1.193166741306726
    mean_inference_ms: 4.700741156196993
    mean_raw_obs_processing_ms: 0.3983845531981242
  time_since_restore: 521.1199328899384
  time_this_iter_s: 30.21817684173584
  time_total_s: 521.1199328899384
  timers:
    learn_throughput: 6950.581
    learn_time_ms: 23277.477
    sample_throughput: 23156.013
    sample_time_ms: 6987.04
    update_time_ms: 30.037
  timestamp: 1602465952
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     17 |           521.12 | 2750464 |  245.419 |              293.141 |              144.202 |            825.282 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3430.5959976798144
    time_step_min: 3140
  date: 2020-10-12_01-26-22
  done: false
  episode_len_mean: 824.4439010356732
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 246.083318803687
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 184
  episodes_total: 3476
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7002004683017731
        entropy_coeff: 0.0001
        kl: 0.012862827628850937
        model: {}
        policy_loss: -0.013023698372611156
        total_loss: 8.694582064946493
        vf_explained_var: 0.9840855598449707
        vf_loss: 8.706389586130777
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.62857142857143
    gpu_util_percent0: 0.31371428571428567
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15177211101267238
    mean_env_wait_ms: 1.1937907341436729
    mean_inference_ms: 4.685652798549411
    mean_raw_obs_processing_ms: 0.3976597940318463
  time_since_restore: 551.119952917099
  time_this_iter_s: 30.000020027160645
  time_total_s: 551.119952917099
  timers:
    learn_throughput: 6966.704
    learn_time_ms: 23223.606
    sample_throughput: 23156.694
    sample_time_ms: 6986.835
    update_time_ms: 27.735
  timestamp: 1602465982
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     18 |           551.12 | 2912256 |  246.083 |              293.141 |              144.202 |            824.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3426.844703272324
    time_step_min: 3140
  date: 2020-10-12_01-26-53
  done: false
  episode_len_mean: 823.227022564667
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 246.58481902125266
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.695816899339358
        entropy_coeff: 0.0001
        kl: 0.012375916043917337
        model: {}
        policy_loss: -0.014022341221182918
        total_loss: 7.837115565935771
        vf_explained_var: 0.9839866161346436
        vf_loss: 7.849969824155171
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.60285714285714
    gpu_util_percent0: 0.3468571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142856
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516088375745882
    mean_env_wait_ms: 1.1942676527283071
    mean_inference_ms: 4.673515419076087
    mean_raw_obs_processing_ms: 0.39705808470565396
  time_since_restore: 581.2517700195312
  time_this_iter_s: 30.13181710243225
  time_total_s: 581.2517700195312
  timers:
    learn_throughput: 6982.888
    learn_time_ms: 23169.783
    sample_throughput: 23199.95
    sample_time_ms: 6973.808
    update_time_ms: 26.116
  timestamp: 1602466013
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | RUNNING  | 172.17.0.4:33214 |     19 |          581.252 | 3074048 |  246.585 |              293.141 |              144.202 |            823.227 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a2898_00000:
  custom_metrics:
    time_step_max: 4087
    time_step_mean: 3422.8166316894017
    time_step_min: 3140
  date: 2020-10-12_01-27-23
  done: true
  episode_len_mean: 821.8424479166666
  episode_reward_max: 293.1414141414143
  episode_reward_mean: 247.22794349747474
  episode_reward_min: 144.20202020201964
  episodes_this_iter: 206
  episodes_total: 3840
  experiment_id: ff0426aa3316415eaf7ba5a692b33726
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6503153592348099
        entropy_coeff: 0.0001
        kl: 0.011712003809710344
        model: {}
        policy_loss: -0.012204822429490983
        total_loss: 9.729616641998291
        vf_explained_var: 0.9841166138648987
        vf_loss: 9.740715662638346
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.56
    gpu_util_percent0: 0.35314285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33214
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15140731836591212
    mean_env_wait_ms: 1.1948832707254509
    mean_inference_ms: 4.658808880091501
    mean_raw_obs_processing_ms: 0.3963175037149756
  time_since_restore: 611.5053663253784
  time_this_iter_s: 30.253596305847168
  time_total_s: 611.5053663253784
  timers:
    learn_throughput: 6992.232
    learn_time_ms: 23138.822
    sample_throughput: 23134.353
    sample_time_ms: 6993.582
    update_time_ms: 25.636
  timestamp: 1602466043
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: a2898_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | TERMINATED |       |     20 |          611.505 | 3235840 |  247.228 |              293.141 |              144.202 |            821.842 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a2898_00000 | TERMINATED |       |     20 |          611.505 | 3235840 |  247.228 |              293.141 |              144.202 |            821.842 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


