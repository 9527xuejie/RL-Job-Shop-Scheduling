2020-10-12 14:28:52,149	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_40f0d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=15186)[0m 2020-10-12 14:28:54,852	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=15192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15194)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3616.3166666666666
    time_step_min: 3355
  date: 2020-10-12_14-29-28
  done: false
  episode_len_mean: 904.8481012658228
  episode_reward_max: 246.595959595959
  episode_reward_mean: 201.8721391126452
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.169209361076355
        entropy_coeff: 0.0005000000000000001
        kl: 0.004283593191454808
        model: {}
        policy_loss: -0.00855300908733625
        total_loss: 369.24242401123047
        vf_explained_var: 0.588043749332428
        vf_loss: 369.2507044474284
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.80294117647058
    gpu_util_percent0: 0.3552941176470588
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5529411764705885
    vram_util_percent0: 0.08474813342851081
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17031341321897495
    mean_env_wait_ms: 1.1861932553712067
    mean_inference_ms: 5.864637548005592
    mean_raw_obs_processing_ms: 0.45909487343600014
  time_since_restore: 27.977336883544922
  time_this_iter_s: 27.977336883544922
  time_total_s: 27.977336883544922
  timers:
    learn_throughput: 8657.463
    learn_time_ms: 18688.154
    sample_throughput: 17578.013
    sample_time_ms: 9204.226
    update_time_ms: 48.626
  timestamp: 1602512968
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      1 |          27.9773 | 161792 |  201.872 |              246.596 |              106.747 |            904.848 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4331
    time_step_mean: 3626.0323741007196
    time_step_min: 3254
  date: 2020-10-12_14-29-54
  done: false
  episode_len_mean: 904.6550632911392
  episode_reward_max: 257.35353535353516
  episode_reward_mean: 199.26425648893976
  episode_reward_min: 94.17171717171675
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1384726762771606
        entropy_coeff: 0.0005000000000000001
        kl: 0.007555847250235577
        model: {}
        policy_loss: -0.009366699125772962
        total_loss: 89.9572073618571
        vf_explained_var: 0.8351356983184814
        vf_loss: 89.96638933817546
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.815625
    gpu_util_percent0: 0.316875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7531250000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16651014364905137
    mean_env_wait_ms: 1.1833695055526812
    mean_inference_ms: 5.6591177095207
    mean_raw_obs_processing_ms: 0.451227145822387
  time_since_restore: 54.179380655288696
  time_this_iter_s: 26.202043771743774
  time_total_s: 54.179380655288696
  timers:
    learn_throughput: 8772.076
    learn_time_ms: 18443.982
    sample_throughput: 18892.793
    sample_time_ms: 8563.689
    update_time_ms: 40.419
  timestamp: 1602512994
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      2 |          54.1794 | 323584 |  199.264 |              257.354 |              94.1717 |            904.655 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4331
    time_step_mean: 3633.0733944954127
    time_step_min: 3254
  date: 2020-10-12_14-30-20
  done: false
  episode_len_mean: 899.1413502109705
  episode_reward_max: 257.35353535353516
  episode_reward_mean: 199.64480245492877
  episode_reward_min: 94.17171717171675
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.123505175113678
        entropy_coeff: 0.0005000000000000001
        kl: 0.00928467131840686
        model: {}
        policy_loss: -0.012755329177404443
        total_loss: 44.79078483581543
        vf_explained_var: 0.9124049544334412
        vf_loss: 44.803174336751304
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.954838709677425
    gpu_util_percent0: 0.29709677419354835
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16349364096032282
    mean_env_wait_ms: 1.1825086193667256
    mean_inference_ms: 5.468179823729243
    mean_raw_obs_processing_ms: 0.44248277330479036
  time_since_restore: 79.76840448379517
  time_this_iter_s: 25.58902382850647
  time_total_s: 79.76840448379517
  timers:
    learn_throughput: 8770.128
    learn_time_ms: 18448.078
    sample_throughput: 20076.879
    sample_time_ms: 8058.623
    update_time_ms: 38.863
  timestamp: 1602513020
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      3 |          79.7684 | 485376 |  199.645 |              257.354 |              94.1717 |            899.141 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3626.841750841751
    time_step_min: 3254
  date: 2020-10-12_14-30-45
  done: false
  episode_len_mean: 894.5094936708861
  episode_reward_max: 257.35353535353516
  episode_reward_mean: 200.8474939266076
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1135420103867848
        entropy_coeff: 0.0005000000000000001
        kl: 0.008282240596599877
        model: {}
        policy_loss: -0.011898660280470116
        total_loss: 39.95386600494385
        vf_explained_var: 0.9208271503448486
        vf_loss: 39.96549320220947
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.622580645161293
    gpu_util_percent0: 0.38709677419354843
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16129845841169024
    mean_env_wait_ms: 1.182704300372627
    mean_inference_ms: 5.322835308888667
    mean_raw_obs_processing_ms: 0.4351930196282956
  time_since_restore: 105.127845287323
  time_this_iter_s: 25.359440803527832
  time_total_s: 105.127845287323
  timers:
    learn_throughput: 8774.783
    learn_time_ms: 18438.292
    sample_throughput: 20855.522
    sample_time_ms: 7757.754
    update_time_ms: 40.738
  timestamp: 1602513045
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      4 |          105.128 | 647168 |  200.847 |              257.354 |              74.7778 |            894.509 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3616.928191489362
    time_step_min: 3254
  date: 2020-10-12_14-31-11
  done: false
  episode_len_mean: 890.3
  episode_reward_max: 257.35353535353516
  episode_reward_mean: 202.15541490857922
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0863073368867238
        entropy_coeff: 0.0005000000000000001
        kl: 0.00802083076753964
        model: {}
        policy_loss: -0.010518901399336755
        total_loss: 31.891902287801106
        vf_explained_var: 0.937171459197998
        vf_loss: 31.902161121368408
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.519354838709674
    gpu_util_percent0: 0.4335483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15963040047883406
    mean_env_wait_ms: 1.1832794593882914
    mean_inference_ms: 5.210720058858853
    mean_raw_obs_processing_ms: 0.4293402675067856
  time_since_restore: 130.72516560554504
  time_this_iter_s: 25.597320318222046
  time_total_s: 130.72516560554504
  timers:
    learn_throughput: 8773.407
    learn_time_ms: 18441.182
    sample_throughput: 21237.007
    sample_time_ms: 7618.399
    update_time_ms: 40.198
  timestamp: 1602513071
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      5 |          130.725 | 808960 |  202.155 |              257.354 |              74.7778 |              890.3 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3608.4322033898306
    time_step_min: 3244
  date: 2020-10-12_14-31-36
  done: false
  episode_len_mean: 885.3126272912424
  episode_reward_max: 258.8686868686869
  episode_reward_mean: 203.83381678290004
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 192
  episodes_total: 982
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0417972803115845
        entropy_coeff: 0.0005000000000000001
        kl: 0.00803802243899554
        model: {}
        policy_loss: -0.011555042661105594
        total_loss: 29.145253658294678
        vf_explained_var: 0.9571675658226013
        vf_loss: 29.156526406606037
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.293333333333333
    gpu_util_percent0: 0.3783333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7533333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15805764488718776
    mean_env_wait_ms: 1.1844852076902292
    mean_inference_ms: 5.106448264340254
    mean_raw_obs_processing_ms: 0.4237371169028984
  time_since_restore: 156.11558294296265
  time_this_iter_s: 25.390417337417603
  time_total_s: 156.11558294296265
  timers:
    learn_throughput: 8784.945
    learn_time_ms: 18416.962
    sample_throughput: 21519.114
    sample_time_ms: 7518.525
    update_time_ms: 37.048
  timestamp: 1602513096
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      6 |          156.116 | 970752 |  203.834 |              258.869 |              74.7778 |            885.313 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3593.012234910277
    time_step_min: 3212
  date: 2020-10-12_14-32-01
  done: false
  episode_len_mean: 879.5348101265823
  episode_reward_max: 263.7171717171712
  episode_reward_mean: 206.26859576780438
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 282
  episodes_total: 1264
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.052981048822403
        entropy_coeff: 0.0005000000000000001
        kl: 0.00756885576993227
        model: {}
        policy_loss: -0.013547717448091134
        total_loss: 24.316144307454426
        vf_explained_var: 0.9633116722106934
        vf_loss: 24.329460938771565
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.235483870967744
    gpu_util_percent0: 0.35064516129032264
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564791595224078
    mean_env_wait_ms: 1.1859950145943021
    mean_inference_ms: 4.9962569760348625
    mean_raw_obs_processing_ms: 0.41800912582489935
  time_since_restore: 181.35727906227112
  time_this_iter_s: 25.24169611930847
  time_total_s: 181.35727906227112
  timers:
    learn_throughput: 8788.306
    learn_time_ms: 18409.919
    sample_throughput: 21815.635
    sample_time_ms: 7416.332
    update_time_ms: 35.01
  timestamp: 1602513121
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      7 |          181.357 | 1132544 |  206.269 |              263.717 |              74.7778 |            879.535 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3584.440751445087
    time_step_min: 3212
  date: 2020-10-12_14-32-27
  done: false
  episode_len_mean: 875.0407876230661
  episode_reward_max: 263.7171717171712
  episode_reward_mean: 207.88383838383817
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.025655210018158
        entropy_coeff: 0.0005000000000000001
        kl: 0.007761195845281084
        model: {}
        policy_loss: -0.012660732085350901
        total_loss: 18.453331629435223
        vf_explained_var: 0.9655329585075378
        vf_loss: 18.465729077657063
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.493548387096773
    gpu_util_percent0: 0.3825806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15579220636819247
    mean_env_wait_ms: 1.1868179058496457
    mean_inference_ms: 4.94864390498379
    mean_raw_obs_processing_ms: 0.4154746772057917
  time_since_restore: 206.93996357917786
  time_this_iter_s: 25.58268451690674
  time_total_s: 206.93996357917786
  timers:
    learn_throughput: 8775.038
    learn_time_ms: 18437.755
    sample_throughput: 22020.717
    sample_time_ms: 7347.263
    update_time_ms: 35.241
  timestamp: 1602513147
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      8 |           206.94 | 1294336 |  207.884 |              263.717 |              74.7778 |            875.041 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3574.6420233463036
    time_step_min: 3212
  date: 2020-10-12_14-32-53
  done: false
  episode_len_mean: 870.4873417721519
  episode_reward_max: 267.20202020201987
  episode_reward_mean: 209.55290244214274
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0090048958857853
        entropy_coeff: 0.0005000000000000001
        kl: 0.007344354099283616
        model: {}
        policy_loss: -0.011860693940737596
        total_loss: 18.446773687998455
        vf_explained_var: 0.963460385799408
        vf_loss: 18.458404541015625
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.545161290322586
    gpu_util_percent0: 0.3583870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15519573912157342
    mean_env_wait_ms: 1.1877829537241915
    mean_inference_ms: 4.906975364860664
    mean_raw_obs_processing_ms: 0.4132074080185321
  time_since_restore: 232.32007455825806
  time_this_iter_s: 25.3801109790802
  time_total_s: 232.32007455825806
  timers:
    learn_throughput: 8780.469
    learn_time_ms: 18426.351
    sample_throughput: 22174.147
    sample_time_ms: 7296.425
    update_time_ms: 36.471
  timestamp: 1602513173
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |      9 |           232.32 | 1456128 |  209.553 |              267.202 |              74.7778 |            870.487 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3564.078730904818
    time_step_min: 3179
  date: 2020-10-12_14-33-18
  done: false
  episode_len_mean: 866.4586206896552
  episode_reward_max: 268.71717171717165
  episode_reward_mean: 211.2001044932078
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 160
  episodes_total: 1740
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9668994247913361
        entropy_coeff: 0.0005000000000000001
        kl: 0.007379486147935192
        model: {}
        policy_loss: -0.011729328679696968
        total_loss: 17.816092491149902
        vf_explained_var: 0.9671626687049866
        vf_loss: 17.82756741841634
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.309999999999995
    gpu_util_percent0: 0.382
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15466570010463013
    mean_env_wait_ms: 1.188835228568871
    mean_inference_ms: 4.869955382236245
    mean_raw_obs_processing_ms: 0.41115332129627663
  time_since_restore: 257.74751353263855
  time_this_iter_s: 25.427438974380493
  time_total_s: 257.74751353263855
  timers:
    learn_throughput: 8781.733
    learn_time_ms: 18423.699
    sample_throughput: 22284.22
    sample_time_ms: 7260.384
    update_time_ms: 36.745
  timestamp: 1602513198
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     10 |          257.748 | 1617920 |    211.2 |              268.717 |              74.7778 |            866.459 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3544.0879284649777
    time_step_min: 3179
  date: 2020-10-12_14-33-44
  done: false
  episode_len_mean: 859.2252559726962
  episode_reward_max: 274.02020202020196
  episode_reward_mean: 214.2406414215286
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 311
  episodes_total: 2051
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9493600130081177
        entropy_coeff: 0.0005000000000000001
        kl: 0.006886738818138838
        model: {}
        policy_loss: -0.010961758438497782
        total_loss: 22.52125628789266
        vf_explained_var: 0.9688637852668762
        vf_loss: 22.53200387954712
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.70645161290323
    gpu_util_percent0: 0.3632258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538092541441087
    mean_env_wait_ms: 1.190954562220891
    mean_inference_ms: 4.810519892540785
    mean_raw_obs_processing_ms: 0.407882372001208
  time_since_restore: 283.0604531764984
  time_this_iter_s: 25.312939643859863
  time_total_s: 283.0604531764984
  timers:
    learn_throughput: 8799.727
    learn_time_ms: 18386.025
    sample_throughput: 23007.566
    sample_time_ms: 7032.121
    update_time_ms: 34.371
  timestamp: 1602513224
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     11 |           283.06 | 1779712 |  214.241 |               274.02 |              74.7778 |            859.225 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3534.241030358786
    time_step_min: 3150
  date: 2020-10-12_14-34-09
  done: false
  episode_len_mean: 856.0664556962025
  episode_reward_max: 274.02020202020196
  episode_reward_mean: 215.7192677224321
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 161
  episodes_total: 2212
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9360186457633972
        entropy_coeff: 0.0005000000000000001
        kl: 0.006805013477181395
        model: {}
        policy_loss: -0.011606539716012776
        total_loss: 14.837892452875773
        vf_explained_var: 0.9714512228965759
        vf_loss: 14.849286794662476
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.38709677419355
    gpu_util_percent0: 0.3622580645161289
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15344611784759626
    mean_env_wait_ms: 1.191901012428983
    mean_inference_ms: 4.784887191819064
    mean_raw_obs_processing_ms: 0.40648609889466975
  time_since_restore: 308.48743057250977
  time_this_iter_s: 25.426977396011353
  time_total_s: 308.48743057250977
  timers:
    learn_throughput: 8791.442
    learn_time_ms: 18403.352
    sample_throughput: 23329.615
    sample_time_ms: 6935.048
    update_time_ms: 35.64
  timestamp: 1602513249
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     12 |          308.487 | 1941504 |  215.719 |               274.02 |              74.7778 |            856.066 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3524.1796740994855
    time_step_min: 3150
  date: 2020-10-12_14-34-35
  done: false
  episode_len_mean: 854.0987341772152
  episode_reward_max: 274.02020202020196
  episode_reward_mean: 217.11411584196375
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.917464887102445
        entropy_coeff: 0.0005000000000000001
        kl: 0.007187117318001886
        model: {}
        policy_loss: -0.01065789075801149
        total_loss: 11.536466916402182
        vf_explained_var: 0.9758577346801758
        vf_loss: 11.5468643506368
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.166666666666668
    gpu_util_percent0: 0.3630000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15311974655741706
    mean_env_wait_ms: 1.1927496175668943
    mean_inference_ms: 4.762052341367081
    mean_raw_obs_processing_ms: 0.4052212821104409
  time_since_restore: 333.90312361717224
  time_this_iter_s: 25.415693044662476
  time_total_s: 333.90312361717224
  timers:
    learn_throughput: 8792.854
    learn_time_ms: 18400.397
    sample_throughput: 23381.315
    sample_time_ms: 6919.713
    update_time_ms: 35.847
  timestamp: 1602513275
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     13 |          333.903 | 2103296 |  217.114 |               274.02 |              74.7778 |            854.099 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3515.129614767255
    time_step_min: 3137
  date: 2020-10-12_14-35-00
  done: false
  episode_len_mean: 851.9537549407114
  episode_reward_max: 275.08080808080814
  episode_reward_mean: 218.34401325508028
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 160
  episodes_total: 2530
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8839244097471237
        entropy_coeff: 0.0005000000000000001
        kl: 0.006774009283011158
        model: {}
        policy_loss: -0.011904717515183924
        total_loss: 13.830247561136881
        vf_explained_var: 0.9751328825950623
        vf_loss: 13.84191664059957
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.687096774193545
    gpu_util_percent0: 0.3783870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15281636616358452
    mean_env_wait_ms: 1.1935941479702468
    mean_inference_ms: 4.7409879893684765
    mean_raw_obs_processing_ms: 0.40403913876361713
  time_since_restore: 359.2359104156494
  time_this_iter_s: 25.332786798477173
  time_total_s: 359.2359104156494
  timers:
    learn_throughput: 8799.94
    learn_time_ms: 18385.581
    sample_throughput: 23340.137
    sample_time_ms: 6931.922
    update_time_ms: 35.005
  timestamp: 1602513300
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     14 |          359.236 | 2265088 |  218.344 |              275.081 |              74.7778 |            851.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3500.4163090128754
    time_step_min: 3137
  date: 2020-10-12_14-35-26
  done: false
  episode_len_mean: 847.9442484121383
  episode_reward_max: 275.08080808080814
  episode_reward_mean: 220.51883335828273
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 304
  episodes_total: 2834
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8736105312903722
        entropy_coeff: 0.0005000000000000001
        kl: 0.0062687892544393735
        model: {}
        policy_loss: -0.010797865291048462
        total_loss: 14.933183749516806
        vf_explained_var: 0.9792088866233826
        vf_loss: 14.943791627883911
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.20645161290323
    gpu_util_percent0: 0.33387096774193553
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15230871159368473
    mean_env_wait_ms: 1.1951405488214726
    mean_inference_ms: 4.705862265788898
    mean_raw_obs_processing_ms: 0.40208650144718316
  time_since_restore: 384.7372827529907
  time_this_iter_s: 25.50137233734131
  time_total_s: 384.7372827529907
  timers:
    learn_throughput: 8798.815
    learn_time_ms: 18387.93
    sample_throughput: 23384.43
    sample_time_ms: 6918.792
    update_time_ms: 34.849
  timestamp: 1602513326
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     15 |          384.737 | 2426880 |  220.519 |              275.081 |              74.7778 |            847.944 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3493.861673414305
    time_step_min: 3137
  date: 2020-10-12_14-35-51
  done: false
  episode_len_mean: 846.0689540306462
  episode_reward_max: 275.08080808080814
  episode_reward_mean: 221.5660805254408
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 168
  episodes_total: 3002
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8535224894682566
        entropy_coeff: 0.0005000000000000001
        kl: 0.006619990609275798
        model: {}
        policy_loss: -0.010143043616532546
        total_loss: 11.625003178914389
        vf_explained_var: 0.9782131314277649
        vf_loss: 11.634911298751831
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.35161290322581
    gpu_util_percent0: 0.35935483870967744
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520694166371878
    mean_env_wait_ms: 1.1958705516069568
    mean_inference_ms: 4.688927216397983
    mean_raw_obs_processing_ms: 0.401171702368993
  time_since_restore: 410.12982869148254
  time_this_iter_s: 25.39254593849182
  time_total_s: 410.12982869148254
  timers:
    learn_throughput: 8791.9
    learn_time_ms: 18402.393
    sample_throughput: 23462.264
    sample_time_ms: 6895.839
    update_time_ms: 36.162
  timestamp: 1602513351
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     16 |           410.13 | 2588672 |  221.566 |              275.081 |              74.7778 |            846.069 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3487.5397181294043
    time_step_min: 3137
  date: 2020-10-12_14-36-17
  done: false
  episode_len_mean: 844.1161392405063
  episode_reward_max: 275.08080808080814
  episode_reward_mean: 222.54211417977223
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8495060205459595
        entropy_coeff: 0.0005000000000000001
        kl: 0.006349431467242539
        model: {}
        policy_loss: -0.012107226405836021
        total_loss: 10.89086365699768
        vf_explained_var: 0.9773384928703308
        vf_loss: 10.902761061986288
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.173333333333332
    gpu_util_percent0: 0.35233333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15185661774284875
    mean_env_wait_ms: 1.1965568417810744
    mean_inference_ms: 4.674132306173612
    mean_raw_obs_processing_ms: 0.4003437303243064
  time_since_restore: 435.59550070762634
  time_this_iter_s: 25.4656720161438
  time_total_s: 435.59550070762634
  timers:
    learn_throughput: 8789.219
    learn_time_ms: 18408.006
    sample_throughput: 23420.541
    sample_time_ms: 6908.124
    update_time_ms: 37.752
  timestamp: 1602513377
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     17 |          435.596 | 2750464 |  222.542 |              275.081 |              74.7778 |            844.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3480.486388384755
    time_step_min: 3137
  date: 2020-10-12_14-36-42
  done: false
  episode_len_mean: 841.9829545454545
  episode_reward_max: 277.35353535353516
  episode_reward_mean: 223.7197543617997
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 184
  episodes_total: 3344
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8174087206522623
        entropy_coeff: 0.0005000000000000001
        kl: 0.007216097398971518
        model: {}
        policy_loss: -0.011498963499131301
        total_loss: 13.150360743204752
        vf_explained_var: 0.9775157570838928
        vf_loss: 13.16154670715332
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.67741935483871
    gpu_util_percent0: 0.327741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15163190693595288
    mean_env_wait_ms: 1.1974064501674722
    mean_inference_ms: 4.658487479520832
    mean_raw_obs_processing_ms: 0.39946410300406743
  time_since_restore: 460.81631445884705
  time_this_iter_s: 25.220813751220703
  time_total_s: 460.81631445884705
  timers:
    learn_throughput: 8802.596
    learn_time_ms: 18380.032
    sample_throughput: 23456.339
    sample_time_ms: 6897.581
    update_time_ms: 38.771
  timestamp: 1602513402
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     18 |          460.816 | 2912256 |   223.72 |              277.354 |              74.7778 |            841.983 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3468.8776077885955
    time_step_min: 3121
  date: 2020-10-12_14-37-08
  done: false
  episode_len_mean: 839.2174511423067
  episode_reward_max: 277.5050505050504
  episode_reward_mean: 225.50545087539297
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 289
  episodes_total: 3633
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8106405337651571
        entropy_coeff: 0.0005000000000000001
        kl: 0.005711381828101973
        model: {}
        policy_loss: -0.009296051983255893
        total_loss: 12.59952704111735
        vf_explained_var: 0.9803258776664734
        vf_loss: 12.608657042185465
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.512903225806458
    gpu_util_percent0: 0.39483870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130053112880512
    mean_env_wait_ms: 1.198495852470083
    mean_inference_ms: 4.635596644951426
    mean_raw_obs_processing_ms: 0.39818056592464823
  time_since_restore: 486.33569145202637
  time_this_iter_s: 25.51937699317932
  time_total_s: 486.33569145202637
  timers:
    learn_throughput: 8790.103
    learn_time_ms: 18406.154
    sample_throughput: 23480.554
    sample_time_ms: 6890.468
    update_time_ms: 38.655
  timestamp: 1602513428
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     19 |          486.336 | 3074048 |  225.505 |              277.505 |              74.7778 |            839.217 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3462.9064997336177
    time_step_min: 3121
  date: 2020-10-12_14-37-33
  done: false
  episode_len_mean: 837.8349156118144
  episode_reward_max: 278.565656565657
  episode_reward_mean: 226.38830552359022
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 159
  episodes_total: 3792
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8071876466274261
        entropy_coeff: 0.0005000000000000001
        kl: 0.0058333837271978455
        model: {}
        policy_loss: -0.01144625450069725
        total_loss: 8.772553523381552
        vf_explained_var: 0.9817249774932861
        vf_loss: 8.783819993336996
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.946666666666665
    gpu_util_percent0: 0.30199999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15113869158732718
    mean_env_wait_ms: 1.1990602357490687
    mean_inference_ms: 4.62438764905373
    mean_raw_obs_processing_ms: 0.3975498122149247
  time_since_restore: 511.6045913696289
  time_this_iter_s: 25.26889991760254
  time_total_s: 511.6045913696289
  timers:
    learn_throughput: 8792.173
    learn_time_ms: 18401.821
    sample_throughput: 23522.922
    sample_time_ms: 6878.057
    update_time_ms: 38.537
  timestamp: 1602513453
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     20 |          511.605 | 3235840 |  226.388 |              278.566 |              74.7778 |            837.835 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3456.5080500894455
    time_step_min: 3121
  date: 2020-10-12_14-37-59
  done: false
  episode_len_mean: 836.770437863832
  episode_reward_max: 278.565656565657
  episode_reward_mean: 227.26982045205267
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 159
  episodes_total: 3951
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7912125339110693
        entropy_coeff: 0.0005000000000000001
        kl: 0.006185428200600048
        model: {}
        policy_loss: -0.010615241718672527
        total_loss: 9.660934766133627
        vf_explained_var: 0.9788644313812256
        vf_loss: 9.671326955159506
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.90967741935484
    gpu_util_percent0: 0.3596774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509858215637263
    mean_env_wait_ms: 1.1996104954264382
    mean_inference_ms: 4.613807923450466
    mean_raw_obs_processing_ms: 0.39695043130106183
  time_since_restore: 536.9804892539978
  time_this_iter_s: 25.375897884368896
  time_total_s: 536.9804892539978
  timers:
    learn_throughput: 8782.025
    learn_time_ms: 18423.085
    sample_throughput: 23583.648
    sample_time_ms: 6860.347
    update_time_ms: 40.411
  timestamp: 1602513479
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     21 |           536.98 | 3397632 |   227.27 |              278.566 |              74.7778 |             836.77 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3447.855593056895
    time_step_min: 3114
  date: 2020-10-12_14-38-24
  done: false
  episode_len_mean: 835.048972766364
  episode_reward_max: 279.6262626262625
  episode_reward_mean: 228.53481783916556
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 235
  episodes_total: 4186
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.759943018356959
        entropy_coeff: 0.0005000000000000001
        kl: 0.006279778007107477
        model: {}
        policy_loss: -0.010360730404499918
        total_loss: 12.314131418863932
        vf_explained_var: 0.9803383946418762
        vf_loss: 12.324244101842245
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.306451612903224
    gpu_util_percent0: 0.3596774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15077305957697276
    mean_env_wait_ms: 1.2004371049659013
    mean_inference_ms: 4.599358299842693
    mean_raw_obs_processing_ms: 0.396130886915351
  time_since_restore: 562.5779259204865
  time_this_iter_s: 25.597436666488647
  time_total_s: 562.5779259204865
  timers:
    learn_throughput: 8767.369
    learn_time_ms: 18453.882
    sample_throughput: 23626.62
    sample_time_ms: 6847.869
    update_time_ms: 38.096
  timestamp: 1602513504
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     22 |          562.578 | 3559424 |  228.535 |              279.626 |              74.7778 |            835.049 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3440.1703534777653
    time_step_min: 3114
  date: 2020-10-12_14-38-50
  done: false
  episode_len_mean: 833.3927198733891
  episode_reward_max: 279.6262626262625
  episode_reward_mean: 229.59495246381965
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 237
  episodes_total: 4423
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7440361777941386
        entropy_coeff: 0.0005000000000000001
        kl: 0.005954018871610363
        model: {}
        policy_loss: -0.011595885191733638
        total_loss: 9.518235127131144
        vf_explained_var: 0.9834404587745667
        vf_loss: 9.52960737546285
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.916666666666668
    gpu_util_percent0: 0.3936666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15058286170316518
    mean_env_wait_ms: 1.2011267371746173
    mean_inference_ms: 4.585816322540044
    mean_raw_obs_processing_ms: 0.3953819686450838
  time_since_restore: 587.8663332462311
  time_this_iter_s: 25.28840732574463
  time_total_s: 587.8663332462311
  timers:
    learn_throughput: 8768.613
    learn_time_ms: 18451.265
    sample_throughput: 23664.28
    sample_time_ms: 6836.971
    update_time_ms: 38.005
  timestamp: 1602513530
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | RUNNING  | 172.17.0.4:15186 |     23 |          587.866 | 3721216 |  229.595 |              279.626 |              74.7778 |            833.393 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_40f0d_00000:
  custom_metrics:
    time_step_max: 4459
    time_step_mean: 3435.027068661972
    time_step_min: 3114
  date: 2020-10-12_14-39-15
  done: true
  episode_len_mean: 832.1865997381057
  episode_reward_max: 279.6262626262625
  episode_reward_mean: 230.303748969397
  episode_reward_min: 74.77777777777752
  episodes_this_iter: 159
  episodes_total: 4582
  experiment_id: d1d68d2ed69a4d5791cf27d4e03499fc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7401020477215449
        entropy_coeff: 0.0005000000000000001
        kl: 0.006353482875662546
        model: {}
        policy_loss: -0.009180035073465357
        total_loss: 8.316651423772177
        vf_explained_var: 0.9818807244300842
        vf_loss: 8.325566053390503
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.561290322580643
    gpu_util_percent0: 0.3419354838709678
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15186
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15046283769521293
    mean_env_wait_ms: 1.2015966537767815
    mean_inference_ms: 4.577441376529022
    mean_raw_obs_processing_ms: 0.39491303722290977
  time_since_restore: 613.0704839229584
  time_this_iter_s: 25.204150676727295
  time_total_s: 613.0704839229584
  timers:
    learn_throughput: 8764.241
    learn_time_ms: 18460.469
    sample_throughput: 23739.604
    sample_time_ms: 6815.278
    update_time_ms: 36.594
  timestamp: 1602513555
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 40f0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | TERMINATED |       |     24 |           613.07 | 3883008 |  230.304 |              279.626 |              74.7778 |            832.187 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_40f0d_00000 | TERMINATED |       |     24 |           613.07 | 3883008 |  230.304 |              279.626 |              74.7778 |            832.187 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


