2020-10-12 12:30:12,909	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ad858_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=57679)[0m 2020-10-12 12:30:15,608	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=57592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57632)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57632)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57654)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_12-30-49
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1823383669058483
        entropy_coeff: 0.0005000000000000001
        kl: 0.006917016425480445
        model: {}
        policy_loss: -0.009157503198366612
        total_loss: 507.07493591308594
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.593939393939394
    gpu_util_percent0: 0.28818181818181815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.563636363636364
    vram_util_percent0: 0.08736346740610434
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16890503735261111
    mean_env_wait_ms: 1.1702247577230296
    mean_inference_ms: 5.661956237105169
    mean_raw_obs_processing_ms: 0.4499529408392769
  time_since_restore: 28.237815141677856
  time_this_iter_s: 28.237815141677856
  time_total_s: 28.237815141677856
  timers:
    learn_throughput: 8559.016
    learn_time_ms: 18903.107
    sample_throughput: 17589.407
    sample_time_ms: 9198.263
    update_time_ms: 98.214
  timestamp: 1602505849
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      1 |          28.2378 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3614.2256944444443
    time_step_min: 3379
  date: 2020-10-12_12-31-15
  done: false
  episode_len_mean: 892.4873417721519
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 217.54734049354283
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.149937113126119
        entropy_coeff: 0.0005000000000000001
        kl: 0.007523950111741821
        model: {}
        policy_loss: -0.00998671705989788
        total_loss: 126.33550771077473
        vf_explained_var: 0.8110877871513367
        vf_loss: 126.34455998738606
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.38709677419354
    gpu_util_percent0: 0.33709677419354844
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.751612903225806
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16522538421298727
    mean_env_wait_ms: 1.166785318106883
    mean_inference_ms: 5.478239392992289
    mean_raw_obs_processing_ms: 0.44201243673943585
  time_since_restore: 54.568071365356445
  time_this_iter_s: 26.33025622367859
  time_total_s: 54.568071365356445
  timers:
    learn_throughput: 8650.173
    learn_time_ms: 18703.904
    sample_throughput: 19174.478
    sample_time_ms: 8437.883
    update_time_ms: 65.669
  timestamp: 1602505875
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      2 |          54.5681 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3605.479820627803
    time_step_min: 3310
  date: 2020-10-12_12-31-41
  done: false
  episode_len_mean: 888.5801687763714
  episode_reward_max: 264.50505050505006
  episode_reward_mean: 219.20585602864062
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1411352157592773
        entropy_coeff: 0.0005000000000000001
        kl: 0.010440803055341044
        model: {}
        policy_loss: -0.013970387983135879
        total_loss: 54.93683338165283
        vf_explained_var: 0.8966913819313049
        vf_loss: 54.94928582509359
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.876666666666665
    gpu_util_percent0: 0.3706666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16260294589169655
    mean_env_wait_ms: 1.1663843852803522
    mean_inference_ms: 5.317580712460233
    mean_raw_obs_processing_ms: 0.4346313705797556
  time_since_restore: 80.45094752311707
  time_this_iter_s: 25.88287615776062
  time_total_s: 80.45094752311707
  timers:
    learn_throughput: 8664.155
    learn_time_ms: 18673.719
    sample_throughput: 20162.774
    sample_time_ms: 8024.293
    update_time_ms: 51.182
  timestamp: 1602505901
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      3 |          80.4509 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3591.1639072847684
    time_step_min: 3227
  date: 2020-10-12_12-32-07
  done: false
  episode_len_mean: 885.4873417721519
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 221.420326684567
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1191200812657673
        entropy_coeff: 0.0005000000000000001
        kl: 0.011468215147033334
        model: {}
        policy_loss: -0.013862663588952273
        total_loss: 39.326786041259766
        vf_explained_var: 0.9241357445716858
        vf_loss: 39.33891359965006
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.43333333333333
    gpu_util_percent0: 0.37566666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1607462757833792
    mean_env_wait_ms: 1.1666065594299164
    mean_inference_ms: 5.19759320615125
    mean_raw_obs_processing_ms: 0.42884899221182987
  time_since_restore: 106.41191577911377
  time_this_iter_s: 25.960968255996704
  time_total_s: 106.41191577911377
  timers:
    learn_throughput: 8645.902
    learn_time_ms: 18713.143
    sample_throughput: 20794.811
    sample_time_ms: 7780.403
    update_time_ms: 46.964
  timestamp: 1602505927
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      4 |          106.412 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3577.469816272966
    time_step_min: 3227
  date: 2020-10-12_12-32-33
  done: false
  episode_len_mean: 882.6164556962025
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 223.37348165196246
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0904998779296875
        entropy_coeff: 0.0005000000000000001
        kl: 0.010465693194419146
        model: {}
        policy_loss: -0.013936646308138734
        total_loss: 29.070746898651123
        vf_explained_var: 0.9454066157341003
        vf_loss: 29.0831356048584
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.55333333333333
    gpu_util_percent0: 0.4026666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15932651553390745
    mean_env_wait_ms: 1.167247236922676
    mean_inference_ms: 5.105156955761531
    mean_raw_obs_processing_ms: 0.4241619853874412
  time_since_restore: 132.39279627799988
  time_this_iter_s: 25.98088049888611
  time_total_s: 132.39279627799988
  timers:
    learn_throughput: 8644.99
    learn_time_ms: 18715.117
    sample_throughput: 21124.511
    sample_time_ms: 7658.97
    update_time_ms: 44.841
  timestamp: 1602505953
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      5 |          132.393 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3562.2380487804876
    time_step_min: 3215
  date: 2020-10-12_12-32-59
  done: false
  episode_len_mean: 875.4055080721747
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 225.90998302109395
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 263
  episodes_total: 1053
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0669801433881123
        entropy_coeff: 0.0005000000000000001
        kl: 0.010119187956055006
        model: {}
        policy_loss: -0.014624884177464992
        total_loss: 30.67037757237752
        vf_explained_var: 0.9617660641670227
        vf_loss: 30.683512210845947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.896774193548392
    gpu_util_percent0: 0.4380645161290322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15758373732759218
    mean_env_wait_ms: 1.1697938862862185
    mean_inference_ms: 4.993265760954177
    mean_raw_obs_processing_ms: 0.41869440795286283
  time_since_restore: 158.20772171020508
  time_this_iter_s: 25.8149254322052
  time_total_s: 158.20772171020508
  timers:
    learn_throughput: 8650.438
    learn_time_ms: 18703.33
    sample_throughput: 21428.196
    sample_time_ms: 7550.426
    update_time_ms: 54.438
  timestamp: 1602505979
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      6 |          158.208 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3547.7540453074434
    time_step_min: 3215
  date: 2020-10-12_12-33-25
  done: false
  episode_len_mean: 868.5514240506329
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 228.15807601329732
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 211
  episodes_total: 1264
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0668786863485973
        entropy_coeff: 0.0005000000000000001
        kl: 0.012256689059237639
        model: {}
        policy_loss: -0.01610318278350557
        total_loss: 20.370780150095623
        vf_explained_var: 0.963979959487915
        vf_loss: 20.384966214497883
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.853333333333335
    gpu_util_percent0: 0.34933333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15657329873395373
    mean_env_wait_ms: 1.1718041449096683
    mean_inference_ms: 4.928618743314384
    mean_raw_obs_processing_ms: 0.4154075703104024
  time_since_restore: 184.31369256973267
  time_this_iter_s: 26.105970859527588
  time_total_s: 184.31369256973267
  timers:
    learn_throughput: 8635.087
    learn_time_ms: 18736.58
    sample_throughput: 21626.365
    sample_time_ms: 7481.239
    update_time_ms: 52.288
  timestamp: 1602506005
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      7 |          184.314 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3536.647776183644
    time_step_min: 3215
  date: 2020-10-12_12-33-51
  done: false
  episode_len_mean: 862.704641350211
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 229.98016025231198
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0334690809249878
        entropy_coeff: 0.0005000000000000001
        kl: 0.010793289790550867
        model: {}
        policy_loss: -0.015747709141578525
        total_loss: 15.715624650319418
        vf_explained_var: 0.969296395778656
        vf_loss: 15.729730685551962
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.253333333333334
    gpu_util_percent0: 0.391
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1559479711492542
    mean_env_wait_ms: 1.1733561902991976
    mean_inference_ms: 4.888176842818723
    mean_raw_obs_processing_ms: 0.4133021243199457
  time_since_restore: 210.29469919204712
  time_this_iter_s: 25.981006622314453
  time_total_s: 210.29469919204712
  timers:
    learn_throughput: 8632.364
    learn_time_ms: 18742.491
    sample_throughput: 21765.348
    sample_time_ms: 7433.467
    update_time_ms: 49.493
  timestamp: 1602506031
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      8 |          210.295 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3525.568943298969
    time_step_min: 3215
  date: 2020-10-12_12-34-17
  done: false
  episode_len_mean: 857.1208860759493
  episode_reward_max: 279.3535353535359
  episode_reward_mean: 231.70662319396482
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0033017992973328
        entropy_coeff: 0.0005000000000000001
        kl: 0.010770521514738599
        model: {}
        policy_loss: -0.015525121105990062
        total_loss: 16.273523728052776
        vf_explained_var: 0.9674468040466309
        vf_loss: 16.28739635149638
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.610000000000003
    gpu_util_percent0: 0.27566666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15539724462957527
    mean_env_wait_ms: 1.175024142163589
    mean_inference_ms: 4.852607294414321
    mean_raw_obs_processing_ms: 0.41139122673210116
  time_since_restore: 236.31488513946533
  time_this_iter_s: 26.020185947418213
  time_total_s: 236.31488513946533
  timers:
    learn_throughput: 8625.483
    learn_time_ms: 18757.443
    sample_throughput: 21885.114
    sample_time_ms: 7392.787
    update_time_ms: 46.251
  timestamp: 1602506057
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      9 |          236.315 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3504.7218934911243
    time_step_min: 3186
  date: 2020-10-12_12-34-43
  done: false
  episode_len_mean: 847.3826179120297
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 234.9192882722293
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 307
  episodes_total: 1887
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9698180854320526
        entropy_coeff: 0.0005000000000000001
        kl: 0.008762541770314177
        model: {}
        policy_loss: -0.011754670903125467
        total_loss: 22.15676514307658
        vf_explained_var: 0.9699413776397705
        vf_loss: 22.167253017425537
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.686666666666667
    gpu_util_percent0: 0.25466666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15453766769147795
    mean_env_wait_ms: 1.1787124191264264
    mean_inference_ms: 4.796413184950241
    mean_raw_obs_processing_ms: 0.40843775652716663
  time_since_restore: 262.18814992904663
  time_this_iter_s: 25.8732647895813
  time_total_s: 262.18814992904663
  timers:
    learn_throughput: 8627.415
    learn_time_ms: 18753.242
    sample_throughput: 21977.845
    sample_time_ms: 7361.595
    update_time_ms: 44.093
  timestamp: 1602506083
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     10 |          262.188 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3494.990128331688
    time_step_min: 3159
  date: 2020-10-12_12-35-09
  done: false
  episode_len_mean: 842.626582278481
  episode_reward_max: 287.38383838383817
  episode_reward_mean: 236.53693212553955
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.959399938583374
        entropy_coeff: 0.0005000000000000001
        kl: 0.009050344349816442
        model: {}
        policy_loss: -0.014448691198291877
        total_loss: 14.143741130828857
        vf_explained_var: 0.9704552292823792
        vf_loss: 14.156859795252482
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.470000000000006
    gpu_util_percent0: 0.31033333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541531067576189
    mean_env_wait_ms: 1.180539782661793
    mean_inference_ms: 4.7710904173214255
    mean_raw_obs_processing_ms: 0.40708730490687545
  time_since_restore: 288.0478582382202
  time_this_iter_s: 25.859708309173584
  time_total_s: 288.0478582382202
  timers:
    learn_throughput: 8633.513
    learn_time_ms: 18739.996
    sample_throughput: 22654.324
    sample_time_ms: 7141.771
    update_time_ms: 37.934
  timestamp: 1602506109
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     11 |          288.048 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3486.236721611722
    time_step_min: 3147
  date: 2020-10-12_12-35-35
  done: false
  episode_len_mean: 839.50226039783
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 237.80845069136197
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9463174144426981
        entropy_coeff: 0.0005000000000000001
        kl: 0.009074758971109986
        model: {}
        policy_loss: -0.014368217787705362
        total_loss: 10.841783205668131
        vf_explained_var: 0.9763579368591309
        vf_loss: 10.854809761047363
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.709999999999997
    gpu_util_percent0: 0.304
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15382456786108878
    mean_env_wait_ms: 1.1821934851322788
    mean_inference_ms: 4.749452794942857
    mean_raw_obs_processing_ms: 0.40591959145529394
  time_since_restore: 314.2713918685913
  time_this_iter_s: 26.223533630371094
  time_total_s: 314.2713918685913
  timers:
    learn_throughput: 8608.293
    learn_time_ms: 18794.898
    sample_throughput: 22846.513
    sample_time_ms: 7081.693
    update_time_ms: 38.592
  timestamp: 1602506135
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     12 |          314.271 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3477.1867900715188
    time_step_min: 3147
  date: 2020-10-12_12-36-01
  done: false
  episode_len_mean: 836.276923076923
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 239.12358512358495
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 193
  episodes_total: 2405
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9069925745328268
        entropy_coeff: 0.0005000000000000001
        kl: 0.009530291194096208
        model: {}
        policy_loss: -0.014515867456793785
        total_loss: 15.319237470626831
        vf_explained_var: 0.9747470021247864
        vf_loss: 15.332300901412964
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.57333333333333
    gpu_util_percent0: 0.26733333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15346836889333854
    mean_env_wait_ms: 1.184240944593027
    mean_inference_ms: 4.725537933532759
    mean_raw_obs_processing_ms: 0.40463245423111577
  time_since_restore: 340.12329864501953
  time_this_iter_s: 25.851906776428223
  time_total_s: 340.12329864501953
  timers:
    learn_throughput: 8602.467
    learn_time_ms: 18807.627
    sample_throughput: 22905.641
    sample_time_ms: 7063.413
    update_time_ms: 40.411
  timestamp: 1602506161
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     13 |          340.123 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3465.9672686230247
    time_step_min: 3147
  date: 2020-10-12_12-36-27
  done: false
  episode_len_mean: 832.3082650781831
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 240.80178553968565
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 281
  episodes_total: 2686
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9011691262324651
        entropy_coeff: 0.0005000000000000001
        kl: 0.010886709050585827
        model: {}
        policy_loss: -0.01605825025762897
        total_loss: 13.799258867899576
        vf_explained_var: 0.9779562950134277
        vf_loss: 13.813590288162231
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.203333333333333
    gpu_util_percent0: 0.39166666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15301494054162276
    mean_env_wait_ms: 1.1868015832357257
    mean_inference_ms: 4.695915855449172
    mean_raw_obs_processing_ms: 0.4030395525153571
  time_since_restore: 365.95724272727966
  time_this_iter_s: 25.833944082260132
  time_total_s: 365.95724272727966
  timers:
    learn_throughput: 8610.589
    learn_time_ms: 18789.887
    sample_throughput: 22889.673
    sample_time_ms: 7068.34
    update_time_ms: 39.225
  timestamp: 1602506187
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     14 |          365.957 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3459.754971590909
    time_step_min: 3147
  date: 2020-10-12_12-36-53
  done: false
  episode_len_mean: 830.3291139240506
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 241.694508374888
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8705271085103353
        entropy_coeff: 0.0005000000000000001
        kl: 0.010132285223032037
        model: {}
        policy_loss: -0.01209646585630253
        total_loss: 9.354986588160196
        vf_explained_var: 0.9806396961212158
        vf_loss: 9.36549154917399
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.339999999999996
    gpu_util_percent0: 0.354
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15279157288304182
    mean_env_wait_ms: 1.188104613473158
    mean_inference_ms: 4.681133757261421
    mean_raw_obs_processing_ms: 0.4022444482464537
  time_since_restore: 391.6302752494812
  time_this_iter_s: 25.673032522201538
  time_total_s: 391.6302752494812
  timers:
    learn_throughput: 8614.25
    learn_time_ms: 18781.902
    sample_throughput: 22961.178
    sample_time_ms: 7046.328
    update_time_ms: 37.541
  timestamp: 1602506213
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     15 |           391.63 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3454.032279757902
    time_step_min: 3147
  date: 2020-10-12_12-37-19
  done: false
  episode_len_mean: 828.5073284477015
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 242.50461645098542
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8471738596757253
        entropy_coeff: 0.0005000000000000001
        kl: 0.009305963292717934
        model: {}
        policy_loss: -0.01094130908313673
        total_loss: 10.646601835886637
        vf_explained_var: 0.9784726500511169
        vf_loss: 10.656105756759644
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.168965517241375
    gpu_util_percent0: 0.37931034482758613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15258489228875483
    mean_env_wait_ms: 1.189348100743969
    mean_inference_ms: 4.667388374821382
    mean_raw_obs_processing_ms: 0.4014845687165312
  time_since_restore: 417.28298902511597
  time_this_iter_s: 25.652713775634766
  time_total_s: 417.28298902511597
  timers:
    learn_throughput: 8611.392
    learn_time_ms: 18788.135
    sample_throughput: 23005.777
    sample_time_ms: 7032.669
    update_time_ms: 29.153
  timestamp: 1602506239
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     16 |          417.283 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3446.2361408882084
    time_step_min: 3147
  date: 2020-10-12_12-37-45
  done: false
  episode_len_mean: 825.9881566960219
  episode_reward_max: 289.9595959595964
  episode_reward_mean: 243.72948433622582
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 291
  episodes_total: 3293
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8250234176715215
        entropy_coeff: 0.0005000000000000001
        kl: 0.008491925351942578
        model: {}
        policy_loss: -0.014777651784243062
        total_loss: 15.209494908650717
        vf_explained_var: 0.9786728024482727
        vf_loss: 15.222986777623495
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.81666666666667
    gpu_util_percent0: 0.405
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15225128410563682
    mean_env_wait_ms: 1.191534804694793
    mean_inference_ms: 4.644749359521727
    mean_raw_obs_processing_ms: 0.4002669504773126
  time_since_restore: 442.85631251335144
  time_this_iter_s: 25.573323488235474
  time_total_s: 442.85631251335144
  timers:
    learn_throughput: 8621.52
    learn_time_ms: 18766.065
    sample_throughput: 23099.783
    sample_time_ms: 7004.049
    update_time_ms: 27.27
  timestamp: 1602506265
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     17 |          442.856 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3440.9040023201856
    time_step_min: 3098
  date: 2020-10-12_12-38-10
  done: false
  episode_len_mean: 824.563003452244
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 244.5732671943833
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 183
  episodes_total: 3476
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8241499215364456
        entropy_coeff: 0.0005000000000000001
        kl: 0.007864817045629025
        model: {}
        policy_loss: -0.01140341673938868
        total_loss: 8.79675587018331
        vf_explained_var: 0.9828992486000061
        vf_loss: 8.806998491287231
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.268965517241377
    gpu_util_percent0: 0.32137931034482753
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152057784099256
    mean_env_wait_ms: 1.1927444276404982
    mean_inference_ms: 4.631954197589499
    mean_raw_obs_processing_ms: 0.3995722632347076
  time_since_restore: 468.4573698043823
  time_this_iter_s: 25.601057291030884
  time_total_s: 468.4573698043823
  timers:
    learn_throughput: 8625.27
    learn_time_ms: 18757.906
    sample_throughput: 23193.06
    sample_time_ms: 6975.88
    update_time_ms: 26.475
  timestamp: 1602506290
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     18 |          468.457 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3436.840266222962
    time_step_min: 3098
  date: 2020-10-12_12-38-36
  done: false
  episode_len_mean: 823.8428728673638
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.09397497262097
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8113949745893478
        entropy_coeff: 0.0005000000000000001
        kl: 0.008743428780386845
        model: {}
        policy_loss: -0.012751462903300611
        total_loss: 8.8964794476827
        vf_explained_var: 0.9816879630088806
        vf_loss: 8.907887935638428
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.160000000000004
    gpu_util_percent0: 0.31700000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15190300447660146
    mean_env_wait_ms: 1.1937104261191516
    mean_inference_ms: 4.621606530580184
    mean_raw_obs_processing_ms: 0.3990076443002664
  time_since_restore: 494.1212737560272
  time_this_iter_s: 25.663903951644897
  time_total_s: 494.1212737560272
  timers:
    learn_throughput: 8633.094
    learn_time_ms: 18740.905
    sample_throughput: 23256.792
    sample_time_ms: 6956.763
    update_time_ms: 26.349
  timestamp: 1602506316
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     19 |          494.121 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3432.525217850541
    time_step_min: 3098
  date: 2020-10-12_12-39-02
  done: false
  episode_len_mean: 823.0579292267365
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.79004990931585
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 181
  episodes_total: 3815
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7609985868136088
        entropy_coeff: 0.0005000000000000001
        kl: 0.00916624628007412
        model: {}
        policy_loss: -0.012107667707217237
        total_loss: 10.657151778539022
        vf_explained_var: 0.9814252257347107
        vf_loss: 10.66780686378479
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.175862068965515
    gpu_util_percent0: 0.36344827586206896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76551724137931
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15173262102728452
    mean_env_wait_ms: 1.194739519238314
    mean_inference_ms: 4.6104790880218705
    mean_raw_obs_processing_ms: 0.3983916300855253
  time_since_restore: 519.5943777561188
  time_this_iter_s: 25.473104000091553
  time_total_s: 519.5943777561188
  timers:
    learn_throughput: 8634.98
    learn_time_ms: 18736.812
    sample_throughput: 23382.066
    sample_time_ms: 6919.491
    update_time_ms: 26.922
  timestamp: 1602506342
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     20 |          519.594 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3425.473593711619
    time_step_min: 3098
  date: 2020-10-12_12-39-28
  done: false
  episode_len_mean: 821.8972920224445
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 246.80025184758034
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 284
  episodes_total: 4099
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7578712403774261
        entropy_coeff: 0.0005000000000000001
        kl: 0.0086368964985013
        model: {}
        policy_loss: -0.011422600480727851
        total_loss: 10.725571791330973
        vf_explained_var: 0.9839944839477539
        vf_loss: 10.735645691553751
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.413333333333338
    gpu_util_percent0: 0.36233333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15149336115425896
    mean_env_wait_ms: 1.196135945498552
    mean_inference_ms: 4.5943737192150405
    mean_raw_obs_processing_ms: 0.39750761177887367
  time_since_restore: 545.1678259372711
  time_this_iter_s: 25.573448181152344
  time_total_s: 545.1678259372711
  timers:
    learn_throughput: 8638.164
    learn_time_ms: 18729.907
    sample_throughput: 23454.768
    sample_time_ms: 6898.043
    update_time_ms: 25.122
  timestamp: 1602506368
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     21 |          545.168 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3421.670599339311
    time_step_min: 3098
  date: 2020-10-12_12-39-54
  done: false
  episode_len_mean: 821.5065635255509
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.35105627299706
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 4266
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7521579414606094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007824398732433716
        model: {}
        policy_loss: -0.01322558480508936
        total_loss: 7.959930698076884
        vf_explained_var: 0.9843184947967529
        vf_loss: 7.971967538197835
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.103333333333335
    gpu_util_percent0: 0.3143333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15135817854915368
    mean_env_wait_ms: 1.1968631050270366
    mean_inference_ms: 4.58570350856658
    mean_raw_obs_processing_ms: 0.3970226544952488
  time_since_restore: 570.9309539794922
  time_this_iter_s: 25.76312804222107
  time_total_s: 570.9309539794922
  timers:
    learn_throughput: 8645.196
    learn_time_ms: 18714.67
    sample_throughput: 23563.448
    sample_time_ms: 6866.228
    update_time_ms: 24.993
  timestamp: 1602506394
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     22 |          570.931 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3418.63762511374
    time_step_min: 3098
  date: 2020-10-12_12-40-20
  done: false
  episode_len_mean: 821.0913200723327
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.84626098233684
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.739922359585762
        entropy_coeff: 0.0005000000000000001
        kl: 0.008788479414458076
        model: {}
        policy_loss: -0.013709326779159406
        total_loss: 7.252472162246704
        vf_explained_var: 0.9847645163536072
        vf_loss: 7.264793713887532
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.030000000000005
    gpu_util_percent0: 0.41166666666666674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15123807745980236
    mean_env_wait_ms: 1.1974930413341178
    mean_inference_ms: 4.577881618246516
    mean_raw_obs_processing_ms: 0.3965811523986444
  time_since_restore: 596.7764484882355
  time_this_iter_s: 25.845494508743286
  time_total_s: 596.7764484882355
  timers:
    learn_throughput: 8638.437
    learn_time_ms: 18729.313
    sample_throughput: 23647.317
    sample_time_ms: 6841.875
    update_time_ms: 25.27
  timestamp: 1602506420
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     23 |          596.776 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ad858_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3414.4957691473205
    time_step_min: 3098
  date: 2020-10-12_12-40-45
  done: true
  episode_len_mean: 820.656243260729
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 248.46065137029112
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 213
  episodes_total: 4637
  experiment_id: d2d95ffef53c4f8ba545f23c7d900134
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7039715051651001
        entropy_coeff: 0.0005000000000000001
        kl: 0.007829503583100935
        model: {}
        policy_loss: -0.010663946062171211
        total_loss: 8.341045339902243
        vf_explained_var: 0.9864241480827332
        vf_loss: 8.350495417912802
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.83448275862069
    gpu_util_percent0: 0.3296551724137931
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7655172413793094
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57679
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510830566654544
    mean_env_wait_ms: 1.1982758128961588
    mean_inference_ms: 4.567927674219303
    mean_raw_obs_processing_ms: 0.3960149133084128
  time_since_restore: 622.3432440757751
  time_this_iter_s: 25.566795587539673
  time_total_s: 622.3432440757751
  timers:
    learn_throughput: 8634.993
    learn_time_ms: 18736.783
    sample_throughput: 23768.17
    sample_time_ms: 6807.087
    update_time_ms: 25.138
  timestamp: 1602506445
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: ad858_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | TERMINATED |       |     24 |          622.343 | 3883008 |  248.461 |              296.626 |              133.899 |            820.656 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ad858_00000 | TERMINATED |       |     24 |          622.343 | 3883008 |  248.461 |              296.626 |              133.899 |            820.656 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


