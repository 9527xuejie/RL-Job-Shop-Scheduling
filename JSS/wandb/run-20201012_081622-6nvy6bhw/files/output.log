2020-10-12 08:16:26,316	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_39cc5_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=24878)[0m 2020-10-12 08:16:29,112	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=24825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24755)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_08-16-58
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.185864080985387
        entropy_coeff: 0.0005000000000000001
        kl: 0.004079875051199148
        model: {}
        policy_loss: -0.006393474138045955
        total_loss: 514.7339019775391
        vf_explained_var: 0.4917435944080353
        vf_loss: 514.7400767008463
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.08275862068966
    gpu_util_percent0: 0.2706896551724137
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.53448275862069
    vram_util_percent0: 0.08293561484262792
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16959718290248305
    mean_env_wait_ms: 1.1668397527154708
    mean_inference_ms: 5.6675725838548425
    mean_raw_obs_processing_ms: 0.45125070049572086
  time_since_restore: 24.041186809539795
  time_this_iter_s: 24.041186809539795
  time_total_s: 24.041186809539795
  timers:
    learn_throughput: 10872.209
    learn_time_ms: 14881.244
    sample_throughput: 17812.94
    sample_time_ms: 9082.835
    update_time_ms: 47.25
  timestamp: 1602490618
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      1 |          24.0412 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3621.2881944444443
    time_step_min: 3263
  date: 2020-10-12_08-17-21
  done: false
  episode_len_mean: 890.0727848101266
  episode_reward_max: 271.62626262626253
  episode_reward_mean: 217.58521928142156
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1563906073570251
        entropy_coeff: 0.0005000000000000001
        kl: 0.007153310541373988
        model: {}
        policy_loss: -0.006601389720647906
        total_loss: 148.90216318766275
        vf_explained_var: 0.7816783785820007
        vf_loss: 148.90863291422525
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.835714285714285
    gpu_util_percent0: 0.29464285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7428571428571424
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16544807941264583
    mean_env_wait_ms: 1.165790257442274
    mean_inference_ms: 5.466143985210929
    mean_raw_obs_processing_ms: 0.43924275373531213
  time_since_restore: 46.73395586013794
  time_this_iter_s: 22.692769050598145
  time_total_s: 46.73395586013794
  timers:
    learn_throughput: 10915.082
    learn_time_ms: 14822.793
    sample_throughput: 19177.544
    sample_time_ms: 8436.534
    update_time_ms: 68.763
  timestamp: 1602490641
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      2 |           46.734 | 323584 |  217.585 |              271.626 |              145.717 |            890.073 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3617.560538116592
    time_step_min: 3263
  date: 2020-10-12_08-17-43
  done: false
  episode_len_mean: 884.5611814345991
  episode_reward_max: 271.62626262626253
  episode_reward_mean: 217.97167881345075
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.147742599248886
        entropy_coeff: 0.0005000000000000001
        kl: 0.007976852473802865
        model: {}
        policy_loss: -0.010943490701417128
        total_loss: 72.53540929158528
        vf_explained_var: 0.8764762282371521
        vf_loss: 72.54612922668457
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.673076923076923
    gpu_util_percent0: 0.32769230769230767
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7653846153846158
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16269042725297467
    mean_env_wait_ms: 1.1667953562932982
    mean_inference_ms: 5.300973246000417
    mean_raw_obs_processing_ms: 0.4303547572544862
  time_since_restore: 68.67958068847656
  time_this_iter_s: 21.945624828338623
  time_total_s: 68.67958068847656
  timers:
    learn_throughput: 10942.549
    learn_time_ms: 14785.586
    sample_throughput: 20197.389
    sample_time_ms: 8010.54
    update_time_ms: 55.862
  timestamp: 1602490663
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      3 |          68.6796 | 485376 |  217.972 |              271.626 |              118.596 |            884.561 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3614.201986754967
    time_step_min: 3263
  date: 2020-10-12_08-18-05
  done: false
  episode_len_mean: 878.743670886076
  episode_reward_max: 271.62626262626253
  episode_reward_mean: 219.13441375783128
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1307151317596436
        entropy_coeff: 0.0005000000000000001
        kl: 0.007435552775859833
        model: {}
        policy_loss: -0.008821662476596734
        total_loss: 57.703648249308266
        vf_explained_var: 0.8985523581504822
        vf_loss: 57.71229076385498
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.37307692307692
    gpu_util_percent0: 0.37769230769230766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.757692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16071866402244744
    mean_env_wait_ms: 1.1686171756642982
    mean_inference_ms: 5.177265320403001
    mean_raw_obs_processing_ms: 0.42365264313897055
  time_since_restore: 90.54482674598694
  time_this_iter_s: 21.865246057510376
  time_total_s: 90.54482674598694
  timers:
    learn_throughput: 10943.822
    learn_time_ms: 14783.866
    sample_throughput: 20855.405
    sample_time_ms: 7757.797
    update_time_ms: 51.57
  timestamp: 1602490685
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      4 |          90.5448 | 647168 |  219.134 |              271.626 |              118.596 |            878.744 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3603.303149606299
    time_step_min: 3263
  date: 2020-10-12_08-18-27
  done: false
  episode_len_mean: 872.032911392405
  episode_reward_max: 277.989898989899
  episode_reward_mean: 220.47570643140241
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0931349396705627
        entropy_coeff: 0.0005000000000000001
        kl: 0.00779568237097313
        model: {}
        policy_loss: -0.008994614414405078
        total_loss: 45.30020809173584
        vf_explained_var: 0.932476282119751
        vf_loss: 45.30897013346354
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.75925925925926
    gpu_util_percent0: 0.36481481481481487
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.755555555555555
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15922985707676396
    mean_env_wait_ms: 1.1714250251780574
    mean_inference_ms: 5.082715379115769
    mean_raw_obs_processing_ms: 0.4184893832756008
  time_since_restore: 112.39339995384216
  time_this_iter_s: 21.848573207855225
  time_total_s: 112.39339995384216
  timers:
    learn_throughput: 10950.47
    learn_time_ms: 14774.891
    sample_throughput: 21290.579
    sample_time_ms: 7599.23
    update_time_ms: 48.6
  timestamp: 1602490707
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      5 |          112.393 | 808960 |  220.476 |               277.99 |              118.596 |            872.033 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3580.025974025974
    time_step_min: 3252
  date: 2020-10-12_08-18-48
  done: false
  episode_len_mean: 859.9168173598554
  episode_reward_max: 277.989898989899
  episode_reward_mean: 224.50477651743455
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0964580277601879
        entropy_coeff: 0.0005000000000000001
        kl: 0.0070520887384191155
        model: {}
        policy_loss: -0.009450642672769996
        total_loss: 36.19568475087484
        vf_explained_var: 0.9530174732208252
        vf_loss: 36.2049773534139
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.42
    gpu_util_percent0: 0.28240000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.756
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15727627060891738
    mean_env_wait_ms: 1.176935910840223
    mean_inference_ms: 4.9546206565535345
    mean_raw_obs_processing_ms: 0.4118872265080656
  time_since_restore: 133.9969527721405
  time_this_iter_s: 21.60355281829834
  time_total_s: 133.9969527721405
  timers:
    learn_throughput: 10972.109
    learn_time_ms: 14745.752
    sample_throughput: 21605.627
    sample_time_ms: 7488.42
    update_time_ms: 43.97
  timestamp: 1602490728
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      6 |          133.997 | 970752 |  224.505 |               277.99 |              118.596 |            859.917 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3568.9069579288025
    time_step_min: 3223
  date: 2020-10-12_08-19-11
  done: false
  episode_len_mean: 855.3409810126582
  episode_reward_max: 277.989898989899
  episode_reward_mean: 226.3009365809997
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0852240125338237
        entropy_coeff: 0.0005000000000000001
        kl: 0.006654882531923552
        model: {}
        policy_loss: -0.008402673081339648
        total_loss: 22.136696815490723
        vf_explained_var: 0.9591858386993408
        vf_loss: 22.1449769337972
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.133333333333333
    gpu_util_percent0: 0.3274074074074074
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774074074074074
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15656674946834911
    mean_env_wait_ms: 1.1790376306777075
    mean_inference_ms: 4.908632400838693
    mean_raw_obs_processing_ms: 0.4094826609603066
  time_since_restore: 156.16001439094543
  time_this_iter_s: 22.16306161880493
  time_total_s: 156.16001439094543
  timers:
    learn_throughput: 10962.953
    learn_time_ms: 14758.067
    sample_throughput: 21706.713
    sample_time_ms: 7453.547
    update_time_ms: 42.91
  timestamp: 1602490751
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      7 |           156.16 | 1132544 |  226.301 |               277.99 |              118.596 |            855.341 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3559.409612625538
    time_step_min: 3213
  date: 2020-10-12_08-19-33
  done: false
  episode_len_mean: 851.2285513361463
  episode_reward_max: 279.2020202020205
  episode_reward_mean: 227.61643864808408
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.064836581548055
        entropy_coeff: 0.0005000000000000001
        kl: 0.007024736143648624
        model: {}
        policy_loss: -0.01098796930940201
        total_loss: 18.97636540730794
        vf_explained_var: 0.9632197022438049
        vf_loss: 18.98718277613322
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.669230769230772
    gpu_util_percent0: 0.38384615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773076923076923
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15595891964857586
    mean_env_wait_ms: 1.1809454626407365
    mean_inference_ms: 4.868793649237494
    mean_raw_obs_processing_ms: 0.407373353338115
  time_since_restore: 178.08209371566772
  time_this_iter_s: 21.92207932472229
  time_total_s: 178.08209371566772
  timers:
    learn_throughput: 10962.634
    learn_time_ms: 14758.497
    sample_throughput: 21846.272
    sample_time_ms: 7405.932
    update_time_ms: 42.294
  timestamp: 1602490773
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      8 |          178.082 | 1294336 |  227.616 |              279.202 |              118.596 |            851.229 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3544.464445868033
    time_step_min: 3191
  date: 2020-10-12_08-19-55
  done: false
  episode_len_mean: 847.2133417243549
  episode_reward_max: 282.53535353535335
  episode_reward_mean: 229.62328762769275
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 167
  episodes_total: 1589
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0196023285388947
        entropy_coeff: 0.0005000000000000001
        kl: 0.006671490341735383
        model: {}
        policy_loss: -0.0071269801701419055
        total_loss: 18.681314945220947
        vf_explained_var: 0.9678203463554382
        vf_loss: 18.688284556070965
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.38148148148148
    gpu_util_percent0: 0.31999999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7592592592592586
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.155400467758317
    mean_env_wait_ms: 1.183039650073914
    mean_inference_ms: 4.832418911477187
    mean_raw_obs_processing_ms: 0.40543635804228817
  time_since_restore: 200.01625061035156
  time_this_iter_s: 21.934156894683838
  time_total_s: 200.01625061035156
  timers:
    learn_throughput: 10966.485
    learn_time_ms: 14753.314
    sample_throughput: 21935.371
    sample_time_ms: 7375.85
    update_time_ms: 41.465
  timestamp: 1602490795
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      9 |          200.016 | 1456128 |  229.623 |              282.535 |              118.596 |            847.213 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3524.805674518201
    time_step_min: 3191
  date: 2020-10-12_08-20-16
  done: false
  episode_len_mean: 839.9789029535865
  episode_reward_max: 288.1414141414144
  episode_reward_mean: 232.63740250607327
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 307
  episodes_total: 1896
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0076924065748851
        entropy_coeff: 0.0005000000000000001
        kl: 0.006664008173781137
        model: {}
        policy_loss: -0.007970896758100329
        total_loss: 19.40124209721883
        vf_explained_var: 0.9715626239776611
        vf_loss: 19.409050464630127
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.65
    gpu_util_percent0: 0.3926923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761538461538461
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545620977237074
    mean_env_wait_ms: 1.186670827850528
    mean_inference_ms: 4.777711485075414
    mean_raw_obs_processing_ms: 0.40263050559742963
  time_since_restore: 221.60317945480347
  time_this_iter_s: 21.586928844451904
  time_total_s: 221.60317945480347
  timers:
    learn_throughput: 10981.455
    learn_time_ms: 14733.202
    sample_throughput: 22066.542
    sample_time_ms: 7332.005
    update_time_ms: 41.18
  timestamp: 1602490816
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     10 |          221.603 | 1617920 |  232.637 |              288.141 |              118.596 |            839.979 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3515.567620927937
    time_step_min: 3191
  date: 2020-10-12_08-20-38
  done: false
  episode_len_mean: 836.7551119766309
  episode_reward_max: 288.1414141414144
  episode_reward_mean: 234.13157377081416
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9877197394768397
        entropy_coeff: 0.0005000000000000001
        kl: 0.007032672797019283
        model: {}
        policy_loss: -0.0085028958710609
        total_loss: 13.62386417388916
        vf_explained_var: 0.972416877746582
        vf_loss: 13.632157802581787
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.884615384615383
    gpu_util_percent0: 0.35500000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15420689223114267
    mean_env_wait_ms: 1.188281984880439
    mean_inference_ms: 4.754489900097536
    mean_raw_obs_processing_ms: 0.40144947710727935
  time_since_restore: 243.3785741329193
  time_this_iter_s: 21.775394678115845
  time_total_s: 243.3785741329193
  timers:
    learn_throughput: 10994.005
    learn_time_ms: 14716.384
    sample_throughput: 22725.409
    sample_time_ms: 7119.432
    update_time_ms: 41.124
  timestamp: 1602490838
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     11 |          243.379 | 1779712 |  234.132 |              288.141 |              118.596 |            836.755 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3506.289377289377
    time_step_min: 3185
  date: 2020-10-12_08-21-00
  done: false
  episode_len_mean: 834.1546112115732
  episode_reward_max: 288.1414141414144
  episode_reward_mean: 235.46928142181295
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9678831497828165
        entropy_coeff: 0.0005000000000000001
        kl: 0.006004722556099296
        model: {}
        policy_loss: -0.009751358816477781
        total_loss: 12.226415316263834
        vf_explained_var: 0.9737133383750916
        vf_loss: 12.23604973157247
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.969230769230776
    gpu_util_percent0: 0.3538461538461538
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7615384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15388558015710302
    mean_env_wait_ms: 1.1897205745623838
    mean_inference_ms: 4.733412954819154
    mean_raw_obs_processing_ms: 0.40035092487229396
  time_since_restore: 265.1564075946808
  time_this_iter_s: 21.777833461761475
  time_total_s: 265.1564075946808
  timers:
    learn_throughput: 11014.664
    learn_time_ms: 14688.781
    sample_throughput: 22915.538
    sample_time_ms: 7060.362
    update_time_ms: 35.679
  timestamp: 1602490860
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     12 |          265.156 | 1941504 |  235.469 |              288.141 |              118.596 |            834.155 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3491.8694060211556
    time_step_min: 3185
  date: 2020-10-12_08-21-22
  done: false
  episode_len_mean: 830.4947707160096
  episode_reward_max: 288.1414141414144
  episode_reward_mean: 237.5231031148166
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 274
  episodes_total: 2486
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9290325542291006
        entropy_coeff: 0.0005000000000000001
        kl: 0.006295189222631355
        model: {}
        policy_loss: -0.008376634260154484
        total_loss: 16.791339874267578
        vf_explained_var: 0.9763460755348206
        vf_loss: 16.799551486968994
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.807692307692307
    gpu_util_percent0: 0.35038461538461535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753846153846154
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534026797728033
    mean_env_wait_ms: 1.1921915934861729
    mean_inference_ms: 4.701865327501849
    mean_raw_obs_processing_ms: 0.39870932714343327
  time_since_restore: 286.9444353580475
  time_this_iter_s: 21.7880277633667
  time_total_s: 286.9444353580475
  timers:
    learn_throughput: 11020.361
    learn_time_ms: 14681.189
    sample_throughput: 22948.562
    sample_time_ms: 7050.202
    update_time_ms: 36.619
  timestamp: 1602490882
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     13 |          286.944 | 2103296 |  237.523 |              288.141 |              118.596 |            830.495 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3483.349134687735
    time_step_min: 3185
  date: 2020-10-12_08-21-43
  done: false
  episode_len_mean: 828.1734921816828
  episode_reward_max: 288.1414141414144
  episode_reward_mean: 238.66669675158124
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 200
  episodes_total: 2686
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9232238580783209
        entropy_coeff: 0.0005000000000000001
        kl: 0.006286289620523651
        model: {}
        policy_loss: -0.01046323703970605
        total_loss: 11.78066317240397
        vf_explained_var: 0.9783161282539368
        vf_loss: 11.79095975557963
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.0
    gpu_util_percent0: 0.2956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15309949060833375
    mean_env_wait_ms: 1.1936688099878277
    mean_inference_ms: 4.68158069729053
    mean_raw_obs_processing_ms: 0.3976814010577938
  time_since_restore: 308.1764705181122
  time_this_iter_s: 21.232035160064697
  time_total_s: 308.1764705181122
  timers:
    learn_throughput: 11062.35
    learn_time_ms: 14625.464
    sample_throughput: 22970.509
    sample_time_ms: 7043.466
    update_time_ms: 34.789
  timestamp: 1602490903
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     14 |          308.176 | 2265088 |  238.667 |              288.141 |              118.596 |            828.173 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3477.3824573863635
    time_step_min: 3185
  date: 2020-10-12_08-22-05
  done: false
  episode_len_mean: 826.8424753867791
  episode_reward_max: 288.1414141414144
  episode_reward_mean: 239.64862762647567
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9125363181034724
        entropy_coeff: 0.0005000000000000001
        kl: 0.00608441144383202
        model: {}
        policy_loss: -0.008707707068727663
        total_loss: 9.64974331855774
        vf_explained_var: 0.9798218607902527
        vf_loss: 9.65829865137736
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.60769230769231
    gpu_util_percent0: 0.3346153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15288317920572567
    mean_env_wait_ms: 1.194748016689442
    mean_inference_ms: 4.667225431805814
    mean_raw_obs_processing_ms: 0.3969378355610825
  time_since_restore: 329.7988615036011
  time_this_iter_s: 21.62239098548889
  time_total_s: 329.7988615036011
  timers:
    learn_throughput: 11071.0
    learn_time_ms: 14614.036
    sample_throughput: 22991.378
    sample_time_ms: 7037.073
    update_time_ms: 34.298
  timestamp: 1602490925
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     15 |          329.799 | 2426880 |  239.649 |              288.141 |              118.596 |            826.842 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3471.586357526882
    time_step_min: 3141
  date: 2020-10-12_08-22-27
  done: false
  episode_len_mean: 825.6671105193076
  episode_reward_max: 290.11111111111103
  episode_reward_mean: 240.53267024438787
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8860243856906891
        entropy_coeff: 0.0005000000000000001
        kl: 0.006397477972010772
        model: {}
        policy_loss: -0.008911015300933892
        total_loss: 11.561505238215128
        vf_explained_var: 0.9785943031311035
        vf_loss: 11.57021967569987
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.15925925925926
    gpu_util_percent0: 0.3262962962962963
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77037037037037
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15268173840271962
    mean_env_wait_ms: 1.19574489708898
    mean_inference_ms: 4.653763309399263
    mean_raw_obs_processing_ms: 0.39622961868207607
  time_since_restore: 351.7714014053345
  time_this_iter_s: 21.9725399017334
  time_total_s: 351.7714014053345
  timers:
    learn_throughput: 11050.606
    learn_time_ms: 14641.007
    sample_throughput: 22973.716
    sample_time_ms: 7042.483
    update_time_ms: 36.284
  timestamp: 1602490947
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     16 |          351.771 | 2588672 |  240.533 |              290.111 |              118.596 |            825.667 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3461.5548112058464
    time_step_min: 3141
  date: 2020-10-12_08-22-49
  done: false
  episode_len_mean: 823.8010265700483
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 242.11498133508994
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 308
  episodes_total: 3312
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8602482428153356
        entropy_coeff: 0.0005000000000000001
        kl: 0.006070932140573859
        model: {}
        policy_loss: -0.009451528991727779
        total_loss: 13.428233623504639
        vf_explained_var: 0.981722891330719
        vf_loss: 13.437508344650269
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.77692307692308
    gpu_util_percent0: 0.40192307692307705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.757692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523316783764433
    mean_env_wait_ms: 1.197482520364091
    mean_inference_ms: 4.630753591799989
    mean_raw_obs_processing_ms: 0.39506937213176363
  time_since_restore: 373.392630815506
  time_this_iter_s: 21.62122941017151
  time_total_s: 373.392630815506
  timers:
    learn_throughput: 11067.625
    learn_time_ms: 14618.493
    sample_throughput: 23078.296
    sample_time_ms: 7010.57
    update_time_ms: 35.004
  timestamp: 1602490969
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     17 |          373.393 | 2750464 |  242.115 |              290.414 |              118.596 |            823.801 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3455.939385150812
    time_step_min: 3141
  date: 2020-10-12_08-23-11
  done: false
  episode_len_mean: 822.9513808975835
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 242.9883733770384
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 164
  episodes_total: 3476
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8480297277371088
        entropy_coeff: 0.0005000000000000001
        kl: 0.005980685236863792
        model: {}
        policy_loss: -0.009295757947256789
        total_loss: 8.385785063107809
        vf_explained_var: 0.98355633020401
        vf_loss: 8.394906878471375
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.719230769230762
    gpu_util_percent0: 0.38961538461538464
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15216380576721844
    mean_env_wait_ms: 1.198240484170083
    mean_inference_ms: 4.619870814820799
    mean_raw_obs_processing_ms: 0.39451138085377374
  time_since_restore: 394.9590709209442
  time_this_iter_s: 21.566440105438232
  time_total_s: 394.9590709209442
  timers:
    learn_throughput: 11083.274
    learn_time_ms: 14597.852
    sample_throughput: 23126.733
    sample_time_ms: 6995.887
    update_time_ms: 33.651
  timestamp: 1602490991
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     18 |          394.959 | 2912256 |  242.988 |              290.414 |              118.596 |            822.951 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3450.849694952856
    time_step_min: 3141
  date: 2020-10-12_08-23-32
  done: false
  episode_len_mean: 822.1293340671436
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 243.76256789135152
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8463053901990255
        entropy_coeff: 0.0005000000000000001
        kl: 0.005816654340984921
        model: {}
        policy_loss: -0.008370639804828292
        total_loss: 9.871557076772055
        vf_explained_var: 0.9790952801704407
        vf_loss: 9.879769563674927
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.973076923076924
    gpu_util_percent0: 0.4196153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15201376411298773
    mean_env_wait_ms: 1.1989255429744285
    mean_inference_ms: 4.61002629957187
    mean_raw_obs_processing_ms: 0.39400633263886187
  time_since_restore: 416.5034601688385
  time_this_iter_s: 21.544389247894287
  time_total_s: 416.5034601688385
  timers:
    learn_throughput: 11104.878
    learn_time_ms: 14569.453
    sample_throughput: 23182.323
    sample_time_ms: 6979.111
    update_time_ms: 32.143
  timestamp: 1602491012
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     19 |          416.503 | 3074048 |  243.763 |              290.414 |              118.596 |            822.129 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3444.7242281527997
    time_step_min: 3141
  date: 2020-10-12_08-23-54
  done: false
  episode_len_mean: 820.728051948052
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 244.5843499934408
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 216
  episodes_total: 3850
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8126419484615326
        entropy_coeff: 0.0005000000000000001
        kl: 0.005857201875187457
        model: {}
        policy_loss: -0.00785230855884341
        total_loss: 12.330925305684408
        vf_explained_var: 0.9810908436775208
        vf_loss: 12.338598330815634
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.684
    gpu_util_percent0: 0.3696
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.756
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15182597036787565
    mean_env_wait_ms: 1.1998648566925316
    mean_inference_ms: 4.59769219767983
    mean_raw_obs_processing_ms: 0.3933754930031549
  time_since_restore: 437.9918293952942
  time_this_iter_s: 21.48836922645569
  time_total_s: 437.9918293952942
  timers:
    learn_throughput: 11114.896
    learn_time_ms: 14556.322
    sample_throughput: 23172.677
    sample_time_ms: 6982.016
    update_time_ms: 32.369
  timestamp: 1602491034
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     20 |          437.992 | 3235840 |  244.584 |              290.414 |              118.596 |            820.728 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3437.690441176471
    time_step_min: 3141
  date: 2020-10-12_08-24-16
  done: false
  episode_len_mean: 819.2585199610517
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 245.53567072870865
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 258
  episodes_total: 4108
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7962117195129395
        entropy_coeff: 0.0005000000000000001
        kl: 0.004699128757541378
        model: {}
        policy_loss: -0.007990811747731641
        total_loss: 10.702264308929443
        vf_explained_var: 0.9830734729766846
        vf_loss: 10.710183302561441
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.366666666666667
    gpu_util_percent0: 0.29074074074074074
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7629629629629626
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15161483382226207
    mean_env_wait_ms: 1.2008228195208275
    mean_inference_ms: 4.584031516371675
    mean_raw_obs_processing_ms: 0.392688806021127
  time_since_restore: 459.91959524154663
  time_this_iter_s: 21.92776584625244
  time_total_s: 459.91959524154663
  timers:
    learn_throughput: 11108.902
    learn_time_ms: 14564.176
    sample_throughput: 23146.475
    sample_time_ms: 6989.919
    update_time_ms: 31.574
  timestamp: 1602491056
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     21 |           459.92 | 3397632 |  245.536 |              290.414 |              118.596 |            819.259 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3433.871165644172
    time_step_min: 3141
  date: 2020-10-12_08-24-38
  done: false
  episode_len_mean: 818.1823722456634
  episode_reward_max: 293.89898989899
  episode_reward_mean: 246.1614527838156
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7922417124112447
        entropy_coeff: 0.0005000000000000001
        kl: 0.006179819426809748
        model: {}
        policy_loss: -0.010333442517245809
        total_loss: 7.185657620429993
        vf_explained_var: 0.9850761890411377
        vf_loss: 7.1960781415303545
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.17307692307692
    gpu_util_percent0: 0.41423076923076924
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15149682416537705
    mean_env_wait_ms: 1.201374445162289
    mean_inference_ms: 4.576403214104389
    mean_raw_obs_processing_ms: 0.39230323446183507
  time_since_restore: 481.6516396999359
  time_this_iter_s: 21.732044458389282
  time_total_s: 481.6516396999359
  timers:
    learn_throughput: 11106.817
    learn_time_ms: 14566.909
    sample_throughput: 23172.025
    sample_time_ms: 6982.212
    update_time_ms: 31.216
  timestamp: 1602491078
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     22 |          481.652 | 3559424 |  246.161 |              293.899 |              118.596 |            818.182 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3429.85662349466
    time_step_min: 3135
  date: 2020-10-12_08-25-00
  done: false
  episode_len_mean: 817.115601715963
  episode_reward_max: 293.89898989899
  episode_reward_mean: 246.75540457635734
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 163
  episodes_total: 4429
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7696222414573034
        entropy_coeff: 0.0005000000000000001
        kl: 0.006637000245973468
        model: {}
        policy_loss: -0.008142252181035778
        total_loss: 9.046889623006185
        vf_explained_var: 0.9829367995262146
        vf_loss: 9.055085023244223
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.426923076923078
    gpu_util_percent0: 0.32230769230769235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15138571915254828
    mean_env_wait_ms: 1.2019350771701267
    mean_inference_ms: 4.569002703077179
    mean_raw_obs_processing_ms: 0.3919233349017119
  time_since_restore: 503.2853772640228
  time_this_iter_s: 21.633737564086914
  time_total_s: 503.2853772640228
  timers:
    learn_throughput: 11104.524
    learn_time_ms: 14569.917
    sample_throughput: 23231.381
    sample_time_ms: 6964.373
    update_time_ms: 29.524
  timestamp: 1602491100
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     23 |          503.285 | 3721216 |  246.755 |              293.899 |              118.596 |            817.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3423.16099532114
    time_step_min: 3135
  date: 2020-10-12_08-25-21
  done: false
  episode_len_mean: 815.1300211416491
  episode_reward_max: 293.89898989899
  episode_reward_mean: 247.74651376342703
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 301
  episodes_total: 4730
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7392598738272985
        entropy_coeff: 0.0005000000000000001
        kl: 0.005826210797143479
        model: {}
        policy_loss: -0.009122005936660571
        total_loss: 10.013187249501547
        vf_explained_var: 0.9857361912727356
        vf_loss: 10.022387663523356
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.756
    gpu_util_percent0: 0.36560000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7640000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15118670580087262
    mean_env_wait_ms: 1.2029626221917573
    mean_inference_ms: 4.556226465372887
    mean_raw_obs_processing_ms: 0.391288705553902
  time_since_restore: 524.8132407665253
  time_this_iter_s: 21.52786350250244
  time_total_s: 524.8132407665253
  timers:
    learn_throughput: 11072.325
    learn_time_ms: 14612.288
    sample_throughput: 23276.561
    sample_time_ms: 6950.855
    update_time_ms: 29.333
  timestamp: 1602491121
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     24 |          524.813 | 3883008 |  247.747 |              293.899 |              118.596 |             815.13 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3419.282751540041
    time_step_min: 3135
  date: 2020-10-12_08-25-43
  done: false
  episode_len_mean: 814.100653327889
  episode_reward_max: 293.89898989899
  episode_reward_mean: 248.32132678355623
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 168
  episodes_total: 4898
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7336608171463013
        entropy_coeff: 0.0005000000000000001
        kl: 0.006113760716592272
        model: {}
        policy_loss: -0.009550909734874343
        total_loss: 6.576909343401591
        vf_explained_var: 0.9865676760673523
        vf_loss: 6.58652130762736
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.73076923076923
    gpu_util_percent0: 0.32346153846153847
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15108537890214208
    mean_env_wait_ms: 1.2034634470979062
    mean_inference_ms: 4.549592354974739
    mean_raw_obs_processing_ms: 0.3909562190733837
  time_since_restore: 546.2893211841583
  time_this_iter_s: 21.476080417633057
  time_total_s: 546.2893211841583
  timers:
    learn_throughput: 11081.383
    learn_time_ms: 14600.343
    sample_throughput: 23282.075
    sample_time_ms: 6949.209
    update_time_ms: 27.926
  timestamp: 1602491143
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     25 |          546.289 | 4044800 |  248.321 |              293.899 |              118.596 |            814.101 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3415.8178564326904
    time_step_min: 3128
  date: 2020-10-12_08-26-05
  done: false
  episode_len_mean: 813.1633379473997
  episode_reward_max: 293.89898989899
  episode_reward_mean: 248.8292395978771
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 159
  episodes_total: 5057
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7295501778523127
        entropy_coeff: 0.0005000000000000001
        kl: 0.005874564366725584
        model: {}
        policy_loss: -0.008493003813782707
        total_loss: 7.950014750162761
        vf_explained_var: 0.983363151550293
        vf_loss: 7.958578626314799
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.542307692307695
    gpu_util_percent0: 0.3719230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7884615384615383
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509959980043755
    mean_env_wait_ms: 1.2039438535670208
    mean_inference_ms: 4.543643745260567
    mean_raw_obs_processing_ms: 0.39065745577815003
  time_since_restore: 567.7602591514587
  time_this_iter_s: 21.470937967300415
  time_total_s: 567.7602591514587
  timers:
    learn_throughput: 11102.74
    learn_time_ms: 14572.258
    sample_throughput: 23346.655
    sample_time_ms: 6929.986
    update_time_ms: 25.614
  timestamp: 1602491165
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     26 |           567.76 | 4206592 |  248.829 |              293.899 |              118.596 |            813.163 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3409.7600677455775
    time_step_min: 3128
  date: 2020-10-12_08-26-26
  done: false
  episode_len_mean: 811.4490827405466
  episode_reward_max: 293.89898989899
  episode_reward_mean: 249.6970396590389
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 285
  episodes_total: 5342
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.6967413127422333
        entropy_coeff: 0.0005000000000000001
        kl: 0.006306514337969323
        model: {}
        policy_loss: -0.009041692143606875
        total_loss: 9.368427356084188
        vf_explained_var: 0.9863912463188171
        vf_loss: 9.377501646677652
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.844
    gpu_util_percent0: 0.3772
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15084418754751167
    mean_env_wait_ms: 1.204832560302368
    mean_inference_ms: 4.533798639536211
    mean_raw_obs_processing_ms: 0.3901641161662921
  time_since_restore: 589.397045135498
  time_this_iter_s: 21.636785984039307
  time_total_s: 589.397045135498
  timers:
    learn_throughput: 11092.25
    learn_time_ms: 14586.04
    sample_throughput: 23395.212
    sample_time_ms: 6915.603
    update_time_ms: 27.344
  timestamp: 1602491186
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     27 |          589.397 | 4368384 |  249.697 |              293.899 |              118.596 |            811.449 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_39cc5_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3405.737549981825
    time_step_min: 3128
  date: 2020-10-12_08-26-48
  done: true
  episode_len_mean: 810.4667269439421
  episode_reward_max: 293.89898989899
  episode_reward_mean: 250.2915045573273
  episode_reward_min: 118.59595959595967
  episodes_this_iter: 188
  episodes_total: 5530
  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.675686240196228
        entropy_coeff: 0.0005000000000000001
        kl: 0.005107206680501501
        model: {}
        policy_loss: -0.00786691315685554
        total_loss: 7.04692538579305
        vf_explained_var: 0.9860422015190125
        vf_loss: 7.054874618848165
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.199999999999996
    gpu_util_percent0: 0.33692307692307694
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780769230769231
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24878
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15074896499452803
    mean_env_wait_ms: 1.2053334662527855
    mean_inference_ms: 4.527474043839373
    mean_raw_obs_processing_ms: 0.3898601834278142
  time_since_restore: 610.9207043647766
  time_this_iter_s: 21.523659229278564
  time_total_s: 610.9207043647766
  timers:
    learn_throughput: 11086.727
    learn_time_ms: 14593.306
    sample_throughput: 23437.181
    sample_time_ms: 6903.219
    update_time_ms: 27.218
  timestamp: 1602491208
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: 39cc5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | TERMINATED |       |     28 |          610.921 | 4530176 |  250.292 |              293.899 |              118.596 |            810.467 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_39cc5_00000 | TERMINATED |       |     28 |          610.921 | 4530176 |  250.292 |              293.899 |              118.596 |            810.467 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


