2020-10-09 10:05:49,983	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_02e02_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=65839)[0m 2020-10-09 10:05:53,021	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=65872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65725)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-09_10-07-06
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1647065848112106
        entropy_coeff: 0.0
        kl: 0.004588506685104221
        model: {}
        policy_loss: -0.013151872786693275
        total_loss: 482.15632247924805
        vf_explained_var: 0.5976046919822693
        vf_loss: 482.1685592651367
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.385714285714283
    gpu_util_percent0: 0.3624675324675325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00012987012987012987
    ram_util_percent: 9.866233766233767
    vram_util_percent0: 0.26185400365459405
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24193196651485827
    mean_env_wait_ms: 3.246691139364876
    mean_inference_ms: 9.020326834617112
    mean_raw_obs_processing_ms: 0.8563718504285914
  time_since_restore: 67.14943742752075
  time_this_iter_s: 67.14943742752075
  time_total_s: 67.14943742752075
  timers:
    learn_throughput: 6301.08
    learn_time_ms: 51353.733
    sample_throughput: 20570.816
    sample_time_ms: 15730.246
    update_time_ms: 25.723
  timestamp: 1602238026
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      1 |          67.1494 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3211.0
  date: 2020-10-09_10-08-11
  done: false
  episode_len_mean: 875.5174050632911
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.528496995269
  episode_reward_min: 132.60606060606042
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1350080341100692
        entropy_coeff: 0.0
        kl: 0.005414370284415782
        model: {}
        policy_loss: -0.01429169726325199
        total_loss: 101.71122226715087
        vf_explained_var: 0.8564453125
        vf_loss: 101.72497291564942
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.951315789473686
    gpu_util_percent0: 0.3261842105263158
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.185526315789476
    vram_util_percent0: 0.2695059639916453
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23697978396107935
    mean_env_wait_ms: 3.227282603991965
    mean_inference_ms: 8.637884394718279
    mean_raw_obs_processing_ms: 0.8405782414580697
  time_since_restore: 132.76619410514832
  time_this_iter_s: 65.61675667762756
  time_total_s: 132.76619410514832
  timers:
    learn_throughput: 6319.928
    learn_time_ms: 51200.585
    sample_throughput: 21435.595
    sample_time_ms: 15095.639
    update_time_ms: 23.787
  timestamp: 1602238091
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      2 |          132.766 | 647168 |  228.528 |              284.798 |              132.606 |            875.517 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3211.0
  date: 2020-10-09_10-09-16
  done: false
  episode_len_mean: 874.1191983122363
  episode_reward_max: 287.1616161616156
  episode_reward_mean: 229.37751992498812
  episode_reward_min: 132.60606060606042
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1294090926647187
        entropy_coeff: 0.0
        kl: 0.006144991365727037
        model: {}
        policy_loss: -0.015762338519562036
        total_loss: 23.530592489242554
        vf_explained_var: 0.9560779333114624
        vf_loss: 23.545740032196044
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.725333333333328
    gpu_util_percent0: 0.3572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.205333333333334
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2344328811500153
    mean_env_wait_ms: 3.2193789316346995
    mean_inference_ms: 8.403079281771557
    mean_raw_obs_processing_ms: 0.8308303480214049
  time_since_restore: 197.7077705860138
  time_this_iter_s: 64.94157648086548
  time_total_s: 197.7077705860138
  timers:
    learn_throughput: 6321.672
    learn_time_ms: 51186.456
    sample_throughput: 22134.189
    sample_time_ms: 14619.194
    update_time_ms: 26.997
  timestamp: 1602238156
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      3 |          197.708 | 970752 |  229.378 |              287.162 |              132.606 |            874.119 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-10-22
  done: false
  episode_len_mean: 871.7049050632911
  episode_reward_max: 288.9898989898994
  episode_reward_mean: 229.99907300856654
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1141992151737212
        entropy_coeff: 0.0
        kl: 0.006369423179421574
        model: {}
        policy_loss: -0.015277896466432139
        total_loss: 19.24227056503296
        vf_explained_var: 0.9613660573959351
        vf_loss: 19.256911516189575
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.422666666666668
    gpu_util_percent0: 0.27053333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.214666666666668
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23262671793969322
    mean_env_wait_ms: 3.2161106060197153
    mean_inference_ms: 8.245270583153399
    mean_raw_obs_processing_ms: 0.8234370972937141
  time_since_restore: 262.782751083374
  time_this_iter_s: 65.07498049736023
  time_total_s: 262.782751083374
  timers:
    learn_throughput: 6323.067
    learn_time_ms: 51175.166
    sample_throughput: 22444.693
    sample_time_ms: 14416.949
    update_time_ms: 27.621
  timestamp: 1602238222
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      4 |          262.783 | 1294336 |  229.999 |               288.99 |              105.939 |            871.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-11-27
  done: false
  episode_len_mean: 868.4118761844599
  episode_reward_max: 288.9898989898994
  episode_reward_mean: 230.8278234014177
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 319
  episodes_total: 1583
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0829231142997742
        entropy_coeff: 0.0
        kl: 0.006164489069487899
        model: {}
        policy_loss: -0.01594096632907167
        total_loss: 19.27858147621155
        vf_explained_var: 0.9681673049926758
        vf_loss: 19.293906116485594
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.42162162162162
    gpu_util_percent0: 0.3268918918918919
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.248648648648647
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23133137424404326
    mean_env_wait_ms: 3.2177327624593777
    mean_inference_ms: 8.128111751908005
    mean_raw_obs_processing_ms: 0.8173090499018427
  time_since_restore: 327.93531227111816
  time_this_iter_s: 65.15256118774414
  time_total_s: 327.93531227111816
  timers:
    learn_throughput: 6315.292
    learn_time_ms: 51238.17
    sample_throughput: 22718.739
    sample_time_ms: 14243.044
    update_time_ms: 26.96
  timestamp: 1602238287
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      5 |          327.935 | 1617920 |  230.828 |               288.99 |              105.939 |            868.412 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-12-32
  done: false
  episode_len_mean: 860.5433996383364
  episode_reward_max: 288.9898989898994
  episode_reward_mean: 232.60194622536378
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 629
  episodes_total: 2212
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1015238612890244
        entropy_coeff: 0.0
        kl: 0.005823430675081909
        model: {}
        policy_loss: -0.01543478223029524
        total_loss: 19.459236001968385
        vf_explained_var: 0.9717954397201538
        vf_loss: 19.474088764190675
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.630666666666666
    gpu_util_percent0: 0.3302666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.24933333333333
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22959392643793008
    mean_env_wait_ms: 3.2243815317358706
    mean_inference_ms: 7.973272276178329
    mean_raw_obs_processing_ms: 0.8096641443892536
  time_since_restore: 392.98933243751526
  time_this_iter_s: 65.0540201663971
  time_total_s: 392.98933243751526
  timers:
    learn_throughput: 6314.363
    learn_time_ms: 51245.704
    sample_throughput: 22877.538
    sample_time_ms: 14144.179
    update_time_ms: 28.328
  timestamp: 1602238352
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      6 |          392.989 | 1941504 |  232.602 |               288.99 |              105.939 |            860.543 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-13-37
  done: false
  episode_len_mean: 857.160996835443
  episode_reward_max: 292.38383838383817
  episode_reward_mean: 233.37082054724445
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0911965250968934
        entropy_coeff: 0.0
        kl: 0.005998330959118903
        model: {}
        policy_loss: -0.017079190886579453
        total_loss: 13.021632742881774
        vf_explained_var: 0.9748754501342773
        vf_loss: 13.038112235069274
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.461333333333336
    gpu_util_percent0: 0.35919999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.26933333333333
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22895299782223802
    mean_env_wait_ms: 3.227528508486691
    mean_inference_ms: 7.917734090915439
    mean_raw_obs_processing_ms: 0.806912264640937
  time_since_restore: 458.1821873188019
  time_this_iter_s: 65.19285488128662
  time_total_s: 458.1821873188019
  timers:
    learn_throughput: 6312.303
    learn_time_ms: 51262.433
    sample_throughput: 22978.539
    sample_time_ms: 14082.009
    update_time_ms: 28.362
  timestamp: 1602238417
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      7 |          458.182 | 2265088 |  233.371 |              292.384 |              105.939 |            857.161 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-14-43
  done: false
  episode_len_mean: 853.4222925457103
  episode_reward_max: 292.38383838383817
  episode_reward_mean: 234.3486588813592
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.076454719901085
        entropy_coeff: 0.0
        kl: 0.005717079539317637
        model: {}
        policy_loss: -0.01750379567965865
        total_loss: 11.501771259307862
        vf_explained_var: 0.976117730140686
        vf_loss: 11.518703389167786
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.09733333333333
    gpu_util_percent0: 0.3232
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.263999999999996
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22843764966797445
    mean_env_wait_ms: 3.2309331226412676
    mean_inference_ms: 7.869627746967071
    mean_raw_obs_processing_ms: 0.8045586720823749
  time_since_restore: 523.4076142311096
  time_this_iter_s: 65.22542691230774
  time_total_s: 523.4076142311096
  timers:
    learn_throughput: 6308.36
    learn_time_ms: 51294.472
    sample_throughput: 23084.099
    sample_time_ms: 14017.614
    update_time_ms: 30.441
  timestamp: 1602238483
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      8 |          523.408 | 2588672 |  234.349 |              292.384 |              105.939 |            853.422 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-15-48
  done: false
  episode_len_mean: 850.2505536222715
  episode_reward_max: 292.38383838383817
  episode_reward_mean: 235.532467988969
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 317
  episodes_total: 3161
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0442002534866333
        entropy_coeff: 0.0
        kl: 0.00595433188136667
        model: {}
        policy_loss: -0.01801828796742484
        total_loss: 11.742424821853637
        vf_explained_var: 0.9773195385932922
        vf_loss: 11.759847831726074
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.476
    gpu_util_percent0: 0.3492
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.254666666666663
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22801072611443127
    mean_env_wait_ms: 3.2344223001746113
    mean_inference_ms: 7.827643254857833
    mean_raw_obs_processing_ms: 0.8023723617381381
  time_since_restore: 588.7333471775055
  time_this_iter_s: 65.32573294639587
  time_total_s: 588.7333471775055
  timers:
    learn_throughput: 6304.997
    learn_time_ms: 51321.831
    sample_throughput: 23149.438
    sample_time_ms: 13978.05
    update_time_ms: 29.866
  timestamp: 1602238548
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | RUNNING  | 172.17.0.4:65839 |      9 |          588.733 | 2912256 |  235.532 |              292.384 |              105.939 |            850.251 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_02e02_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3133.0
  date: 2020-10-09_10-16-53
  done: true
  episode_len_mean: 845.3092348284961
  episode_reward_max: 292.38383838383817
  episode_reward_mean: 237.08692998587446
  episode_reward_min: 105.93939393939385
  episodes_this_iter: 629
  episodes_total: 3790
  experiment_id: 2aea78bb002741c580c89b9366f4f84c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0355813443660735
        entropy_coeff: 0.0
        kl: 0.005575651209801436
        model: {}
        policy_loss: -0.01623824074631557
        total_loss: 15.372476983070374
        vf_explained_var: 0.9791250228881836
        vf_loss: 15.388157534599305
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.358666666666668
    gpu_util_percent0: 0.3078666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.261333333333331
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65839
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2273291195474485
    mean_env_wait_ms: 3.241609388353658
    mean_inference_ms: 7.760541465370701
    mean_raw_obs_processing_ms: 0.7988971592637039
  time_since_restore: 654.0358564853668
  time_this_iter_s: 65.30250930786133
  time_total_s: 654.0358564853668
  timers:
    learn_throughput: 6304.228
    learn_time_ms: 51328.094
    sample_throughput: 23181.347
    sample_time_ms: 13958.809
    update_time_ms: 30.613
  timestamp: 1602238613
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: 02e02_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | TERMINATED |       |     10 |          654.036 | 3235840 |  237.087 |              292.384 |              105.939 |            845.309 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_02e02_00000 | TERMINATED |       |     10 |          654.036 | 3235840 |  237.087 |              292.384 |              105.939 |            845.309 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


