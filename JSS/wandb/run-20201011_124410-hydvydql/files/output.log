2020-10-11 12:44:13,992	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_7876d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=61353)[0m 2020-10-11 12:44:16,730	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=61326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61273)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3584.5733333333333
    time_step_min: 3342
  date: 2020-10-11_12-45-28
  done: false
  episode_len_mean: 890.4599156118144
  episode_reward_max: 265.262626262626
  episode_reward_mean: 220.14243702851277
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 237
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.1767056143802146
        entropy_coeff: 9.999999999999998e-05
        kl: 0.010039032760845579
        model: {}
        policy_loss: -0.020911252733481968
        total_loss: 543.38525390625
        vf_explained_var: 0.7185948491096497
        vf_loss: 543.4042836064878
    num_steps_sampled: 364032
    num_steps_trained: 364032
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.935897435897434
    gpu_util_percent0: 0.37858974358974357
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8961538461538474
    vram_util_percent0: 0.0962316354248135
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18945789059906748
    mean_env_wait_ms: 1.6292314330787518
    mean_inference_ms: 5.73797361161321
    mean_raw_obs_processing_ms: 0.5703258263856948
  time_since_restore: 66.60671973228455
  time_this_iter_s: 66.60671973228455
  time_total_s: 66.60671973228455
  timers:
    learn_throughput: 6969.315
    learn_time_ms: 52233.539
    sample_throughput: 25455.244
    sample_time_ms: 14300.865
    update_time_ms: 23.152
  timestamp: 1602420328
  timesteps_since_restore: 0
  timesteps_total: 364032
  training_iteration: 1
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 30.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      1 |          66.6067 | 364032 |  220.142 |              265.263 |              128.444 |             890.46 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3593.9423076923076
    time_step_min: 3285
  date: 2020-10-11_12-46-33
  done: false
  episode_len_mean: 887.7623066104079
  episode_reward_max: 271.7777777777774
  episode_reward_mean: 222.20419383710498
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 474
  episodes_total: 711
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.1361391233361287
        entropy_coeff: 9.999999999999998e-05
        kl: 0.011022355731414713
        model: {}
        policy_loss: -0.021337824833133946
        total_loss: 61.82920820816703
        vf_explained_var: 0.9223678708076477
        vf_loss: 61.84845567786175
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.251315789473683
    gpu_util_percent0: 0.339078947368421
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.330263157894735
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18440817164896367
    mean_env_wait_ms: 1.6386541864970425
    mean_inference_ms: 5.310682018801044
    mean_raw_obs_processing_ms: 0.5499232779366612
  time_since_restore: 130.8555097579956
  time_this_iter_s: 64.24879002571106
  time_total_s: 130.8555097579956
  timers:
    learn_throughput: 6987.958
    learn_time_ms: 52094.186
    sample_throughput: 27566.762
    sample_time_ms: 13205.468
    update_time_ms: 23.533
  timestamp: 1602420393
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 2
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      2 |          130.856 | 728064 |  222.204 |              271.778 |              128.444 |            887.762 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3592.8897996357014
    time_step_min: 3235
  date: 2020-10-11_12-47-37
  done: false
  episode_len_mean: 884.5097046413503
  episode_reward_max: 275.8686868686864
  episode_reward_mean: 222.21723564761515
  episode_reward_min: 114.20202020202011
  episodes_this_iter: 474
  episodes_total: 1185
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.1164878192155256
        entropy_coeff: 9.999999999999998e-05
        kl: 0.011357404899014078
        model: {}
        policy_loss: -0.023774502697684195
        total_loss: 28.15468804732613
        vf_explained_var: 0.9606987237930298
        vf_loss: 28.17630261960237
    num_steps_sampled: 1092096
    num_steps_trained: 1092096
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.981333333333332
    gpu_util_percent0: 0.36106666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.373333333333332
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1819962987769107
    mean_env_wait_ms: 1.6435647730452645
    mean_inference_ms: 5.1215443192599315
    mean_raw_obs_processing_ms: 0.5406176774580053
  time_since_restore: 195.19590425491333
  time_this_iter_s: 64.34039449691772
  time_total_s: 195.19590425491333
  timers:
    learn_throughput: 6966.894
    learn_time_ms: 52251.692
    sample_throughput: 28683.952
    sample_time_ms: 12691.138
    update_time_ms: 22.525
  timestamp: 1602420457
  timesteps_since_restore: 0
  timesteps_total: 1092096
  training_iteration: 3
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      3 |          195.196 | 1092096 |  222.217 |              275.869 |              114.202 |             884.51 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3584.2843340234645
    time_step_min: 3235
  date: 2020-10-11_12-48-41
  done: false
  episode_len_mean: 879.4016927083334
  episode_reward_max: 275.8686868686864
  episode_reward_mean: 223.14249921085835
  episode_reward_min: 114.20202020202011
  episodes_this_iter: 351
  episodes_total: 1536
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0935835009035857
        entropy_coeff: 9.999999999999998e-05
        kl: 0.011497157787823158
        model: {}
        policy_loss: -0.024615388363599777
        total_loss: 20.16217215164848
        vf_explained_var: 0.9703385829925537
        vf_loss: 20.184597512950067
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.871999999999996
    gpu_util_percent0: 0.3525333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.374666666666665
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18079046712823024
    mean_env_wait_ms: 1.6470390227547955
    mean_inference_ms: 5.0255712062546785
    mean_raw_obs_processing_ms: 0.5352748348085334
  time_since_restore: 259.39753699302673
  time_this_iter_s: 64.2016327381134
  time_total_s: 259.39753699302673
  timers:
    learn_throughput: 6958.699
    learn_time_ms: 52313.227
    sample_throughput: 29330.386
    sample_time_ms: 12411.429
    update_time_ms: 26.417
  timestamp: 1602420521
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 4
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      4 |          259.398 | 1456128 |  223.142 |              275.869 |              114.202 |            879.402 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3575.051962410171
    time_step_min: 3235
  date: 2020-10-11_12-49-46
  done: false
  episode_len_mean: 874.2325949367089
  episode_reward_max: 276.7777777777775
  episode_reward_mean: 224.33147935046648
  episode_reward_min: 104.2020202020196
  episodes_this_iter: 360
  episodes_total: 1896
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.095483194226804
        entropy_coeff: 9.999999999999998e-05
        kl: 0.01118191797286272
        model: {}
        policy_loss: -0.026670097494902817
        total_loss: 14.77200466653575
        vf_explained_var: 0.9706268310546875
        vf_loss: 14.79654776531717
    num_steps_sampled: 1820160
    num_steps_trained: 1820160
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.59333333333333
    gpu_util_percent0: 0.3896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.363999999999998
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17986720106052478
    mean_env_wait_ms: 1.649460185208566
    mean_inference_ms: 4.948784235438269
    mean_raw_obs_processing_ms: 0.5306985053831846
  time_since_restore: 323.7372143268585
  time_this_iter_s: 64.33967733383179
  time_total_s: 323.7372143268585
  timers:
    learn_throughput: 6949.206
    learn_time_ms: 52384.689
    sample_throughput: 29745.655
    sample_time_ms: 12238.157
    update_time_ms: 26.955
  timestamp: 1602420586
  timesteps_since_restore: 0
  timesteps_total: 1820160
  training_iteration: 5
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 31.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      5 |          323.737 | 1820160 |  224.331 |              276.778 |              104.202 |            874.233 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3561.5536574682437
    time_step_min: 3235
  date: 2020-10-11_12-50-50
  done: false
  episode_len_mean: 868.2227848101265
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 226.44655414908556
  episode_reward_min: 104.2020202020196
  episodes_this_iter: 474
  episodes_total: 2370
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.06443524878958
        entropy_coeff: 9.999999999999998e-05
        kl: 0.010872062781582708
        model: {}
        policy_loss: -0.026571301136003887
        total_loss: 16.532850680143937
        vf_explained_var: 0.9762391448020935
        vf_loss: 16.55735393192457
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.835999999999995
    gpu_util_percent0: 0.3938666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.359999999999999
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1789086922156962
    mean_env_wait_ms: 1.652983150231772
    mean_inference_ms: 4.871988110516174
    mean_raw_obs_processing_ms: 0.5261210280467796
  time_since_restore: 387.8489375114441
  time_this_iter_s: 64.11172318458557
  time_total_s: 387.8489375114441
  timers:
    learn_throughput: 6949.855
    learn_time_ms: 52379.799
    sample_throughput: 30024.165
    sample_time_ms: 12124.634
    update_time_ms: 25.707
  timestamp: 1602420650
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 6
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      6 |          387.849 | 2184192 |  226.447 |              283.596 |              104.202 |            868.223 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3545.2201668480234
    time_step_min: 3172
  date: 2020-10-11_12-51-55
  done: false
  episode_len_mean: 862.901547116737
  episode_reward_max: 285.414141414141
  episode_reward_mean: 228.77794825896075
  episode_reward_min: 104.2020202020196
  episodes_this_iter: 474
  episodes_total: 2844
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0365995790647424
        entropy_coeff: 9.999999999999998e-05
        kl: 0.01073666524303996
        model: {}
        policy_loss: -0.028600989314525024
        total_loss: 14.838709914165994
        vf_explained_var: 0.9783196449279785
        vf_loss: 14.865267338960066
    num_steps_sampled: 2548224
    num_steps_trained: 2548224
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.02
    gpu_util_percent0: 0.35573333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.3679999999999986
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17820886431918193
    mean_env_wait_ms: 1.6564032292079394
    mean_inference_ms: 4.814313017086546
    mean_raw_obs_processing_ms: 0.5227275943450053
  time_since_restore: 452.6463158130646
  time_this_iter_s: 64.79737830162048
  time_total_s: 452.6463158130646
  timers:
    learn_throughput: 6940.527
    learn_time_ms: 52450.192
    sample_throughput: 30137.72
    sample_time_ms: 12078.95
    update_time_ms: 25.618
  timestamp: 1602420715
  timesteps_since_restore: 0
  timesteps_total: 2548224
  training_iteration: 7
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      7 |          452.646 | 2548224 |  228.778 |              285.414 |              104.202 |            862.902 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3531.4138037759208
    time_step_min: 3172
  date: 2020-10-11_12-52-59
  done: false
  episode_len_mean: 858.2474382157926
  episode_reward_max: 287.98989898989896
  episode_reward_mean: 231.19980090233238
  episode_reward_min: 104.2020202020196
  episodes_this_iter: 474
  episodes_total: 3318
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.01291983542235
        entropy_coeff: 9.999999999999998e-05
        kl: 0.010912327298327633
        model: {}
        policy_loss: -0.026286454770066168
        total_loss: 12.868426530257516
        vf_explained_var: 0.9801144003868103
        vf_loss: 12.892631821010424
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.4
    gpu_util_percent0: 0.39826666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.371999999999999
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17766214197564026
    mean_env_wait_ms: 1.6595893649093354
    mean_inference_ms: 4.768877939294246
    mean_raw_obs_processing_ms: 0.5200785978339683
  time_since_restore: 517.0017900466919
  time_this_iter_s: 64.35547423362732
  time_total_s: 517.0017900466919
  timers:
    learn_throughput: 6935.481
    learn_time_ms: 52488.355
    sample_throughput: 30331.896
    sample_time_ms: 12001.624
    update_time_ms: 25.853
  timestamp: 1602420779
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 8
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      8 |          517.002 | 2912256 |    231.2 |               287.99 |              104.202 |            858.247 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3518.5597840755736
    time_step_min: 3172
  date: 2020-10-11_12-54-04
  done: false
  episode_len_mean: 854.0556434599156
  episode_reward_max: 287.98989898989896
  episode_reward_mean: 233.0994997442781
  episode_reward_min: 104.2020202020196
  episodes_this_iter: 474
  episodes_total: 3792
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 0.985657300638116
        entropy_coeff: 9.999999999999998e-05
        kl: 0.010492238944963268
        model: {}
        policy_loss: -0.028133739352874134
        total_loss: 12.100027581919795
        vf_explained_var: 0.9811524748802185
        vf_loss: 12.126161616781484
    num_steps_sampled: 3276288
    num_steps_trained: 3276288
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.744594594594595
    gpu_util_percent0: 0.36027027027027025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.382432432432432
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17721176074622577
    mean_env_wait_ms: 1.6624407036511462
    mean_inference_ms: 4.731822383225139
    mean_raw_obs_processing_ms: 0.5179183292599059
  time_since_restore: 581.1235826015472
  time_this_iter_s: 64.12179255485535
  time_total_s: 581.1235826015472
  timers:
    learn_throughput: 6938.241
    learn_time_ms: 52467.475
    sample_throughput: 30422.607
    sample_time_ms: 11965.839
    update_time_ms: 25.515
  timestamp: 1602420844
  timesteps_since_restore: 0
  timesteps_total: 3276288
  training_iteration: 9
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | RUNNING  | 172.17.0.4:61353 |      9 |          581.124 | 3276288 |  233.099 |               287.99 |              104.202 |            854.056 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7876d_00000:
  custom_metrics:
    time_step_max: 4302
    time_step_mean: 3507.7578972751385
    time_step_min: 3172
  date: 2020-10-11_12-55-08
  done: true
  episode_len_mean: 850.3155408597071
  episode_reward_max: 287.98989898989896
  episode_reward_mean: 234.76724972922406
  episode_reward_min: 104.2020202020196
  episodes_this_iter: 442
  episodes_total: 4234
  experiment_id: 7e02a8774e9b47b498c12ae775802a77
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 0.9662370759507884
        entropy_coeff: 9.999999999999998e-05
        kl: 0.0107698869365065
        model: {}
        policy_loss: -0.029331929414816525
        total_loss: 10.332957599474037
        vf_explained_var: 0.9836652278900146
        vf_loss: 10.360232228818147
    num_steps_sampled: 3640320
    num_steps_trained: 3640320
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.066666666666663
    gpu_util_percent0: 0.37799999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.377333333333333
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61353
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17684874293836036
    mean_env_wait_ms: 1.66488718310332
    mean_inference_ms: 4.7027750323228386
    mean_raw_obs_processing_ms: 0.5161978347844255
  time_since_restore: 645.53444647789
  time_this_iter_s: 64.41086387634277
  time_total_s: 645.53444647789
  timers:
    learn_throughput: 6937.421
    learn_time_ms: 52473.678
    sample_throughput: 30500.952
    sample_time_ms: 11935.103
    update_time_ms: 26.465
  timestamp: 1602420908
  timesteps_since_restore: 0
  timesteps_total: 3640320
  training_iteration: 10
  trial_id: 7876d_00000
  
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | TERMINATED |       |     10 |          645.534 | 3640320 |  234.767 |               287.99 |              104.202 |            850.316 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7876d_00000 | TERMINATED |       |     10 |          645.534 | 3640320 |  234.767 |               287.99 |              104.202 |            850.316 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


