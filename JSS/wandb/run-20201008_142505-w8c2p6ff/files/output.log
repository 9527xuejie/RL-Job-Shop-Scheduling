2020-10-08 14:25:07,555	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_11823_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=33202)[0m 2020-10-08 14:25:10,570	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=33230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33194)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_14-25-42
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1623204231262207
        entropy_coeff: 0.0
        kl: 0.0048057976178824905
        model: {}
        policy_loss: -0.00972368239890784
        total_loss: 8.319466400146485
        vf_explained_var: 0.7498777508735657
        vf_loss: 8.328228569030761
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.63333333333333
    gpu_util_percent0: 0.26266666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003333333333333333
    ram_util_percent: 9.49
    vram_util_percent0: 0.2729856783644911
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17678140968259154
    mean_env_wait_ms: 1.6502532711659141
    mean_inference_ms: 5.870735121936333
    mean_raw_obs_processing_ms: 0.4788182656976241
  time_since_restore: 25.622228860855103
  time_this_iter_s: 25.622228860855103
  time_total_s: 25.622228860855103
  timers:
    learn_throughput: 10340.312
    learn_time_ms: 15646.724
    sample_throughput: 16338.488
    sample_time_ms: 9902.507
    update_time_ms: 42.975
  timestamp: 1602167142
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3217.0
  date: 2020-10-08_14-26-06
  done: false
  episode_len_mean: 870.7974683544304
  episode_reward_max: 278.3535353535354
  episode_reward_mean: 226.3724267996418
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.138706338405609
        entropy_coeff: 0.0
        kl: 0.006825200421735645
        model: {}
        policy_loss: -0.01274334719637409
        total_loss: 7.690042400360108
        vf_explained_var: 0.8869457244873047
        vf_loss: 7.702103328704834
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.425925925925924
    gpu_util_percent0: 0.3437037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.73703703703704
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17196632938280343
    mean_env_wait_ms: 1.646491991621751
    mean_inference_ms: 5.588687582318563
    mean_raw_obs_processing_ms: 0.467505042931231
  time_since_restore: 49.39094591140747
  time_this_iter_s: 23.768717050552368
  time_total_s: 49.39094591140747
  timers:
    learn_throughput: 10452.268
    learn_time_ms: 15479.129
    sample_throughput: 17702.943
    sample_time_ms: 9139.271
    update_time_ms: 38.137
  timestamp: 1602167166
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3217.0
  date: 2020-10-08_14-26-30
  done: false
  episode_len_mean: 866.331223628692
  episode_reward_max: 278.3535353535354
  episode_reward_mean: 226.87126539658163
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.1217446804046631
        entropy_coeff: 0.0
        kl: 0.007683717552572489
        model: {}
        policy_loss: -0.014337884564884006
        total_loss: 8.763248443603516
        vf_explained_var: 0.9284197092056274
        vf_loss: 8.77681770324707
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.08620689655172
    gpu_util_percent0: 0.3172413793103448
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755172413793105
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16894469760208242
    mean_env_wait_ms: 1.6450424063300917
    mean_inference_ms: 5.427040881695507
    mean_raw_obs_processing_ms: 0.45877313240781425
  time_since_restore: 73.57178139686584
  time_this_iter_s: 24.180835485458374
  time_total_s: 73.57178139686584
  timers:
    learn_throughput: 10452.901
    learn_time_ms: 15478.191
    sample_throughput: 18089.282
    sample_time_ms: 8944.081
    update_time_ms: 56.055
  timestamp: 1602167190
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3217.0
  date: 2020-10-08_14-26-54
  done: false
  episode_len_mean: 861.253164556962
  episode_reward_max: 278.3535353535354
  episode_reward_mean: 227.7450294080039
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0939712405204773
        entropy_coeff: 0.0
        kl: 0.009209706541150808
        model: {}
        policy_loss: -0.015771377924829723
        total_loss: 8.429035234451295
        vf_explained_var: 0.9521434903144836
        vf_loss: 8.443885612487794
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.03333333333334
    gpu_util_percent0: 0.2777777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16676384022481172
    mean_env_wait_ms: 1.6466515242102222
    mean_inference_ms: 5.307577815654116
    mean_raw_obs_processing_ms: 0.4522795805237597
  time_since_restore: 97.21736693382263
  time_this_iter_s: 23.645585536956787
  time_total_s: 97.21736693382263
  timers:
    learn_throughput: 10478.311
    learn_time_ms: 15440.657
    sample_throughput: 18466.869
    sample_time_ms: 8761.204
    update_time_ms: 52.666
  timestamp: 1602167214
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3217.0
  date: 2020-10-08_14-27-17
  done: false
  episode_len_mean: 849.2613882863341
  episode_reward_max: 278.3535353535354
  episode_reward_mean: 228.4696860141544
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 290
  episodes_total: 922
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0592716097831727
        entropy_coeff: 0.0
        kl: 0.007743995590135455
        model: {}
        policy_loss: -0.014329827937763185
        total_loss: 12.433664703369141
        vf_explained_var: 0.967904269695282
        vf_loss: 12.447219848632812
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.35357142857143
    gpu_util_percent0: 0.2582142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746428571428572
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16431055835082262
    mean_env_wait_ms: 1.6540874340682217
    mean_inference_ms: 5.1659246506223315
    mean_raw_obs_processing_ms: 0.4451297976580212
  time_since_restore: 120.98013472557068
  time_this_iter_s: 23.762767791748047
  time_total_s: 120.98013472557068
  timers:
    learn_throughput: 10471.141
    learn_time_ms: 15451.229
    sample_throughput: 18710.121
    sample_time_ms: 8647.299
    update_time_ms: 46.768
  timestamp: 1602167237
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3217.0
  date: 2020-10-08_14-27-41
  done: false
  episode_len_mean: 842.2649186256781
  episode_reward_max: 278.3535353535354
  episode_reward_mean: 228.83911447202573
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 184
  episodes_total: 1106
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0483574509620666
        entropy_coeff: 0.0
        kl: 0.007546161720529199
        model: {}
        policy_loss: -0.015934903593733906
        total_loss: 6.211568450927734
        vf_explained_var: 0.979483425617218
        vf_loss: 6.22674880027771
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.42962962962963
    gpu_util_percent0: 0.23518518518518516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16320835121240662
    mean_env_wait_ms: 1.658072254904595
    mean_inference_ms: 5.101929976377745
    mean_raw_obs_processing_ms: 0.44197622201871506
  time_since_restore: 144.46361637115479
  time_this_iter_s: 23.483481645584106
  time_total_s: 144.46361637115479
  timers:
    learn_throughput: 10482.756
    learn_time_ms: 15434.108
    sample_throughput: 18930.618
    sample_time_ms: 8546.578
    update_time_ms: 45.48
  timestamp: 1602167261
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-28-05
  done: false
  episode_len_mean: 837.381329113924
  episode_reward_max: 279.83838383838383
  episode_reward_mean: 228.88543664493022
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0276257395744324
        entropy_coeff: 0.0
        kl: 0.006892968993633985
        model: {}
        policy_loss: -0.01625481452792883
        total_loss: 5.934515047073364
        vf_explained_var: 0.9834254384040833
        vf_loss: 5.950080394744873
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.47777777777778
    gpu_util_percent0: 0.2955555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16243749898577767
    mean_env_wait_ms: 1.6615503416153818
    mean_inference_ms: 5.056720554339727
    mean_raw_obs_processing_ms: 0.439742077717109
  time_since_restore: 168.09322547912598
  time_this_iter_s: 23.62960910797119
  time_total_s: 168.09322547912598
  timers:
    learn_throughput: 10486.247
    learn_time_ms: 15428.971
    sample_throughput: 19063.221
    sample_time_ms: 8487.128
    update_time_ms: 45.241
  timestamp: 1602167285
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-28-28
  done: false
  episode_len_mean: 833.6736990154711
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 229.3878233814942
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9920619606971741
        entropy_coeff: 0.0
        kl: 0.0067844231147319075
        model: {}
        policy_loss: -0.01662699868902564
        total_loss: 5.330079460144043
        vf_explained_var: 0.9873720407485962
        vf_loss: 5.346027898788452
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.72222222222223
    gpu_util_percent0: 0.2811111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16179048159969586
    mean_env_wait_ms: 1.664834322637065
    mean_inference_ms: 5.017627986563437
    mean_raw_obs_processing_ms: 0.43762471876215703
  time_since_restore: 191.7211263179779
  time_this_iter_s: 23.62790083885193
  time_total_s: 191.7211263179779
  timers:
    learn_throughput: 10499.739
    learn_time_ms: 15409.145
    sample_throughput: 19126.146
    sample_time_ms: 8459.205
    update_time_ms: 44.366
  timestamp: 1602167308
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-28-52
  done: false
  episode_len_mean: 827.9994246260069
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 229.99320593739455
  episode_reward_min: 114.74747474747485
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9606243968009949
        entropy_coeff: 0.0
        kl: 0.005957465758547187
        model: {}
        policy_loss: -0.013455570582300425
        total_loss: 7.494734096527099
        vf_explained_var: 0.9888100624084473
        vf_loss: 7.5075939178466795
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.90357142857143
    gpu_util_percent0: 0.26678571428571424
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746428571428572
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16076244116115793
    mean_env_wait_ms: 1.6704480394177186
    mean_inference_ms: 4.955192966914281
    mean_raw_obs_processing_ms: 0.4343471050403994
  time_since_restore: 215.57324147224426
  time_this_iter_s: 23.852115154266357
  time_total_s: 215.57324147224426
  timers:
    learn_throughput: 10506.415
    learn_time_ms: 15399.353
    sample_throughput: 19131.856
    sample_time_ms: 8456.681
    update_time_ms: 41.666
  timestamp: 1602167332
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-29-16
  done: false
  episode_len_mean: 826.5395569620254
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 230.1556546477432
  episode_reward_min: 114.74747474747485
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9285854279994965
        entropy_coeff: 0.0
        kl: 0.0062581704463809725
        model: {}
        policy_loss: -0.016021200059913098
        total_loss: 3.8204103231430055
        vf_explained_var: 0.9922056198120117
        vf_loss: 3.835805630683899
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.096296296296295
    gpu_util_percent0: 0.25592592592592595
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1603412050605606
    mean_env_wait_ms: 1.6728638400028686
    mean_inference_ms: 4.929926052491426
    mean_raw_obs_processing_ms: 0.4330192737930434
  time_since_restore: 238.919837474823
  time_this_iter_s: 23.346596002578735
  time_total_s: 238.919837474823
  timers:
    learn_throughput: 10519.707
    learn_time_ms: 15379.897
    sample_throughput: 19222.536
    sample_time_ms: 8416.788
    update_time_ms: 40.812
  timestamp: 1602167356
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-29-39
  done: false
  episode_len_mean: 825.4615384615385
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 230.21514069615333
  episode_reward_min: 114.74747474747485
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9235042989253998
        entropy_coeff: 0.0
        kl: 0.005789411393925548
        model: {}
        policy_loss: -0.014859883906319737
        total_loss: 4.004831600189209
        vf_explained_var: 0.9919689893722534
        vf_loss: 4.019112539291382
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.4
    gpu_util_percent0: 0.3125925925925926
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15996985034496003
    mean_env_wait_ms: 1.675007114196491
    mean_inference_ms: 4.907016710777437
    mean_raw_obs_processing_ms: 0.4317794077781022
  time_since_restore: 262.4391770362854
  time_this_iter_s: 23.519339561462402
  time_total_s: 262.4391770362854
  timers:
    learn_throughput: 10544.089
    learn_time_ms: 15344.332
    sample_throughput: 19638.715
    sample_time_ms: 8238.421
    update_time_ms: 40.485
  timestamp: 1602167379
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-30-03
  done: false
  episode_len_mean: 824.152428057554
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 230.18242224402292
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 170
  episodes_total: 2224
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.8818272411823272
        entropy_coeff: 0.0
        kl: 0.005413110228255391
        model: {}
        policy_loss: -0.013095138547942042
        total_loss: 5.083396100997925
        vf_explained_var: 0.9921062588691711
        vf_loss: 5.0959498405456545
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.042857142857144
    gpu_util_percent0: 0.1942857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15960744702974256
    mean_env_wait_ms: 1.677271579492208
    mean_inference_ms: 4.884761150099492
    mean_raw_obs_processing_ms: 0.4305594741365648
  time_since_restore: 286.0365300178528
  time_this_iter_s: 23.597352981567383
  time_total_s: 286.0365300178528
  timers:
    learn_throughput: 10540.17
    learn_time_ms: 15350.038
    sample_throughput: 19693.201
    sample_time_ms: 8215.627
    update_time_ms: 39.264
  timestamp: 1602167403
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-30-27
  done: false
  episode_len_mean: 822.2670094936709
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 230.69313387034907
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 304
  episodes_total: 2528
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.8522311568260192
        entropy_coeff: 0.0
        kl: 0.005159769672900438
        model: {}
        policy_loss: -0.012773643853142858
        total_loss: 5.1331462383270265
        vf_explained_var: 0.9925912618637085
        vf_loss: 5.145403909683227
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.01481481481482
    gpu_util_percent0: 0.30111111111111116
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15905681990758594
    mean_env_wait_ms: 1.68066117965344
    mean_inference_ms: 4.850479242048183
    mean_raw_obs_processing_ms: 0.4287066632526924
  time_since_restore: 309.50186347961426
  time_this_iter_s: 23.465333461761475
  time_total_s: 309.50186347961426
  timers:
    learn_throughput: 10553.501
    learn_time_ms: 15330.648
    sample_throughput: 19829.166
    sample_time_ms: 8159.294
    update_time_ms: 40.29
  timestamp: 1602167427
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-30-50
  done: false
  episode_len_mean: 821.4538346984364
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 230.94512511563886
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.8369874477386474
        entropy_coeff: 0.0
        kl: 0.005370886158198118
        model: {}
        policy_loss: -0.01467731585726142
        total_loss: 3.154995489120483
        vf_explained_var: 0.9942510724067688
        vf_loss: 3.1691357612609865
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.181481481481484
    gpu_util_percent0: 0.3040740740740741
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1588082507195649
    mean_env_wait_ms: 1.6822641931487865
    mean_inference_ms: 4.835116455543884
    mean_raw_obs_processing_ms: 0.42786989591003743
  time_since_restore: 332.9755485057831
  time_this_iter_s: 23.473685026168823
  time_total_s: 332.9755485057831
  timers:
    learn_throughput: 10555.883
    learn_time_ms: 15327.187
    sample_throughput: 19878.044
    sample_time_ms: 8139.232
    update_time_ms: 45.711
  timestamp: 1602167450
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-31-14
  done: false
  episode_len_mean: 820.854781997187
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 231.2064917813863
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.827689278125763
        entropy_coeff: 0.0
        kl: 0.005339382635429502
        model: {}
        policy_loss: -0.014263017289340495
        total_loss: 3.00002179145813
        vf_explained_var: 0.9941463470458984
        vf_loss: 3.0137508869171143
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.57037037037037
    gpu_util_percent0: 0.2274074074074074
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77037037037037
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15857855076630387
    mean_env_wait_ms: 1.6837618809370547
    mean_inference_ms: 4.820936656490715
    mean_raw_obs_processing_ms: 0.4270767088680792
  time_since_restore: 356.605441570282
  time_this_iter_s: 23.6298930644989
  time_total_s: 356.605441570282
  timers:
    learn_throughput: 10553.654
    learn_time_ms: 15330.425
    sample_throughput: 19924.68
    sample_time_ms: 8120.181
    update_time_ms: 47.653
  timestamp: 1602167474
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-31-38
  done: false
  episode_len_mean: 820.0182767624021
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 231.22214310203864
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 220
  episodes_total: 3064
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.7918125212192535
        entropy_coeff: 0.0
        kl: 0.004892151476815343
        model: {}
        policy_loss: -0.012084704916924238
        total_loss: 4.1488186597824095
        vf_explained_var: 0.9942665100097656
        vf_loss: 4.160414218902588
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.81481481481482
    gpu_util_percent0: 0.3077777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.158297804116007
    mean_env_wait_ms: 1.6859562656031242
    mean_inference_ms: 4.803618536248515
    mean_raw_obs_processing_ms: 0.42616514556223817
  time_since_restore: 380.0873718261719
  time_this_iter_s: 23.481930255889893
  time_total_s: 380.0873718261719
  timers:
    learn_throughput: 10556.149
    learn_time_ms: 15326.802
    sample_throughput: 19915.022
    sample_time_ms: 8124.119
    update_time_ms: 46.174
  timestamp: 1602167498
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-32-01
  done: false
  episode_len_mean: 819.2076552139844
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 231.34207049396923
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 254
  episodes_total: 3318
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.7639730334281921
        entropy_coeff: 0.0
        kl: 0.004952558875083923
        model: {}
        policy_loss: -0.011812644638121128
        total_loss: 3.641219711303711
        vf_explained_var: 0.9940530061721802
        vf_loss: 3.6527847766876222
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.58928571428571
    gpu_util_percent0: 0.33428571428571435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746428571428572
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579861428053209
    mean_env_wait_ms: 1.6878268274425987
    mean_inference_ms: 4.784786851610141
    mean_raw_obs_processing_ms: 0.4251258149287427
  time_since_restore: 403.5224757194519
  time_this_iter_s: 23.43510389328003
  time_total_s: 403.5224757194519
  timers:
    learn_throughput: 10564.477
    learn_time_ms: 15314.719
    sample_throughput: 19933.192
    sample_time_ms: 8116.713
    update_time_ms: 45.777
  timestamp: 1602167521
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-32-25
  done: false
  episode_len_mean: 818.5304948216341
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 231.56991956387816
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 0.7660917460918426
        entropy_coeff: 0.0
        kl: 0.005422895355150103
        model: {}
        policy_loss: -0.013137935660779476
        total_loss: 2.9323360919952393
        vf_explained_var: 0.9942866563796997
        vf_loss: 2.94533851146698
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.25925925925925
    gpu_util_percent0: 0.36148148148148146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.759259259259261
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15781721284272957
    mean_env_wait_ms: 1.6890502862525536
    mean_inference_ms: 4.774409463690571
    mean_raw_obs_processing_ms: 0.4245721837690542
  time_since_restore: 426.88156366348267
  time_this_iter_s: 23.35908794403076
  time_total_s: 426.88156366348267
  timers:
    learn_throughput: 10562.111
    learn_time_ms: 15318.149
    sample_throughput: 20027.117
    sample_time_ms: 8078.647
    update_time_ms: 51.49
  timestamp: 1602167545
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-32-49
  done: false
  episode_len_mean: 817.8346629986245
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 231.78994900865604
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 159
  episodes_total: 3635
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 0.761504179239273
        entropy_coeff: 0.0
        kl: 0.00561123825609684
        model: {}
        policy_loss: -0.01371184946037829
        total_loss: 2.586661458015442
        vf_explained_var: 0.9948149919509888
        vf_loss: 2.6002331018447875
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.98518518518519
    gpu_util_percent0: 0.25
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576552038626758
    mean_env_wait_ms: 1.6902745430630273
    mean_inference_ms: 4.764639495963006
    mean_raw_obs_processing_ms: 0.42404147010851506
  time_since_restore: 450.4647214412689
  time_this_iter_s: 23.583157777786255
  time_total_s: 450.4647214412689
  timers:
    learn_throughput: 10558.952
    learn_time_ms: 15322.733
    sample_throughput: 20107.322
    sample_time_ms: 8046.422
    update_time_ms: 53.421
  timestamp: 1602167569
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-33-12
  done: false
  episode_len_mean: 816.6687881873727
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 232.22543664753442
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 293
  episodes_total: 3928
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 0.7176933705806732
        entropy_coeff: 0.0
        kl: 0.004935431573539972
        model: {}
        policy_loss: -0.011507348460145294
        total_loss: 3.7333247661590576
        vf_explained_var: 0.9947683215141296
        vf_loss: 3.744708704948425
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.92962962962963
    gpu_util_percent0: 0.22925925925925927
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15738510281829127
    mean_env_wait_ms: 1.6923950386450304
    mean_inference_ms: 4.748233050103123
    mean_raw_obs_processing_ms: 0.4231474863161252
  time_since_restore: 473.9994788169861
  time_this_iter_s: 23.534757375717163
  time_total_s: 473.9994788169861
  timers:
    learn_throughput: 10546.772
    learn_time_ms: 15340.429
    sample_throughput: 20112.723
    sample_time_ms: 8044.261
    update_time_ms: 53.96
  timestamp: 1602167592
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-33-36
  done: false
  episode_len_mean: 815.9362220058423
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 232.68833171048362
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 180
  episodes_total: 4108
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.6961194634437561
        entropy_coeff: 0.0
        kl: 0.0054001738782972096
        model: {}
        policy_loss: -0.013575149234384298
        total_loss: 2.1967584609985353
        vf_explained_var: 0.9954622387886047
        vf_loss: 2.210266089439392
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.440740740740736
    gpu_util_percent0: 0.29666666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15722895249997093
    mean_env_wait_ms: 1.6936030533075188
    mean_inference_ms: 4.738907510439971
    mean_raw_obs_processing_ms: 0.42262820408828605
  time_since_restore: 497.52709674835205
  time_this_iter_s: 23.527617931365967
  time_total_s: 497.52709674835205
  timers:
    learn_throughput: 10537.753
    learn_time_ms: 15353.558
    sample_throughput: 20139.989
    sample_time_ms: 8033.371
    update_time_ms: 52.995
  timestamp: 1602167616
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-34-00
  done: false
  episode_len_mean: 815.2585560243788
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 232.9339172313856
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.7063014328479766
        entropy_coeff: 0.0
        kl: 0.005521039292216301
        model: {}
        policy_loss: -0.013345666276291013
        total_loss: 2.40686240196228
        vf_explained_var: 0.994661808013916
        vf_loss: 2.4201390743255615
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.3
    gpu_util_percent0: 0.3596428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15710538677505165
    mean_env_wait_ms: 1.694637493002915
    mean_inference_ms: 4.731284261187251
    mean_raw_obs_processing_ms: 0.42220494507105216
  time_since_restore: 521.2907056808472
  time_this_iter_s: 23.763608932495117
  time_total_s: 521.2907056808472
  timers:
    learn_throughput: 10529.291
    learn_time_ms: 15365.897
    sample_throughput: 20152.527
    sample_time_ms: 8028.373
    update_time_ms: 60.563
  timestamp: 1602167640
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-34-24
  done: false
  episode_len_mean: 814.5122444394518
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 233.18438711990723
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 185
  episodes_total: 4451
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.687007212638855
        entropy_coeff: 0.0
        kl: 0.005151082994416356
        model: {}
        policy_loss: -0.0136242700740695
        total_loss: 2.3987212419509887
        vf_explained_var: 0.9956458210945129
        vf_loss: 2.412281060218811
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.87777777777778
    gpu_util_percent0: 0.32259259259259254
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15697868978775206
    mean_env_wait_ms: 1.6959996633636125
    mean_inference_ms: 4.723299684373984
    mean_raw_obs_processing_ms: 0.42177767922029563
  time_since_restore: 544.7509255409241
  time_this_iter_s: 23.460219860076904
  time_total_s: 544.7509255409241
  timers:
    learn_throughput: 10523.637
    learn_time_ms: 15374.152
    sample_throughput: 20153.695
    sample_time_ms: 8027.908
    update_time_ms: 54.413
  timestamp: 1602167664
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-34-48
  done: false
  episode_len_mean: 813.3535864978903
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 233.57533989685885
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 289
  episodes_total: 4740
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.6324166178703308
        entropy_coeff: 0.0
        kl: 0.0048749387264251706
        model: {}
        policy_loss: -0.011797640426084399
        total_loss: 2.6533204078674317
        vf_explained_var: 0.9955232739448547
        vf_loss: 2.66505708694458
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.074074074074076
    gpu_util_percent0: 0.3251851851851852
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15677630383088909
    mean_env_wait_ms: 1.6975983446472827
    mean_inference_ms: 4.710750302441915
    mean_raw_obs_processing_ms: 0.421060709542158
  time_since_restore: 568.4359018802643
  time_this_iter_s: 23.68497633934021
  time_total_s: 568.4359018802643
  timers:
    learn_throughput: 10517.772
    learn_time_ms: 15382.726
    sample_throughput: 20124.264
    sample_time_ms: 8039.648
    update_time_ms: 48.571
  timestamp: 1602167688
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-35-11
  done: false
  episode_len_mean: 812.6929358922009
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 233.80383252698485
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 158
  episodes_total: 4898
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 0.0001
        entropy: 0.6476718962192536
        entropy_coeff: 0.0
        kl: 0.004980697343125939
        model: {}
        policy_loss: -0.012937380420044064
        total_loss: 2.2160698890686037
        vf_explained_var: 0.9949172735214233
        vf_loss: 2.2289761781692503
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.93703703703704
    gpu_util_percent0: 0.2511111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15667803602924033
    mean_env_wait_ms: 1.6985389146300989
    mean_inference_ms: 4.704622565044838
    mean_raw_obs_processing_ms: 0.420720785257639
  time_since_restore: 592.1190402507782
  time_this_iter_s: 23.683138370513916
  time_total_s: 592.1190402507782
  timers:
    learn_throughput: 10525.475
    learn_time_ms: 15371.468
    sample_throughput: 20083.377
    sample_time_ms: 8056.016
    update_time_ms: 47.817
  timestamp: 1602167711
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_11823_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3204.0
  date: 2020-10-08_14-35-35
  done: true
  episode_len_mean: 812.0104784499803
  episode_reward_max: 281.6060606060598
  episode_reward_mean: 234.07366667864886
  episode_reward_min: 99.12121212121178
  episodes_this_iter: 160
  episodes_total: 5058
  experiment_id: 421e23f0dd5440b2b1dad81139e219db
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 0.0001
        entropy: 0.6387091696262359
        entropy_coeff: 0.0
        kl: 0.00521918865852058
        model: {}
        policy_loss: -0.013382896583061665
        total_loss: 2.0056067228317263
        vf_explained_var: 0.9955011606216431
        vf_loss: 2.0189733505249023
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.729629629629635
    gpu_util_percent0: 0.267037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33202
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15658306876779257
    mean_env_wait_ms: 1.6995085455679213
    mean_inference_ms: 4.6987769399539845
    mean_raw_obs_processing_ms: 0.42039589930108456
  time_since_restore: 615.6618909835815
  time_this_iter_s: 23.542850732803345
  time_total_s: 615.6618909835815
  timers:
    learn_throughput: 10524.21
    learn_time_ms: 15373.315
    sample_throughput: 20076.608
    sample_time_ms: 8058.732
    update_time_ms: 48.59
  timestamp: 1602167735
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: '11823_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


