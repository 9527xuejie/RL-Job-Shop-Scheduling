2020-10-11 21:00:41,272	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_d30a2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=62234)[0m 2020-10-11 21:00:44,003	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=62115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62174)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_21-01-22
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1846147278944652
        entropy_coeff: 0.0005000000000000001
        kl: 0.004924804321490228
        model: {}
        policy_loss: -0.010641525208484381
        total_loss: 502.23648834228516
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.894871794871793
    gpu_util_percent0: 0.25230769230769234
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.582051282051281
    vram_util_percent0: 0.08867766649006405
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16887927430763258
    mean_env_wait_ms: 1.1652203760385587
    mean_inference_ms: 5.934694631116631
    mean_raw_obs_processing_ms: 0.4534957010681962
  time_since_restore: 33.12209439277649
  time_this_iter_s: 33.12209439277649
  time_total_s: 33.12209439277649
  timers:
    learn_throughput: 6869.662
    learn_time_ms: 23551.669
    sample_throughput: 17049.89
    sample_time_ms: 9489.328
    update_time_ms: 51.755
  timestamp: 1602450082
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      1 |          33.1221 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4185
    time_step_mean: 3622.6423611111113
    time_step_min: 3341
  date: 2020-10-11_21-01-53
  done: false
  episode_len_mean: 890.2246835443038
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 216.1472637770104
  episode_reward_min: 131.9292929292925
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1507324576377869
        entropy_coeff: 0.0005000000000000001
        kl: 0.007903704070486128
        model: {}
        policy_loss: -0.010593259202626845
        total_loss: 127.33559099833171
        vf_explained_var: 0.8138229846954346
        vf_loss: 127.34597078959148
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.302777777777777
    gpu_util_percent0: 0.3425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666675
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16469611100466625
    mean_env_wait_ms: 1.1624384045473164
    mean_inference_ms: 5.672675291257544
    mean_raw_obs_processing_ms: 0.44142359944225423
  time_since_restore: 64.31196713447571
  time_this_iter_s: 31.18987274169922
  time_total_s: 64.31196713447571
  timers:
    learn_throughput: 6896.064
    learn_time_ms: 23461.5
    sample_throughput: 18778.059
    sample_time_ms: 8616.013
    update_time_ms: 40.765
  timestamp: 1602450113
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      2 |           64.312 | 323584 |  216.147 |              262.687 |              131.929 |            890.225 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4185
    time_step_mean: 3625.3340807174886
    time_step_min: 3341
  date: 2020-10-11_21-02-24
  done: false
  episode_len_mean: 885.3924050632911
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 216.5537015726887
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1411346793174744
        entropy_coeff: 0.0005000000000000001
        kl: 0.009678286267444491
        model: {}
        policy_loss: -0.014822538554047545
        total_loss: 59.26638380686442
        vf_explained_var: 0.9010727405548096
        vf_loss: 59.28081130981445
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.93333333333333
    gpu_util_percent0: 0.43
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769444444444445
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16186127073412962
    mean_env_wait_ms: 1.1628950307695645
    mean_inference_ms: 5.463932506862992
    mean_raw_obs_processing_ms: 0.4320148359300278
  time_since_restore: 94.81541085243225
  time_this_iter_s: 30.503443717956543
  time_total_s: 94.81541085243225
  timers:
    learn_throughput: 6905.671
    learn_time_ms: 23428.86
    sample_throughput: 19990.535
    sample_time_ms: 8093.43
    update_time_ms: 40.168
  timestamp: 1602450144
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      3 |          94.8154 | 485376 |  216.554 |              262.687 |               88.596 |            885.392 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3625.890728476821
    time_step_min: 3319
  date: 2020-10-11_21-02-54
  done: false
  episode_len_mean: 881.0474683544304
  episode_reward_max: 263.1414141414135
  episode_reward_mean: 216.6672580232705
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1199288368225098
        entropy_coeff: 0.0005000000000000001
        kl: 0.008813565596938133
        model: {}
        policy_loss: -0.01598833860286201
        total_loss: 43.194626808166504
        vf_explained_var: 0.9295213222503662
        vf_loss: 43.21029249827067
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.625714285714285
    gpu_util_percent0: 0.39542857142857146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15980628331144572
    mean_env_wait_ms: 1.1637984117526274
    mean_inference_ms: 5.311069396510328
    mean_raw_obs_processing_ms: 0.42492139608903734
  time_since_restore: 125.31587386131287
  time_this_iter_s: 30.500463008880615
  time_total_s: 125.31587386131287
  timers:
    learn_throughput: 6891.886
    learn_time_ms: 23475.723
    sample_throughput: 20825.108
    sample_time_ms: 7769.083
    update_time_ms: 40.082
  timestamp: 1602450174
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      4 |          125.316 | 647168 |  216.667 |              263.141 |               88.596 |            881.047 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3617.989501312336
    time_step_min: 3319
  date: 2020-10-11_21-03-25
  done: false
  episode_len_mean: 876.6645569620254
  episode_reward_max: 266.4747474747477
  episode_reward_mean: 217.92468993734798
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0852691729863484
        entropy_coeff: 0.0005000000000000001
        kl: 0.008571949942658344
        model: {}
        policy_loss: -0.015522021086023111
        total_loss: 32.49041668574015
        vf_explained_var: 0.9495692253112793
        vf_loss: 32.50562445322672
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.336111111111112
    gpu_util_percent0: 0.29750000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15827940346203617
    mean_env_wait_ms: 1.1653887755618106
    mean_inference_ms: 5.19521798517494
    mean_raw_obs_processing_ms: 0.41936086879997186
  time_since_restore: 155.66413283348083
  time_this_iter_s: 30.34825897216797
  time_total_s: 155.66413283348083
  timers:
    learn_throughput: 6896.237
    learn_time_ms: 23460.91
    sample_throughput: 21322.79
    sample_time_ms: 7587.75
    update_time_ms: 39.805
  timestamp: 1602450205
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      5 |          155.664 | 808960 |  217.925 |              266.475 |               88.596 |            876.665 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3598.4014869888474
    time_step_min: 3287
  date: 2020-10-11_21-03-55
  done: false
  episode_len_mean: 867.0471014492754
  episode_reward_max: 267.98989898989913
  episode_reward_mean: 220.5384826526129
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0762771268685658
        entropy_coeff: 0.0005000000000000001
        kl: 0.00847935164347291
        model: {}
        policy_loss: -0.014069491167902015
        total_loss: 36.22017447153727
        vf_explained_var: 0.9600384831428528
        vf_loss: 36.23393313090006
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.61666666666667
    gpu_util_percent0: 0.3075
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15622966249322434
    mean_env_wait_ms: 1.1691919550324101
    mean_inference_ms: 5.040222246072178
    mean_raw_obs_processing_ms: 0.41225482870607244
  time_since_restore: 186.20327401161194
  time_this_iter_s: 30.539141178131104
  time_total_s: 186.20327401161194
  timers:
    learn_throughput: 6892.876
    learn_time_ms: 23472.352
    sample_throughput: 21678.309
    sample_time_ms: 7463.313
    update_time_ms: 39.318
  timestamp: 1602450235
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      6 |          186.203 | 970752 |  220.538 |               267.99 |               88.596 |            867.047 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3586.6108414239484
    time_step_min: 3287
  date: 2020-10-11_21-04-26
  done: false
  episode_len_mean: 862.6424050632911
  episode_reward_max: 272.53535353535324
  episode_reward_mean: 222.52336657716384
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0611263513565063
        entropy_coeff: 0.0005000000000000001
        kl: 0.00855419528670609
        model: {}
        policy_loss: -0.01313585601747036
        total_loss: 17.229157129923504
        vf_explained_var: 0.9695212244987488
        vf_loss: 17.24196783701579
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.540000000000003
    gpu_util_percent0: 0.35828571428571426
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15548233344232182
    mean_env_wait_ms: 1.1708512091965155
    mean_inference_ms: 4.983543307465965
    mean_raw_obs_processing_ms: 0.40964623597366495
  time_since_restore: 216.3135061264038
  time_this_iter_s: 30.11023211479187
  time_total_s: 216.3135061264038
  timers:
    learn_throughput: 6902.224
    learn_time_ms: 23440.561
    sample_throughput: 21962.517
    sample_time_ms: 7366.733
    update_time_ms: 37.105
  timestamp: 1602450266
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      7 |          216.314 | 1132544 |  222.523 |              272.535 |               88.596 |            862.642 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3574.7453371592537
    time_step_min: 3224
  date: 2020-10-11_21-04-56
  done: false
  episode_len_mean: 858.2257383966245
  episode_reward_max: 277.5353535353528
  episode_reward_mean: 224.2597707028085
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0459068516890209
        entropy_coeff: 0.0005000000000000001
        kl: 0.007586693585229416
        model: {}
        policy_loss: -0.01487944574910216
        total_loss: 17.728309154510498
        vf_explained_var: 0.9674603343009949
        vf_loss: 17.742952823638916
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.108571428571427
    gpu_util_percent0: 0.34142857142857147
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15484852031344556
    mean_env_wait_ms: 1.1723946225626019
    mean_inference_ms: 4.935319610478374
    mean_raw_obs_processing_ms: 0.4073959576250998
  time_since_restore: 246.65833735466003
  time_this_iter_s: 30.344831228256226
  time_total_s: 246.65833735466003
  timers:
    learn_throughput: 6902.671
    learn_time_ms: 23439.042
    sample_throughput: 22163.096
    sample_time_ms: 7300.063
    update_time_ms: 36.494
  timestamp: 1602450296
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      8 |          246.658 | 1294336 |   224.26 |              277.535 |               88.596 |            858.226 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3562.860824742268
    time_step_min: 3224
  date: 2020-10-11_21-05-27
  done: false
  episode_len_mean: 854.1151898734178
  episode_reward_max: 277.5353535353528
  episode_reward_mean: 226.03343562204307
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.009189561009407
        entropy_coeff: 0.0005000000000000001
        kl: 0.008226582664065063
        model: {}
        policy_loss: -0.015366594326527169
        total_loss: 15.938408533732096
        vf_explained_var: 0.9702828526496887
        vf_loss: 15.953457037607828
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.230555555555558
    gpu_util_percent0: 0.3875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15429921646813516
    mean_env_wait_ms: 1.1738557441960178
    mean_inference_ms: 4.893387847358218
    mean_raw_obs_processing_ms: 0.40537826928387494
  time_since_restore: 276.9730999469757
  time_this_iter_s: 30.314762592315674
  time_total_s: 276.9730999469757
  timers:
    learn_throughput: 6908.182
    learn_time_ms: 23420.345
    sample_throughput: 22276.345
    sample_time_ms: 7262.951
    update_time_ms: 35.637
  timestamp: 1602450327
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |      9 |          276.973 | 1456128 |  226.033 |              277.535 |               88.596 |            854.115 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3538.880580957504
    time_step_min: 3206
  date: 2020-10-11_21-05-57
  done: false
  episode_len_mean: 847.3190249072602
  episode_reward_max: 280.2626262626269
  episode_reward_mean: 229.68314303608406
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 307
  episodes_total: 1887
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9917601197957993
        entropy_coeff: 0.0005000000000000001
        kl: 0.00740070086127768
        model: {}
        policy_loss: -0.013341124024009332
        total_loss: 19.074730396270752
        vf_explained_var: 0.9753614068031311
        vf_loss: 19.08782688776652
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.336111111111116
    gpu_util_percent0: 0.3136111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15343374050409636
    mean_env_wait_ms: 1.17667846300532
    mean_inference_ms: 4.8275823426394275
    mean_raw_obs_processing_ms: 0.4023072510997309
  time_since_restore: 307.7368278503418
  time_this_iter_s: 30.76372790336609
  time_total_s: 307.7368278503418
  timers:
    learn_throughput: 6904.413
    learn_time_ms: 23433.129
    sample_throughput: 22319.849
    sample_time_ms: 7248.795
    update_time_ms: 36.049
  timestamp: 1602450357
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     10 |          307.737 | 1617920 |  229.683 |              280.263 |               88.596 |            847.319 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3528.9536031589337
    time_step_min: 3206
  date: 2020-10-11_21-06-28
  done: false
  episode_len_mean: 844.2448880233691
  episode_reward_max: 280.2626262626269
  episode_reward_mean: 231.221140322406
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9727244724829992
        entropy_coeff: 0.0005000000000000001
        kl: 0.0071904356591403484
        model: {}
        policy_loss: -0.014005071396240965
        total_loss: 11.84699296951294
        vf_explained_var: 0.9785725474357605
        vf_loss: 11.860765298207602
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.822857142857146
    gpu_util_percent0: 0.2691428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15304846538126063
    mean_env_wait_ms: 1.1780375325255315
    mean_inference_ms: 4.7982674724158
    mean_raw_obs_processing_ms: 0.40095765477356715
  time_since_restore: 338.18475675582886
  time_this_iter_s: 30.44792890548706
  time_total_s: 338.18475675582886
  timers:
    learn_throughput: 6913.174
    learn_time_ms: 23403.432
    sample_throughput: 23097.03
    sample_time_ms: 7004.883
    update_time_ms: 34.107
  timestamp: 1602450388
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     11 |          338.185 | 1779712 |  231.221 |              280.263 |               88.596 |            844.245 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3520.5668498168498
    time_step_min: 3206
  date: 2020-10-11_21-06-59
  done: false
  episode_len_mean: 841.4041591320072
  episode_reward_max: 280.2626262626269
  episode_reward_mean: 232.48480282024573
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9606796552737554
        entropy_coeff: 0.0005000000000000001
        kl: 0.007471592941631873
        model: {}
        policy_loss: -0.015197008498944342
        total_loss: 13.117705742518107
        vf_explained_var: 0.9743028283119202
        vf_loss: 13.132635911305746
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.897222222222226
    gpu_util_percent0: 0.4147222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527194748925166
    mean_env_wait_ms: 1.1791835293841875
    mean_inference_ms: 4.773281344852069
    mean_raw_obs_processing_ms: 0.39976067230768764
  time_since_restore: 368.73596835136414
  time_this_iter_s: 30.55121159553528
  time_total_s: 368.73596835136414
  timers:
    learn_throughput: 6914.09
    learn_time_ms: 23400.332
    sample_throughput: 23303.095
    sample_time_ms: 6942.94
    update_time_ms: 34.756
  timestamp: 1602450419
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     12 |          368.736 | 1941504 |  232.485 |              280.263 |               88.596 |            841.404 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3511.8174872665536
    time_step_min: 3206
  date: 2020-10-11_21-07-29
  done: false
  episode_len_mean: 838.8875838926175
  episode_reward_max: 284.20202020202026
  episode_reward_mean: 233.88233848552625
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 172
  episodes_total: 2384
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9221795598665873
        entropy_coeff: 0.0005000000000000001
        kl: 0.007596092570262651
        model: {}
        policy_loss: -0.015219444719453653
        total_loss: 13.35711113611857
        vf_explained_var: 0.977639377117157
        vf_loss: 13.372032086054483
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.862857142857145
    gpu_util_percent0: 0.3682857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523942099558525
    mean_env_wait_ms: 1.1804192519378311
    mean_inference_ms: 4.748654408011027
    mean_raw_obs_processing_ms: 0.3985611582953796
  time_since_restore: 399.1145372390747
  time_this_iter_s: 30.37856888771057
  time_total_s: 399.1145372390747
  timers:
    learn_throughput: 6910.719
    learn_time_ms: 23411.745
    sample_throughput: 23383.877
    sample_time_ms: 6918.955
    update_time_ms: 34.762
  timestamp: 1602450449
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     13 |          399.115 | 2103296 |  233.882 |              284.202 |               88.596 |            838.888 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3498.1188863807374
    time_step_min: 3188
  date: 2020-10-11_21-08-00
  done: false
  episode_len_mean: 834.5979151154132
  episode_reward_max: 284.20202020202026
  episode_reward_mean: 235.96700813044805
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 302
  episodes_total: 2686
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9214861939350764
        entropy_coeff: 0.0005000000000000001
        kl: 0.0071946926570187015
        model: {}
        policy_loss: -0.013351308540829146
        total_loss: 14.835413376490274
        vf_explained_var: 0.979828417301178
        vf_loss: 14.848505894343058
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.872222222222224
    gpu_util_percent0: 0.39527777777777773
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15190683901806337
    mean_env_wait_ms: 1.1825130963950208
    mean_inference_ms: 4.711374848328199
    mean_raw_obs_processing_ms: 0.39682556296823607
  time_since_restore: 429.5969123840332
  time_this_iter_s: 30.482375144958496
  time_total_s: 429.5969123840332
  timers:
    learn_throughput: 6911.54
    learn_time_ms: 23408.966
    sample_throughput: 23386.943
    sample_time_ms: 6918.048
    update_time_ms: 34.702
  timestamp: 1602450480
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     14 |          429.597 | 2265088 |  235.967 |              284.202 |               88.596 |            834.598 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3491.8394886363635
    time_step_min: 3188
  date: 2020-10-11_21-08-30
  done: false
  episode_len_mean: 832.3867791842475
  episode_reward_max: 284.20202020202026
  episode_reward_mean: 236.9671717171716
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9004226724306742
        entropy_coeff: 0.0005000000000000001
        kl: 0.007208069786429405
        model: {}
        policy_loss: -0.013761558337137103
        total_loss: 10.551711877187094
        vf_explained_var: 0.9797658324241638
        vf_loss: 10.565202951431274
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.10857142857143
    gpu_util_percent0: 0.3282857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15168287235937344
    mean_env_wait_ms: 1.183496362957713
    mean_inference_ms: 4.694325960713431
    mean_raw_obs_processing_ms: 0.39601435592329065
  time_since_restore: 459.8570351600647
  time_this_iter_s: 30.260122776031494
  time_total_s: 459.8570351600647
  timers:
    learn_throughput: 6912.22
    learn_time_ms: 23406.664
    sample_throughput: 23413.258
    sample_time_ms: 6910.273
    update_time_ms: 34.049
  timestamp: 1602450510
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     15 |          459.857 | 2426880 |  236.967 |              284.202 |               88.596 |            832.387 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3485.892064559516
    time_step_min: 3188
  date: 2020-10-11_21-09-00
  done: false
  episode_len_mean: 830.3870752831446
  episode_reward_max: 287.98989898989873
  episode_reward_mean: 237.99570320123274
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.883683979511261
        entropy_coeff: 0.0005000000000000001
        kl: 0.006876855467756589
        model: {}
        policy_loss: -0.015000158843273917
        total_loss: 9.659654299418131
        vf_explained_var: 0.9799847602844238
        vf_loss: 9.674408833185831
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.840000000000003
    gpu_util_percent0: 0.44428571428571423
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514746461245046
    mean_env_wait_ms: 1.1844410880214482
    mean_inference_ms: 4.678481471480669
    mean_raw_obs_processing_ms: 0.39524448825634456
  time_since_restore: 490.13888907432556
  time_this_iter_s: 30.281853914260864
  time_total_s: 490.13888907432556
  timers:
    learn_throughput: 6914.335
    learn_time_ms: 23399.501
    sample_throughput: 23450.474
    sample_time_ms: 6899.306
    update_time_ms: 34.184
  timestamp: 1602450540
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     16 |          490.139 | 2588672 |  237.996 |               287.99 |               88.596 |            830.387 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3475.6844047985237
    time_step_min: 3167
  date: 2020-10-11_21-09-31
  done: false
  episode_len_mean: 827.1854223848734
  episode_reward_max: 287.98989898989873
  episode_reward_mean: 239.62352712855906
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 277
  episodes_total: 3279
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8587738970915476
        entropy_coeff: 0.0005000000000000001
        kl: 0.006916678316580753
        model: {}
        policy_loss: -0.012511584752549728
        total_loss: 14.398477554321289
        vf_explained_var: 0.9803693890571594
        vf_loss: 14.41072670618693
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.485714285714284
    gpu_util_percent0: 0.39285714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511486396968897
    mean_env_wait_ms: 1.1860967504064093
    mean_inference_ms: 4.653291209728969
    mean_raw_obs_processing_ms: 0.39405856081131335
  time_since_restore: 520.2730791568756
  time_this_iter_s: 30.13419008255005
  time_total_s: 520.2730791568756
  timers:
    learn_throughput: 6914.466
    learn_time_ms: 23399.06
    sample_throughput: 23444.247
    sample_time_ms: 6901.139
    update_time_ms: 34.006
  timestamp: 1602450571
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     17 |          520.273 | 2750464 |  239.624 |               287.99 |               88.596 |            827.185 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3469.3190255220416
    time_step_min: 3144
  date: 2020-10-11_21-10-01
  done: false
  episode_len_mean: 824.9479286536249
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 240.624545222071
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 197
  episodes_total: 3476
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8442238519589106
        entropy_coeff: 0.0005000000000000001
        kl: 0.007084058636489014
        model: {}
        policy_loss: -0.014629053592216223
        total_loss: 10.824065446853638
        vf_explained_var: 0.9808571338653564
        vf_loss: 10.83840799331665
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.308333333333334
    gpu_util_percent0: 0.42805555555555563
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333345
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15093677769332092
    mean_env_wait_ms: 1.1871823911234791
    mean_inference_ms: 4.637721250806401
    mean_raw_obs_processing_ms: 0.393314944102691
  time_since_restore: 550.3701868057251
  time_this_iter_s: 30.097107648849487
  time_total_s: 550.3701868057251
  timers:
    learn_throughput: 6920.753
    learn_time_ms: 23377.803
    sample_throughput: 23462.07
    sample_time_ms: 6895.896
    update_time_ms: 34.336
  timestamp: 1602450601
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     18 |           550.37 | 2912256 |  240.625 |              289.657 |               88.596 |            824.948 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3465.189961175818
    time_step_min: 3144
  date: 2020-10-11_21-10-31
  done: false
  episode_len_mean: 823.5038525041277
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 241.21011713169108
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8410505006710688
        entropy_coeff: 0.0005000000000000001
        kl: 0.007028338382951915
        model: {}
        policy_loss: -0.012794313098614415
        total_loss: 10.480183601379395
        vf_explained_var: 0.9795172810554504
        vf_loss: 10.492695411046347
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.26571428571429
    gpu_util_percent0: 0.36314285714285716
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428585
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150779671387167
    mean_env_wait_ms: 1.187986519347687
    mean_inference_ms: 4.6259541351537345
    mean_raw_obs_processing_ms: 0.39275270462795464
  time_since_restore: 580.6426711082458
  time_this_iter_s: 30.272484302520752
  time_total_s: 580.6426711082458
  timers:
    learn_throughput: 6916.265
    learn_time_ms: 23392.971
    sample_throughput: 23535.681
    sample_time_ms: 6874.328
    update_time_ms: 35.399
  timestamp: 1602450631
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | RUNNING  | 172.17.0.4:62234 |     19 |          580.643 | 3074048 |   241.21 |              289.657 |               88.596 |            823.504 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d30a2_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3460.29231581727
    time_step_min: 3144
  date: 2020-10-11_21-11-02
  done: true
  episode_len_mean: 822.3347313237222
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 241.98501396666526
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 181
  episodes_total: 3815
  experiment_id: fa9e4c139297489a8cd593fcf1690cbf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8101343264182409
        entropy_coeff: 0.0005000000000000001
        kl: 0.007008894269044201
        model: {}
        policy_loss: -0.014301851236571869
        total_loss: 10.842975616455078
        vf_explained_var: 0.9824185371398926
        vf_loss: 10.856981674830118
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.07428571428572
    gpu_util_percent0: 0.26371428571428573
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62234
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15060905112235592
    mean_env_wait_ms: 1.1888454687989638
    mean_inference_ms: 4.613144975411359
    mean_raw_obs_processing_ms: 0.3921391510156757
  time_since_restore: 610.8664443492889
  time_this_iter_s: 30.22377324104309
  time_total_s: 610.8664443492889
  timers:
    learn_throughput: 6921.898
    learn_time_ms: 23373.937
    sample_throughput: 23656.066
    sample_time_ms: 6839.345
    update_time_ms: 34.998
  timestamp: 1602450662
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: d30a2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | TERMINATED |       |     20 |          610.866 | 3235840 |  241.985 |              289.657 |               88.596 |            822.335 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d30a2_00000 | TERMINATED |       |     20 |          610.866 | 3235840 |  241.985 |              289.657 |               88.596 |            822.335 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


