2020-11-01 12:04:54,756	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 12.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_74f1e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=52265)[0m 2020-11-01 12:04:57,569	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=52167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52160)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1270.6712550607288
    time_step_min: 1054
  date: 2020-11-01_12-05-25
  done: false
  episode_len_mean: 116.74350904799371
  episode_reward_max: 41.65306122448979
  episode_reward_mean: 30.6028275983879
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1271
  episodes_total: 1271
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1384523808956146
        entropy_coeff: 0.0005000000000000001
        kl: 0.006007326611628135
        model: {}
        policy_loss: -0.006815222654646884
        total_loss: 36.897240002950035
        vf_explained_var: 0.7482123374938965
        vf_loss: 36.903422355651855
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.62222222222222
    gpu_util_percent0: 0.40222222222222226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4333333333333336
    vram_util_percent0: 0.08172381958869332
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16969461340934525
    mean_env_wait_ms: 0.6709388448442125
    mean_inference_ms: 5.213710332296094
    mean_raw_obs_processing_ms: 0.4500044725167772
  time_since_restore: 22.275667190551758
  time_this_iter_s: 22.275667190551758
  time_total_s: 22.275667190551758
  timers:
    learn_throughput: 11194.703
    learn_time_ms: 14452.55
    sample_throughput: 20900.055
    sample_time_ms: 7741.224
    update_time_ms: 42.347
  timestamp: 1604232325
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      1 |          22.2757 | 161792 |  30.6028 |              41.6531 |              10.2755 |            116.744 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1252.1281568036186
    time_step_min: 1039
  date: 2020-11-01_12-05-46
  done: false
  episode_len_mean: 116.04722945332837
  episode_reward_max: 42.41836734693876
  episode_reward_mean: 31.48901419995294
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1418
  episodes_total: 2689
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1159119109312694
        entropy_coeff: 0.0005000000000000001
        kl: 0.010711442679166794
        model: {}
        policy_loss: -0.012819082303982062
        total_loss: 9.95718256632487
        vf_explained_var: 0.8801858425140381
        vf_loss: 9.968417485555014
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.4
    gpu_util_percent0: 0.3830769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5076923076923077
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1663996838490878
    mean_env_wait_ms: 0.6661199624654368
    mean_inference_ms: 5.065247663215141
    mean_raw_obs_processing_ms: 0.443431096131331
  time_since_restore: 43.45249390602112
  time_this_iter_s: 21.17682671546936
  time_total_s: 43.45249390602112
  timers:
    learn_throughput: 11200.574
    learn_time_ms: 14444.974
    sample_throughput: 22507.211
    sample_time_ms: 7188.452
    update_time_ms: 40.119
  timestamp: 1604232346
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      2 |          43.4525 | 323584 |   31.489 |              42.4184 |              10.2755 |            116.047 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1229.5523227383862
    time_step_min: 1039
  date: 2020-11-01_12-06-06
  done: false
  episode_len_mean: 114.94789142026175
  episode_reward_max: 42.41836734693877
  episode_reward_mean: 32.67046455033783
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1437
  episodes_total: 4126
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0916709005832672
        entropy_coeff: 0.0005000000000000001
        kl: 0.011045165204753479
        model: {}
        policy_loss: -0.012844632374860035
        total_loss: 6.921001553535461
        vf_explained_var: 0.9159042239189148
        vf_loss: 6.9321829080581665
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.06
    gpu_util_percent0: 0.4312
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.516
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16376589972908362
    mean_env_wait_ms: 0.6617033666285996
    mean_inference_ms: 4.920294910569432
    mean_raw_obs_processing_ms: 0.43664206722952675
  time_since_restore: 63.84919023513794
  time_this_iter_s: 20.39669632911682
  time_total_s: 63.84919023513794
  timers:
    learn_throughput: 11232.084
    learn_time_ms: 14404.451
    sample_throughput: 23846.064
    sample_time_ms: 6784.851
    update_time_ms: 37.748
  timestamp: 1604232366
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      3 |          63.8492 | 485376 |  32.6705 |              42.4184 |              10.2755 |            114.948 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1208.264137437366
    time_step_min: 1039
  date: 2020-11-01_12-06-27
  done: false
  episode_len_mean: 113.67087482219061
  episode_reward_max: 42.41836734693879
  episode_reward_mean: 33.766906406944
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1498
  episodes_total: 5624
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.064699391523997
        entropy_coeff: 0.0005000000000000001
        kl: 0.010414493580659231
        model: {}
        policy_loss: -0.015563213809703788
        total_loss: 5.088392059008281
        vf_explained_var: 0.9388461709022522
        vf_loss: 5.102404753367106
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.656000000000002
    gpu_util_percent0: 0.4268
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5120000000000005
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16163926361569136
    mean_env_wait_ms: 0.6582592695889212
    mean_inference_ms: 4.803322913432019
    mean_raw_obs_processing_ms: 0.43060689585891204
  time_since_restore: 84.06805443763733
  time_this_iter_s: 20.21886420249939
  time_total_s: 84.06805443763733
  timers:
    learn_throughput: 11266.122
    learn_time_ms: 14360.931
    sample_throughput: 24659.344
    sample_time_ms: 6561.083
    update_time_ms: 34.947
  timestamp: 1604232387
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      4 |          84.0681 | 647168 |  33.7669 |              42.4184 |              10.2755 |            113.671 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1189.914229193161
    time_step_min: 1039
  date: 2020-11-01_12-06-47
  done: false
  episode_len_mean: 112.46028398706594
  episode_reward_max: 42.4183673469388
  episode_reward_mean: 34.71768564026201
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1489
  episodes_total: 7113
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0440024832884471
        entropy_coeff: 0.0005000000000000001
        kl: 0.009285129917164644
        model: {}
        policy_loss: -0.013422702313012755
        total_loss: 3.5668797492980957
        vf_explained_var: 0.956657886505127
        vf_loss: 3.5789673924446106
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.128
    gpu_util_percent0: 0.3836
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.508
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15996949149852113
    mean_env_wait_ms: 0.6557683164407656
    mean_inference_ms: 4.714004318455946
    mean_raw_obs_processing_ms: 0.42569876525023526
  time_since_restore: 104.25618076324463
  time_this_iter_s: 20.1881263256073
  time_total_s: 104.25618076324463
  timers:
    learn_throughput: 11286.122
    learn_time_ms: 14335.482
    sample_throughput: 25221.502
    sample_time_ms: 6414.844
    update_time_ms: 36.706
  timestamp: 1604232407
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      5 |          104.256 | 808960 |  34.7177 |              42.4184 |              10.2755 |             112.46 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1173.5402272200324
    time_step_min: 1039
  date: 2020-11-01_12-07-08
  done: false
  episode_len_mean: 111.30085430616485
  episode_reward_max: 42.4183673469388
  episode_reward_mean: 35.54994369024451
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1549
  episodes_total: 8662
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.00481882194678
        entropy_coeff: 0.0005000000000000001
        kl: 0.00909763171027104
        model: {}
        policy_loss: -0.013866825815057382
        total_loss: 2.7730772693951926
        vf_explained_var: 0.9670748114585876
        vf_loss: 2.785626987616221
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.65416666666667
    gpu_util_percent0: 0.4445833333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5083333333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1585845452097359
    mean_env_wait_ms: 0.6539711743603752
    mean_inference_ms: 4.639796008274598
    mean_raw_obs_processing_ms: 0.4215553460221708
  time_since_restore: 124.31111264228821
  time_this_iter_s: 20.05493187904358
  time_total_s: 124.31111264228821
  timers:
    learn_throughput: 11300.348
    learn_time_ms: 14317.435
    sample_throughput: 25694.821
    sample_time_ms: 6296.677
    update_time_ms: 36.949
  timestamp: 1604232428
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      6 |          124.311 | 970752 |  35.5499 |              42.4184 |              10.2755 |            111.301 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1160.6071287908626
    time_step_min: 1039
  date: 2020-11-01_12-07-28
  done: false
  episode_len_mean: 110.30445447409733
  episode_reward_max: 42.41836734693881
  episode_reward_mean: 36.22964990548809
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1530
  episodes_total: 10192
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9723203877607981
        entropy_coeff: 0.0005000000000000001
        kl: 0.008056929800659418
        model: {}
        policy_loss: -0.013902826050374037
        total_loss: 2.177985966205597
        vf_explained_var: 0.9740824103355408
        vf_loss: 2.1907635927200317
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.691999999999997
    gpu_util_percent0: 0.4035999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.516
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15747431107692764
    mean_env_wait_ms: 0.652680726552872
    mean_inference_ms: 4.58049716107533
    mean_raw_obs_processing_ms: 0.4181133612914104
  time_since_restore: 144.8035752773285
  time_this_iter_s: 20.492462635040283
  time_total_s: 144.8035752773285
  timers:
    learn_throughput: 11282.551
    learn_time_ms: 14340.019
    sample_throughput: 25937.899
    sample_time_ms: 6237.668
    update_time_ms: 37.177
  timestamp: 1604232448
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      7 |          144.804 | 1132544 |  36.2296 |              42.4184 |              10.2755 |            110.304 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1148.888252883383
    time_step_min: 1039
  date: 2020-11-01_12-07-49
  done: false
  episode_len_mean: 109.45600885784856
  episode_reward_max: 42.41836734693881
  episode_reward_mean: 36.816230060715206
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1549
  episodes_total: 11741
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9466134955485662
        entropy_coeff: 0.0005000000000000001
        kl: 0.007931554379562536
        model: {}
        policy_loss: -0.013606403217030069
        total_loss: 1.6076118151346843
        vf_explained_var: 0.9807720184326172
        vf_loss: 1.6201052069664001
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.764000000000006
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15654498685345614
    mean_env_wait_ms: 0.6516967139634099
    mean_inference_ms: 4.530832158888852
    mean_raw_obs_processing_ms: 0.4150856418377815
  time_since_restore: 165.37314867973328
  time_this_iter_s: 20.569573402404785
  time_total_s: 165.37314867973328
  timers:
    learn_throughput: 11279.608
    learn_time_ms: 14343.761
    sample_throughput: 26039.205
    sample_time_ms: 6213.4
    update_time_ms: 37.773
  timestamp: 1604232469
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      8 |          165.373 | 1294336 |  36.8162 |              42.4184 |              10.2755 |            109.456 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1139.0165774998115
    time_step_min: 1039
  date: 2020-11-01_12-08-10
  done: false
  episode_len_mean: 108.7133839332682
  episode_reward_max: 42.41836734693881
  episode_reward_mean: 37.319474329147006
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1566
  episodes_total: 13307
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9164896359046301
        entropy_coeff: 0.0005000000000000001
        kl: 0.007841601696175834
        model: {}
        policy_loss: -0.011578070591591919
        total_loss: 1.2525162895520527
        vf_explained_var: 0.985228955745697
        vf_loss: 1.262984275817871
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.692000000000004
    gpu_util_percent0: 0.4428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15575594110735325
    mean_env_wait_ms: 0.6509075806283173
    mean_inference_ms: 4.488645311807507
    mean_raw_obs_processing_ms: 0.41243497179424105
  time_since_restore: 185.73600935935974
  time_this_iter_s: 20.362860679626465
  time_total_s: 185.73600935935974
  timers:
    learn_throughput: 11283.252
    learn_time_ms: 14339.128
    sample_throughput: 26176.544
    sample_time_ms: 6180.801
    update_time_ms: 37.693
  timestamp: 1604232490
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      9 |          185.736 | 1456128 |  37.3195 |              42.4184 |              10.2755 |            108.713 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1130.5417816982022
    time_step_min: 1039
  date: 2020-11-01_12-08-30
  done: false
  episode_len_mean: 108.05662658695506
  episode_reward_max: 42.41836734693881
  episode_reward_mean: 37.75363452292987
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1580
  episodes_total: 14887
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.879222497344017
        entropy_coeff: 0.0005000000000000001
        kl: 0.007466738965983192
        model: {}
        policy_loss: -0.010042240721910881
        total_loss: 1.0435242255528767
        vf_explained_var: 0.9878211617469788
        vf_loss: 1.0525127152601879
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.332000000000004
    gpu_util_percent0: 0.3956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15508348116310283
    mean_env_wait_ms: 0.6503758051109494
    mean_inference_ms: 4.452355943495541
    mean_raw_obs_processing_ms: 0.41015056238268827
  time_since_restore: 206.0984218120575
  time_this_iter_s: 20.362412452697754
  time_total_s: 206.0984218120575
  timers:
    learn_throughput: 11288.763
    learn_time_ms: 14332.129
    sample_throughput: 26298.441
    sample_time_ms: 6152.152
    update_time_ms: 42.189
  timestamp: 1604232510
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     10 |          206.098 | 1617920 |  37.7536 |              42.4184 |              10.2755 |            108.057 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1123.1655117918795
    time_step_min: 1039
  date: 2020-11-01_12-08-51
  done: false
  episode_len_mean: 107.44680980106745
  episode_reward_max: 42.41836734693881
  episode_reward_mean: 38.12998569151096
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1601
  episodes_total: 16488
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.852480560541153
        entropy_coeff: 0.0005000000000000001
        kl: 0.006807499914430082
        model: {}
        policy_loss: -0.010430590346610794
        total_loss: 0.7860654095808665
        vf_explained_var: 0.9908618927001953
        vf_loss: 0.7955607374509176
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.468000000000004
    gpu_util_percent0: 0.3796
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15448994642998015
    mean_env_wait_ms: 0.6499845600676837
    mean_inference_ms: 4.420542043950926
    mean_raw_obs_processing_ms: 0.408110786931221
  time_since_restore: 226.6547131538391
  time_this_iter_s: 20.556291341781616
  time_total_s: 226.6547131538391
  timers:
    learn_throughput: 11290.905
    learn_time_ms: 14329.409
    sample_throughput: 27104.621
    sample_time_ms: 5969.167
    update_time_ms: 41.488
  timestamp: 1604232531
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     11 |          226.655 | 1779712 |    38.13 |              42.4184 |              10.2755 |            107.447 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1116.8649711879432
    time_step_min: 1039
  date: 2020-11-01_12-09-12
  done: false
  episode_len_mean: 106.92020570670206
  episode_reward_max: 42.41836734693881
  episode_reward_mean: 38.44685289510628
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1596
  episodes_total: 18084
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8233269800742468
        entropy_coeff: 0.0005000000000000001
        kl: 0.00662518401319782
        model: {}
        policy_loss: -0.011712064248664925
        total_loss: 0.6785962084929148
        vf_explained_var: 0.9921655654907227
        vf_loss: 0.6893948912620544
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.354166666666668
    gpu_util_percent0: 0.39875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15396759428958923
    mean_env_wait_ms: 0.6497269679106826
    mean_inference_ms: 4.392758580495196
    mean_raw_obs_processing_ms: 0.4063257369659057
  time_since_restore: 247.07435011863708
  time_this_iter_s: 20.419636964797974
  time_total_s: 247.07435011863708
  timers:
    learn_throughput: 11289.741
    learn_time_ms: 14330.887
    sample_throughput: 27482.894
    sample_time_ms: 5887.007
    update_time_ms: 40.889
  timestamp: 1604232552
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     12 |          247.074 | 1941504 |  38.4469 |              42.4184 |              10.2755 |             106.92 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1111.391848572737
    time_step_min: 1039
  date: 2020-11-01_12-09-33
  done: false
  episode_len_mean: 106.44390268677942
  episode_reward_max: 42.418367346938815
  episode_reward_mean: 38.727613885718846
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1605
  episodes_total: 19689
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7883199751377106
        entropy_coeff: 0.0005000000000000001
        kl: 0.006895307102240622
        model: {}
        policy_loss: -0.01035230930817003
        total_loss: 0.501528188586235
        vf_explained_var: 0.9942240118980408
        vf_loss: 0.5108955974380175
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.084
    gpu_util_percent0: 0.40480000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15350402726485754
    mean_env_wait_ms: 0.6495522826808918
    mean_inference_ms: 4.367981018992163
    mean_raw_obs_processing_ms: 0.40472308429202836
  time_since_restore: 267.40077471733093
  time_this_iter_s: 20.326424598693848
  time_total_s: 267.40077471733093
  timers:
    learn_throughput: 11287.514
    learn_time_ms: 14333.714
    sample_throughput: 27563.917
    sample_time_ms: 5869.703
    update_time_ms: 41.691
  timestamp: 1604232573
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     13 |          267.401 | 2103296 |  38.7276 |              42.4184 |              10.2755 |            106.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1106.5129543424084
    time_step_min: 1039
  date: 2020-11-01_12-09-53
  done: false
  episode_len_mean: 106.01774397972116
  episode_reward_max: 42.418367346938815
  episode_reward_mean: 38.97570046184929
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1614
  episodes_total: 21303
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7583291182915369
        entropy_coeff: 0.0005000000000000001
        kl: 0.006845557557729383
        model: {}
        policy_loss: -0.010322557670103075
        total_loss: 0.39304836342732113
        vf_explained_var: 0.9954751133918762
        vf_loss: 0.40238098055124283
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.124000000000002
    gpu_util_percent0: 0.4536
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15309019602292354
    mean_env_wait_ms: 0.6494461564466915
    mean_inference_ms: 4.34582608361679
    mean_raw_obs_processing_ms: 0.40327786899763196
  time_since_restore: 287.4316370487213
  time_this_iter_s: 20.03086233139038
  time_total_s: 287.4316370487213
  timers:
    learn_throughput: 11292.259
    learn_time_ms: 14327.692
    sample_throughput: 27660.58
    sample_time_ms: 5849.19
    update_time_ms: 42.894
  timestamp: 1604232593
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     14 |          287.432 | 2265088 |  38.9757 |              42.4184 |              10.2755 |            106.018 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1102.2523617914626
    time_step_min: 1039
  date: 2020-11-01_12-10-14
  done: false
  episode_len_mean: 105.64558951965066
  episode_reward_max: 42.418367346938815
  episode_reward_mean: 39.19350548079495
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1597
  episodes_total: 22900
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7275536010662714
        entropy_coeff: 0.0005000000000000001
        kl: 0.006344522737587492
        model: {}
        policy_loss: -0.01266244207120811
        total_loss: 0.31657364467779797
        vf_explained_var: 0.9963433742523193
        vf_loss: 0.32833095143238705
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.668000000000003
    gpu_util_percent0: 0.4212
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15272256161153888
    mean_env_wait_ms: 0.6493956761565493
    mean_inference_ms: 4.3261627778248455
    mean_raw_obs_processing_ms: 0.40199333508455115
  time_since_restore: 308.00055265426636
  time_this_iter_s: 20.568915605545044
  time_total_s: 308.00055265426636
  timers:
    learn_throughput: 11279.674
    learn_time_ms: 14343.677
    sample_throughput: 27657.34
    sample_time_ms: 5849.876
    update_time_ms: 42.541
  timestamp: 1604232614
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     15 |          308.001 | 2426880 |  39.1935 |              42.4184 |              10.2755 |            105.646 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1098.492356115108
    time_step_min: 1039
  date: 2020-11-01_12-10-35
  done: false
  episode_len_mean: 105.31371428571428
  episode_reward_max: 42.418367346938815
  episode_reward_mean: 39.386209912536444
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1600
  episodes_total: 24500
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6992116371790568
        entropy_coeff: 0.0005000000000000001
        kl: 0.00605107715819031
        model: {}
        policy_loss: -0.010152409401295396
        total_loss: 0.2749015986919403
        vf_explained_var: 0.9968383312225342
        vf_loss: 0.28419339408477146
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.163999999999998
    gpu_util_percent0: 0.4179999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523902557025731
    mean_env_wait_ms: 0.6493845108910767
    mean_inference_ms: 4.308344642074162
    mean_raw_obs_processing_ms: 0.4008263717279235
  time_since_restore: 328.0859045982361
  time_this_iter_s: 20.085351943969727
  time_total_s: 328.0859045982361
  timers:
    learn_throughput: 11277.087
    learn_time_ms: 14346.967
    sample_throughput: 27688.425
    sample_time_ms: 5843.308
    update_time_ms: 42.686
  timestamp: 1604232635
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     16 |          328.086 | 2588672 |  39.3862 |              42.4184 |              10.2755 |            105.314 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1095.0764746490756
    time_step_min: 1039
  date: 2020-11-01_12-10-55
  done: false
  episode_len_mean: 105.01325162772883
  episode_reward_max: 42.418367346938815
  episode_reward_mean: 39.561036900397845
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1610
  episodes_total: 26110
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6637826611598333
        entropy_coeff: 0.0005000000000000001
        kl: 0.006695269180151324
        model: {}
        policy_loss: -0.012259619931379953
        total_loss: 0.2071586512029171
        vf_explained_var: 0.9976064562797546
        vf_loss: 0.21841111406683922
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.967999999999996
    gpu_util_percent0: 0.3992
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15208441102089912
    mean_env_wait_ms: 0.649415271515101
    mean_inference_ms: 4.292010650770931
    mean_raw_obs_processing_ms: 0.3997617754479261
  time_since_restore: 348.3640911579132
  time_this_iter_s: 20.278186559677124
  time_total_s: 348.3640911579132
  timers:
    learn_throughput: 11280.385
    learn_time_ms: 14342.773
    sample_throughput: 27802.66
    sample_time_ms: 5819.299
    update_time_ms: 42.587
  timestamp: 1604232655
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     17 |          348.364 | 2750464 |   39.561 |              42.4184 |              10.2755 |            105.013 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1091.992488262911
    time_step_min: 1039
  date: 2020-11-01_12-11-16
  done: false
  episode_len_mean: 104.74269638606363
  episode_reward_max: 42.41836734693882
  episode_reward_mean: 39.71753728541839
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1616
  episodes_total: 27726
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6395211120446523
        entropy_coeff: 0.0005000000000000001
        kl: 0.005430514691397548
        model: {}
        policy_loss: -0.008808797846237818
        total_loss: 0.18516152476270994
        vf_explained_var: 0.9978885650634766
        vf_loss: 0.19320398072401682
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.428
    gpu_util_percent0: 0.4108
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15180253257231568
    mean_env_wait_ms: 0.6494706645035929
    mean_inference_ms: 4.277042903419588
    mean_raw_obs_processing_ms: 0.3987841767593947
  time_since_restore: 368.70942068099976
  time_this_iter_s: 20.345329523086548
  time_total_s: 368.70942068099976
  timers:
    learn_throughput: 11277.054
    learn_time_ms: 14347.01
    sample_throughput: 27960.312
    sample_time_ms: 5786.488
    update_time_ms: 42.249
  timestamp: 1604232676
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     18 |          368.709 | 2912256 |  39.7175 |              42.4184 |              10.2755 |            104.743 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1089.2314356857796
    time_step_min: 1039
  date: 2020-11-01_12-11-37
  done: false
  episode_len_mean: 104.499846693694
  episode_reward_max: 42.41836734693882
  episode_reward_mean: 39.85814856041556
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1627
  episodes_total: 29353
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6059375007947286
        entropy_coeff: 0.0005000000000000001
        kl: 0.006107187946327031
        model: {}
        policy_loss: -0.009194978279992938
        total_loss: 0.15118268628915152
        vf_explained_var: 0.9982755184173584
        vf_loss: 0.15945919354756674
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.02
    gpu_util_percent0: 0.35119999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15154050336998873
    mean_env_wait_ms: 0.6495464583308167
    mean_inference_ms: 4.263205291197448
    mean_raw_obs_processing_ms: 0.39787967312168704
  time_since_restore: 389.13511419296265
  time_this_iter_s: 20.42569351196289
  time_total_s: 389.13511419296265
  timers:
    learn_throughput: 11265.913
    learn_time_ms: 14361.197
    sample_throughput: 28034.364
    sample_time_ms: 5771.203
    update_time_ms: 43.0
  timestamp: 1604232697
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     19 |          389.135 | 3074048 |  39.8581 |              42.4184 |              10.2755 |              104.5 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1086.7530964007374
    time_step_min: 1039
  date: 2020-11-01_12-11-58
  done: false
  episode_len_mean: 104.28143673891276
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 39.98449496404396
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1606
  episodes_total: 30959
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5802051573991776
        entropy_coeff: 0.0005000000000000001
        kl: 0.006146465195342898
        model: {}
        policy_loss: -0.010908293537795544
        total_loss: 0.12315286882221699
        vf_explained_var: 0.9985630512237549
        vf_loss: 0.13312197600801787
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.708000000000002
    gpu_util_percent0: 0.35119999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130250937481887
    mean_env_wait_ms: 0.649629966463628
    mean_inference_ms: 4.25060756388231
    mean_raw_obs_processing_ms: 0.39705657157981417
  time_since_restore: 409.49588918685913
  time_this_iter_s: 20.360774993896484
  time_total_s: 409.49588918685913
  timers:
    learn_throughput: 11247.919
    learn_time_ms: 14384.172
    sample_throughput: 28152.747
    sample_time_ms: 5746.935
    update_time_ms: 38.327
  timestamp: 1604232718
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     20 |          409.496 | 3235840 |  39.9845 |              42.4184 |              10.2755 |            104.281 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1084.4941429669484
    time_step_min: 1039
  date: 2020-11-01_12-12-19
  done: false
  episode_len_mean: 104.08316697890113
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.09885276551578
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1602
  episodes_total: 32561
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5567689687013626
        entropy_coeff: 0.0005000000000000001
        kl: 0.0057975016146277385
        model: {}
        policy_loss: -0.010689061540081942
        total_loss: 0.10724692543347676
        vf_explained_var: 0.9987431168556213
        vf_loss: 0.11705487407743931
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.752000000000002
    gpu_util_percent0: 0.2972
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15108181784508506
    mean_env_wait_ms: 0.6497188533760437
    mean_inference_ms: 4.2389675381303915
    mean_raw_obs_processing_ms: 0.3962976370894028
  time_since_restore: 429.649621963501
  time_this_iter_s: 20.153732776641846
  time_total_s: 429.649621963501
  timers:
    learn_throughput: 11259.927
    learn_time_ms: 14368.833
    sample_throughput: 28275.485
    sample_time_ms: 5721.988
    update_time_ms: 38.431
  timestamp: 1604232739
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     21 |           429.65 | 3397632 |  40.0989 |              42.4184 |              10.2755 |            104.083 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1082.431136496778
    time_step_min: 1039
  date: 2020-11-01_12-12-40
  done: false
  episode_len_mean: 103.90098314606742
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.20364481818009
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1615
  episodes_total: 34176
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5254394511381785
        entropy_coeff: 0.0005000000000000001
        kl: 0.005307760516492029
        model: {}
        policy_loss: -0.007776977017783793
        total_loss: 0.0964116957038641
        vf_explained_var: 0.9988983273506165
        vf_loss: 0.10338984616100788
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.846153846153847
    gpu_util_percent0: 0.39384615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15087377501627616
    mean_env_wait_ms: 0.6498094517683312
    mean_inference_ms: 4.22804968427196
    mean_raw_obs_processing_ms: 0.3955819072644963
  time_since_restore: 449.9894530773163
  time_this_iter_s: 20.339831113815308
  time_total_s: 449.9894530773163
  timers:
    learn_throughput: 11271.985
    learn_time_ms: 14353.461
    sample_throughput: 28273.456
    sample_time_ms: 5722.399
    update_time_ms: 39.023
  timestamp: 1604232760
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     22 |          449.989 | 3559424 |  40.2036 |              42.4184 |              10.2755 |            103.901 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1080.5109731890743
    time_step_min: 1039
  date: 2020-11-01_12-13-01
  done: false
  episode_len_mean: 103.7305683563748
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.301032520255696
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1629
  episodes_total: 35805
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5021042550603548
        entropy_coeff: 0.0005000000000000001
        kl: 0.0054971032465497656
        model: {}
        policy_loss: -0.00953363478280759
        total_loss: 0.06499722289542358
        vf_explained_var: 0.9992148876190186
        vf_loss: 0.07368248887360096
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.044
    gpu_util_percent0: 0.4084
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15067991150821478
    mean_env_wait_ms: 0.649905891759336
    mean_inference_ms: 4.2178278275443795
    mean_raw_obs_processing_ms: 0.39491348951426497
  time_since_restore: 470.5632412433624
  time_this_iter_s: 20.573788166046143
  time_total_s: 470.5632412433624
  timers:
    learn_throughput: 11273.798
    learn_time_ms: 14351.154
    sample_throughput: 28167.439
    sample_time_ms: 5743.937
    update_time_ms: 38.419
  timestamp: 1604232781
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 74f1e_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     23 |          470.563 | 3721216 |   40.301 |              42.4184 |              10.2755 |            103.731 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1078.7812073715463
    time_step_min: 1039
  date: 2020-11-01_12-13-22
  done: false
  episode_len_mean: 103.57635678593378
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.38915989130335
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1618
  episodes_total: 37423
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.47640378028154373
        entropy_coeff: 0.0005000000000000001
        kl: 0.005069411902998884
        model: {}
        policy_loss: -0.007647299599436034
        total_loss: 0.07074602444966634
        vf_explained_var: 0.9991908073425293
        vf_loss: 0.07761764402190845
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.191999999999997
    gpu_util_percent0: 0.3423999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505016968490393
    mean_env_wait_ms: 0.6500103427408599
    mean_inference_ms: 4.208361564693216
    mean_raw_obs_processing_ms: 0.39429321916174187
  time_since_restore: 490.8706216812134
  time_this_iter_s: 20.307380437850952
  time_total_s: 490.8706216812134
  timers:
    learn_throughput: 11268.008
    learn_time_ms: 14358.528
    sample_throughput: 28090.142
    sample_time_ms: 5759.743
    update_time_ms: 37.55
  timestamp: 1604232802
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 74f1e_00000
  
2020-11-01 12:13:23,494	WARNING util.py:136 -- The `process_trial` operation took 0.5319008827209473 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     24 |          490.871 | 3883008 |  40.3892 |              42.4184 |              10.2755 |            103.576 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1077.1880225698897
    time_step_min: 1039
  date: 2020-11-01_12-13-43
  done: false
  episode_len_mean: 103.43532516783682
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.4702521709755
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1603
  episodes_total: 39026
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.4569598063826561
        entropy_coeff: 0.0005000000000000001
        kl: 0.005172949323120217
        model: {}
        policy_loss: -0.008714882539303895
        total_loss: 0.04905764168749253
        vf_explained_var: 0.999389111995697
        vf_loss: 0.056966414054234825
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.62
    gpu_util_percent0: 0.41119999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15033752613342766
    mean_env_wait_ms: 0.6501147929596541
    mean_inference_ms: 4.199582565004314
    mean_raw_obs_processing_ms: 0.3937192610273736
  time_since_restore: 511.1436126232147
  time_this_iter_s: 20.272990942001343
  time_total_s: 511.1436126232147
  timers:
    learn_throughput: 11277.804
    learn_time_ms: 14346.056
    sample_throughput: 28126.832
    sample_time_ms: 5752.23
    update_time_ms: 37.351
  timestamp: 1604232823
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 74f1e_00000
  
2020-11-01 12:13:44,581	WARNING util.py:136 -- The `process_trial` operation took 0.5550427436828613 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     25 |          511.144 | 4044800 |  40.4703 |              42.4184 |              10.2755 |            103.435 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1075.718860070445
    time_step_min: 1039
  date: 2020-11-01_12-14-04
  done: false
  episode_len_mean: 103.30375292235757
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.545045112914124
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1609
  episodes_total: 40635
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.4321967264016469
        entropy_coeff: 0.0005000000000000001
        kl: 0.0049026469544818
        model: {}
        policy_loss: -0.00738874361559283
        total_loss: 0.0522269361341993
        vf_explained_var: 0.9993705749511719
        vf_loss: 0.058851247653365135
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.028000000000002
    gpu_util_percent0: 0.35119999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15018377726680818
    mean_env_wait_ms: 0.650226839982744
    mean_inference_ms: 4.191307577339299
    mean_raw_obs_processing_ms: 0.39318264874410647
  time_since_restore: 531.2994961738586
  time_this_iter_s: 20.15588355064392
  time_total_s: 531.2994961738586
  timers:
    learn_throughput: 11281.716
    learn_time_ms: 14341.08
    sample_throughput: 28095.697
    sample_time_ms: 5758.604
    update_time_ms: 36.136
  timestamp: 1604232844
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 74f1e_00000
  
2020-11-01 12:14:05,496	WARNING util.py:136 -- The `process_trial` operation took 0.5645184516906738 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     26 |          531.299 | 4206592 |   40.545 |              42.4184 |              10.2755 |            103.304 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1074.3374860851236
    time_step_min: 1039
  date: 2020-11-01_12-14-26
  done: false
  episode_len_mean: 103.18162671273399
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.61544301559989
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1622
  episodes_total: 42257
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.41156937927007675
        entropy_coeff: 0.0005000000000000001
        kl: 0.005988262050474684
        model: {}
        policy_loss: -0.0108474350903028
        total_loss: 0.03666358132613823
        vf_explained_var: 0.9995186924934387
        vf_loss: 0.04711797585090002
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.450000000000003
    gpu_util_percent0: 0.37384615384615383
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15003777931603987
    mean_env_wait_ms: 0.6503388710349208
    mean_inference_ms: 4.1834680864066325
    mean_raw_obs_processing_ms: 0.39267008619808885
  time_since_restore: 551.8160552978516
  time_this_iter_s: 20.51655912399292
  time_total_s: 551.8160552978516
  timers:
    learn_throughput: 11287.466
    learn_time_ms: 14333.775
    sample_throughput: 28001.168
    sample_time_ms: 5778.045
    update_time_ms: 35.1
  timestamp: 1604232866
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 74f1e_00000
  
2020-11-01 12:14:26,878	WARNING util.py:136 -- The `process_trial` operation took 0.603750467300415 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     27 |          551.816 | 4368384 |  40.6154 |              42.4184 |              10.2755 |            103.182 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1073.064150513113
    time_step_min: 1039
  date: 2020-11-01_12-14-47
  done: false
  episode_len_mean: 103.0678804174452
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.68016949294415
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1629
  episodes_total: 43886
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.38193487375974655
        entropy_coeff: 0.0005000000000000001
        kl: 0.0054754362208768725
        model: {}
        policy_loss: -0.007502093746249254
        total_loss: 0.052860286086797714
        vf_explained_var: 0.999366819858551
        vf_loss: 0.06000580328206221
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.916000000000004
    gpu_util_percent0: 0.35960000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1498996451948512
    mean_env_wait_ms: 0.6504529892483883
    mean_inference_ms: 4.176045627745146
    mean_raw_obs_processing_ms: 0.3921857888681881
  time_since_restore: 572.0441946983337
  time_this_iter_s: 20.228139400482178
  time_total_s: 572.0441946983337
  timers:
    learn_throughput: 11297.604
    learn_time_ms: 14320.912
    sample_throughput: 28005.61
    sample_time_ms: 5777.128
    update_time_ms: 32.987
  timestamp: 1604232887
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: 74f1e_00000
  
2020-11-01 12:14:47,924	WARNING util.py:136 -- The `process_trial` operation took 0.6126041412353516 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     28 |          572.044 | 4530176 |  40.6802 |              42.4184 |              10.2755 |            103.068 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1071.8849808631385
    time_step_min: 1039
  date: 2020-11-01_12-15-08
  done: false
  episode_len_mean: 102.9628774891204
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.74035570973741
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1612
  episodes_total: 45498
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.3544607609510422
        entropy_coeff: 0.0005000000000000001
        kl: 0.005010240633661549
        model: {}
        policy_loss: -0.006979774484837738
        total_loss: 0.030745272990316153
        vf_explained_var: 0.999602735042572
        vf_loss: 0.037401253978411354
    num_steps_sampled: 4691968
    num_steps_trained: 4691968
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.657692307692308
    gpu_util_percent0: 0.32384615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.565384615384615
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1497713859875804
    mean_env_wait_ms: 0.650569464769825
    mean_inference_ms: 4.169137947749732
    mean_raw_obs_processing_ms: 0.39173452138746384
  time_since_restore: 592.6739168167114
  time_this_iter_s: 20.629722118377686
  time_total_s: 592.6739168167114
  timers:
    learn_throughput: 11299.681
    learn_time_ms: 14318.28
    sample_throughput: 27922.916
    sample_time_ms: 5794.237
    update_time_ms: 30.389
  timestamp: 1604232908
  timesteps_since_restore: 0
  timesteps_total: 4691968
  training_iteration: 29
  trial_id: 74f1e_00000
  
2020-11-01 12:15:09,523	WARNING util.py:136 -- The `process_trial` operation took 0.6120882034301758 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     29 |          592.674 | 4691968 |  40.7404 |              42.4184 |              10.2755 |            102.963 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_74f1e_00000:
  custom_metrics:
    time_step_max: 1669
    time_step_mean: 1070.7854881546798
    time_step_min: 1039
  date: 2020-11-01_12-15-29
  done: true
  episode_len_mean: 102.86573533470627
  episode_reward_max: 42.41836734693883
  episode_reward_mean: 40.79621711744931
  episode_reward_min: 10.27551020408163
  episodes_this_iter: 1603
  episodes_total: 47101
  experiment_id: 230a00995083408db67ee3cc3bc356c5
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.3281017740567525
        entropy_coeff: 0.0005000000000000001
        kl: 0.005293768752987186
        model: {}
        policy_loss: -0.007335715092873822
        total_loss: 0.022672869653130572
        vf_explained_var: 0.9996854662895203
        vf_loss: 0.029643258700768154
    num_steps_sampled: 4853760
    num_steps_trained: 4853760
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.851999999999997
    gpu_util_percent0: 0.41879999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52265
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1496498957417332
    mean_env_wait_ms: 0.6506846363524779
    mean_inference_ms: 4.162635555621303
    mean_raw_obs_processing_ms: 0.39130720698712607
  time_since_restore: 613.0474860668182
  time_this_iter_s: 20.37356925010681
  time_total_s: 613.0474860668182
  timers:
    learn_throughput: 11310.582
    learn_time_ms: 14304.481
    sample_throughput: 27887.371
    sample_time_ms: 5801.623
    update_time_ms: 30.76
  timestamp: 1604232929
  timesteps_since_restore: 0
  timesteps_total: 4853760
  training_iteration: 30
  trial_id: 74f1e_00000
  
2020-11-01 12:15:30,803	WARNING util.py:136 -- The `process_trial` operation took 0.6821863651275635 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 24.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | TERMINATED |       |     30 |          613.047 | 4853760 |  40.7962 |              42.4184 |              10.2755 |            102.866 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 24.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_74f1e_00000 | TERMINATED |       |     30 |          613.047 | 4853760 |  40.7962 |              42.4184 |              10.2755 |            102.866 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


