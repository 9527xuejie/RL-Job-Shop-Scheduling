2020-10-12 17:22:26,182	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_8033a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=9278)[0m 2020-10-12 17:22:28,962	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=9215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9217)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3771.2241379310344
    time_step_min: 3428
  date: 2020-10-12_17-23-01
  done: false
  episode_len_mean: 902.7784810126582
  episode_reward_max: 270.95959595959573
  episode_reward_mean: 218.82112261859064
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1593314011891682
        entropy_coeff: 0.009999999999999998
        kl: 0.007030583336018026
        model: {}
        policy_loss: -0.010280341647254923
        total_loss: 463.3080291748047
        vf_explained_var: 0.5503719449043274
        vf_loss: 463.32850392659503
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.170588235294115
    gpu_util_percent0: 0.3647058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5588235294117645
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16917713338410867
    mean_env_wait_ms: 1.167531294674003
    mean_inference_ms: 5.436821787693721
    mean_raw_obs_processing_ms: 0.44797452742319555
  time_since_restore: 27.392566442489624
  time_this_iter_s: 27.392566442489624
  time_total_s: 27.392566442489624
  timers:
    learn_throughput: 8626.066
    learn_time_ms: 18756.175
    sample_throughput: 18900.058
    sample_time_ms: 8560.397
    update_time_ms: 46.128
  timestamp: 1602523381
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      1 |          27.3926 | 161792 |  218.821 |               270.96 |              107.323 |            902.778 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3761.0839416058393
    time_step_min: 3428
  date: 2020-10-12_17-23-28
  done: false
  episode_len_mean: 900.5411392405064
  episode_reward_max: 270.95959595959573
  episode_reward_mean: 221.10152154455918
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1370031237602234
        entropy_coeff: 0.009999999999999998
        kl: 0.008772346967210373
        model: {}
        policy_loss: -0.00966885961436977
        total_loss: 113.82320721944173
        vf_explained_var: 0.8112062811851501
        vf_loss: 113.8424924214681
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.609375
    gpu_util_percent0: 0.3821875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16563279867623415
    mean_env_wait_ms: 1.1649208361532228
    mean_inference_ms: 5.353822290191971
    mean_raw_obs_processing_ms: 0.44010219869464146
  time_since_restore: 53.994969606399536
  time_this_iter_s: 26.602403163909912
  time_total_s: 53.994969606399536
  timers:
    learn_throughput: 8662.314
    learn_time_ms: 18677.689
    sample_throughput: 19656.34
    sample_time_ms: 8231.034
    update_time_ms: 51.205
  timestamp: 1602523408
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      2 |           53.995 | 323584 |  221.102 |               270.96 |              103.081 |            900.541 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3739.8703703703704
    time_step_min: 3315
  date: 2020-10-12_17-23-53
  done: false
  episode_len_mean: 895.9029535864979
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 223.21697992584038
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1293126444021861
        entropy_coeff: 0.009999999999999998
        kl: 0.009467250667512417
        model: {}
        policy_loss: -0.01379787746797471
        total_loss: 52.770127614339195
        vf_explained_var: 0.8894534111022949
        vf_loss: 52.793323834737144
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.553333333333335
    gpu_util_percent0: 0.3336666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16282739173547509
    mean_env_wait_ms: 1.164674626883317
    mean_inference_ms: 5.222227801340358
    mean_raw_obs_processing_ms: 0.4319843962758859
  time_since_restore: 79.44427466392517
  time_this_iter_s: 25.449305057525635
  time_total_s: 79.44427466392517
  timers:
    learn_throughput: 8705.078
    learn_time_ms: 18585.934
    sample_throughput: 20726.224
    sample_time_ms: 7806.149
    update_time_ms: 45.777
  timestamp: 1602523433
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      3 |          79.4443 | 485376 |  223.217 |              287.323 |              103.081 |            895.903 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3731.747457627119
    time_step_min: 3315
  date: 2020-10-12_17-24-19
  done: false
  episode_len_mean: 892.5854430379746
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 223.70868495077326
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1181162496407826
        entropy_coeff: 0.009999999999999998
        kl: 0.00943851649450759
        model: {}
        policy_loss: -0.010301764472387731
        total_loss: 40.121353467305504
        vf_explained_var: 0.9233471751213074
        vf_loss: 40.140947341918945
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.129032258064516
    gpu_util_percent0: 0.3590322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16072132944983394
    mean_env_wait_ms: 1.1654325450946321
    mean_inference_ms: 5.112691034483701
    mean_raw_obs_processing_ms: 0.425423369829017
  time_since_restore: 104.79071354866028
  time_this_iter_s: 25.346438884735107
  time_total_s: 104.79071354866028
  timers:
    learn_throughput: 8714.09
    learn_time_ms: 18566.711
    sample_throughput: 21447.677
    sample_time_ms: 7543.568
    update_time_ms: 43.951
  timestamp: 1602523459
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      4 |          104.791 | 647168 |  223.709 |              287.323 |              103.081 |            892.585 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3722.177807486631
    time_step_min: 3315
  date: 2020-10-12_17-24-45
  done: false
  episode_len_mean: 887.7063291139241
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 225.24402250351585
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0898156464099884
        entropy_coeff: 0.009999999999999998
        kl: 0.009857317976032695
        model: {}
        policy_loss: -0.014866382368685057
        total_loss: 32.77305142084757
        vf_explained_var: 0.9323835372924805
        vf_loss: 32.796843846639
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.435483870967747
    gpu_util_percent0: 0.3648387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1591154253348706
    mean_env_wait_ms: 1.167085091962285
    mean_inference_ms: 5.0250886640594885
    mean_raw_obs_processing_ms: 0.4200988787137812
  time_since_restore: 130.40513253211975
  time_this_iter_s: 25.614418983459473
  time_total_s: 130.40513253211975
  timers:
    learn_throughput: 8706.422
    learn_time_ms: 18583.064
    sample_throughput: 21868.211
    sample_time_ms: 7398.502
    update_time_ms: 53.502
  timestamp: 1602523485
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      5 |          130.405 | 808960 |  225.244 |              287.323 |              103.081 |            887.706 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3711.438057482656
    time_step_min: 3315
  date: 2020-10-12_17-25-10
  done: false
  episode_len_mean: 877.6736441484301
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 227.04802544954757
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 261
  episodes_total: 1051
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0496035317579906
        entropy_coeff: 0.009999999999999998
        kl: 0.009100019931793213
        model: {}
        policy_loss: -0.012603524567869803
        total_loss: 42.86450513203939
        vf_explained_var: 0.9450351595878601
        vf_loss: 42.8857847849528
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.990000000000006
    gpu_util_percent0: 0.3339999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15722544770373748
    mean_env_wait_ms: 1.1711667857581274
    mean_inference_ms: 4.9201224730141595
    mean_raw_obs_processing_ms: 0.4138831010175219
  time_since_restore: 155.9185073375702
  time_this_iter_s: 25.51337480545044
  time_total_s: 155.9185073375702
  timers:
    learn_throughput: 8717.718
    learn_time_ms: 18558.984
    sample_throughput: 22073.081
    sample_time_ms: 7329.833
    update_time_ms: 51.297
  timestamp: 1602523510
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      6 |          155.919 | 970752 |  227.048 |              287.323 |              103.081 |            877.674 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3704.864975450082
    time_step_min: 3315
  date: 2020-10-12_17-25-36
  done: false
  episode_len_mean: 871.248417721519
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 228.08152729829914
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 213
  episodes_total: 1264
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0710477530956268
        entropy_coeff: 0.009999999999999998
        kl: 0.009814029559493065
        model: {}
        policy_loss: -0.013590444560880618
        total_loss: 26.7813556989034
        vf_explained_var: 0.9541693329811096
        vf_loss: 26.803694089253742
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.206451612903233
    gpu_util_percent0: 0.31064516129032255
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1561090981777768
    mean_env_wait_ms: 1.1735130599417278
    mean_inference_ms: 4.858045163356089
    mean_raw_obs_processing_ms: 0.4103334183615469
  time_since_restore: 181.43821740150452
  time_this_iter_s: 25.519710063934326
  time_total_s: 181.43821740150452
  timers:
    learn_throughput: 8722.384
    learn_time_ms: 18549.057
    sample_throughput: 22237.65
    sample_time_ms: 7275.589
    update_time_ms: 47.403
  timestamp: 1602523536
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      7 |          181.438 | 1132544 |  228.082 |              287.323 |              103.081 |            871.248 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3698.43115942029
    time_step_min: 3315
  date: 2020-10-12_17-26-01
  done: false
  episode_len_mean: 866.7573839662447
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 229.2272940374204
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.037222961584727
        entropy_coeff: 0.009999999999999998
        kl: 0.01117557822726667
        model: {}
        policy_loss: -0.013946619195242723
        total_loss: 20.10233147939046
        vf_explained_var: 0.9605448842048645
        vf_loss: 20.124415397644043
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.148387096774194
    gpu_util_percent0: 0.3312903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15543583338051983
    mean_env_wait_ms: 1.175232914919787
    mean_inference_ms: 4.819893567972194
    mean_raw_obs_processing_ms: 0.4081378528803049
  time_since_restore: 207.12819910049438
  time_this_iter_s: 25.689981698989868
  time_total_s: 207.12819910049438
  timers:
    learn_throughput: 8708.146
    learn_time_ms: 18579.386
    sample_throughput: 22415.021
    sample_time_ms: 7218.017
    update_time_ms: 45.767
  timestamp: 1602523561
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      8 |          207.128 | 1294336 |  229.227 |              287.323 |              103.081 |            866.757 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3690.797789336801
    time_step_min: 3315
  date: 2020-10-12_17-26-27
  done: false
  episode_len_mean: 861.5620253164557
  episode_reward_max: 287.3232323232322
  episode_reward_mean: 230.53851809231531
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.024802525838216
        entropy_coeff: 0.009999999999999998
        kl: 0.008312498374531666
        model: {}
        policy_loss: -0.012617092882464931
        total_loss: 20.119685014088947
        vf_explained_var: 0.9583740830421448
        vf_loss: 20.14088789621989
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.35806451612904
    gpu_util_percent0: 0.35903225806451616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15484604997404183
    mean_env_wait_ms: 1.177086962447155
    mean_inference_ms: 4.786264228370961
    mean_raw_obs_processing_ms: 0.4061733687056738
  time_since_restore: 232.4851667881012
  time_this_iter_s: 25.35696768760681
  time_total_s: 232.4851667881012
  timers:
    learn_throughput: 8715.223
    learn_time_ms: 18564.299
    sample_throughput: 22570.15
    sample_time_ms: 7168.406
    update_time_ms: 50.537
  timestamp: 1602523587
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |      9 |          232.485 | 1456128 |  230.539 |              287.323 |              103.081 |            861.562 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3674.3488764044946
    time_step_min: 3249
  date: 2020-10-12_17-26-53
  done: false
  episode_len_mean: 854.6470911086718
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 232.85586379713692
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 242
  episodes_total: 1822
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9747188091278076
        entropy_coeff: 0.009999999999999998
        kl: 0.008089105055357019
        model: {}
        policy_loss: -0.0121427947627429
        total_loss: 24.63535515467326
        vf_explained_var: 0.9637289643287659
        vf_loss: 24.655627091725666
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.509999999999998
    gpu_util_percent0: 0.35366666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410105877865388
    mean_env_wait_ms: 1.1801308275190543
    mean_inference_ms: 4.742828296846979
    mean_raw_obs_processing_ms: 0.40364595210817955
  time_since_restore: 258.06603169441223
  time_this_iter_s: 25.580864906311035
  time_total_s: 258.06603169441223
  timers:
    learn_throughput: 8715.337
    learn_time_ms: 18564.055
    sample_throughput: 22650.122
    sample_time_ms: 7143.096
    update_time_ms: 50.31
  timestamp: 1602523613
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     10 |          258.066 | 1617920 |  232.856 |              297.323 |              103.081 |            854.647 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3660.9348906560635
    time_step_min: 3249
  date: 2020-10-12_17-27-19
  done: false
  episode_len_mean: 849.2624148003895
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 234.88984292781737
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 232
  episodes_total: 2054
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9879359851280848
        entropy_coeff: 0.009999999999999998
        kl: 0.008899578669418892
        model: {}
        policy_loss: -0.013296371779385177
        total_loss: 15.727051496505737
        vf_explained_var: 0.9707307815551758
        vf_loss: 15.74844741821289
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.503124999999997
    gpu_util_percent0: 0.3515625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15349691554157666
    mean_env_wait_ms: 1.1825106376073693
    mean_inference_ms: 4.708681705677999
    mean_raw_obs_processing_ms: 0.4017069818819455
  time_since_restore: 283.9925277233124
  time_this_iter_s: 25.926496028900146
  time_total_s: 283.9925277233124
  timers:
    learn_throughput: 8710.561
    learn_time_ms: 18574.234
    sample_throughput: 23169.018
    sample_time_ms: 6983.119
    update_time_ms: 49.824
  timestamp: 1602523639
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     11 |          283.993 | 1779712 |   234.89 |              297.323 |              103.081 |            849.262 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3650.7926267281105
    time_step_min: 3249
  date: 2020-10-12_17-27-45
  done: false
  episode_len_mean: 845.996835443038
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 236.18974555683394
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9731865127881368
        entropy_coeff: 0.009999999999999998
        kl: 0.008122207674508294
        model: {}
        policy_loss: -0.01138104306301102
        total_loss: 14.974854151407877
        vf_explained_var: 0.9679295420646667
        vf_loss: 14.994342724482218
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.138709677419357
    gpu_util_percent0: 0.38225806451612904
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15314893138853072
    mean_env_wait_ms: 1.1840694833411376
    mean_inference_ms: 4.688555586074523
    mean_raw_obs_processing_ms: 0.40054068777146495
  time_since_restore: 309.9998209476471
  time_this_iter_s: 26.007293224334717
  time_total_s: 309.9998209476471
  timers:
    learn_throughput: 8701.868
    learn_time_ms: 18592.789
    sample_throughput: 23431.947
    sample_time_ms: 6904.761
    update_time_ms: 48.449
  timestamp: 1602523665
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     12 |              310 | 1941504 |   236.19 |              297.323 |              103.081 |            845.997 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3641.907216494845
    time_step_min: 3249
  date: 2020-10-12_17-28-11
  done: false
  episode_len_mean: 843.3118143459916
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 237.50952563610772
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9437140127023061
        entropy_coeff: 0.009999999999999998
        kl: 0.009322391745323936
        model: {}
        policy_loss: -0.013838691947360834
        total_loss: 13.794757525126139
        vf_explained_var: 0.9703602194786072
        vf_loss: 13.816168705622355
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.183870967741935
    gpu_util_percent0: 0.3916129032258065
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15283358973770503
    mean_env_wait_ms: 1.185541963680028
    mean_inference_ms: 4.670315396209243
    mean_raw_obs_processing_ms: 0.3994671558320914
  time_since_restore: 335.66336965560913
  time_this_iter_s: 25.663548707962036
  time_total_s: 335.66336965560913
  timers:
    learn_throughput: 8692.461
    learn_time_ms: 18612.91
    sample_throughput: 23430.328
    sample_time_ms: 6905.238
    update_time_ms: 49.553
  timestamp: 1602523691
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     13 |          335.663 | 2103296 |   237.51 |              297.323 |              103.081 |            843.312 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3629.273142857143
    time_step_min: 3249
  date: 2020-10-12_17-28-36
  done: false
  episode_len_mean: 838.9898762654668
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 239.31406301485026
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 297
  episodes_total: 2667
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9190889398256937
        entropy_coeff: 0.009999999999999998
        kl: 0.007398002742168804
        model: {}
        policy_loss: -0.011500320300304642
        total_loss: 17.8931622505188
        vf_explained_var: 0.975060224533081
        vf_loss: 17.912374019622803
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.393548387096768
    gpu_util_percent0: 0.39741935483870966
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15232807198560294
    mean_env_wait_ms: 1.188169761794071
    mean_inference_ms: 4.640610842777529
    mean_raw_obs_processing_ms: 0.39776890892464667
  time_since_restore: 361.3411777019501
  time_this_iter_s: 25.677808046340942
  time_total_s: 361.3411777019501
  timers:
    learn_throughput: 8688.377
    learn_time_ms: 18621.659
    sample_throughput: 23348.11
    sample_time_ms: 6929.555
    update_time_ms: 48.147
  timestamp: 1602523716
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     14 |          361.341 | 2265088 |  239.314 |              297.323 |              103.081 |             838.99 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3621.70306923626
    time_step_min: 3249
  date: 2020-10-12_17-29-02
  done: false
  episode_len_mean: 836.9180731364276
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 240.39716788134493
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 177
  episodes_total: 2844
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9202035963535309
        entropy_coeff: 0.009999999999999998
        kl: 0.007997686509042978
        model: {}
        policy_loss: -0.014388365690441182
        total_loss: 12.009172042210897
        vf_explained_var: 0.9767346382141113
        vf_loss: 12.031162897745768
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.177419354838705
    gpu_util_percent0: 0.4158064516129033
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15206402532078883
    mean_env_wait_ms: 1.1895139522080447
    mean_inference_ms: 4.625425932770904
    mean_raw_obs_processing_ms: 0.39690059466033456
  time_since_restore: 387.22700548171997
  time_this_iter_s: 25.885827779769897
  time_total_s: 387.22700548171997
  timers:
    learn_throughput: 8685.791
    learn_time_ms: 18627.205
    sample_throughput: 23256.038
    sample_time_ms: 6956.989
    update_time_ms: 42.286
  timestamp: 1602523742
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     15 |          387.227 | 2426880 |  240.397 |              297.323 |              103.081 |            836.918 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3616.004054054054
    time_step_min: 3249
  date: 2020-10-12_17-29-28
  done: false
  episode_len_mean: 835.3847435043305
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 241.26000174967513
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9150711745023727
        entropy_coeff: 0.009999999999999998
        kl: 0.007132770338406165
        model: {}
        policy_loss: -0.010613611142616719
        total_loss: 11.799842993418375
        vf_explained_var: 0.9748950004577637
        vf_loss: 11.818180799484253
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.545161290322582
    gpu_util_percent0: 0.41645161290322574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15184897156923371
    mean_env_wait_ms: 1.1906370573232365
    mean_inference_ms: 4.6129962839548035
    mean_raw_obs_processing_ms: 0.3961833604259978
  time_since_restore: 412.824702501297
  time_this_iter_s: 25.597697019577026
  time_total_s: 412.824702501297
  timers:
    learn_throughput: 8685.387
    learn_time_ms: 18628.07
    sample_throughput: 23236.852
    sample_time_ms: 6962.733
    update_time_ms: 42.318
  timestamp: 1602523768
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     16 |          412.825 | 2588672 |   241.26 |              297.323 |              103.081 |            835.385 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3610.6658163265306
    time_step_min: 3249
  date: 2020-10-12_17-29-54
  done: false
  episode_len_mean: 833.8442416614223
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 242.0906198549369
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 176
  episodes_total: 3178
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8658195187648138
        entropy_coeff: 0.009999999999999998
        kl: 0.008863970326880613
        model: {}
        policy_loss: -0.015020921642038351
        total_loss: 14.347493489583334
        vf_explained_var: 0.9751224517822266
        vf_loss: 14.369399944941202
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.2741935483871
    gpu_util_percent0: 0.3858064516129033
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516300948507995
    mean_env_wait_ms: 1.1918153846947148
    mean_inference_ms: 4.600413786571401
    mean_raw_obs_processing_ms: 0.39543592768507957
  time_since_restore: 438.76113295555115
  time_this_iter_s: 25.93643045425415
  time_total_s: 438.76113295555115
  timers:
    learn_throughput: 8674.068
    learn_time_ms: 18652.379
    sample_throughput: 23184.373
    sample_time_ms: 6978.494
    update_time_ms: 43.825
  timestamp: 1602523794
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     17 |          438.761 | 2750464 |  242.091 |              297.323 |              103.081 |            833.844 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3601.875874125874
    time_step_min: 3249
  date: 2020-10-12_17-30-20
  done: false
  episode_len_mean: 831.1997697179045
  episode_reward_max: 297.3232323232324
  episode_reward_mean: 243.44127806563026
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 296
  episodes_total: 3474
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8665603796641032
        entropy_coeff: 0.009999999999999998
        kl: 0.007582330455382665
        model: {}
        policy_loss: -0.012080611400354732
        total_loss: 16.237193902333576
        vf_explained_var: 0.9764125347137451
        vf_loss: 16.256423711776733
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.354838709677423
    gpu_util_percent0: 0.43483870967741944
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15129544486693977
    mean_env_wait_ms: 1.1936127445241729
    mean_inference_ms: 4.581134862444662
    mean_raw_obs_processing_ms: 0.39434699634863024
  time_since_restore: 464.2873737812042
  time_this_iter_s: 25.526240825653076
  time_total_s: 464.2873737812042
  timers:
    learn_throughput: 8693.121
    learn_time_ms: 18611.497
    sample_throughput: 23125.272
    sample_time_ms: 6996.329
    update_time_ms: 48.873
  timestamp: 1602523820
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     18 |          464.287 | 2912256 |  243.441 |              297.323 |              103.081 |              831.2 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3596.6564587973276
    time_step_min: 3212
  date: 2020-10-12_17-30-46
  done: false
  episode_len_mean: 829.8544303797469
  episode_reward_max: 302.9292929292933
  episode_reward_mean: 244.2783781680313
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 160
  episodes_total: 3634
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.872158095240593
        entropy_coeff: 0.009999999999999998
        kl: 0.007503455349554618
        model: {}
        policy_loss: -0.013317631518778702
        total_loss: 11.288967370986938
        vf_explained_var: 0.9771515727043152
        vf_loss: 11.309505780537924
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.09354838709678
    gpu_util_percent0: 0.36580645161290326
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511328846075904
    mean_env_wait_ms: 1.1944836631086548
    mean_inference_ms: 4.571873260963519
    mean_raw_obs_processing_ms: 0.393820815281553
  time_since_restore: 489.8420579433441
  time_this_iter_s: 25.554684162139893
  time_total_s: 489.8420579433441
  timers:
    learn_throughput: 8691.054
    learn_time_ms: 18615.923
    sample_throughput: 23082.225
    sample_time_ms: 7009.376
    update_time_ms: 43.974
  timestamp: 1602523846
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     19 |          489.842 | 3074048 |  244.278 |              302.929 |              103.081 |            829.854 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3591.639221955769
    time_step_min: 3212
  date: 2020-10-12_17-31-11
  done: false
  episode_len_mean: 828.4990777338603
  episode_reward_max: 302.9292929292933
  episode_reward_mean: 245.044396534515
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 161
  episodes_total: 3795
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.852908730506897
        entropy_coeff: 0.009999999999999998
        kl: 0.008324692064585784
        model: {}
        policy_loss: -0.014183204097207636
        total_loss: 10.850107987721762
        vf_explained_var: 0.9776797890663147
        vf_loss: 10.871155341466268
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.55
    gpu_util_percent0: 0.30633333333333346
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.79
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509802817626636
    mean_env_wait_ms: 1.1953204597698706
    mean_inference_ms: 4.563089693765757
    mean_raw_obs_processing_ms: 0.39331244683923877
  time_since_restore: 515.2349293231964
  time_this_iter_s: 25.392871379852295
  time_total_s: 515.2349293231964
  timers:
    learn_throughput: 8696.341
    learn_time_ms: 18604.606
    sample_throughput: 23104.562
    sample_time_ms: 7002.6
    update_time_ms: 42.863
  timestamp: 1602523871
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     20 |          515.235 | 3235840 |  245.044 |              302.929 |              103.081 |            828.499 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3582.357873720988
    time_step_min: 3212
  date: 2020-10-12_17-31-37
  done: false
  episode_len_mean: 826.21190417387
  episode_reward_max: 302.9292929292933
  episode_reward_mean: 246.38588902110746
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 254
  episodes_total: 4049
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8158281644185384
        entropy_coeff: 0.009999999999999998
        kl: 0.008616499175938467
        model: {}
        policy_loss: -0.010538949475934109
        total_loss: 14.13656465212504
        vf_explained_var: 0.9790515303611755
        vf_loss: 14.153538703918457
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.938709677419357
    gpu_util_percent0: 0.37580645161290316
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15075166342417953
    mean_env_wait_ms: 1.1966037074332603
    mean_inference_ms: 4.550101721715485
    mean_raw_obs_processing_ms: 0.3925844513428973
  time_since_restore: 541.0791537761688
  time_this_iter_s: 25.844224452972412
  time_total_s: 541.0791537761688
  timers:
    learn_throughput: 8695.75
    learn_time_ms: 18605.872
    sample_throughput: 23134.651
    sample_time_ms: 6993.492
    update_time_ms: 42.948
  timestamp: 1602523897
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     21 |          541.079 | 3397632 |  246.386 |              302.929 |              103.081 |            826.212 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3575.015625
    time_step_min: 3212
  date: 2020-10-12_17-32-03
  done: false
  episode_len_mean: 824.1744022503516
  episode_reward_max: 302.9292929292933
  episode_reward_mean: 247.49353592180583
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 217
  episodes_total: 4266
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8308208535114924
        entropy_coeff: 0.009999999999999998
        kl: 0.007081258809193969
        model: {}
        policy_loss: -0.011739856670222556
        total_loss: 10.788744846979776
        vf_explained_var: 0.9794524312019348
        vf_loss: 10.807376702626547
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.983870967741936
    gpu_util_percent0: 0.362258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15057902408915616
    mean_env_wait_ms: 1.1975741775856688
    mean_inference_ms: 4.540100535820213
    mean_raw_obs_processing_ms: 0.3920193653532012
  time_since_restore: 566.6955597400665
  time_this_iter_s: 25.616405963897705
  time_total_s: 566.6955597400665
  timers:
    learn_throughput: 8702.387
    learn_time_ms: 18591.68
    sample_throughput: 23216.306
    sample_time_ms: 6968.895
    update_time_ms: 42.614
  timestamp: 1602523923
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     22 |          566.696 | 3559424 |  247.494 |              302.929 |              103.081 |            824.174 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3569.9988589685076
    time_step_min: 3212
  date: 2020-10-12_17-32-29
  done: false
  episode_len_mean: 822.6066907775769
  episode_reward_max: 302.9292929292933
  episode_reward_mean: 248.26396880194338
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8254567633072535
        entropy_coeff: 0.009999999999999998
        kl: 0.0073718843050301075
        model: {}
        policy_loss: -0.011949952051509172
        total_loss: 9.86139965057373
        vf_explained_var: 0.978172242641449
        vf_loss: 9.88012949625651
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.590322580645168
    gpu_util_percent0: 0.35677419354838713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15046035221872134
    mean_env_wait_ms: 1.1982712519187757
    mean_inference_ms: 4.533238539058816
    mean_raw_obs_processing_ms: 0.3916305053637505
  time_since_restore: 592.3940143585205
  time_this_iter_s: 25.69845461845398
  time_total_s: 592.3940143585205
  timers:
    learn_throughput: 8697.165
    learn_time_ms: 18602.844
    sample_throughput: 23243.701
    sample_time_ms: 6960.682
    update_time_ms: 42.04
  timestamp: 1602523949
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | RUNNING  | 172.17.0.4:9278 |     23 |          592.394 | 3721216 |  248.264 |              302.929 |              103.081 |            822.607 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8033a_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3564.1736487953117
    time_step_min: 3212
  date: 2020-10-12_17-32-54
  done: true
  episode_len_mean: 820.4450419445042
  episode_reward_max: 302.9292929292933
  episode_reward_mean: 249.1878236006004
  episode_reward_min: 103.08080808080787
  episodes_this_iter: 225
  episodes_total: 4649
  experiment_id: f9fc4c0b6a464083b932ef4cbf7e3310
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7843719075123469
        entropy_coeff: 0.009999999999999998
        kl: 0.008358718555731079
        model: {}
        policy_loss: -0.013861584981592992
        total_loss: 13.342822790145874
        vf_explained_var: 0.9780540466308594
        vf_loss: 13.362856229146322
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.151612903225804
    gpu_util_percent0: 0.3693548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9278
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15030081462169173
    mean_env_wait_ms: 1.1992631340580964
    mean_inference_ms: 4.524085441795567
    mean_raw_obs_processing_ms: 0.3911013956665079
  time_since_restore: 618.0124852657318
  time_this_iter_s: 25.618470907211304
  time_total_s: 618.0124852657318
  timers:
    learn_throughput: 8695.583
    learn_time_ms: 18606.228
    sample_throughput: 23286.055
    sample_time_ms: 6948.021
    update_time_ms: 44.589
  timestamp: 1602523974
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 8033a_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | TERMINATED |       |     24 |          618.012 | 3883008 |  249.188 |              302.929 |              103.081 |            820.445 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8033a_00000 | TERMINATED |       |     24 |          618.012 | 3883008 |  249.188 |              302.929 |              103.081 |            820.445 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


