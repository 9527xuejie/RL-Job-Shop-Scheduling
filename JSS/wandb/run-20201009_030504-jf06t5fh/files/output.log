2020-10-09 03:05:06,254	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_3c6be_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=16638)[0m 2020-10-09 03:05:09,263	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=16631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16498)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-09_03-05-39
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1635942101478576
        entropy_coeff: 0.0
        kl: 0.0035138906445354224
        model: {}
        policy_loss: -0.012293910863809288
        total_loss: 495.81426696777345
        vf_explained_var: 0.5586104393005371
        vf_loss: 495.82586975097655
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 38.179310344827584
    gpu_util_percent0: 0.3262068965517242
    gpu_util_percent1: 0.0003448275862068966
    gpu_util_percent2: 0.0003448275862068966
    ram_util_percent: 9.520689655172411
    vram_util_percent0: 0.27390834756449267
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17281113895747205
    mean_env_wait_ms: 1.6334659385622265
    mean_inference_ms: 5.675837539456148
    mean_raw_obs_processing_ms: 0.46820319335598315
  time_since_restore: 24.53150963783264
  time_this_iter_s: 24.53150963783264
  time_total_s: 24.53150963783264
  timers:
    learn_throughput: 10891.188
    learn_time_ms: 14855.312
    sample_throughput: 16859.422
    sample_time_ms: 9596.533
    update_time_ms: 42.835
  timestamp: 1602212739
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      1 |          24.5315 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3277.0
  date: 2020-10-09_03-06-02
  done: false
  episode_len_mean: 877.126582278481
  episode_reward_max: 273.929292929293
  episode_reward_mean: 228.78886970975555
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.1350104808807373
        entropy_coeff: 0.0
        kl: 0.004707499267533421
        model: {}
        policy_loss: -0.013637096248567104
        total_loss: 112.51151123046876
        vf_explained_var: 0.8019649386405945
        vf_loss: 112.52467727661133
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.026923076923076
    gpu_util_percent0: 0.37884615384615383
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.742307692307692
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16886088916790679
    mean_env_wait_ms: 1.6315099387919454
    mean_inference_ms: 5.425577867223743
    mean_raw_obs_processing_ms: 0.4572855848676558
  time_since_restore: 47.40128803253174
  time_this_iter_s: 22.869778394699097
  time_total_s: 47.40128803253174
  timers:
    learn_throughput: 10998.723
    learn_time_ms: 14710.071
    sample_throughput: 18167.239
    sample_time_ms: 8905.701
    update_time_ms: 39.614
  timestamp: 1602212762
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      2 |          47.4013 | 323584 |  228.789 |              273.929 |              115.788 |            877.127 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3231.0
  date: 2020-10-09_03-06-25
  done: false
  episode_len_mean: 875.8565400843881
  episode_reward_max: 279.48484848484816
  episode_reward_mean: 229.54547585560223
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.1276044011116029
        entropy_coeff: 0.0
        kl: 0.005753421364352107
        model: {}
        policy_loss: -0.015910479286685587
        total_loss: 56.86800422668457
        vf_explained_var: 0.8854900598526001
        vf_loss: 56.88362693786621
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.408
    gpu_util_percent0: 0.25800000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16634364280185357
    mean_env_wait_ms: 1.6303566060966226
    mean_inference_ms: 5.284566840747639
    mean_raw_obs_processing_ms: 0.44865651882593127
  time_since_restore: 70.08709239959717
  time_this_iter_s: 22.68580436706543
  time_total_s: 70.08709239959717
  timers:
    learn_throughput: 11033.819
    learn_time_ms: 14663.282
    sample_throughput: 18793.485
    sample_time_ms: 8608.941
    update_time_ms: 39.98
  timestamp: 1602212785
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      3 |          70.0871 | 485376 |  229.545 |              279.485 |              115.788 |            875.857 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3231.0
  date: 2020-10-09_03-06-48
  done: false
  episode_len_mean: 874.2215189873418
  episode_reward_max: 279.48484848484816
  episode_reward_mean: 230.44867983633787
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.1144239544868468
        entropy_coeff: 0.0
        kl: 0.005844885902479291
        model: {}
        policy_loss: -0.01680287579074502
        total_loss: 36.687211990356445
        vf_explained_var: 0.9231963157653809
        vf_loss: 36.70372276306152
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.111538461538466
    gpu_util_percent0: 0.2730769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16452556296729454
    mean_env_wait_ms: 1.630221240066444
    mean_inference_ms: 5.179388648118825
    mean_raw_obs_processing_ms: 0.44272010754411956
  time_since_restore: 92.69261884689331
  time_this_iter_s: 22.605526447296143
  time_total_s: 92.69261884689331
  timers:
    learn_throughput: 11022.638
    learn_time_ms: 14678.156
    sample_throughput: 19238.076
    sample_time_ms: 8409.989
    update_time_ms: 35.07
  timestamp: 1602212808
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      4 |          92.6926 | 647168 |  230.449 |              279.485 |              115.788 |            874.222 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_03-07-10
  done: false
  episode_len_mean: 871.8417721518987
  episode_reward_max: 279.66666666666606
  episode_reward_mean: 231.34214294847186
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.087269127368927
        entropy_coeff: 0.0
        kl: 0.005915942788124085
        model: {}
        policy_loss: -0.016846791375428438
        total_loss: 28.512984466552734
        vf_explained_var: 0.9472180604934692
        vf_loss: 28.529536247253418
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.22692307692308
    gpu_util_percent0: 0.30500000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1632057186380095
    mean_env_wait_ms: 1.631310470105794
    mean_inference_ms: 5.099187064731964
    mean_raw_obs_processing_ms: 0.43809713821954394
  time_since_restore: 115.31629419326782
  time_this_iter_s: 22.62367534637451
  time_total_s: 115.31629419326782
  timers:
    learn_throughput: 11032.006
    learn_time_ms: 14665.692
    sample_throughput: 19470.638
    sample_time_ms: 8309.538
    update_time_ms: 35.35
  timestamp: 1602212830
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      5 |          115.316 | 808960 |  231.342 |              279.667 |              115.788 |            871.842 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3210.0
  date: 2020-10-09_03-07-33
  done: false
  episode_len_mean: 866.0398550724638
  episode_reward_max: 280.37373737373724
  episode_reward_mean: 233.44018994290715
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.0930539131164552
        entropy_coeff: 0.0
        kl: 0.00585087426006794
        model: {}
        policy_loss: -0.014920222386717797
        total_loss: 30.642051696777344
        vf_explained_var: 0.9563310742378235
        vf_loss: 30.656679344177245
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.711999999999996
    gpu_util_percent0: 0.25120000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.756
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1615491878928811
    mean_env_wait_ms: 1.634289150524354
    mean_inference_ms: 4.991397514290039
    mean_raw_obs_processing_ms: 0.43221638368243814
  time_since_restore: 137.8466112613678
  time_this_iter_s: 22.530317068099976
  time_total_s: 137.8466112613678
  timers:
    learn_throughput: 11021.951
    learn_time_ms: 14679.071
    sample_throughput: 19711.809
    sample_time_ms: 8207.872
    update_time_ms: 34.565
  timestamp: 1602212853
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      6 |          137.847 | 970752 |   233.44 |              280.374 |              115.788 |             866.04 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3210.0
  date: 2020-10-09_03-07-55
  done: false
  episode_len_mean: 863.2507911392405
  episode_reward_max: 282.65656565656553
  episode_reward_mean: 234.57149021864194
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.094828975200653
        entropy_coeff: 0.0
        kl: 0.005641797138378024
        model: {}
        policy_loss: -0.016677248664200305
        total_loss: 18.994069862365723
        vf_explained_var: 0.9607902765274048
        vf_loss: 19.01046485900879
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.204
    gpu_util_percent0: 0.2772
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.768
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1609351764421197
    mean_env_wait_ms: 1.6357500874395767
    mean_inference_ms: 4.952061786697572
    mean_raw_obs_processing_ms: 0.4301833996797436
  time_since_restore: 160.2605323791504
  time_this_iter_s: 22.413921117782593
  time_total_s: 160.2605323791504
  timers:
    learn_throughput: 11030.895
    learn_time_ms: 14667.169
    sample_throughput: 19872.189
    sample_time_ms: 8141.629
    update_time_ms: 32.392
  timestamp: 1602212875
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      7 |          160.261 | 1132544 |  234.571 |              282.657 |              115.788 |            863.251 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3184.0
  date: 2020-10-09_03-08-18
  done: false
  episode_len_mean: 860.689170182841
  episode_reward_max: 285.67676767676744
  episode_reward_mean: 235.496128656466
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.0751481413841248
        entropy_coeff: 0.0
        kl: 0.0057609457522630695
        model: {}
        policy_loss: -0.016471171914599837
        total_loss: 19.582926177978514
        vf_explained_var: 0.9606234431266785
        vf_loss: 19.599109268188478
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.48846153846154
    gpu_util_percent0: 0.24807692307692308
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75769230769231
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16041510298868852
    mean_env_wait_ms: 1.637259959753518
    mean_inference_ms: 4.918557434553323
    mean_raw_obs_processing_ms: 0.4284307689062911
  time_since_restore: 182.83272314071655
  time_this_iter_s: 22.572190761566162
  time_total_s: 182.83272314071655
  timers:
    learn_throughput: 11026.993
    learn_time_ms: 14672.36
    sample_throughput: 19988.17
    sample_time_ms: 8094.388
    update_time_ms: 33.06
  timestamp: 1602212898
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      8 |          182.833 | 1294336 |  235.496 |              285.677 |              115.788 |            860.689 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-09_03-08-41
  done: false
  episode_len_mean: 858.3170886075949
  episode_reward_max: 285.67676767676744
  episode_reward_mean: 236.83571154583794
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.0550728559494018
        entropy_coeff: 0.0
        kl: 0.005947930598631501
        model: {}
        policy_loss: -0.016897777235135435
        total_loss: 15.2647274017334
        vf_explained_var: 0.9662826657295227
        vf_loss: 15.281328010559083
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.72
    gpu_util_percent0: 0.2396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.767999999999999
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15998337695960255
    mean_env_wait_ms: 1.6386850417726846
    mean_inference_ms: 4.889503601801496
    mean_raw_obs_processing_ms: 0.42683995554188736
  time_since_restore: 205.2414195537567
  time_this_iter_s: 22.40869641304016
  time_total_s: 205.2414195537567
  timers:
    learn_throughput: 11034.374
    learn_time_ms: 14662.544
    sample_throughput: 20086.123
    sample_time_ms: 8054.914
    update_time_ms: 33.099
  timestamp: 1602212921
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |      9 |          205.241 | 1456128 |  236.836 |              285.677 |              115.788 |            858.317 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-09_03-09-03
  done: false
  episode_len_mean: 854.3219967087219
  episode_reward_max: 285.67676767676744
  episode_reward_mean: 238.67497797503265
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 243
  episodes_total: 1823
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.016876494884491
        entropy_coeff: 0.0
        kl: 0.005541880242526531
        model: {}
        policy_loss: -0.015824597561731935
        total_loss: 21.259523773193358
        vf_explained_var: 0.9685574769973755
        vf_loss: 21.275071716308595
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.08461538461538
    gpu_util_percent0: 0.4034615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15943992278991936
    mean_env_wait_ms: 1.6410549723568286
    mean_inference_ms: 4.852266618842089
    mean_raw_obs_processing_ms: 0.42476383849518906
  time_since_restore: 227.96951484680176
  time_this_iter_s: 22.728095293045044
  time_total_s: 227.96951484680176
  timers:
    learn_throughput: 11020.178
    learn_time_ms: 14681.433
    sample_throughput: 20154.056
    sample_time_ms: 8027.764
    update_time_ms: 33.159
  timestamp: 1602212943
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     10 |           227.97 | 1617920 |  238.675 |              285.677 |              115.788 |            854.322 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-09_03-09-26
  done: false
  episode_len_mean: 851.0272638753652
  episode_reward_max: 285.67676767676744
  episode_reward_mean: 240.16178336431486
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 231
  episodes_total: 2054
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.0309948921203613
        entropy_coeff: 0.0
        kl: 0.005586620885878801
        model: {}
        policy_loss: -0.016185095300897956
        total_loss: 13.459691619873047
        vf_explained_var: 0.9753389358520508
        vf_loss: 13.475597286224366
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.931999999999995
    gpu_util_percent0: 0.344
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760000000000002
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15902334451341887
    mean_env_wait_ms: 1.6432286116314572
    mean_inference_ms: 4.822951350326051
    mean_raw_obs_processing_ms: 0.4232738971613195
  time_since_restore: 250.532240152359
  time_this_iter_s: 22.56272530555725
  time_total_s: 250.532240152359
  timers:
    learn_throughput: 11039.374
    learn_time_ms: 14655.903
    sample_throughput: 20595.937
    sample_time_ms: 7855.53
    update_time_ms: 32.07
  timestamp: 1602212966
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     11 |          250.532 | 1779712 |  240.162 |              285.677 |              115.788 |            851.027 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3100.0
  date: 2020-10-09_03-09-49
  done: false
  episode_len_mean: 848.875678119349
  episode_reward_max: 295.1414141414141
  episode_reward_mean: 240.99462984273094
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.0093911290168762
        entropy_coeff: 0.0
        kl: 0.005460567260161042
        model: {}
        policy_loss: -0.01704194867052138
        total_loss: 12.253048992156982
        vf_explained_var: 0.9753111600875854
        vf_loss: 12.269818115234376
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.516000000000005
    gpu_util_percent0: 0.3028
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15875710000648866
    mean_env_wait_ms: 1.644530281828927
    mean_inference_ms: 4.805464466800582
    mean_raw_obs_processing_ms: 0.42233525765309166
  time_since_restore: 273.3256061077118
  time_this_iter_s: 22.793365955352783
  time_total_s: 273.3256061077118
  timers:
    learn_throughput: 11034.591
    learn_time_ms: 14662.256
    sample_throughput: 20630.489
    sample_time_ms: 7842.374
    update_time_ms: 30.33
  timestamp: 1602212989
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     12 |          273.326 | 1941504 |  240.995 |              295.141 |              115.788 |            848.876 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3100.0
  date: 2020-10-09_03-10-12
  done: false
  episode_len_mean: 847.0430379746836
  episode_reward_max: 295.1414141414141
  episode_reward_mean: 241.80153006861852
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9880557596683502
        entropy_coeff: 0.0
        kl: 0.005633105151355266
        model: {}
        policy_loss: -0.015603921562433242
        total_loss: 15.450887680053711
        vf_explained_var: 0.9676672220230103
        vf_loss: 15.466209983825683
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.05
    gpu_util_percent0: 0.3403846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15852037923871345
    mean_env_wait_ms: 1.645738841213171
    mean_inference_ms: 4.789556008733007
    mean_raw_obs_processing_ms: 0.4214759252178338
  time_since_restore: 295.7567529678345
  time_this_iter_s: 22.43114686012268
  time_total_s: 295.7567529678345
  timers:
    learn_throughput: 11031.643
    learn_time_ms: 14666.174
    sample_throughput: 20703.794
    sample_time_ms: 7814.606
    update_time_ms: 29.093
  timestamp: 1602213012
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     13 |          295.757 | 2103296 |  241.802 |              295.141 |              115.788 |            847.043 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-10-35
  done: false
  episode_len_mean: 844.1892720306513
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 243.17500677270777
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 240
  episodes_total: 2610
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9486512899398803
        entropy_coeff: 0.0
        kl: 0.005396779533475638
        model: {}
        policy_loss: -0.015401770547032356
        total_loss: 18.92274875640869
        vf_explained_var: 0.9715396165847778
        vf_loss: 18.937880516052246
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.21153846153846
    gpu_util_percent0: 0.295
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581808574390993
    mean_env_wait_ms: 1.6475620580951966
    mean_inference_ms: 4.768072787063575
    mean_raw_obs_processing_ms: 0.4202898558853414
  time_since_restore: 318.7886919975281
  time_this_iter_s: 23.031939029693604
  time_total_s: 318.7886919975281
  timers:
    learn_throughput: 11023.892
    learn_time_ms: 14676.486
    sample_throughput: 20627.075
    sample_time_ms: 7843.671
    update_time_ms: 31.476
  timestamp: 1602213035
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     14 |          318.789 | 2265088 |  243.175 |              299.283 |              115.788 |            844.189 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-10-57
  done: false
  episode_len_mean: 841.4321378340366
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 244.42018284106877
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 234
  episodes_total: 2844
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9608245015144348
        entropy_coeff: 0.0
        kl: 0.005358022404834628
        model: {}
        policy_loss: -0.01515944164711982
        total_loss: 13.316986179351806
        vf_explained_var: 0.9758182764053345
        vf_loss: 13.331878280639648
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.315384615384616
    gpu_util_percent0: 0.3373076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15791601342992545
    mean_env_wait_ms: 1.6492517234603696
    mean_inference_ms: 4.749803952967335
    mean_raw_obs_processing_ms: 0.4193389821598051
  time_since_restore: 341.3033893108368
  time_this_iter_s: 22.514697313308716
  time_total_s: 341.3033893108368
  timers:
    learn_throughput: 11024.476
    learn_time_ms: 14675.709
    sample_throughput: 20668.412
    sample_time_ms: 7827.984
    update_time_ms: 36.755
  timestamp: 1602213057
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     15 |          341.303 | 2426880 |   244.42 |              299.283 |              115.788 |            841.432 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-11-20
  done: false
  episode_len_mean: 839.3980679546969
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 245.1830362250081
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9492599666118622
        entropy_coeff: 0.0
        kl: 0.005126431444659829
        model: {}
        policy_loss: -0.01577321467921138
        total_loss: 12.317150592803955
        vf_explained_var: 0.9739915728569031
        vf_loss: 12.33266773223877
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.808
    gpu_util_percent0: 0.3304000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.768
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1577464029300514
    mean_env_wait_ms: 1.6503672523943556
    mean_inference_ms: 4.738721495316022
    mean_raw_obs_processing_ms: 0.41875983015859386
  time_since_restore: 363.81551456451416
  time_this_iter_s: 22.512125253677368
  time_total_s: 363.81551456451416
  timers:
    learn_throughput: 11037.039
    learn_time_ms: 14659.004
    sample_throughput: 20633.478
    sample_time_ms: 7841.237
    update_time_ms: 37.798
  timestamp: 1602213080
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     16 |          363.816 | 2588672 |  245.183 |              299.283 |              115.788 |            839.398 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-11-43
  done: false
  episode_len_mean: 837.6001265422335
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 246.00398799766077
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 3161
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9188430309295654
        entropy_coeff: 0.0
        kl: 0.005502896988764406
        model: {}
        policy_loss: -0.01618853071704507
        total_loss: 10.24655647277832
        vf_explained_var: 0.978076159954071
        vf_loss: 10.262469673156739
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.31153846153846
    gpu_util_percent0: 0.31961538461538463
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15758789090337078
    mean_env_wait_ms: 1.6514810216111202
    mean_inference_ms: 4.728332513328262
    mean_raw_obs_processing_ms: 0.4181983558861187
  time_since_restore: 386.44645404815674
  time_this_iter_s: 22.630939483642578
  time_total_s: 386.44645404815674
  timers:
    learn_throughput: 11028.411
    learn_time_ms: 14670.473
    sample_throughput: 20612.163
    sample_time_ms: 7849.346
    update_time_ms: 39.286
  timestamp: 1602213103
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     17 |          386.446 | 2750464 |  246.004 |              299.283 |              115.788 |              837.6 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-12-05
  done: false
  episode_len_mean: 834.5216763005781
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 247.18914287382484
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 299
  episodes_total: 3460
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9020475089550019
        entropy_coeff: 0.0
        kl: 0.005325380805879831
        model: {}
        policy_loss: -0.01460872390307486
        total_loss: 16.7103572845459
        vf_explained_var: 0.9759536981582642
        vf_loss: 16.72470016479492
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.967999999999996
    gpu_util_percent0: 0.2572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573226206772797
    mean_env_wait_ms: 1.6535251588984081
    mean_inference_ms: 4.710857731748923
    mean_raw_obs_processing_ms: 0.4172927172672053
  time_since_restore: 408.90347146987915
  time_this_iter_s: 22.457017421722412
  time_total_s: 408.90347146987915
  timers:
    learn_throughput: 11037.088
    learn_time_ms: 14658.939
    sample_throughput: 20611.955
    sample_time_ms: 7849.425
    update_time_ms: 39.136
  timestamp: 1602213125
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     18 |          408.903 | 2912256 |  247.189 |              299.283 |              115.788 |            834.522 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-12-28
  done: false
  episode_len_mean: 832.9543203082003
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 247.88628719778953
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 174
  episodes_total: 3634
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.9007503092288971
        entropy_coeff: 0.0
        kl: 0.005303696729242802
        model: {}
        policy_loss: -0.016653150971978902
        total_loss: 9.054275798797608
        vf_explained_var: 0.9815114140510559
        vf_loss: 9.070663738250733
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.330769230769235
    gpu_util_percent0: 0.2726923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.776923076923078
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15718856864600927
    mean_env_wait_ms: 1.6546978402705734
    mean_inference_ms: 4.701756315162418
    mean_raw_obs_processing_ms: 0.4168309609298851
  time_since_restore: 431.43633341789246
  time_this_iter_s: 22.532861948013306
  time_total_s: 431.43633341789246
  timers:
    learn_throughput: 11043.71
    learn_time_ms: 14650.149
    sample_throughput: 20556.998
    sample_time_ms: 7870.41
    update_time_ms: 37.763
  timestamp: 1602213148
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     19 |          431.436 | 3074048 |  247.886 |              299.283 |              115.788 |            832.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-12-51
  done: false
  episode_len_mean: 831.5685654008439
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 248.40168829646666
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8949060797691345
        entropy_coeff: 0.0
        kl: 0.005565313482657075
        model: {}
        policy_loss: -0.01613840740174055
        total_loss: 9.403546810150146
        vf_explained_var: 0.9794608354568481
        vf_loss: 9.419406986236572
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.434615384615384
    gpu_util_percent0: 0.25461538461538463
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.780769230769232
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1570715521872434
    mean_env_wait_ms: 1.655712296872789
    mean_inference_ms: 4.69401632478483
    mean_raw_obs_processing_ms: 0.4164297570087439
  time_since_restore: 454.1178557872772
  time_this_iter_s: 22.681522369384766
  time_total_s: 454.1178557872772
  timers:
    learn_throughput: 11061.665
    learn_time_ms: 14626.369
    sample_throughput: 20509.633
    sample_time_ms: 7888.586
    update_time_ms: 38.427
  timestamp: 1602213171
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     20 |          454.118 | 3235840 |  248.402 |              299.283 |              115.788 |            831.569 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-13-14
  done: false
  episode_len_mean: 829.7923771313942
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 249.06556538301763
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 196
  episodes_total: 3988
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8617749631404876
        entropy_coeff: 0.0
        kl: 0.005345986783504486
        model: {}
        policy_loss: -0.015940317453350873
        total_loss: 10.492369365692138
        vf_explained_var: 0.9819173812866211
        vf_loss: 10.508042144775391
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.792307692307695
    gpu_util_percent0: 0.3434615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15693281707209722
    mean_env_wait_ms: 1.6570038945142633
    mean_inference_ms: 4.685005633899352
    mean_raw_obs_processing_ms: 0.4159420074612242
  time_since_restore: 476.83705854415894
  time_this_iter_s: 22.719202756881714
  time_total_s: 476.83705854415894
  timers:
    learn_throughput: 11053.515
    learn_time_ms: 14637.154
    sample_throughput: 20496.317
    sample_time_ms: 7893.711
    update_time_ms: 37.152
  timestamp: 1602213194
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     21 |          476.837 | 3397632 |  249.066 |              299.283 |              115.788 |            829.792 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-13-37
  done: false
  episode_len_mean: 827.5056258790436
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 249.93239473970826
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 278
  episodes_total: 4266
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8547482192516327
        entropy_coeff: 0.0
        kl: 0.005083319591358304
        model: {}
        policy_loss: -0.015161011484451592
        total_loss: 10.347057914733886
        vf_explained_var: 0.9824047088623047
        vf_loss: 10.361964797973632
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.15769230769231
    gpu_util_percent0: 0.2992307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1567640650636127
    mean_env_wait_ms: 1.6587128585951014
    mean_inference_ms: 4.673607675500395
    mean_raw_obs_processing_ms: 0.4153820945787261
  time_since_restore: 499.52031540870667
  time_this_iter_s: 22.68325686454773
  time_total_s: 499.52031540870667
  timers:
    learn_throughput: 11053.158
    learn_time_ms: 14637.627
    sample_throughput: 20531.452
    sample_time_ms: 7880.203
    update_time_ms: 38.446
  timestamp: 1602213217
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     22 |           499.52 | 3559424 |  249.932 |              299.283 |              115.788 |            827.506 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-13-59
  done: false
  episode_len_mean: 826.3589511754069
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 250.40054477870922
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8543944478034973
        entropy_coeff: 0.0
        kl: 0.005409677838906645
        model: {}
        policy_loss: -0.016276362352073193
        total_loss: 7.975495004653931
        vf_explained_var: 0.9825857877731323
        vf_loss: 7.991500759124756
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.364
    gpu_util_percent0: 0.35519999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.772
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566724787627433
    mean_env_wait_ms: 1.6596511340134408
    mean_inference_ms: 4.667565422850847
    mean_raw_obs_processing_ms: 0.4150775645950716
  time_since_restore: 522.1536014080048
  time_this_iter_s: 22.633285999298096
  time_total_s: 522.1536014080048
  timers:
    learn_throughput: 11053.503
    learn_time_ms: 14637.169
    sample_throughput: 20478.918
    sample_time_ms: 7900.417
    update_time_ms: 37.733
  timestamp: 1602213239
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     23 |          522.154 | 3721216 |  250.401 |              299.283 |              115.788 |            826.359 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-14-23
  done: false
  episode_len_mean: 825.3230802792322
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 250.83047975390897
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 160
  episodes_total: 4584
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8351674199104309
        entropy_coeff: 0.0
        kl: 0.0053764669690281154
        model: {}
        policy_loss: -0.01604114572983235
        total_loss: 9.378364562988281
        vf_explained_var: 0.9796935319900513
        vf_loss: 9.394137001037597
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.34444444444445
    gpu_util_percent0: 0.33185185185185184
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15658565352874038
    mean_env_wait_ms: 1.6606186448826905
    mean_inference_ms: 4.661743698698958
    mean_raw_obs_processing_ms: 0.414775892429353
  time_since_restore: 545.2683615684509
  time_this_iter_s: 23.114760160446167
  time_total_s: 545.2683615684509
  timers:
    learn_throughput: 11065.224
    learn_time_ms: 14621.665
    sample_throughput: 20419.212
    sample_time_ms: 7923.518
    update_time_ms: 37.301
  timestamp: 1602213263
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     24 |          545.268 | 3883008 |   250.83 |              299.283 |              115.788 |            825.323 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-14-45
  done: false
  episode_len_mean: 823.7929759704251
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 251.56715646918965
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 285
  episodes_total: 4869
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8138371646404267
        entropy_coeff: 0.0
        kl: 0.005146903358399868
        model: {}
        policy_loss: -0.015000650752335786
        total_loss: 11.413798809051514
        vf_explained_var: 0.9825458526611328
        vf_loss: 11.428542327880859
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.572
    gpu_util_percent0: 0.31720000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.752
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15644144159290369
    mean_env_wait_ms: 1.6622007032605537
    mean_inference_ms: 4.6521962692787024
    mean_raw_obs_processing_ms: 0.4142781132762021
  time_since_restore: 567.6815423965454
  time_this_iter_s: 22.413180828094482
  time_total_s: 567.6815423965454
  timers:
    learn_throughput: 11061.857
    learn_time_ms: 14626.116
    sample_throughput: 20441.931
    sample_time_ms: 7914.712
    update_time_ms: 30.642
  timestamp: 1602213285
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     25 |          567.682 | 4044800 |  251.567 |              299.283 |              115.788 |            823.793 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-15-08
  done: false
  episode_len_mean: 823.0089003164557
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 251.96188946426278
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 187
  episodes_total: 5056
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.80954310297966
        entropy_coeff: 0.0
        kl: 0.004904722655192017
        model: {}
        policy_loss: -0.0155746222124435
        total_loss: 9.889146327972412
        vf_explained_var: 0.9806920886039734
        vf_loss: 9.904475879669189
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.592000000000006
    gpu_util_percent0: 0.31360000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.772
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15635539095918805
    mean_env_wait_ms: 1.6631726218631573
    mean_inference_ms: 4.646362880124602
    mean_raw_obs_processing_ms: 0.41400035201887314
  time_since_restore: 590.1268813610077
  time_this_iter_s: 22.44533896446228
  time_total_s: 590.1268813610077
  timers:
    learn_throughput: 11061.011
    learn_time_ms: 14627.235
    sample_throughput: 20465.964
    sample_time_ms: 7905.418
    update_time_ms: 29.089
  timestamp: 1602213308
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | RUNNING  | 172.17.0.4:16638 |     26 |          590.127 | 4206592 |  251.962 |              299.283 |              115.788 |            823.009 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3c6be_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3070.0
  date: 2020-10-09_03-15-31
  done: true
  episode_len_mean: 822.3833908707327
  episode_reward_max: 299.2828282828286
  episode_reward_mean: 252.3845319322879
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 5214
  experiment_id: d9c67cabe9b54413948925ab3fb62549
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 0.8119788765907288
        entropy_coeff: 0.0
        kl: 0.0054354199673980474
        model: {}
        policy_loss: -0.016428670892491937
        total_loss: 8.332065677642822
        vf_explained_var: 0.9809784889221191
        vf_loss: 8.348358297348023
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.70384615384615
    gpu_util_percent0: 0.2830769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.780769230769232
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1562860188890644
    mean_env_wait_ms: 1.6639650682548126
    mean_inference_ms: 4.641717657714609
    mean_raw_obs_processing_ms: 0.4137664624097947
  time_since_restore: 612.767391204834
  time_this_iter_s: 22.640509843826294
  time_total_s: 612.767391204834
  timers:
    learn_throughput: 11066.239
    learn_time_ms: 14620.324
    sample_throughput: 20448.355
    sample_time_ms: 7912.226
    update_time_ms: 29.132
  timestamp: 1602213331
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 3c6be_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | TERMINATED |       |     27 |          612.767 | 4368384 |  252.385 |              299.283 |              115.788 |            822.383 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3c6be_00000 | TERMINATED |       |     27 |          612.767 | 4368384 |  252.385 |              299.283 |              115.788 |            822.383 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


