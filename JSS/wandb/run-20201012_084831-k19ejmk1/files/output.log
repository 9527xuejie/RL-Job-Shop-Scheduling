2020-10-12 08:48:35,558	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b7bce_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=34085)[0m 2020-10-12 08:48:38,359	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=34097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34059)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_08-49-12
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1850829323132832
        entropy_coeff: 0.0001
        kl: 0.004093626630492508
        model: {}
        policy_loss: -0.007868677183675269
        total_loss: 507.0761362711589
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.742857142857144
    gpu_util_percent0: 0.3002857142857142
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.56
    vram_util_percent0: 0.08552921332521203
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17007244483450748
    mean_env_wait_ms: 1.1758881463206599
    mean_inference_ms: 5.917305108683092
    mean_raw_obs_processing_ms: 0.4570395183180467
  time_since_restore: 28.66883397102356
  time_this_iter_s: 28.66883397102356
  time_total_s: 28.66883397102356
  timers:
    learn_throughput: 8378.585
    learn_time_ms: 19310.181
    sample_throughput: 17406.221
    sample_time_ms: 9295.067
    update_time_ms: 30.95
  timestamp: 1602492552
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      1 |          28.6688 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3608.8055555555557
    time_step_min: 3250
  date: 2020-10-12_08-49-39
  done: false
  episode_len_mean: 890.7056962025316
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.07793121084234
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1567376752694447
        entropy_coeff: 0.0001
        kl: 0.0070590757532045245
        model: {}
        policy_loss: -0.010883362002156597
        total_loss: 129.9215234120687
        vf_explained_var: 0.8072310090065002
        vf_loss: 129.93181800842285
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.309375
    gpu_util_percent0: 0.3934375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.746875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1654431794837442
    mean_env_wait_ms: 1.1717627648886877
    mean_inference_ms: 5.636689216114889
    mean_raw_obs_processing_ms: 0.4442287200505556
  time_since_restore: 55.46663856506348
  time_this_iter_s: 26.797804594039917
  time_total_s: 55.46663856506348
  timers:
    learn_throughput: 8431.924
    learn_time_ms: 19188.029
    sample_throughput: 19080.628
    sample_time_ms: 8479.386
    update_time_ms: 26.183
  timestamp: 1602492579
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      2 |          55.4666 | 323584 |  217.078 |              273.596 |              138.899 |            890.706 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3602.798206278027
    time_step_min: 3250
  date: 2020-10-12_08-50-06
  done: false
  episode_len_mean: 886.1392405063291
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 218.34343434343413
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.143834412097931
        entropy_coeff: 0.0001
        kl: 0.00900065409950912
        model: {}
        policy_loss: -0.012952111646882258
        total_loss: 62.266885121663414
        vf_explained_var: 0.8935738205909729
        vf_loss: 62.279051780700684
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.86969696969697
    gpu_util_percent0: 0.3557575757575758
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772727272727273
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16235099515447016
    mean_env_wait_ms: 1.1711995477544175
    mean_inference_ms: 5.4315394961722845
    mean_raw_obs_processing_ms: 0.43519531090754504
  time_since_restore: 82.2608654499054
  time_this_iter_s: 26.79422688484192
  time_total_s: 82.2608654499054
  timers:
    learn_throughput: 8392.687
    learn_time_ms: 19277.736
    sample_throughput: 20060.368
    sample_time_ms: 8065.256
    update_time_ms: 31.521
  timestamp: 1602492606
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      3 |          82.2609 | 485376 |  218.343 |              273.596 |               137.99 |            886.139 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3596.7533112582782
    time_step_min: 3250
  date: 2020-10-12_08-50-32
  done: false
  episode_len_mean: 882.5870253164557
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 219.16725802327048
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1256821552912395
        entropy_coeff: 0.0001
        kl: 0.00838832138106227
        model: {}
        policy_loss: -0.013208418832315752
        total_loss: 44.44708792368571
        vf_explained_var: 0.9239999651908875
        vf_loss: 44.45957056681315
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.36875
    gpu_util_percent0: 0.391875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16020915492558616
    mean_env_wait_ms: 1.170960792081896
    mean_inference_ms: 5.284510582773325
    mean_raw_obs_processing_ms: 0.4283467072729477
  time_since_restore: 108.49334454536438
  time_this_iter_s: 26.232479095458984
  time_total_s: 108.49334454536438
  timers:
    learn_throughput: 8417.216
    learn_time_ms: 19221.558
    sample_throughput: 20719.894
    sample_time_ms: 7808.534
    update_time_ms: 32.449
  timestamp: 1602492632
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      4 |          108.493 | 647168 |  219.167 |              273.596 |               137.99 |            882.587 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3591.5629921259842
    time_step_min: 3242
  date: 2020-10-12_08-50-58
  done: false
  episode_len_mean: 878.2569620253165
  episode_reward_max: 274.8080808080809
  episode_reward_mean: 220.1586753612068
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0966354012489319
        entropy_coeff: 0.0001
        kl: 0.008652650052681565
        model: {}
        policy_loss: -0.013121832271281164
        total_loss: 35.068282763163246
        vf_explained_var: 0.9439868927001953
        vf_loss: 35.080649058024086
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.806451612903228
    gpu_util_percent0: 0.33806451612903227
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15864704471293362
    mean_env_wait_ms: 1.1715553513448569
    mean_inference_ms: 5.174791401279589
    mean_raw_obs_processing_ms: 0.42303087966284747
  time_since_restore: 134.80124497413635
  time_this_iter_s: 26.307900428771973
  time_total_s: 134.80124497413635
  timers:
    learn_throughput: 8433.414
    learn_time_ms: 19184.638
    sample_throughput: 21073.852
    sample_time_ms: 7677.382
    update_time_ms: 34.264
  timestamp: 1602492658
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      5 |          134.801 | 808960 |  220.159 |              274.808 |               137.99 |            878.257 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3575.0697674418607
    time_step_min: 3187
  date: 2020-10-12_08-51-25
  done: false
  episode_len_mean: 868.2937443336356
  episode_reward_max: 283.14141414141375
  episode_reward_mean: 223.16600272901252
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 313
  episodes_total: 1103
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0826950172583263
        entropy_coeff: 0.0001
        kl: 0.008017374784685671
        model: {}
        policy_loss: -0.009852176726174852
        total_loss: 37.77317714691162
        vf_explained_var: 0.9565708637237549
        vf_loss: 37.78233687082926
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.121875000000003
    gpu_util_percent0: 0.27375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7687500000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15658011148034967
    mean_env_wait_ms: 1.174675724672405
    mean_inference_ms: 5.028787591019388
    mean_raw_obs_processing_ms: 0.41624576281956216
  time_since_restore: 161.20420932769775
  time_this_iter_s: 26.4029643535614
  time_total_s: 161.20420932769775
  timers:
    learn_throughput: 8429.684
    learn_time_ms: 19193.126
    sample_throughput: 21351.224
    sample_time_ms: 7577.645
    update_time_ms: 35.274
  timestamp: 1602492685
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      6 |          161.204 | 970752 |  223.166 |              283.141 |               137.99 |            868.294 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3561.846278317152
    time_step_min: 3187
  date: 2020-10-12_08-51-51
  done: false
  episode_len_mean: 862.3742088607595
  episode_reward_max: 283.14141414141375
  episode_reward_mean: 225.2731747858328
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 161
  episodes_total: 1264
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0706466734409332
        entropy_coeff: 0.0001
        kl: 0.007869300238477686
        model: {}
        policy_loss: -0.013351764432930699
        total_loss: 18.482054869333904
        vf_explained_var: 0.9659532904624939
        vf_loss: 18.49472649892171
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.371875000000003
    gpu_util_percent0: 0.3028125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7843750000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15583032328558655
    mean_env_wait_ms: 1.1762072212287429
    mean_inference_ms: 4.975444621996932
    mean_raw_obs_processing_ms: 0.41371028178839997
  time_since_restore: 187.448495388031
  time_this_iter_s: 26.244286060333252
  time_total_s: 187.448495388031
  timers:
    learn_throughput: 8432.115
    learn_time_ms: 19187.593
    sample_throughput: 21579.106
    sample_time_ms: 7497.623
    update_time_ms: 33.196
  timestamp: 1602492711
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      7 |          187.448 | 1132544 |  225.273 |              283.141 |               137.99 |            862.374 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3551.647776183644
    time_step_min: 3187
  date: 2020-10-12_08-52-17
  done: false
  episode_len_mean: 858.2130801687764
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 227.1781954566763
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0530053079128265
        entropy_coeff: 0.0001
        kl: 0.007424288894981146
        model: {}
        policy_loss: -0.014031020080437884
        total_loss: 18.28844420115153
        vf_explained_var: 0.9650914669036865
        vf_loss: 18.30183744430542
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.77741935483871
    gpu_util_percent0: 0.35290322580645167
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552016030465719
    mean_env_wait_ms: 1.177545756181366
    mean_inference_ms: 4.930081334310762
    mean_raw_obs_processing_ms: 0.4114917803237996
  time_since_restore: 213.53041887283325
  time_this_iter_s: 26.081923484802246
  time_total_s: 213.53041887283325
  timers:
    learn_throughput: 8438.094
    learn_time_ms: 19173.999
    sample_throughput: 21784.1
    sample_time_ms: 7427.068
    update_time_ms: 31.904
  timestamp: 1602492737
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      8 |           213.53 | 1294336 |  227.178 |              286.929 |               137.99 |            858.213 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3540.2345360824743
    time_step_min: 3187
  date: 2020-10-12_08-52-44
  done: false
  episode_len_mean: 854.4341772151898
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 228.90886715253788
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0118485788504283
        entropy_coeff: 0.0001
        kl: 0.007579043585186203
        model: {}
        policy_loss: -0.010258643926742176
        total_loss: 15.40296204884847
        vf_explained_var: 0.9705337882041931
        vf_loss: 15.412563880284628
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.028125
    gpu_util_percent0: 0.28875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15465717991487304
    mean_env_wait_ms: 1.1788196979458856
    mean_inference_ms: 4.890577734493217
    mean_raw_obs_processing_ms: 0.40947510696166484
  time_since_restore: 239.88541412353516
  time_this_iter_s: 26.354995250701904
  time_total_s: 239.88541412353516
  timers:
    learn_throughput: 8430.599
    learn_time_ms: 19191.043
    sample_throughput: 21948.377
    sample_time_ms: 7371.479
    update_time_ms: 32.818
  timestamp: 1602492764
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      9 |          239.885 | 1456128 |  228.909 |              286.929 |               137.99 |            854.434 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3518.7373791621912
    time_step_min: 3186
  date: 2020-10-12_08-53-10
  done: false
  episode_len_mean: 847.1243386243386
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 232.65247715247702
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 310
  episodes_total: 1890
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9885825465122858
        entropy_coeff: 0.0001
        kl: 0.00694818701595068
        model: {}
        policy_loss: -0.011202118165480593
        total_loss: 19.333553791046143
        vf_explained_var: 0.9741263389587402
        vf_loss: 19.344160079956055
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.171875000000004
    gpu_util_percent0: 0.366875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537913928501555
    mean_env_wait_ms: 1.1815222635861933
    mean_inference_ms: 4.82769070236409
    mean_raw_obs_processing_ms: 0.40637037872756154
  time_since_restore: 266.2845878601074
  time_this_iter_s: 26.399173736572266
  time_total_s: 266.2845878601074
  timers:
    learn_throughput: 8422.288
    learn_time_ms: 19209.982
    sample_throughput: 22077.44
    sample_time_ms: 7328.386
    update_time_ms: 32.191
  timestamp: 1602492790
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     10 |          266.285 | 1617920 |  232.652 |              286.929 |               137.99 |            847.124 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3508.0286278381045
    time_step_min: 3186
  date: 2020-10-12_08-53-37
  done: false
  episode_len_mean: 843.8758519961052
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 234.34446214825948
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 164
  episodes_total: 2054
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9782296568155289
        entropy_coeff: 0.0001
        kl: 0.0074202436953783035
        model: {}
        policy_loss: -0.011524421182305863
        total_loss: 11.349893887837728
        vf_explained_var: 0.9778836369514465
        vf_loss: 11.360774596532186
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.859375
    gpu_util_percent0: 0.3996875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15341298736907588
    mean_env_wait_ms: 1.182803549867535
    mean_inference_ms: 4.800486837254802
    mean_raw_obs_processing_ms: 0.4050289869370817
  time_since_restore: 292.6636288166046
  time_this_iter_s: 26.379040956497192
  time_total_s: 292.6636288166046
  timers:
    learn_throughput: 8427.411
    learn_time_ms: 19198.305
    sample_throughput: 22779.97
    sample_time_ms: 7102.38
    update_time_ms: 32.804
  timestamp: 1602492817
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     11 |          292.664 | 1779712 |  234.344 |              286.929 |               137.99 |            843.876 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3497.526098901099
    time_step_min: 3186
  date: 2020-10-12_08-54-04
  done: false
  episode_len_mean: 840.8141952983725
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 236.0104069629385
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9659954756498337
        entropy_coeff: 0.0001
        kl: 0.00687529263086617
        model: {}
        policy_loss: -0.011743300943635404
        total_loss: 12.973399877548218
        vf_explained_var: 0.9719108939170837
        vf_loss: 12.984552383422852
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.0375
    gpu_util_percent0: 0.3734375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15308703300869356
    mean_env_wait_ms: 1.1839233426991242
    mean_inference_ms: 4.776752266580966
    mean_raw_obs_processing_ms: 0.4038223853919892
  time_since_restore: 319.32670307159424
  time_this_iter_s: 26.663074254989624
  time_total_s: 319.32670307159424
  timers:
    learn_throughput: 8410.676
    learn_time_ms: 19236.504
    sample_throughput: 22953.491
    sample_time_ms: 7048.688
    update_time_ms: 34.115
  timestamp: 1602492844
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     12 |          319.327 | 1941504 |   236.01 |              289.505 |               137.99 |            840.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3487.3178360101438
    time_step_min: 3170
  date: 2020-10-12_08-54-30
  done: false
  episode_len_mean: 837.5388471177945
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 237.452001215159
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 182
  episodes_total: 2394
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9220593820015589
        entropy_coeff: 0.0001
        kl: 0.007104225301494201
        model: {}
        policy_loss: -0.013087665856194993
        total_loss: 14.173670689264933
        vf_explained_var: 0.976102352142334
        vf_loss: 14.186140378316244
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.990624999999998
    gpu_util_percent0: 0.41125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15275050689489206
    mean_env_wait_ms: 1.185314088380426
    mean_inference_ms: 4.752351706120319
    mean_raw_obs_processing_ms: 0.40256148646908374
  time_since_restore: 345.71136808395386
  time_this_iter_s: 26.38466501235962
  time_total_s: 345.71136808395386
  timers:
    learn_throughput: 8421.636
    learn_time_ms: 19211.469
    sample_throughput: 22999.846
    sample_time_ms: 7034.482
    update_time_ms: 32.334
  timestamp: 1602492870
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     13 |          345.711 | 2103296 |  237.452 |              289.505 |               137.99 |            837.539 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3473.3540255831454
    time_step_min: 3170
  date: 2020-10-12_08-54-56
  done: false
  episode_len_mean: 833.4810126582279
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 239.5821054927532
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 292
  episodes_total: 2686
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9201588133970896
        entropy_coeff: 0.0001
        kl: 0.006468101870268583
        model: {}
        policy_loss: -0.012541183774980405
        total_loss: 12.514065821965536
        vf_explained_var: 0.980458676815033
        vf_loss: 12.526052554448446
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.29032258064516
    gpu_util_percent0: 0.26
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935484
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15228345130729537
    mean_env_wait_ms: 1.187280207898762
    mean_inference_ms: 4.71811277229724
    mean_raw_obs_processing_ms: 0.40084569327447034
  time_since_restore: 371.8659472465515
  time_this_iter_s: 26.154579162597656
  time_total_s: 371.8659472465515
  timers:
    learn_throughput: 8414.105
    learn_time_ms: 19228.665
    sample_throughput: 23061.751
    sample_time_ms: 7015.599
    update_time_ms: 30.845
  timestamp: 1602492896
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     14 |          371.866 | 2265088 |  239.582 |              289.505 |               137.99 |            833.481 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3466.54296875
    time_step_min: 3170
  date: 2020-10-12_08-55-23
  done: false
  episode_len_mean: 831.3913502109705
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 240.64524996803468
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9064158648252487
        entropy_coeff: 0.0001
        kl: 0.00678737946630766
        model: {}
        policy_loss: -0.012710827655003717
        total_loss: 10.679505268732706
        vf_explained_var: 0.9777107238769531
        vf_loss: 10.691628138224283
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.15625
    gpu_util_percent0: 0.4253125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15206312503267996
    mean_env_wait_ms: 1.1882550082909067
    mean_inference_ms: 4.702014857161813
    mean_raw_obs_processing_ms: 0.4000297807155428
  time_since_restore: 398.0466570854187
  time_this_iter_s: 26.180709838867188
  time_total_s: 398.0466570854187
  timers:
    learn_throughput: 8407.018
    learn_time_ms: 19244.874
    sample_throughput: 23146.341
    sample_time_ms: 6989.96
    update_time_ms: 29.278
  timestamp: 1602492923
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     15 |          398.047 | 2426880 |  240.645 |              289.505 |               137.99 |            831.391 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3459.892737054472
    time_step_min: 3170
  date: 2020-10-12_08-55-49
  done: false
  episode_len_mean: 830.020652898068
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 241.5691289981762
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8919036090373993
        entropy_coeff: 0.0001
        kl: 0.0065164086408913136
        model: {}
        policy_loss: -0.011898661767190788
        total_loss: 10.162490367889404
        vf_explained_var: 0.9785982966423035
        vf_loss: 10.173826615015665
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.645161290322584
    gpu_util_percent0: 0.2887096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.796774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15185997816865093
    mean_env_wait_ms: 1.189151489734091
    mean_inference_ms: 4.687070910686898
    mean_raw_obs_processing_ms: 0.3992559422384103
  time_since_restore: 424.27648854255676
  time_this_iter_s: 26.22983145713806
  time_total_s: 424.27648854255676
  timers:
    learn_throughput: 8405.859
    learn_time_ms: 19247.528
    sample_throughput: 23211.371
    sample_time_ms: 6970.377
    update_time_ms: 27.953
  timestamp: 1602492949
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     16 |          424.276 | 2588672 |  241.569 |              289.505 |               137.99 |            830.021 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3451.432941903585
    time_step_min: 3158
  date: 2020-10-12_08-56-15
  done: false
  episode_len_mean: 827.9087009803922
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 242.70980020796188
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 262
  episodes_total: 3264
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8572876205046972
        entropy_coeff: 0.0001
        kl: 0.006706862438780566
        model: {}
        policy_loss: -0.011741302907466888
        total_loss: 15.199506441752115
        vf_explained_var: 0.97942715883255
        vf_loss: 15.210662841796875
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.09375
    gpu_util_percent0: 0.258125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515595823770812
    mean_env_wait_ms: 1.1906200247039116
    mean_inference_ms: 4.6648538886424795
    mean_raw_obs_processing_ms: 0.3981096057596664
  time_since_restore: 450.64882588386536
  time_this_iter_s: 26.372337341308594
  time_total_s: 450.64882588386536
  timers:
    learn_throughput: 8400.577
    learn_time_ms: 19259.63
    sample_throughput: 23211.151
    sample_time_ms: 6970.443
    update_time_ms: 27.937
  timestamp: 1602492975
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     17 |          450.649 | 2750464 |   242.71 |              289.505 |               137.99 |            827.909 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3445.4002320185614
    time_step_min: 3146
  date: 2020-10-12_08-56-42
  done: false
  episode_len_mean: 826.5290563866513
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 243.6558072090292
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 212
  episodes_total: 3476
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8529605269432068
        entropy_coeff: 0.0001
        kl: 0.005917649987774591
        model: {}
        policy_loss: -0.011277009830034027
        total_loss: 11.547587235768637
        vf_explained_var: 0.9794904589653015
        vf_loss: 11.558358192443848
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.915625
    gpu_util_percent0: 0.3628125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15133785103605502
    mean_env_wait_ms: 1.191584841695774
    mean_inference_ms: 4.648617413271504
    mean_raw_obs_processing_ms: 0.39729234515600503
  time_since_restore: 476.97072649002075
  time_this_iter_s: 26.321900606155396
  time_total_s: 476.97072649002075
  timers:
    learn_throughput: 8395.439
    learn_time_ms: 19271.416
    sample_throughput: 23176.748
    sample_time_ms: 6980.789
    update_time_ms: 28.097
  timestamp: 1602493002
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     18 |          476.971 | 2912256 |  243.656 |              289.505 |               137.99 |            826.529 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3440.769828064337
    time_step_min: 3110
  date: 2020-10-12_08-57-09
  done: false
  episode_len_mean: 825.8247110621904
  episode_reward_max: 294.80808080808083
  episode_reward_mean: 244.29612303552858
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8457075009743372
        entropy_coeff: 0.0001
        kl: 0.0065199139062315226
        model: {}
        policy_loss: -0.01116289470034341
        total_loss: 10.043978214263916
        vf_explained_var: 0.9801807403564453
        vf_loss: 10.05457361539205
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.028125000000003
    gpu_util_percent0: 0.3709375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15118726408563093
    mean_env_wait_ms: 1.1922445706080023
    mean_inference_ms: 4.637558704514457
    mean_raw_obs_processing_ms: 0.39672423215429875
  time_since_restore: 503.39529490470886
  time_this_iter_s: 26.42456841468811
  time_total_s: 503.39529490470886
  timers:
    learn_throughput: 8393.952
    learn_time_ms: 19274.829
    sample_throughput: 23160.391
    sample_time_ms: 6985.72
    update_time_ms: 26.742
  timestamp: 1602493029
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     19 |          503.395 | 3074048 |  244.296 |              294.808 |               137.99 |            825.825 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3436.3805732484075
    time_step_min: 3110
  date: 2020-10-12_08-57-35
  done: false
  episode_len_mean: 825.2513171759747
  episode_reward_max: 294.80808080808083
  episode_reward_mean: 244.92866228140193
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 162
  episodes_total: 3796
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8178661465644836
        entropy_coeff: 0.0001
        kl: 0.006614145318356653
        model: {}
        policy_loss: -0.012304873768395433
        total_loss: 9.505411148071289
        vf_explained_var: 0.9820902943611145
        vf_loss: 9.517136255900065
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.078125
    gpu_util_percent0: 0.35906249999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510429657502081
    mean_env_wait_ms: 1.192856382314414
    mean_inference_ms: 4.62689228134805
    mean_raw_obs_processing_ms: 0.396167015727833
  time_since_restore: 530.0132410526276
  time_this_iter_s: 26.6179461479187
  time_total_s: 530.0132410526276
  timers:
    learn_throughput: 8390.823
    learn_time_ms: 19282.018
    sample_throughput: 23114.347
    sample_time_ms: 6999.635
    update_time_ms: 26.699
  timestamp: 1602493055
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     20 |          530.013 | 3235840 |  244.929 |              294.808 |               137.99 |            825.251 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3430.280848963475
    time_step_min: 3110
  date: 2020-10-12_08-58-01
  done: false
  episode_len_mean: 824.5730392156863
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 245.9245023767082
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 284
  episodes_total: 4080
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7949359466632208
        entropy_coeff: 0.0001
        kl: 0.005695687839761376
        model: {}
        policy_loss: -0.010721294248166183
        total_loss: 15.119903961817423
        vf_explained_var: 0.9795476794242859
        vf_loss: 15.13013505935669
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.970967741935496
    gpu_util_percent0: 0.2858064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15081021016993768
    mean_env_wait_ms: 1.1938311523447187
    mean_inference_ms: 4.609823498747463
    mean_raw_obs_processing_ms: 0.3952899981501372
  time_since_restore: 556.0116183757782
  time_this_iter_s: 25.998377323150635
  time_total_s: 556.0116183757782
  timers:
    learn_throughput: 8390.545
    learn_time_ms: 19282.656
    sample_throughput: 23227.118
    sample_time_ms: 6965.651
    update_time_ms: 25.037
  timestamp: 1602493081
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     21 |          556.012 | 3397632 |  245.925 |              297.687 |               137.99 |            824.573 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3425.592968381312
    time_step_min: 3110
  date: 2020-10-12_08-58-28
  done: false
  episode_len_mean: 824.3506797937177
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 246.62825157339924
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 186
  episodes_total: 4266
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7829316059748331
        entropy_coeff: 0.0001
        kl: 0.006042617450778683
        model: {}
        policy_loss: -0.012270252065112194
        total_loss: 7.568831443786621
        vf_explained_var: 0.9859895706176758
        vf_loss: 7.580575466156006
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.241935483870968
    gpu_util_percent0: 0.3670967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506735177497089
    mean_env_wait_ms: 1.1943510202197607
    mean_inference_ms: 4.599612224692007
    mean_raw_obs_processing_ms: 0.39477214392820853
  time_since_restore: 582.0807523727417
  time_this_iter_s: 26.0691339969635
  time_total_s: 582.0807523727417
  timers:
    learn_throughput: 8398.157
    learn_time_ms: 19265.179
    sample_throughput: 23366.851
    sample_time_ms: 6923.997
    update_time_ms: 23.8
  timestamp: 1602493108
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     22 |          582.081 | 3559424 |  246.628 |              297.687 |               137.99 |            824.351 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b7bce_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3422.125568698817
    time_step_min: 3110
  date: 2020-10-12_08-58-54
  done: true
  episode_len_mean: 823.993444846293
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 247.1778681936909
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: bdb1a6019ef04c8e88e76bae07290266
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7830241670211157
        entropy_coeff: 0.0001
        kl: 0.005572947518279155
        model: {}
        policy_loss: -0.008857697199952478
        total_loss: 9.253699541091919
        vf_explained_var: 0.9810841679573059
        vf_loss: 9.262078205744425
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.900000000000002
    gpu_util_percent0: 0.38935483870967735
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34085
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15056252631630285
    mean_env_wait_ms: 1.1947686150241412
    mean_inference_ms: 4.5914235205060585
    mean_raw_obs_processing_ms: 0.3943504348186309
  time_since_restore: 608.0074863433838
  time_this_iter_s: 25.92673397064209
  time_total_s: 608.0074863433838
  timers:
    learn_throughput: 8400.852
    learn_time_ms: 19258.999
    sample_throughput: 23501.826
    sample_time_ms: 6884.231
    update_time_ms: 23.432
  timestamp: 1602493134
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: b7bce_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | TERMINATED |       |     23 |          608.007 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b7bce_00000 | TERMINATED |       |     23 |          608.007 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


