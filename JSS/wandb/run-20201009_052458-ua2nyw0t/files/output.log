2020-10-09 05:25:00,754	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c7fc8_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=60527)[0m 2020-10-09 05:25:03,831	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=60521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60428)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60428)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60426)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60426)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60432)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60465)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-09_05-25-54
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1665229678153992
        entropy_coeff: 0.0
        kl: 0.0030239457497373222
        model: {}
        policy_loss: -0.00859066005796194
        total_loss: 494.75294799804686
        vf_explained_var: 0.5504283905029297
        vf_loss: 494.7609405517578
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.58846153846154
    gpu_util_percent0: 0.3567307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.790384615384616
    vram_util_percent0: 0.31439690188460284
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24335880638751473
    mean_env_wait_ms: 3.2336347697141106
    mean_inference_ms: 9.047998438355508
    mean_raw_obs_processing_ms: 0.8542607440813047
  time_since_restore: 44.92808151245117
  time_this_iter_s: 44.92808151245117
  time_total_s: 44.92808151245117
  timers:
    learn_throughput: 11111.738
    learn_time_ms: 29120.918
    sample_throughput: 20555.814
    sample_time_ms: 15741.726
    update_time_ms: 28.095
  timestamp: 1602221154
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      1 |          44.9281 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3198.0
  date: 2020-10-09_05-26-37
  done: false
  episode_len_mean: 873.7958860759494
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.10761091931963
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.137348735332489
        entropy_coeff: 0.0
        kl: 0.004654662590473891
        model: {}
        policy_loss: -0.010138954455032944
        total_loss: 120.45739135742187
        vf_explained_var: 0.7989535331726074
        vf_loss: 120.46706619262696
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.406122448979595
    gpu_util_percent0: 0.34755102040816327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.163265306122451
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23778931086836383
    mean_env_wait_ms: 3.2235150755397846
    mean_inference_ms: 8.665071261429585
    mean_raw_obs_processing_ms: 0.8359010268347193
  time_since_restore: 87.8889000415802
  time_this_iter_s: 42.96081852912903
  time_total_s: 87.8889000415802
  timers:
    learn_throughput: 11183.569
    learn_time_ms: 28933.877
    sample_throughput: 21698.261
    sample_time_ms: 14912.9
    update_time_ms: 32.107
  timestamp: 1602221197
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      2 |          87.8889 | 647168 |  229.108 |              284.798 |              147.061 |            873.796 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3197.0
  date: 2020-10-09_05-27-21
  done: false
  episode_len_mean: 872.5654008438819
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.82017431700962
  episode_reward_min: 140.33333333333334
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.1308077692985534
        entropy_coeff: 0.0
        kl: 0.005543247330933809
        model: {}
        policy_loss: -0.011552988551557064
        total_loss: 58.76521530151367
        vf_explained_var: 0.8804458379745483
        vf_loss: 58.77649154663086
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.08958333333333
    gpu_util_percent0: 0.34604166666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.193750000000001
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23477275698690092
    mean_env_wait_ms: 3.2196222171847535
    mean_inference_ms: 8.426180251167606
    mean_raw_obs_processing_ms: 0.8239453474759002
  time_since_restore: 131.10438656806946
  time_this_iter_s: 43.21548652648926
  time_total_s: 131.10438656806946
  timers:
    learn_throughput: 11179.528
    learn_time_ms: 28944.334
    sample_throughput: 22081.889
    sample_time_ms: 14653.819
    update_time_ms: 31.451
  timestamp: 1602221241
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      3 |          131.104 | 970752 |   229.82 |              284.798 |              140.333 |            872.565 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3197.0
  date: 2020-10-09_05-28-03
  done: false
  episode_len_mean: 870.4248417721519
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.1978247666537
  episode_reward_min: 140.33333333333334
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.1201124429702758
        entropy_coeff: 0.0
        kl: 0.005229676049202681
        model: {}
        policy_loss: -0.011866700276732445
        total_loss: 41.949629592895505
        vf_explained_var: 0.9127581715583801
        vf_loss: 41.961234664916994
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.725000000000005
    gpu_util_percent0: 0.32187499999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.183333333333332
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2329434702784066
    mean_env_wait_ms: 3.22006482104749
    mean_inference_ms: 8.263101647418349
    mean_raw_obs_processing_ms: 0.815540531663904
  time_since_restore: 173.77947545051575
  time_this_iter_s: 42.67508888244629
  time_total_s: 173.77947545051575
  timers:
    learn_throughput: 11184.323
    learn_time_ms: 28931.926
    sample_throughput: 22466.868
    sample_time_ms: 14402.72
    update_time_ms: 34.551
  timestamp: 1602221283
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      4 |          173.779 | 1294336 |  230.198 |              284.798 |              140.333 |            870.425 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3197.0
  date: 2020-10-09_05-28-46
  done: false
  episode_len_mean: 868.1205047318612
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.81983239333383
  episode_reward_min: 140.33333333333334
  episodes_this_iter: 321
  episodes_total: 1585
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.086342179775238
        entropy_coeff: 0.0
        kl: 0.005469889752566815
        model: {}
        policy_loss: -0.0116492482367903
        total_loss: 30.61054458618164
        vf_explained_var: 0.9458280801773071
        vf_loss: 30.621920013427733
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.558333333333334
    gpu_util_percent0: 0.33791666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.220833333333333
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23162044671893933
    mean_env_wait_ms: 3.2222537042718327
    mean_inference_ms: 8.140059156937115
    mean_raw_obs_processing_ms: 0.808922454186173
  time_since_restore: 216.54192209243774
  time_this_iter_s: 42.762446641922
  time_total_s: 216.54192209243774
  timers:
    learn_throughput: 11191.684
    learn_time_ms: 28912.896
    sample_throughput: 22654.35
    sample_time_ms: 14283.526
    update_time_ms: 32.449
  timestamp: 1602221326
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      5 |          216.542 | 1617920 |   230.82 |              284.798 |              140.333 |            868.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3197.0
  date: 2020-10-09_05-29-29
  done: false
  episode_len_mean: 862.8467450271248
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 232.48056514512194
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 627
  episodes_total: 2212
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.1005380630493165
        entropy_coeff: 0.0
        kl: 0.005415052222087979
        model: {}
        policy_loss: -0.010861733637284487
        total_loss: 32.46632041931152
        vf_explained_var: 0.9527653455734253
        vf_loss: 32.476912117004396
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.865957446808522
    gpu_util_percent0: 0.3495744680851064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.217021276595746
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22981480887410477
    mean_env_wait_ms: 3.227714954623431
    mean_inference_ms: 7.976668737446962
    mean_raw_obs_processing_ms: 0.8007063280091962
  time_since_restore: 258.91929626464844
  time_this_iter_s: 42.37737417221069
  time_total_s: 258.91929626464844
  timers:
    learn_throughput: 11205.369
    learn_time_ms: 28877.586
    sample_throughput: 22851.633
    sample_time_ms: 14160.213
    update_time_ms: 33.758
  timestamp: 1602221369
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      6 |          258.919 | 1941504 |  232.481 |              284.798 |              125.788 |            862.847 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3192.0
  date: 2020-10-09_05-30-11
  done: false
  episode_len_mean: 859.6475474683544
  episode_reward_max: 284.93939393939365
  episode_reward_mean: 233.5249568469504
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.094920551776886
        entropy_coeff: 0.0
        kl: 0.0052336101885885
        model: {}
        policy_loss: -0.011457698605954646
        total_loss: 21.099847412109376
        vf_explained_var: 0.9564622044563293
        vf_loss: 21.11104335784912
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.189583333333335
    gpu_util_percent0: 0.3408333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.252083333333333
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22917232619385183
    mean_env_wait_ms: 3.2309064139461716
    mean_inference_ms: 7.917814208224749
    mean_raw_obs_processing_ms: 0.7978068130931228
  time_since_restore: 301.5084547996521
  time_this_iter_s: 42.58915853500366
  time_total_s: 301.5084547996521
  timers:
    learn_throughput: 11193.897
    learn_time_ms: 28907.181
    sample_throughput: 23033.566
    sample_time_ms: 14048.368
    update_time_ms: 34.07
  timestamp: 1602221411
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      7 |          301.508 | 2265088 |  233.525 |              284.939 |              125.788 |            859.648 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3192.0
  date: 2020-10-09_05-30-54
  done: false
  episode_len_mean: 856.8495077355836
  episode_reward_max: 287.717171717172
  episode_reward_mean: 234.44899416101933
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.083617377281189
        entropy_coeff: 0.0
        kl: 0.004954190738499164
        model: {}
        policy_loss: -0.012084105820395052
        total_loss: 17.59351863861084
        vf_explained_var: 0.9621307253837585
        vf_loss: 17.60535583496094
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.21914893617021
    gpu_util_percent0: 0.3580851063829787
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.253191489361702
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22863688461076623
    mean_env_wait_ms: 3.2339997635792033
    mean_inference_ms: 7.867214016541958
    mean_raw_obs_processing_ms: 0.795254015206144
  time_since_restore: 343.83959007263184
  time_this_iter_s: 42.331135272979736
  time_total_s: 343.83959007263184
  timers:
    learn_throughput: 11198.724
    learn_time_ms: 28894.72
    sample_throughput: 23166.2
    sample_time_ms: 13967.936
    update_time_ms: 33.011
  timestamp: 1602221454
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      8 |           343.84 | 2588672 |  234.449 |              287.717 |              125.788 |             856.85 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3192.0
  date: 2020-10-09_05-31-37
  done: false
  episode_len_mean: 854.006329113924
  episode_reward_max: 287.717171717172
  episode_reward_mean: 235.30700358010472
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 316
  episodes_total: 3160
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 1.0598385095596314
        entropy_coeff: 0.0
        kl: 0.005118076549842953
        model: {}
        policy_loss: -0.011554112564772368
        total_loss: 20.164242362976076
        vf_explained_var: 0.9581744074821472
        vf_loss: 20.175668716430664
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.818749999999998
    gpu_util_percent0: 0.34479166666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.235416666666667
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2282004625114618
    mean_env_wait_ms: 3.2372927352993233
    mean_inference_ms: 7.823217411119237
    mean_raw_obs_processing_ms: 0.7930249450084542
  time_since_restore: 386.45467042922974
  time_this_iter_s: 42.6150803565979
  time_total_s: 386.45467042922974
  timers:
    learn_throughput: 11192.253
    learn_time_ms: 28911.427
    sample_throughput: 23264.403
    sample_time_ms: 13908.975
    update_time_ms: 33.372
  timestamp: 1602221497
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |      9 |          386.455 | 2912256 |  235.307 |              287.717 |              125.788 |            854.006 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_05-32-19
  done: false
  episode_len_mean: 849.0153968675338
  episode_reward_max: 287.717171717172
  episode_reward_mean: 236.82466019365395
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 607
  episodes_total: 3767
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 1.0383127570152282
        entropy_coeff: 0.0
        kl: 0.00509772771038115
        model: {}
        policy_loss: -0.010779408598318696
        total_loss: 29.310605239868163
        vf_explained_var: 0.9599756002426147
        vf_loss: 29.321257209777833
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.897872340425533
    gpu_util_percent0: 0.33936170212765954
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.229787234042554
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2274897567354915
    mean_env_wait_ms: 3.2435182060377197
    mean_inference_ms: 7.753858408483735
    mean_raw_obs_processing_ms: 0.7896288403081618
  time_since_restore: 429.10511803627014
  time_this_iter_s: 42.650447607040405
  time_total_s: 429.10511803627014
  timers:
    learn_throughput: 11190.267
    learn_time_ms: 28916.557
    sample_throughput: 23342.942
    sample_time_ms: 13862.177
    update_time_ms: 33.785
  timestamp: 1602221539
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |     10 |          429.105 | 3235840 |  236.825 |              287.717 |              125.788 |            849.015 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_05-33-02
  done: false
  episode_len_mean: 846.4727361246348
  episode_reward_max: 287.717171717172
  episode_reward_mean: 237.43160917844452
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 341
  episodes_total: 4108
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 1.0370907425880431
        entropy_coeff: 0.0
        kl: 0.00522912098094821
        model: {}
        policy_loss: -0.01170048345811665
        total_loss: 16.52592601776123
        vf_explained_var: 0.9680167436599731
        vf_loss: 16.537495422363282
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.818749999999998
    gpu_util_percent0: 0.35041666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.247916666666667
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22719694740759525
    mean_env_wait_ms: 3.2472821244105714
    mean_inference_ms: 7.722728573833082
    mean_raw_obs_processing_ms: 0.7882929973670612
  time_since_restore: 471.64633417129517
  time_this_iter_s: 42.541216135025024
  time_total_s: 471.64633417129517
  timers:
    learn_throughput: 11192.208
    learn_time_ms: 28911.543
    sample_throughput: 23757.188
    sample_time_ms: 13620.467
    update_time_ms: 34.931
  timestamp: 1602221582
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 11
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |     11 |          471.646 | 3559424 |  237.432 |              287.717 |              125.788 |            846.473 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_05-33-45
  done: false
  episode_len_mean: 844.5879294755877
  episode_reward_max: 290.0505050505048
  episode_reward_mean: 238.17084041134663
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 316
  episodes_total: 4424
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 1.028391706943512
        entropy_coeff: 0.0
        kl: 0.004838761314749718
        model: {}
        policy_loss: -0.011867112247273326
        total_loss: 15.691248989105224
        vf_explained_var: 0.9673389196395874
        vf_loss: 15.702994918823242
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.279591836734696
    gpu_util_percent0: 0.33836734693877557
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.242857142857142
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22693821818800217
    mean_env_wait_ms: 3.250291577869543
    mean_inference_ms: 7.6964814034634275
    mean_raw_obs_processing_ms: 0.7871183830868909
  time_since_restore: 514.5255355834961
  time_this_iter_s: 42.87920141220093
  time_total_s: 514.5255355834961
  timers:
    learn_throughput: 11184.936
    learn_time_ms: 28930.339
    sample_throughput: 23816.624
    sample_time_ms: 13586.477
    update_time_ms: 34.41
  timestamp: 1602221625
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 12
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |     12 |          514.526 | 3883008 |  238.171 |              290.051 |              125.788 |            844.588 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3180.0
  date: 2020-10-09_05-34-28
  done: false
  episode_len_mean: 842.8162447257384
  episode_reward_max: 290.0505050505048
  episode_reward_mean: 238.9339236244298
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 316
  episodes_total: 4740
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.9974108040332794
        entropy_coeff: 0.0
        kl: 0.005232171481475234
        model: {}
        policy_loss: -0.012115311995148658
        total_loss: 14.852477073669434
        vf_explained_var: 0.969476044178009
        vf_loss: 14.86452693939209
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.48085106382979
    gpu_util_percent0: 0.3708510638297872
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.240425531914894
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2267103490991695
    mean_env_wait_ms: 3.2532198524405707
    mean_inference_ms: 7.672723349806404
    mean_raw_obs_processing_ms: 0.7859928029315542
  time_since_restore: 557.3067560195923
  time_this_iter_s: 42.78122043609619
  time_total_s: 557.3067560195923
  timers:
    learn_throughput: 11183.014
    learn_time_ms: 28935.311
    sample_throughput: 23903.926
    sample_time_ms: 13536.856
    update_time_ms: 33.539
  timestamp: 1602221668
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 13
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | RUNNING  | 172.17.0.4:60527 |     13 |          557.307 | 4206592 |  238.934 |              290.051 |              125.788 |            842.816 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c7fc8_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-09_05-35-11
  done: true
  episode_len_mean: 839.2735250186706
  episode_reward_max: 290.0505050505048
  episode_reward_mean: 240.61831156976777
  episode_reward_min: 125.78787878787873
  episodes_this_iter: 616
  episodes_total: 5356
  experiment_id: a9958e7b98004ec3a3ad8fede2640243
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.9693107843399048
        entropy_coeff: 0.0
        kl: 0.005091832205653191
        model: {}
        policy_loss: -0.010392849310301244
        total_loss: 22.69399490356445
        vf_explained_var: 0.9680725336074829
        vf_loss: 22.704323768615723
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.445833333333336
    gpu_util_percent0: 0.34979166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.237499999999999
    vram_util_percent0: 0.3556083961954739
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60527
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22633620168248578
    mean_env_wait_ms: 3.2587320808160984
    mean_inference_ms: 7.632651424009872
    mean_raw_obs_processing_ms: 0.7840982347181833
  time_since_restore: 600.2105250358582
  time_this_iter_s: 42.90376901626587
  time_total_s: 600.2105250358582
  timers:
    learn_throughput: 11174.787
    learn_time_ms: 28956.616
    sample_throughput: 23901.407
    sample_time_ms: 13538.282
    update_time_ms: 31.477
  timestamp: 1602221711
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 14
  trial_id: c7fc8_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | TERMINATED |       |     14 |          600.211 | 4530176 |  240.618 |              290.051 |              125.788 |            839.274 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c7fc8_00000 | TERMINATED |       |     14 |          600.211 | 4530176 |  240.618 |              290.051 |              125.788 |            839.274 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


