2020-10-10 19:24:51,694	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_45add_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=73165)[0m 2020-10-10 19:24:54,601	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=73115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73095)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_19-25-38
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1834681970732552
        entropy_coeff: 0.00010000000000000002
        kl: 0.005415608607498663
        model: {}
        policy_loss: -0.011517197313618712
        total_loss: 9.18045779636928
        vf_explained_var: 0.7775402665138245
        vf_loss: 9.191010407039098
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.723404255319153
    gpu_util_percent0: 0.38425531914893624
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002127659574468085
    ram_util_percent: 6.306382978723401
    vram_util_percent0: 0.19440276895808178
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17137463279033968
    mean_env_wait_ms: 1.205365006369402
    mean_inference_ms: 5.446491394561173
    mean_raw_obs_processing_ms: 0.45186970549698563
  time_since_restore: 38.54662728309631
  time_this_iter_s: 38.54662728309631
  time_total_s: 38.54662728309631
  timers:
    learn_throughput: 5418.427
    learn_time_ms: 29859.589
    sample_throughput: 18765.424
    sample_time_ms: 8621.814
    update_time_ms: 26.36
  timestamp: 1602357938
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      1 |          38.5466 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3599.0798611111113
    time_step_min: 3244
  date: 2020-10-10_19-26-16
  done: false
  episode_len_mean: 882.3607594936709
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 220.22522695307484
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.152957831110273
        entropy_coeff: 0.00010000000000000002
        kl: 0.006822915115792837
        model: {}
        policy_loss: -0.015099957310927234
        total_loss: 6.338258572987148
        vf_explained_var: 0.9137042760848999
        vf_loss: 6.3521091256822855
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.75111111111111
    gpu_util_percent0: 0.37600000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1668235923763918
    mean_env_wait_ms: 1.2023126169173788
    mean_inference_ms: 5.276052486709582
    mean_raw_obs_processing_ms: 0.44143337044429753
  time_since_restore: 75.81407380104065
  time_this_iter_s: 37.267446517944336
  time_total_s: 75.81407380104065
  timers:
    learn_throughput: 5460.443
    learn_time_ms: 29629.833
    sample_throughput: 19704.464
    sample_time_ms: 8210.931
    update_time_ms: 22.1
  timestamp: 1602357976
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      2 |          75.8141 | 323584 |  220.225 |              274.505 |              145.717 |            882.361 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3594.1905829596412
    time_step_min: 3244
  date: 2020-10-10_19-26-53
  done: false
  episode_len_mean: 874.8037974683544
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 219.64697609001385
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1425504854747228
        entropy_coeff: 0.00010000000000000002
        kl: 0.007065444951876998
        model: {}
        policy_loss: -0.014220532063128693
        total_loss: 7.078336783817837
        vf_explained_var: 0.9486768841743469
        vf_loss: 7.091258219310215
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.836363636363636
    gpu_util_percent0: 0.39931818181818185
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490909090909091
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16385876074887645
    mean_env_wait_ms: 1.201869435324816
    mean_inference_ms: 5.141272297815931
    mean_raw_obs_processing_ms: 0.4336056171172128
  time_since_restore: 112.53062438964844
  time_this_iter_s: 36.71655058860779
  time_total_s: 112.53062438964844
  timers:
    learn_throughput: 5474.302
    learn_time_ms: 29554.816
    sample_throughput: 20519.044
    sample_time_ms: 7884.968
    update_time_ms: 25.319
  timestamp: 1602358013
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      3 |          112.531 | 485376 |  219.647 |              274.505 |               98.596 |            874.804 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3595.9900662251657
    time_step_min: 3244
  date: 2020-10-10_19-27-29
  done: false
  episode_len_mean: 868.501582278481
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 219.68293696458235
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.113918593951634
        entropy_coeff: 0.00010000000000000002
        kl: 0.007688520775575723
        model: {}
        policy_loss: -0.01821849127632699
        total_loss: 5.947177818843296
        vf_explained_var: 0.9702849984169006
        vf_loss: 5.963969945907593
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.104545454545455
    gpu_util_percent0: 0.43636363636363645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4840909090909085
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1617910352905859
    mean_env_wait_ms: 1.202973226322579
    mean_inference_ms: 5.0412513984132055
    mean_raw_obs_processing_ms: 0.42768882833472277
  time_since_restore: 149.20077419281006
  time_this_iter_s: 36.67014980316162
  time_total_s: 149.20077419281006
  timers:
    learn_throughput: 5480.234
    learn_time_ms: 29522.827
    sample_throughput: 20994.669
    sample_time_ms: 7706.337
    update_time_ms: 24.708
  timestamp: 1602358049
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      4 |          149.201 | 647168 |  219.683 |              274.505 |               98.596 |            868.502 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3603.2417721518987
    time_step_min: 3244
  date: 2020-10-10_19-28-06
  done: false
  episode_len_mean: 861.700488997555
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 219.4318860981451
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 186
  episodes_total: 818
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0728720426559448
        entropy_coeff: 0.00010000000000000002
        kl: 0.006133918351094637
        model: {}
        policy_loss: -0.016626312912973975
        total_loss: 8.134680441447667
        vf_explained_var: 0.9784563779830933
        vf_loss: 8.150187253952026
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.220454545454547
    gpu_util_percent0: 0.42
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.479545454545455
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16001872250898577
    mean_env_wait_ms: 1.2058840223481384
    mean_inference_ms: 4.953155792991163
    mean_raw_obs_processing_ms: 0.42238301207712925
  time_since_restore: 185.85929656028748
  time_this_iter_s: 36.65852236747742
  time_total_s: 185.85929656028748
  timers:
    learn_throughput: 5482.855
    learn_time_ms: 29508.713
    sample_throughput: 21312.208
    sample_time_ms: 7591.518
    update_time_ms: 24.544
  timestamp: 1602358086
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      5 |          185.859 | 808960 |  219.432 |              274.505 |               98.596 |              861.7 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3600.1372912801485
    time_step_min: 3244
  date: 2020-10-10_19-28-43
  done: false
  episode_len_mean: 852.6844484629295
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 219.8376714705827
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 288
  episodes_total: 1106
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0856492945126124
        entropy_coeff: 0.00010000000000000002
        kl: 0.0063562998880765265
        model: {}
        policy_loss: -0.015904286260982708
        total_loss: 7.06601003238133
        vf_explained_var: 0.9831683039665222
        vf_loss: 7.080751316887992
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.968181818181815
    gpu_util_percent0: 0.39045454545454544
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.479545454545455
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1582537469550075
    mean_env_wait_ms: 1.2103239079786228
    mean_inference_ms: 4.861668819104466
    mean_raw_obs_processing_ms: 0.4172723186664541
  time_since_restore: 222.59589958190918
  time_this_iter_s: 36.736603021621704
  time_total_s: 222.59589958190918
  timers:
    learn_throughput: 5483.508
    learn_time_ms: 29505.202
    sample_throughput: 21518.08
    sample_time_ms: 7518.887
    update_time_ms: 28.036
  timestamp: 1602358123
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      6 |          222.596 | 970752 |  219.838 |              274.505 |               98.596 |            852.684 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3596.265372168285
    time_step_min: 3228
  date: 2020-10-10_19-29-20
  done: false
  episode_len_mean: 848.373417721519
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 220.39316423730966
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0539691363062178
        entropy_coeff: 0.00010000000000000002
        kl: 0.006377658008464745
        model: {}
        policy_loss: -0.017643214045425078
        total_loss: 4.904232944761004
        vf_explained_var: 0.987388014793396
        vf_loss: 4.920705897467477
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.96590909090909
    gpu_util_percent0: 0.4106818181818182
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495454545454547
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15753110847497676
    mean_env_wait_ms: 1.2122381611536415
    mean_inference_ms: 4.823884775426467
    mean_raw_obs_processing_ms: 0.41514749222394504
  time_since_restore: 259.53913974761963
  time_this_iter_s: 36.94324016571045
  time_total_s: 259.53913974761963
  timers:
    learn_throughput: 5479.057
    learn_time_ms: 29529.169
    sample_throughput: 21660.218
    sample_time_ms: 7469.546
    update_time_ms: 29.791
  timestamp: 1602358160
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      7 |          259.539 | 1132544 |  220.393 |              276.929 |               98.596 |            848.373 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3591.9598278335725
    time_step_min: 3228
  date: 2020-10-10_19-29-56
  done: false
  episode_len_mean: 844.5724331926864
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 221.44853599283962
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0268921170915877
        entropy_coeff: 0.00010000000000000002
        kl: 0.006210594970200743
        model: {}
        policy_loss: -0.01825679885223508
        total_loss: 3.9663906608309065
        vf_explained_var: 0.9903085827827454
        vf_loss: 3.983507922717503
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.504545454545458
    gpu_util_percent0: 0.38886363636363636
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497727272727272
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15690777977869347
    mean_env_wait_ms: 1.2140417561362618
    mean_inference_ms: 4.791421948868315
    mean_raw_obs_processing_ms: 0.4132435135643206
  time_since_restore: 296.1257162094116
  time_this_iter_s: 36.58657646179199
  time_total_s: 296.1257162094116
  timers:
    learn_throughput: 5481.056
    learn_time_ms: 29518.401
    sample_throughput: 21805.109
    sample_time_ms: 7419.912
    update_time_ms: 29.073
  timestamp: 1602358196
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      8 |          296.126 | 1294336 |  221.449 |              276.929 |               98.596 |            844.572 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3585.3762376237623
    time_step_min: 3228
  date: 2020-10-10_19-30-33
  done: false
  episode_len_mean: 840.175790754258
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 222.19002064440005
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 222
  episodes_total: 1644
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9923863921846662
        entropy_coeff: 0.00010000000000000002
        kl: 0.005657353538221547
        model: {}
        policy_loss: -0.01803975356077509
        total_loss: 5.617018904004778
        vf_explained_var: 0.9917067885398865
        vf_loss: 5.634026391165597
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.322222222222226
    gpu_util_percent0: 0.39111111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1562058206161583
    mean_env_wait_ms: 1.2166932142876048
    mean_inference_ms: 4.7532393010950384
    mean_raw_obs_processing_ms: 0.4109740166161929
  time_since_restore: 332.8087842464447
  time_this_iter_s: 36.68306803703308
  time_total_s: 332.8087842464447
  timers:
    learn_throughput: 5480.436
    learn_time_ms: 29521.738
    sample_throughput: 21923.518
    sample_time_ms: 7379.837
    update_time_ms: 28.607
  timestamp: 1602358233
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |      9 |          332.809 | 1456128 |   222.19 |              276.929 |               98.596 |            840.176 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3580.5139186295505
    time_step_min: 3228
  date: 2020-10-10_19-31-11
  done: false
  episode_len_mean: 836.4256329113924
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 223.10273622298928
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 252
  episodes_total: 1896
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9852673794542041
        entropy_coeff: 0.00010000000000000002
        kl: 0.005593760837135571
        model: {}
        policy_loss: -0.01798333239275962
        total_loss: 4.206397005489895
        vf_explained_var: 0.9924936890602112
        vf_loss: 4.223360010555813
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.59333333333333
    gpu_util_percent0: 0.3891111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4799999999999995
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15552899658587307
    mean_env_wait_ms: 1.2191064864241699
    mean_inference_ms: 4.7186106156902445
    mean_raw_obs_processing_ms: 0.4090475912000627
  time_since_restore: 370.05426716804504
  time_this_iter_s: 37.24548292160034
  time_total_s: 370.05426716804504
  timers:
    learn_throughput: 5475.282
    learn_time_ms: 29549.526
    sample_throughput: 21925.913
    sample_time_ms: 7379.031
    update_time_ms: 28.082
  timestamp: 1602358271
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     10 |          370.054 | 1617920 |  223.103 |              276.929 |               98.596 |            836.426 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3575.42152023692
    time_step_min: 3228
  date: 2020-10-10_19-31-48
  done: false
  episode_len_mean: 834.5803310613437
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 223.97179683888535
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9635667204856873
        entropy_coeff: 0.00010000000000000002
        kl: 0.005412034357764891
        model: {}
        policy_loss: -0.018681930045464208
        total_loss: 2.7984406777790616
        vf_explained_var: 0.9946547150611877
        vf_loss: 2.816136598587036
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.374999999999996
    gpu_util_percent0: 0.37522727272727274
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493181818181819
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551794399715962
    mean_env_wait_ms: 1.2204060139545065
    mean_inference_ms: 4.699977142865967
    mean_raw_obs_processing_ms: 0.4079715149291843
  time_since_restore: 407.02319717407227
  time_this_iter_s: 36.96893000602722
  time_total_s: 407.02319717407227
  timers:
    learn_throughput: 5479.276
    learn_time_ms: 29527.99
    sample_throughput: 22342.255
    sample_time_ms: 7241.525
    update_time_ms: 27.752
  timestamp: 1602358308
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     11 |          407.023 | 1779712 |  223.972 |              276.929 |               98.596 |             834.58 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3571.592032967033
    time_step_min: 3228
  date: 2020-10-10_19-32-24
  done: false
  episode_len_mean: 832.6577757685353
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 224.586493323835
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9421826132706234
        entropy_coeff: 0.00010000000000000002
        kl: 0.005153943884319493
        model: {}
        policy_loss: -0.01700497713006501
        total_loss: 2.851137808391026
        vf_explained_var: 0.994509756565094
        vf_loss: 2.8672062499182567
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.22727272727273
    gpu_util_percent0: 0.3670454545454546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502272727272728
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15486689545707383
    mean_env_wait_ms: 1.221633339149953
    mean_inference_ms: 4.683035643781343
    mean_raw_obs_processing_ms: 0.406963788070137
  time_since_restore: 443.6970360279083
  time_this_iter_s: 36.67383885383606
  time_total_s: 443.6970360279083
  timers:
    learn_throughput: 5477.696
    learn_time_ms: 29536.503
    sample_throughput: 22557.803
    sample_time_ms: 7172.33
    update_time_ms: 28.339
  timestamp: 1602358344
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     12 |          443.697 | 1941504 |  224.586 |              276.929 |               98.596 |            832.658 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3567.8042156465344
    time_step_min: 3228
  date: 2020-10-10_19-33-01
  done: false
  episode_len_mean: 829.9058116232464
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 225.02348130604636
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 283
  episodes_total: 2495
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9160412677696773
        entropy_coeff: 0.00010000000000000002
        kl: 0.0046125668034489664
        model: {}
        policy_loss: -0.014916365550431823
        total_loss: 4.650197114263262
        vf_explained_var: 0.9942165017127991
        vf_loss: 4.664282730647495
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.419999999999998
    gpu_util_percent0: 0.394
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48222222222222
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15438237282767034
    mean_env_wait_ms: 1.2238674648095327
    mean_inference_ms: 4.656648478203429
    mean_raw_obs_processing_ms: 0.4054365448987411
  time_since_restore: 480.6243224143982
  time_this_iter_s: 36.92728638648987
  time_total_s: 480.6243224143982
  timers:
    learn_throughput: 5470.193
    learn_time_ms: 29577.019
    sample_throughput: 22623.264
    sample_time_ms: 7151.576
    update_time_ms: 28.531
  timestamp: 1602358381
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     13 |          480.624 | 2103296 |  225.023 |              276.929 |               98.596 |            829.906 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3563.6749435665915
    time_step_min: 3228
  date: 2020-10-10_19-33-38
  done: false
  episode_len_mean: 828.3704393149665
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 225.68631587656154
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 191
  episodes_total: 2686
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8857881086213248
        entropy_coeff: 0.00010000000000000002
        kl: 0.005967651660154972
        model: {}
        policy_loss: -0.015711036090838855
        total_loss: 2.8623763833727156
        vf_explained_var: 0.9950572848320007
        vf_loss: 2.877579314368112
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.58863636363636
    gpu_util_percent0: 0.3931818181818182
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497727272727272
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540948720905437
    mean_env_wait_ms: 1.2251288783916308
    mean_inference_ms: 4.641304400725641
    mean_raw_obs_processing_ms: 0.4045246595207239
  time_since_restore: 517.3168139457703
  time_this_iter_s: 36.69249153137207
  time_total_s: 517.3168139457703
  timers:
    learn_throughput: 5470.574
    learn_time_ms: 29574.961
    sample_throughput: 22614.1
    sample_time_ms: 7154.475
    update_time_ms: 28.667
  timestamp: 1602358418
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     14 |          517.317 | 2265088 |  225.686 |              276.929 |               98.596 |             828.37 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3561.341974431818
    time_step_min: 3228
  date: 2020-10-10_19-34-15
  done: false
  episode_len_mean: 827.3621659634318
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 226.19238801517272
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8831595139844077
        entropy_coeff: 0.00010000000000000002
        kl: 0.005799765798396298
        model: {}
        policy_loss: -0.01696657796856016
        total_loss: 2.3482611690248762
        vf_explained_var: 0.9957090616226196
        vf_loss: 2.3647360801696777
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.00909090909091
    gpu_util_percent0: 0.42136363636363644
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497727272727274
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15388270515339805
    mean_env_wait_ms: 1.2261286641915718
    mean_inference_ms: 4.629618997070015
    mean_raw_obs_processing_ms: 0.40384216522079863
  time_since_restore: 554.0271520614624
  time_this_iter_s: 36.71033811569214
  time_total_s: 554.0271520614624
  timers:
    learn_throughput: 5471.959
    learn_time_ms: 29567.475
    sample_throughput: 22579.835
    sample_time_ms: 7165.331
    update_time_ms: 28.594
  timestamp: 1602358455
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     15 |          554.027 | 2426880 |  226.192 |              276.929 |               98.596 |            827.362 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3558.5315860215055
    time_step_min: 3228
  date: 2020-10-10_19-34-52
  done: false
  episode_len_mean: 826.3485352862849
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 226.61804126484546
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8648073332650321
        entropy_coeff: 0.00010000000000000002
        kl: 0.005463209635178957
        model: {}
        policy_loss: -0.018055317509736466
        total_loss: 2.5676197835377286
        vf_explained_var: 0.9956521987915039
        vf_loss: 2.5852152620043074
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.36818181818182
    gpu_util_percent0: 0.3995454545454546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495454545454547
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1536811473280298
    mean_env_wait_ms: 1.2271020462839504
    mean_inference_ms: 4.618684601231231
    mean_raw_obs_processing_ms: 0.40319609760544534
  time_since_restore: 590.7131910324097
  time_this_iter_s: 36.686038970947266
  time_total_s: 590.7131910324097
  timers:
    learn_throughput: 5474.361
    learn_time_ms: 29554.5
    sample_throughput: 22550.962
    sample_time_ms: 7174.506
    update_time_ms: 26.356
  timestamp: 1602358492
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | RUNNING  | 172.17.0.4:73165 |     16 |          590.713 | 2588672 |  226.618 |              276.929 |               98.596 |            826.349 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_45add_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3552.2850609756097
    time_step_min: 3228
  date: 2020-10-10_19-35-29
  done: true
  episode_len_mean: 824.5716444981862
  episode_reward_max: 276.92929292929307
  episode_reward_mean: 227.52458991364668
  episode_reward_min: 98.59595959595914
  episodes_this_iter: 304
  episodes_total: 3308
  experiment_id: 328d7b8ff408499a9a9bbb18d33316c9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8271780439785549
        entropy_coeff: 0.00010000000000000002
        kl: 0.005490385627906237
        model: {}
        policy_loss: -0.014730052955980812
        total_loss: 3.0998230831963673
        vf_explained_var: 0.9960455298423767
        vf_loss: 3.1140868152890886
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.482222222222223
    gpu_util_percent0: 0.37599999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484444444444445
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 73165
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533406437449877
    mean_env_wait_ms: 1.2288297765392047
    mean_inference_ms: 4.599949228843693
    mean_raw_obs_processing_ms: 0.4021064324516298
  time_since_restore: 627.6370711326599
  time_this_iter_s: 36.923880100250244
  time_total_s: 627.6370711326599
  timers:
    learn_throughput: 5477.416
    learn_time_ms: 29538.015
    sample_throughput: 22501.336
    sample_time_ms: 7190.329
    update_time_ms: 24.613
  timestamp: 1602358529
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 45add_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | TERMINATED |       |     17 |          627.637 | 2750464 |  227.525 |              276.929 |               98.596 |            824.572 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_45add_00000 | TERMINATED |       |     17 |          627.637 | 2750464 |  227.525 |              276.929 |               98.596 |            824.572 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


