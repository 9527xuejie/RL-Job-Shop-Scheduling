2020-10-12 08:59:06,809	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_2ff5d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=61288)[0m 2020-10-12 08:59:09,533	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=61262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61277)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_08-59-39
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1827852825323741
        entropy_coeff: 0.0010000000000000002
        kl: 0.007252133606622617
        model: {}
        policy_loss: -0.007616617986059282
        total_loss: 514.7327270507812
        vf_explained_var: 0.4917435944080353
        vf_loss: 514.7400767008463
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.56551724137931
    gpu_util_percent0: 0.3324137931034483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.53448275862069
    vram_util_percent0: 0.08326359122832815
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17270807500016586
    mean_env_wait_ms: 1.1842317012917596
    mean_inference_ms: 5.789950795657989
    mean_raw_obs_processing_ms: 0.4621999210029076
  time_since_restore: 24.109928607940674
  time_this_iter_s: 24.109928607940674
  time_total_s: 24.109928607940674
  timers:
    learn_throughput: 10784.327
    learn_time_ms: 15002.512
    sample_throughput: 17871.22
    sample_time_ms: 9053.215
    update_time_ms: 24.824
  timestamp: 1602493179
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      1 |          24.1099 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3625.784722222222
    time_step_min: 3334
  date: 2020-10-12_09-00-01
  done: false
  episode_len_mean: 891.1518987341772
  episode_reward_max: 260.86868686868667
  episode_reward_mean: 216.46180155990257
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.152884711821874
        entropy_coeff: 0.0010000000000000002
        kl: 0.00817319944811364
        model: {}
        policy_loss: -0.0077804924512747675
        total_loss: 148.78453318277994
        vf_explained_var: 0.7891508936882019
        vf_loss: 148.79183705647787
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.07857142857143
    gpu_util_percent0: 0.32250000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.739285714285714
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1683284879878786
    mean_env_wait_ms: 1.178056506170735
    mean_inference_ms: 5.592927722285913
    mean_raw_obs_processing_ms: 0.45274332524737865
  time_since_restore: 46.81750416755676
  time_this_iter_s: 22.70757555961609
  time_total_s: 46.81750416755676
  timers:
    learn_throughput: 10943.141
    learn_time_ms: 14784.787
    sample_throughput: 18963.322
    sample_time_ms: 8531.838
    update_time_ms: 53.149
  timestamp: 1602493201
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      2 |          46.8175 | 323584 |  216.462 |              260.869 |              138.293 |            891.152 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3620.9910313901346
    time_step_min: 3288
  date: 2020-10-12_09-00-23
  done: false
  episode_len_mean: 888.1940928270042
  episode_reward_max: 267.8383838383836
  episode_reward_mean: 217.42795038997548
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1462223529815674
        entropy_coeff: 0.0010000000000000002
        kl: 0.008821873382354775
        model: {}
        policy_loss: -0.010471421875990927
        total_loss: 71.87938245137532
        vf_explained_var: 0.8741273880004883
        vf_loss: 71.88923454284668
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.51538461538462
    gpu_util_percent0: 0.30653846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769230769230769
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16521501150125542
    mean_env_wait_ms: 1.1753342821946675
    mean_inference_ms: 5.414212187886819
    mean_raw_obs_processing_ms: 0.4433768456207202
  time_since_restore: 68.74056553840637
  time_this_iter_s: 21.92306137084961
  time_total_s: 68.74056553840637
  timers:
    learn_throughput: 10970.429
    learn_time_ms: 14748.01
    sample_throughput: 20021.387
    sample_time_ms: 8080.958
    update_time_ms: 42.214
  timestamp: 1602493223
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      3 |          68.7406 | 485376 |  217.428 |              267.838 |              138.293 |            888.194 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3610.417218543046
    time_step_min: 3274
  date: 2020-10-12_09-00-45
  done: false
  episode_len_mean: 886.4018987341772
  episode_reward_max: 269.95959595959573
  episode_reward_mean: 219.13753036696053
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.131478746732076
        entropy_coeff: 0.0010000000000000002
        kl: 0.009067467879503965
        model: {}
        policy_loss: -0.011158901480181763
        total_loss: 52.418883641560875
        vf_explained_var: 0.9044191241264343
        vf_loss: 52.4293597539266
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.24230769230769
    gpu_util_percent0: 0.3303846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7653846153846158
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16294839757268015
    mean_env_wait_ms: 1.173896264673618
    mean_inference_ms: 5.278627360149862
    mean_raw_obs_processing_ms: 0.4360804557101574
  time_since_restore: 90.48964166641235
  time_this_iter_s: 21.74907612800598
  time_total_s: 90.48964166641235
  timers:
    learn_throughput: 10991.757
    learn_time_ms: 14719.394
    sample_throughput: 20693.03
    sample_time_ms: 7818.671
    update_time_ms: 37.178
  timestamp: 1602493245
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      4 |          90.4896 | 647168 |  219.138 |               269.96 |              138.293 |            886.402 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3601.9973753280838
    time_step_min: 3274
  date: 2020-10-12_09-01-07
  done: false
  episode_len_mean: 885.8126582278481
  episode_reward_max: 269.95959595959573
  episode_reward_mean: 220.24689937348145
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1002709567546844
        entropy_coeff: 0.0010000000000000002
        kl: 0.010285430510217944
        model: {}
        policy_loss: -0.010795360606759155
        total_loss: 44.717560450236
        vf_explained_var: 0.9204235076904297
        vf_loss: 44.727399826049805
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.892307692307693
    gpu_util_percent0: 0.2823076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761538461538461
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16124317623128723
    mean_env_wait_ms: 1.1728483082955226
    mean_inference_ms: 5.1744935019423375
    mean_raw_obs_processing_ms: 0.4302497501616795
  time_since_restore: 112.25396418571472
  time_this_iter_s: 21.764322519302368
  time_total_s: 112.25396418571472
  timers:
    learn_throughput: 11003.41
    learn_time_ms: 14703.805
    sample_throughput: 21119.87
    sample_time_ms: 7660.653
    update_time_ms: 38.54
  timestamp: 1602493267
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      5 |          112.254 | 808960 |  220.247 |               269.96 |              138.293 |            885.813 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3594.594566353187
    time_step_min: 3243
  date: 2020-10-12_09-01-29
  done: false
  episode_len_mean: 883.11269035533
  episode_reward_max: 274.6565656565651
  episode_reward_mean: 221.7977747013278
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 195
  episodes_total: 985
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0551829834779103
        entropy_coeff: 0.0010000000000000002
        kl: 0.00798146337425957
        model: {}
        policy_loss: -0.008698727258888539
        total_loss: 38.42673524220785
        vf_explained_var: 0.9503893852233887
        vf_loss: 38.43489201863607
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.5037037037037
    gpu_util_percent0: 0.3148148148148148
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7444444444444436
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15962227548441582
    mean_env_wait_ms: 1.1730119604201477
    mean_inference_ms: 5.077774301079153
    mean_raw_obs_processing_ms: 0.4246718082663689
  time_since_restore: 134.24448561668396
  time_this_iter_s: 21.99052143096924
  time_total_s: 134.24448561668396
  timers:
    learn_throughput: 10995.386
    learn_time_ms: 14714.536
    sample_throughput: 21363.685
    sample_time_ms: 7573.225
    update_time_ms: 38.728
  timestamp: 1602493289
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      6 |          134.244 | 970752 |  221.798 |              274.657 |              138.293 |            883.113 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3583.385922330097
    time_step_min: 3223
  date: 2020-10-12_09-01-51
  done: false
  episode_len_mean: 877.7357594936709
  episode_reward_max: 277.68686868686825
  episode_reward_mean: 223.5254762818052
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 279
  episodes_total: 1264
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0733901659647624
        entropy_coeff: 0.0010000000000000002
        kl: 0.009930080346142253
        model: {}
        policy_loss: -0.010789080096098283
        total_loss: 27.276743412017822
        vf_explained_var: 0.9606603980064392
        vf_loss: 27.286620140075684
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.696153846153848
    gpu_util_percent0: 0.3926923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753846153846154
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15799678062042052
    mean_env_wait_ms: 1.1736655135781597
    mean_inference_ms: 4.977340255902446
    mean_raw_obs_processing_ms: 0.4192058798222829
  time_since_restore: 155.88834595680237
  time_this_iter_s: 21.643860340118408
  time_total_s: 155.88834595680237
  timers:
    learn_throughput: 11010.61
    learn_time_ms: 14694.191
    sample_throughput: 21595.994
    sample_time_ms: 7491.76
    update_time_ms: 35.789
  timestamp: 1602493311
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      7 |          155.888 | 1132544 |  223.525 |              277.687 |              138.293 |            877.736 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3573.615494978479
    time_step_min: 3185
  date: 2020-10-12_09-02-13
  done: false
  episode_len_mean: 873.8832630098453
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 224.71825853471407
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0512039462725322
        entropy_coeff: 0.0010000000000000002
        kl: 0.009337255420784155
        model: {}
        policy_loss: -0.010989288333803415
        total_loss: 20.810040314992268
        vf_explained_var: 0.9638325572013855
        vf_loss: 20.820213794708252
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.796153846153842
    gpu_util_percent0: 0.3565384615384615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773076923076923
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15728626041931107
    mean_env_wait_ms: 1.174324554848766
    mean_inference_ms: 4.933508032757876
    mean_raw_obs_processing_ms: 0.41682252620248256
  time_since_restore: 177.49103927612305
  time_this_iter_s: 21.60269331932068
  time_total_s: 177.49103927612305
  timers:
    learn_throughput: 11029.634
    learn_time_ms: 14668.846
    sample_throughput: 21762.194
    sample_time_ms: 7434.545
    update_time_ms: 34.804
  timestamp: 1602493333
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      8 |          177.491 | 1294336 |  224.718 |              283.444 |              138.293 |            873.883 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3565.3086340206187
    time_step_min: 3185
  date: 2020-10-12_09-02-34
  done: false
  episode_len_mean: 870.4778481012659
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 225.85602864083862
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0309100051720936
        entropy_coeff: 0.0010000000000000002
        kl: 0.009246378981818756
        model: {}
        policy_loss: -0.010212190235809734
        total_loss: 20.242994626363117
        vf_explained_var: 0.9640101790428162
        vf_loss: 20.25238800048828
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.023076923076925
    gpu_util_percent0: 0.3438461538461538
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7615384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15665502644242502
    mean_env_wait_ms: 1.1750044143064777
    mean_inference_ms: 4.895217792165296
    mean_raw_obs_processing_ms: 0.41467795490151177
  time_since_restore: 199.20523238182068
  time_this_iter_s: 21.714193105697632
  time_total_s: 199.20523238182068
  timers:
    learn_throughput: 11034.172
    learn_time_ms: 14662.812
    sample_throughput: 21895.441
    sample_time_ms: 7389.301
    update_time_ms: 33.233
  timestamp: 1602493354
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      9 |          199.205 | 1456128 |  225.856 |              283.444 |              138.293 |            870.478 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3557.434248977206
    time_step_min: 3185
  date: 2020-10-12_09-02-56
  done: false
  episode_len_mean: 866.7343300747556
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 227.4051846817803
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 159
  episodes_total: 1739
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9909518311421076
        entropy_coeff: 0.0010000000000000002
        kl: 0.008320549929824969
        model: {}
        policy_loss: -0.010935846860472035
        total_loss: 19.282020409901936
        vf_explained_var: 0.9666249752044678
        vf_loss: 19.292283693949383
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.769230769230766
    gpu_util_percent0: 0.3265384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7653846153846158
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15609390168678733
    mean_env_wait_ms: 1.1757625567836965
    mean_inference_ms: 4.861189757025129
    mean_raw_obs_processing_ms: 0.41269138624484064
  time_since_restore: 221.06112408638
  time_this_iter_s: 21.855891704559326
  time_total_s: 221.06112408638
  timers:
    learn_throughput: 11022.72
    learn_time_ms: 14678.046
    sample_throughput: 22023.152
    sample_time_ms: 7346.451
    update_time_ms: 32.472
  timestamp: 1602493376
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     10 |          221.061 | 1617920 |  227.405 |              283.444 |              138.293 |            866.734 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3539.8850916295196
    time_step_min: 3185
  date: 2020-10-12_09-03-18
  done: false
  episode_len_mean: 859.5857352222765
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 229.98986938263917
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 308
  episodes_total: 2047
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9655184050401052
        entropy_coeff: 0.0010000000000000002
        kl: 0.008406333470096191
        model: {}
        policy_loss: -0.008845852552137027
        total_loss: 24.37638807296753
        vf_explained_var: 0.9691322445869446
        vf_loss: 24.384517987569172
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.292307692307695
    gpu_util_percent0: 0.32807692307692304
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15520738844743057
    mean_env_wait_ms: 1.1775783706239886
    mean_inference_ms: 4.806573187215449
    mean_raw_obs_processing_ms: 0.4096107045646865
  time_since_restore: 242.5982792377472
  time_this_iter_s: 21.537155151367188
  time_total_s: 242.5982792377472
  timers:
    learn_throughput: 11058.94
    learn_time_ms: 14629.973
    sample_throughput: 22674.715
    sample_time_ms: 7135.349
    update_time_ms: 31.807
  timestamp: 1602493398
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     11 |          242.598 | 1779712 |   229.99 |              283.444 |              138.293 |            859.586 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3531.548076923077
    time_step_min: 3185
  date: 2020-10-12_09-03-40
  done: false
  episode_len_mean: 856.9538878842676
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 231.21308930169675
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 165
  episodes_total: 2212
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9565430780251821
        entropy_coeff: 0.0010000000000000002
        kl: 0.008191000708999733
        model: {}
        policy_loss: -0.010603418719256297
        total_loss: 15.069294850031534
        vf_explained_var: 0.9731817245483398
        vf_loss: 15.079216718673706
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.942307692307686
    gpu_util_percent0: 0.3630769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548116402186192
    mean_env_wait_ms: 1.1784918721884388
    mean_inference_ms: 4.782256817941978
    mean_raw_obs_processing_ms: 0.40823214259400425
  time_since_restore: 264.3383433818817
  time_this_iter_s: 21.74006414413452
  time_total_s: 264.3383433818817
  timers:
    learn_throughput: 11057.032
    learn_time_ms: 14632.497
    sample_throughput: 23009.407
    sample_time_ms: 7031.559
    update_time_ms: 25.638
  timestamp: 1602493420
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     12 |          264.338 | 1941504 |  231.213 |              283.444 |              138.293 |            856.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3523.853970964987
    time_step_min: 3185
  date: 2020-10-12_09-04-01
  done: false
  episode_len_mean: 854.989029535865
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 232.36299705919947
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9362313946088155
        entropy_coeff: 0.0010000000000000002
        kl: 0.008440477463106314
        model: {}
        policy_loss: -0.01189564911207223
        total_loss: 12.665011564890543
        vf_explained_var: 0.975372314453125
        vf_loss: 12.67615556716919
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.184615384615384
    gpu_util_percent0: 0.36076923076923073
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15446811486850553
    mean_env_wait_ms: 1.1793126946849357
    mean_inference_ms: 4.761021532588441
    mean_raw_obs_processing_ms: 0.40700798732540167
  time_since_restore: 286.0172369480133
  time_this_iter_s: 21.678893566131592
  time_total_s: 286.0172369480133
  timers:
    learn_throughput: 11056.992
    learn_time_ms: 14632.552
    sample_throughput: 23097.527
    sample_time_ms: 7004.733
    update_time_ms: 27.304
  timestamp: 1602493441
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     13 |          286.017 | 2103296 |  232.363 |              283.444 |              138.293 |            854.989 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3516.10499001996
    time_step_min: 3185
  date: 2020-10-12_09-04-23
  done: false
  episode_len_mean: 852.9842084484801
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 233.51754018670704
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 163
  episodes_total: 2533
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.914815291762352
        entropy_coeff: 0.0010000000000000002
        kl: 0.00748422338316838
        model: {}
        policy_loss: -0.01166970853228122
        total_loss: 14.907468636830648
        vf_explained_var: 0.9727827906608582
        vf_loss: 14.918556292851767
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.930769230769233
    gpu_util_percent0: 0.3576923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7615384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541383191163195
    mean_env_wait_ms: 1.1801036537209806
    mean_inference_ms: 4.740986100983287
    mean_raw_obs_processing_ms: 0.40583169794768054
  time_since_restore: 307.52837777137756
  time_this_iter_s: 21.511140823364258
  time_total_s: 307.52837777137756
  timers:
    learn_throughput: 11064.872
    learn_time_ms: 14622.131
    sample_throughput: 23141.427
    sample_time_ms: 6991.444
    update_time_ms: 27.815
  timestamp: 1602493463
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     14 |          307.528 | 2265088 |  233.518 |              283.444 |              138.293 |            852.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3504.3098845598847
    time_step_min: 3185
  date: 2020-10-12_09-04-45
  done: false
  episode_len_mean: 850.7546428571428
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 235.27869769119758
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 267
  episodes_total: 2800
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.878979096810023
        entropy_coeff: 0.0010000000000000002
        kl: 0.0076557288800055785
        model: {}
        policy_loss: -0.008793464541668072
        total_loss: 14.52612074216207
        vf_explained_var: 0.9794191718101501
        vf_loss: 14.53426194190979
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.834615384615383
    gpu_util_percent0: 0.34461538461538466
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7461538461538457
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15366811327958144
    mean_env_wait_ms: 1.1812971915692976
    mean_inference_ms: 4.712196353201802
    mean_raw_obs_processing_ms: 0.40415147303757676
  time_since_restore: 329.0642874240875
  time_this_iter_s: 21.53590965270996
  time_total_s: 329.0642874240875
  timers:
    learn_throughput: 11080.771
    learn_time_ms: 14601.15
    sample_throughput: 23145.701
    sample_time_ms: 6990.153
    update_time_ms: 26.763
  timestamp: 1602493485
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     15 |          329.064 | 2426880 |  235.279 |              283.444 |              138.293 |            850.755 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3496.693678547411
    time_step_min: 3182
  date: 2020-10-12_09-05-06
  done: false
  episode_len_mean: 849.3787475016655
  episode_reward_max: 291.32323232323205
  episode_reward_mean: 236.53021554653785
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 202
  episodes_total: 3002
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8884957184394201
        entropy_coeff: 0.0010000000000000002
        kl: 0.008369801216758788
        model: {}
        policy_loss: -0.011218314505337426
        total_loss: 9.95873467127482
        vf_explained_var: 0.9824435710906982
        vf_loss: 9.969167629877726
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.73076923076923
    gpu_util_percent0: 0.31269230769230766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773076923076923
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15336117339517932
    mean_env_wait_ms: 1.1820576545560504
    mean_inference_ms: 4.692950490977445
    mean_raw_obs_processing_ms: 0.40307043117947566
  time_since_restore: 350.6308124065399
  time_this_iter_s: 21.566524982452393
  time_total_s: 350.6308124065399
  timers:
    learn_throughput: 11094.652
    learn_time_ms: 14582.882
    sample_throughput: 23230.68
    sample_time_ms: 6964.583
    update_time_ms: 27.054
  timestamp: 1602493506
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     16 |          350.631 | 2588672 |   236.53 |              291.323 |              138.293 |            849.379 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3490.016922094508
    time_step_min: 3177
  date: 2020-10-12_09-05-28
  done: false
  episode_len_mean: 848.128164556962
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 237.6207965733281
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8844639857610067
        entropy_coeff: 0.0010000000000000002
        kl: 0.009058436146005988
        model: {}
        policy_loss: -0.010142707930450948
        total_loss: 10.037593603134155
        vf_explained_var: 0.9795668721199036
        vf_loss: 10.046809116999308
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.138461538461534
    gpu_util_percent0: 0.3169230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15313766348281804
    mean_env_wait_ms: 1.1826199558285937
    mean_inference_ms: 4.679197423372631
    mean_raw_obs_processing_ms: 0.4022791309942792
  time_since_restore: 372.391544342041
  time_this_iter_s: 21.7607319355011
  time_total_s: 372.391544342041
  timers:
    learn_throughput: 11083.646
    learn_time_ms: 14597.363
    sample_throughput: 23245.692
    sample_time_ms: 6960.085
    update_time_ms: 27.493
  timestamp: 1602493528
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     17 |          372.392 | 2750464 |  237.621 |              293.596 |              138.293 |            848.128 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3483.7223572296475
    time_step_min: 3177
  date: 2020-10-12_09-05-50
  done: false
  episode_len_mean: 847.2674698795181
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 238.54772118778135
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 160
  episodes_total: 3320
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8548314025004705
        entropy_coeff: 0.0010000000000000002
        kl: 0.008516259181002775
        model: {}
        policy_loss: -0.011190916178748012
        total_loss: 9.76652201016744
        vf_explained_var: 0.9812417030334473
        vf_loss: 9.776864449183146
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.88461538461539
    gpu_util_percent0: 0.34500000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529240572320849
    mean_env_wait_ms: 1.183106468357993
    mean_inference_ms: 4.666240516840153
    mean_raw_obs_processing_ms: 0.40152035844583606
  time_since_restore: 394.34070897102356
  time_this_iter_s: 21.949164628982544
  time_total_s: 394.34070897102356
  timers:
    learn_throughput: 11064.223
    learn_time_ms: 14622.988
    sample_throughput: 23222.449
    sample_time_ms: 6967.052
    update_time_ms: 26.672
  timestamp: 1602493550
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     18 |          394.341 | 2912256 |  238.548 |              293.596 |              138.293 |            847.267 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3476.3166714001704
    time_step_min: 3177
  date: 2020-10-12_09-06-12
  done: false
  episode_len_mean: 846.5122569737954
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 239.51551013089468
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 229
  episodes_total: 3549
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8149505207935969
        entropy_coeff: 0.0010000000000000002
        kl: 0.0059012921604638295
        model: {}
        policy_loss: -0.00783768025454871
        total_loss: 12.426872173945108
        vf_explained_var: 0.9817931056022644
        vf_loss: 12.43434445063273
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.233333333333327
    gpu_util_percent0: 0.36777777777777776
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7592592592592586
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526486696957768
    mean_env_wait_ms: 1.1837581265941555
    mean_inference_ms: 4.649506556049909
    mean_raw_obs_processing_ms: 0.40053669449346774
  time_since_restore: 416.0491623878479
  time_this_iter_s: 21.70845341682434
  time_total_s: 416.0491623878479
  timers:
    learn_throughput: 11075.836
    learn_time_ms: 14607.656
    sample_throughput: 23179.907
    sample_time_ms: 6979.838
    update_time_ms: 27.896
  timestamp: 1602493572
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     19 |          416.049 | 3074048 |  239.516 |              293.596 |              138.293 |            846.512 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3470.7743740010656
    time_step_min: 3177
  date: 2020-10-12_09-06-34
  done: false
  episode_len_mean: 845.9870438921206
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 240.40188238813298
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 233
  episodes_total: 3782
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8266270160675049
        entropy_coeff: 0.0010000000000000002
        kl: 0.007779809723918636
        model: {}
        policy_loss: -0.010379398086418709
        total_loss: 11.921677827835083
        vf_explained_var: 0.981447696685791
        vf_loss: 11.931328058242798
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.01538461538462
    gpu_util_percent0: 0.33692307692307694
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7615384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15239744721691542
    mean_env_wait_ms: 1.1842913223565388
    mean_inference_ms: 4.633907213688482
    mean_raw_obs_processing_ms: 0.39965976455472496
  time_since_restore: 437.7389130592346
  time_this_iter_s: 21.68975067138672
  time_total_s: 437.7389130592346
  timers:
    learn_throughput: 11082.98
    learn_time_ms: 14598.24
    sample_throughput: 23209.057
    sample_time_ms: 6971.072
    update_time_ms: 28.473
  timestamp: 1602493594
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     20 |          437.739 | 3235840 |  240.402 |              293.596 |              138.293 |            845.987 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3466.7972972972975
    time_step_min: 3170
  date: 2020-10-12_09-06-56
  done: false
  episode_len_mean: 845.693417721519
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 240.8964966116864
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 168
  episodes_total: 3950
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8171754479408264
        entropy_coeff: 0.0010000000000000002
        kl: 0.0071926506934687495
        model: {}
        policy_loss: -0.00922989979153499
        total_loss: 10.540773471196493
        vf_explained_var: 0.9810445308685303
        vf_loss: 10.549381573994955
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.915384615384617
    gpu_util_percent0: 0.39499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522306926361245
    mean_env_wait_ms: 1.1846476379178812
    mean_inference_ms: 4.6236738492529454
    mean_raw_obs_processing_ms: 0.39909001931172966
  time_since_restore: 459.36714267730713
  time_this_iter_s: 21.62822961807251
  time_total_s: 459.36714267730713
  timers:
    learn_throughput: 11081.903
    learn_time_ms: 14599.659
    sample_throughput: 23187.793
    sample_time_ms: 6977.464
    update_time_ms: 28.809
  timestamp: 1602493616
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     21 |          459.367 | 3397632 |  240.896 |              293.596 |              138.293 |            845.693 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3463.1188725490197
    time_step_min: 3162
  date: 2020-10-12_09-07-18
  done: false
  episode_len_mean: 844.7930866601753
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 241.4936315442644
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8059266755978266
        entropy_coeff: 0.0010000000000000002
        kl: 0.009029871318489313
        model: {}
        policy_loss: -0.008191939976920063
        total_loss: 9.447596470514933
        vf_explained_var: 0.9807239174842834
        vf_loss: 9.45478860537211
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.98076923076923
    gpu_util_percent0: 0.3611538461538461
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15208264388982512
    mean_env_wait_ms: 1.1849863794656472
    mean_inference_ms: 4.61455209890159
    mean_raw_obs_processing_ms: 0.3985701308073426
  time_since_restore: 481.05792474746704
  time_this_iter_s: 21.690782070159912
  time_total_s: 481.05792474746704
  timers:
    learn_throughput: 11080.848
    learn_time_ms: 14601.049
    sample_throughput: 23178.999
    sample_time_ms: 6980.112
    update_time_ms: 29.432
  timestamp: 1602493638
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     22 |          481.058 | 3559424 |  241.494 |              293.596 |              138.293 |            844.793 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3459.0384615384614
    time_step_min: 3162
  date: 2020-10-12_09-07-39
  done: false
  episode_len_mean: 843.6079203334878
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 242.17379445216403
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 210
  episodes_total: 4318
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7677705784638723
        entropy_coeff: 0.0010000000000000002
        kl: 0.008771082696815332
        model: {}
        policy_loss: -0.009407734837926304
        total_loss: 12.319875399271647
        vf_explained_var: 0.9799962043762207
        vf_loss: 12.328296820322672
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.765384615384615
    gpu_util_percent0: 0.32230769230769235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15189745302753577
    mean_env_wait_ms: 1.1854631073101427
    mean_inference_ms: 4.603314572970354
    mean_raw_obs_processing_ms: 0.3979223065249024
  time_since_restore: 502.7509262561798
  time_this_iter_s: 21.69300150871277
  time_total_s: 502.7509262561798
  timers:
    learn_throughput: 11086.305
    learn_time_ms: 14593.862
    sample_throughput: 23147.81
    sample_time_ms: 6989.517
    update_time_ms: 28.003
  timestamp: 1602493659
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     23 |          502.751 | 3721216 |  242.174 |              293.596 |              138.293 |            843.608 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3453.384700176367
    time_step_min: 3162
  date: 2020-10-12_09-08-01
  done: false
  episode_len_mean: 842.4776511831726
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 243.03763754990743
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 246
  episodes_total: 4564
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.754533514380455
        entropy_coeff: 0.0010000000000000002
        kl: 0.007815885241143405
        model: {}
        policy_loss: -0.0092500797448641
        total_loss: 10.229537963867188
        vf_explained_var: 0.9839439392089844
        vf_loss: 10.237979650497437
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.830769230769228
    gpu_util_percent0: 0.3080769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769230769230769
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15169897381901554
    mean_env_wait_ms: 1.185963947492432
    mean_inference_ms: 4.590924580195164
    mean_raw_obs_processing_ms: 0.39722662264480574
  time_since_restore: 524.5083110332489
  time_this_iter_s: 21.757384777069092
  time_total_s: 524.5083110332489
  timers:
    learn_throughput: 11064.753
    learn_time_ms: 14622.287
    sample_throughput: 23162.686
    sample_time_ms: 6985.028
    update_time_ms: 27.57
  timestamp: 1602493681
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     24 |          524.508 | 3883008 |  243.038 |              293.596 |              138.293 |            842.478 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3449.6651103565364
    time_step_min: 3162
  date: 2020-10-12_09-08-24
  done: false
  episode_len_mean: 841.5301687763713
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 243.61066359800532
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 176
  episodes_total: 4740
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7572712302207947
        entropy_coeff: 0.0010000000000000002
        kl: 0.006765442124257485
        model: {}
        policy_loss: -0.010398247444148486
        total_loss: 10.084507862726847
        vf_explained_var: 0.9806730151176453
        vf_loss: 10.094310283660889
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.67037037037037
    gpu_util_percent0: 0.3222222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781481481481481
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15156971425403531
    mean_env_wait_ms: 1.1863243146687548
    mean_inference_ms: 4.582885729339996
    mean_raw_obs_processing_ms: 0.3967946175107939
  time_since_restore: 546.6698186397552
  time_this_iter_s: 22.161507606506348
  time_total_s: 546.6698186397552
  timers:
    learn_throughput: 11020.151
    learn_time_ms: 14681.469
    sample_throughput: 23152.27
    sample_time_ms: 6988.17
    update_time_ms: 26.598
  timestamp: 1602493704
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     25 |           546.67 | 4044800 |  243.611 |              293.596 |              138.293 |             841.53 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3446.0199096880133
    time_step_min: 3143
  date: 2020-10-12_09-08-45
  done: false
  episode_len_mean: 840.7914285714286
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 244.18099360956498
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 160
  episodes_total: 4900
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7502193301916122
        entropy_coeff: 0.0010000000000000002
        kl: 0.007255109104638298
        model: {}
        policy_loss: -0.007779860898153856
        total_loss: 8.407378196716309
        vf_explained_var: 0.9829282760620117
        vf_loss: 8.414457241694132
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.6
    gpu_util_percent0: 0.32500000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788461538461538
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514547133877412
    mean_env_wait_ms: 1.1866431863334181
    mean_inference_ms: 4.575851559812878
    mean_raw_obs_processing_ms: 0.39639999605166304
  time_since_restore: 568.4001824855804
  time_this_iter_s: 21.730363845825195
  time_total_s: 568.4001824855804
  timers:
    learn_throughput: 11010.05
    learn_time_ms: 14694.937
    sample_throughput: 23139.623
    sample_time_ms: 6991.989
    update_time_ms: 24.748
  timestamp: 1602493725
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     26 |            568.4 | 4206592 |  244.181 |              293.596 |              138.293 |            840.791 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3441.1055632003145
    time_step_min: 3143
  date: 2020-10-12_09-09-07
  done: false
  episode_len_mean: 839.7184750733138
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 244.85938564530935
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 215
  episodes_total: 5115
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7258548388878504
        entropy_coeff: 0.0010000000000000002
        kl: 0.005995944142341614
        model: {}
        policy_loss: -0.00881769720823892
        total_loss: 12.80167587598165
        vf_explained_var: 0.9796185493469238
        vf_loss: 12.810020287831625
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.50384615384615
    gpu_util_percent0: 0.3807692307692308
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130938128528826
    mean_env_wait_ms: 1.1870839040728018
    mean_inference_ms: 4.567077973491149
    mean_raw_obs_processing_ms: 0.3959029906777852
  time_since_restore: 589.9252982139587
  time_this_iter_s: 21.525115728378296
  time_total_s: 589.9252982139587
  timers:
    learn_throughput: 11022.287
    learn_time_ms: 14678.624
    sample_throughput: 23164.787
    sample_time_ms: 6984.394
    update_time_ms: 24.259
  timestamp: 1602493747
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     27 |          589.925 | 4368384 |  244.859 |              293.596 |              138.293 |            839.718 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2ff5d_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3435.807771728928
    time_step_min: 3143
  date: 2020-10-12_09-09-29
  done: true
  episode_len_mean: 838.581512605042
  episode_reward_max: 293.59595959595947
  episode_reward_mean: 245.61831197125315
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 240
  episodes_total: 5355
  experiment_id: 53eea350ceb84a0185dd431d0f55a03d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7102122207482656
        entropy_coeff: 0.0010000000000000002
        kl: 0.007275186013430357
        model: {}
        policy_loss: -0.01022022515341329
        total_loss: 8.86198623975118
        vf_explained_var: 0.9859199523925781
        vf_loss: 8.871461629867554
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.707692307692305
    gpu_util_percent0: 0.4034615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761538461538461
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61288
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15116122180138195
    mean_env_wait_ms: 1.1875290665151548
    mean_inference_ms: 4.557807153575949
    mean_raw_obs_processing_ms: 0.3953896112400835
  time_since_restore: 611.5453379154205
  time_this_iter_s: 21.620039701461792
  time_total_s: 611.5453379154205
  timers:
    learn_throughput: 11042.42
    learn_time_ms: 14651.86
    sample_throughput: 23203.388
    sample_time_ms: 6972.775
    update_time_ms: 24.119
  timestamp: 1602493769
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: 2ff5d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | TERMINATED |       |     28 |          611.545 | 4530176 |  245.618 |              293.596 |              138.293 |            838.582 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2ff5d_00000 | TERMINATED |       |     28 |          611.545 | 4530176 |  245.618 |              293.596 |              138.293 |            838.582 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


