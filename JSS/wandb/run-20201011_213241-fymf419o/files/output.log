2020-10-11 21:32:45,096	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4dbfc_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=47956)[0m 2020-10-11 21:32:47,782	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=48009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47962)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_21-33-25
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1857230464617412
        entropy_coeff: 0.0005000000000000001
        kl: 0.003798783950818082
        model: {}
        policy_loss: -0.010474004220062247
        total_loss: 502.236811319987
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.744999999999997
    gpu_util_percent0: 0.28525
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5799999999999996
    vram_util_percent0: 0.08847572974745818
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1690763866286765
    mean_env_wait_ms: 1.1688458430027293
    mean_inference_ms: 5.543266654419435
    mean_raw_obs_processing_ms: 0.4514718269190327
  time_since_restore: 32.53148937225342
  time_this_iter_s: 32.53148937225342
  time_total_s: 32.53148937225342
  timers:
    learn_throughput: 6877.116
    learn_time_ms: 23526.143
    sample_throughput: 18137.824
    sample_time_ms: 8920.144
    update_time_ms: 41.753
  timestamp: 1602452005
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      1 |          32.5315 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3616.628472222222
    time_step_min: 3338
  date: 2020-10-11_21-33-56
  done: false
  episode_len_mean: 890.6139240506329
  episode_reward_max: 260.2626262626262
  episode_reward_mean: 216.80175169415654
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1549607912699382
        entropy_coeff: 0.0005000000000000001
        kl: 0.007347609304512541
        model: {}
        policy_loss: -0.010700855811592191
        total_loss: 121.66396522521973
        vf_explained_var: 0.8180515766143799
        vf_loss: 121.6741402943929
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.099999999999998
    gpu_util_percent0: 0.36052631578947364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.755263157894737
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16522508538034614
    mean_env_wait_ms: 1.1651040753373314
    mean_inference_ms: 5.405943301184122
    mean_raw_obs_processing_ms: 0.4430714528543058
  time_since_restore: 63.39335513114929
  time_this_iter_s: 30.861865758895874
  time_total_s: 63.39335513114929
  timers:
    learn_throughput: 6970.785
    learn_time_ms: 23210.012
    sample_throughput: 19299.169
    sample_time_ms: 8383.366
    update_time_ms: 34.164
  timestamp: 1602452036
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      2 |          63.3934 | 323584 |  216.802 |              260.263 |              110.414 |            890.614 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3617.634529147982
    time_step_min: 3332
  date: 2020-10-11_21-34-27
  done: false
  episode_len_mean: 887.9198312236286
  episode_reward_max: 266.7777777777773
  episode_reward_mean: 217.79267357115438
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1440204083919525
        entropy_coeff: 0.0005000000000000001
        kl: 0.007993019962062439
        model: {}
        policy_loss: -0.013092469404606769
        total_loss: 59.01280816396078
        vf_explained_var: 0.8985264897346497
        vf_loss: 59.02527300516764
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.42162162162162
    gpu_util_percent0: 0.3767567567567568
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775675675675677
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16236499198238236
    mean_env_wait_ms: 1.1637808482928664
    mean_inference_ms: 5.258698473188379
    mean_raw_obs_processing_ms: 0.435140659585258
  time_since_restore: 93.8776524066925
  time_this_iter_s: 30.484297275543213
  time_total_s: 93.8776524066925
  timers:
    learn_throughput: 6974.319
    learn_time_ms: 23198.252
    sample_throughput: 20246.206
    sample_time_ms: 7991.226
    update_time_ms: 38.751
  timestamp: 1602452067
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      3 |          93.8777 | 485376 |  217.793 |              266.778 |              110.414 |             887.92 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3608.0562913907283
    time_step_min: 3285
  date: 2020-10-11_21-34-57
  done: false
  episode_len_mean: 885.7104430379746
  episode_reward_max: 268.2929292929291
  episode_reward_mean: 219.3523366577162
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1278011600176494
        entropy_coeff: 0.0005000000000000001
        kl: 0.007670091115869582
        model: {}
        policy_loss: -0.013711634344266107
        total_loss: 37.57364432017008
        vf_explained_var: 0.9326484799385071
        vf_loss: 37.58677101135254
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.816666666666666
    gpu_util_percent0: 0.39111111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1603363987429036
    mean_env_wait_ms: 1.1629191172995006
    mean_inference_ms: 5.144053292924569
    mean_raw_obs_processing_ms: 0.42881980619517046
  time_since_restore: 123.99596667289734
  time_this_iter_s: 30.118314266204834
  time_total_s: 123.99596667289734
  timers:
    learn_throughput: 6988.107
    learn_time_ms: 23152.478
    sample_throughput: 20873.392
    sample_time_ms: 7751.112
    update_time_ms: 36.123
  timestamp: 1602452097
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      4 |          123.996 | 647168 |  219.352 |              268.293 |              110.414 |             885.71 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3596.917322834646
    time_step_min: 3281
  date: 2020-10-11_21-35-27
  done: false
  episode_len_mean: 881.8632911392405
  episode_reward_max: 269.05050505050485
  episode_reward_mean: 220.85506968418346
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1055574119091034
        entropy_coeff: 0.0005000000000000001
        kl: 0.007356660207733512
        model: {}
        policy_loss: -0.015077506580079595
        total_loss: 30.304422696431477
        vf_explained_var: 0.9471704363822937
        vf_loss: 30.31894826889038
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.297297297297295
    gpu_util_percent0: 0.3845945945945946
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775675675675676
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15878778113212297
    mean_env_wait_ms: 1.1632949425380017
    mean_inference_ms: 5.054563808704855
    mean_raw_obs_processing_ms: 0.42372305621665224
  time_since_restore: 154.32704496383667
  time_this_iter_s: 30.33107829093933
  time_total_s: 154.32704496383667
  timers:
    learn_throughput: 6982.128
    learn_time_ms: 23172.306
    sample_throughput: 21294.285
    sample_time_ms: 7597.907
    update_time_ms: 37.682
  timestamp: 1602452127
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      5 |          154.327 | 808960 |  220.855 |              269.051 |              110.414 |            881.863 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3573.6074144486693
    time_step_min: 3264
  date: 2020-10-11_21-35-58
  done: false
  episode_len_mean: 873.2037037037037
  episode_reward_max: 283.1414141414143
  episode_reward_mean: 224.96366442199758
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 290
  episodes_total: 1080
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.085174431403478
        entropy_coeff: 0.0005000000000000001
        kl: 0.007730655216922362
        model: {}
        policy_loss: -0.015309946844354272
        total_loss: 26.320820649464924
        vf_explained_var: 0.9662351012229919
        vf_loss: 26.335513591766357
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.18378378378378
    gpu_util_percent0: 0.357027027027027
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7675675675675686
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15684125045578473
    mean_env_wait_ms: 1.1655187431931016
    mean_inference_ms: 4.938442077897287
    mean_raw_obs_processing_ms: 0.41719360206605843
  time_since_restore: 184.7890009880066
  time_this_iter_s: 30.461956024169922
  time_total_s: 184.7890009880066
  timers:
    learn_throughput: 6973.679
    learn_time_ms: 23200.381
    sample_throughput: 21557.825
    sample_time_ms: 7505.024
    update_time_ms: 35.498
  timestamp: 1602452158
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      6 |          184.789 | 970752 |  224.964 |              283.141 |              110.414 |            873.204 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3560.5784789644013
    time_step_min: 3234
  date: 2020-10-11_21-36-28
  done: false
  episode_len_mean: 868.3591772151899
  episode_reward_max: 283.1414141414143
  episode_reward_mean: 226.61787175552982
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 184
  episodes_total: 1264
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0887006223201752
        entropy_coeff: 0.0005000000000000001
        kl: 0.007638255716301501
        model: {}
        policy_loss: -0.014718286382655302
        total_loss: 21.909285227457683
        vf_explained_var: 0.962185800075531
        vf_loss: 21.923402150472004
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.11621621621622
    gpu_util_percent0: 0.30378378378378373
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7891891891891896
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15594862196411566
    mean_env_wait_ms: 1.1667374636395802
    mean_inference_ms: 4.88488739066329
    mean_raw_obs_processing_ms: 0.4141340757799933
  time_since_restore: 215.0454239845276
  time_this_iter_s: 30.256422996520996
  time_total_s: 215.0454239845276
  timers:
    learn_throughput: 6970.963
    learn_time_ms: 23209.419
    sample_throughput: 21800.969
    sample_time_ms: 7421.322
    update_time_ms: 33.306
  timestamp: 1602452188
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      7 |          215.045 | 1132544 |  226.618 |              283.141 |              110.414 |            868.359 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3551.7826398852226
    time_step_min: 3234
  date: 2020-10-11_21-36-58
  done: false
  episode_len_mean: 864.867088607595
  episode_reward_max: 283.1414141414143
  episode_reward_mean: 227.97093295827455
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0693918069203694
        entropy_coeff: 0.0005000000000000001
        kl: 0.0072084041700388
        model: {}
        policy_loss: -0.015359287809891006
        total_loss: 17.16118319829305
        vf_explained_var: 0.9682703018188477
        vf_loss: 17.17599582672119
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.43611111111111
    gpu_util_percent0: 0.3736111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553017464496277
    mean_env_wait_ms: 1.167773954479952
    mean_inference_ms: 4.845640956992546
    mean_raw_obs_processing_ms: 0.4118794608281288
  time_since_restore: 244.90622901916504
  time_this_iter_s: 29.86080503463745
  time_total_s: 244.90622901916504
  timers:
    learn_throughput: 6980.177
    learn_time_ms: 23178.781
    sample_throughput: 22024.905
    sample_time_ms: 7345.866
    update_time_ms: 31.677
  timestamp: 1602452218
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      8 |          244.906 | 1294336 |  227.971 |              283.141 |              110.414 |            864.867 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3545.026417525773
    time_step_min: 3234
  date: 2020-10-11_21-37-28
  done: false
  episode_len_mean: 861.6037974683544
  episode_reward_max: 283.1414141414143
  episode_reward_mean: 229.1638537271447
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0470322966575623
        entropy_coeff: 0.0005000000000000001
        kl: 0.007123887732935448
        model: {}
        policy_loss: -0.014397265913430601
        total_loss: 16.169137557347614
        vf_explained_var: 0.9692680835723877
        vf_loss: 16.182989835739136
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.110810810810808
    gpu_util_percent0: 0.33810810810810815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7810810810810827
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15473522336587325
    mean_env_wait_ms: 1.1687531690259638
    mean_inference_ms: 4.811115235392844
    mean_raw_obs_processing_ms: 0.4098542456090994
  time_since_restore: 274.98343777656555
  time_this_iter_s: 30.077208757400513
  time_total_s: 274.98343777656555
  timers:
    learn_throughput: 6984.761
    learn_time_ms: 23163.569
    sample_throughput: 22152.982
    sample_time_ms: 7303.396
    update_time_ms: 30.202
  timestamp: 1602452248
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |      9 |          274.983 | 1456128 |  229.164 |              283.141 |              110.414 |            861.604 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3530.4268774703555
    time_step_min: 3234
  date: 2020-10-11_21-37-58
  done: false
  episode_len_mean: 856.5019455252918
  episode_reward_max: 283.1414141414143
  episode_reward_mean: 231.32575897945532
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 219
  episodes_total: 1799
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9955361733833948
        entropy_coeff: 0.0005000000000000001
        kl: 0.007187109091319144
        model: {}
        policy_loss: -0.01544647855189396
        total_loss: 19.70352252324422
        vf_explained_var: 0.9719389081001282
        vf_loss: 19.71838919321696
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.269444444444446
    gpu_util_percent0: 0.3966666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666675
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540789666554751
    mean_env_wait_ms: 1.17050224252806
    mean_inference_ms: 4.7703500879333305
    mean_raw_obs_processing_ms: 0.40745974104297483
  time_since_restore: 305.00637912750244
  time_this_iter_s: 30.02294135093689
  time_total_s: 305.00637912750244
  timers:
    learn_throughput: 6988.192
    learn_time_ms: 23152.198
    sample_throughput: 22283.073
    sample_time_ms: 7260.758
    update_time_ms: 31.322
  timestamp: 1602452278
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     10 |          305.006 | 1617920 |  231.326 |              283.141 |              110.414 |            856.502 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3512.92152023692
    time_step_min: 3175
  date: 2020-10-11_21-38-28
  done: false
  episode_len_mean: 850.5399221032133
  episode_reward_max: 287.53535353535364
  episode_reward_mean: 233.95210134450627
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 255
  episodes_total: 2054
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.998373086253802
        entropy_coeff: 0.0005000000000000001
        kl: 0.006631100395073493
        model: {}
        policy_loss: -0.013022129907767521
        total_loss: 12.730268001556396
        vf_explained_var: 0.9779369831085205
        vf_loss: 12.742793877919516
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.97837837837838
    gpu_util_percent0: 0.36540540540540545
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770270270270271
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534340792922327
    mean_env_wait_ms: 1.1722884823342403
    mean_inference_ms: 4.7310951768402765
    mean_raw_obs_processing_ms: 0.4051327361693945
  time_since_restore: 334.9176182746887
  time_this_iter_s: 29.91123914718628
  time_total_s: 334.9176182746887
  timers:
    learn_throughput: 7007.054
    learn_time_ms: 23089.873
    sample_throughput: 22929.313
    sample_time_ms: 7056.121
    update_time_ms: 29.216
  timestamp: 1602452308
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     11 |          334.918 | 1779712 |  233.952 |              287.535 |              110.414 |             850.54 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3503.0641025641025
    time_step_min: 3174
  date: 2020-10-11_21-38-59
  done: false
  episode_len_mean: 846.8051537070525
  episode_reward_max: 287.53535353535364
  episode_reward_mean: 235.4166073026831
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9765142152706782
        entropy_coeff: 0.0005000000000000001
        kl: 0.006615819758735597
        model: {}
        policy_loss: -0.015855548321269453
        total_loss: 11.430502971013388
        vf_explained_var: 0.9765089154243469
        vf_loss: 11.445854584376017
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.083783783783787
    gpu_util_percent0: 0.3924324324324325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775675675675677
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15309295948325044
    mean_env_wait_ms: 1.1733780559029452
    mean_inference_ms: 4.710122093442377
    mean_raw_obs_processing_ms: 0.4038869614993577
  time_since_restore: 365.5320551395416
  time_this_iter_s: 30.614436864852905
  time_total_s: 365.5320551395416
  timers:
    learn_throughput: 6990.76
    learn_time_ms: 23143.693
    sample_throughput: 23184.618
    sample_time_ms: 6978.42
    update_time_ms: 32.353
  timestamp: 1602452339
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     12 |          365.532 | 1941504 |  235.417 |              287.535 |              110.414 |            846.805 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3494.570025619129
    time_step_min: 3174
  date: 2020-10-11_21-39-29
  done: false
  episode_len_mean: 843.3987341772151
  episode_reward_max: 287.53535353535364
  episode_reward_mean: 236.733921493415
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9475046048561732
        entropy_coeff: 0.0005000000000000001
        kl: 0.006857145267228286
        model: {}
        policy_loss: -0.01510264549870044
        total_loss: 10.932846943537394
        vf_explained_var: 0.9779910445213318
        vf_loss: 10.947394847869873
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.66111111111111
    gpu_util_percent0: 0.3111111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15278433731095692
    mean_env_wait_ms: 1.1744849131756336
    mean_inference_ms: 4.690964028958679
    mean_raw_obs_processing_ms: 0.40272573437302855
  time_since_restore: 395.5878527164459
  time_this_iter_s: 30.055797576904297
  time_total_s: 395.5878527164459
  timers:
    learn_throughput: 6993.133
    learn_time_ms: 23135.838
    sample_throughput: 23297.729
    sample_time_ms: 6944.54
    update_time_ms: 31.099
  timestamp: 1602452369
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     13 |          395.588 | 2103296 |  236.734 |              287.535 |              110.414 |            843.399 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3479.5640542577244
    time_step_min: 3174
  date: 2020-10-11_21-40-00
  done: false
  episode_len_mean: 837.7222222222222
  episode_reward_max: 290.26262626262627
  episode_reward_mean: 238.89441393803799
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 312
  episodes_total: 2682
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9269219487905502
        entropy_coeff: 0.0005000000000000001
        kl: 0.006361560779623687
        model: {}
        policy_loss: -0.012572905397973955
        total_loss: 17.332109133402508
        vf_explained_var: 0.9761894345283508
        vf_loss: 17.34419123331706
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.494594594594595
    gpu_util_percent0: 0.36837837837837833
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7648648648648653
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522557168061207
    mean_env_wait_ms: 1.1767690056686761
    mean_inference_ms: 4.658267768592014
    mean_raw_obs_processing_ms: 0.40078780720058144
  time_since_restore: 425.7881953716278
  time_this_iter_s: 30.200342655181885
  time_total_s: 425.7881953716278
  timers:
    learn_throughput: 6992.356
    learn_time_ms: 23138.409
    sample_throughput: 23302.052
    sample_time_ms: 6943.251
    update_time_ms: 30.386
  timestamp: 1602452400
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     14 |          425.788 | 2265088 |  238.894 |              290.263 |              110.414 |            837.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3473.5522017045455
    time_step_min: 3128
  date: 2020-10-11_21-40-30
  done: false
  episode_len_mean: 835.2011251758087
  episode_reward_max: 292.08080808080786
  episode_reward_mean: 239.92480714316144
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 162
  episodes_total: 2844
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9078671584526697
        entropy_coeff: 0.0005000000000000001
        kl: 0.006723475021620591
        model: {}
        policy_loss: -0.013978067974676378
        total_loss: 8.804759422938028
        vf_explained_var: 0.9820486903190613
        vf_loss: 8.818183183670044
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.43611111111111
    gpu_util_percent0: 0.37027777777777776
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15201572935095442
    mean_env_wait_ms: 1.1778360274822353
    mean_inference_ms: 4.643472726575872
    mean_raw_obs_processing_ms: 0.3998987766477957
  time_since_restore: 456.1455554962158
  time_this_iter_s: 30.357360124588013
  time_total_s: 456.1455554962158
  timers:
    learn_throughput: 6992.953
    learn_time_ms: 23136.435
    sample_throughput: 23289.376
    sample_time_ms: 6947.03
    update_time_ms: 29.453
  timestamp: 1602452430
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     15 |          456.146 | 2426880 |  239.925 |              292.081 |              110.414 |            835.201 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3467.051445864156
    time_step_min: 3128
  date: 2020-10-11_21-41-00
  done: false
  episode_len_mean: 833.0986009327115
  episode_reward_max: 292.08080808080786
  episode_reward_mean: 240.86449774224576
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8989628156026205
        entropy_coeff: 0.0005000000000000001
        kl: 0.006986537133343518
        model: {}
        policy_loss: -0.01517883587803226
        total_loss: 9.380488077799479
        vf_explained_var: 0.9795497059822083
        vf_loss: 9.395068089167276
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.08648648648649
    gpu_util_percent0: 0.33432432432432435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791891891891893
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15180048774506874
    mean_env_wait_ms: 1.1788153607691545
    mean_inference_ms: 4.630203824269656
    mean_raw_obs_processing_ms: 0.3990875096169793
  time_since_restore: 486.276967048645
  time_this_iter_s: 30.1314115524292
  time_total_s: 486.276967048645
  timers:
    learn_throughput: 7000.278
    learn_time_ms: 23112.224
    sample_throughput: 23320.065
    sample_time_ms: 6937.888
    update_time_ms: 29.235
  timestamp: 1602452460
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     16 |          486.277 | 2588672 |  240.864 |              292.081 |              110.414 |            833.099 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3458.0476338729763
    time_step_min: 3128
  date: 2020-10-11_21-41-31
  done: false
  episode_len_mean: 829.7429012345679
  episode_reward_max: 292.08080808080786
  episode_reward_mean: 242.25476992143646
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 238
  episodes_total: 3240
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8594247400760651
        entropy_coeff: 0.0005000000000000001
        kl: 0.006091516076897581
        model: {}
        policy_loss: -0.013718446076381952
        total_loss: 13.025495688120523
        vf_explained_var: 0.9796382784843445
        vf_loss: 13.038730303446451
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.02702702702703
    gpu_util_percent0: 0.3091891891891892
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775675675675677
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15150800503748374
    mean_env_wait_ms: 1.180368644916951
    mean_inference_ms: 4.612109562981156
    mean_raw_obs_processing_ms: 0.3979945025089404
  time_since_restore: 516.6725783348083
  time_this_iter_s: 30.39561128616333
  time_total_s: 516.6725783348083
  timers:
    learn_throughput: 6999.405
    learn_time_ms: 23115.107
    sample_throughput: 23292.336
    sample_time_ms: 6946.148
    update_time_ms: 31.32
  timestamp: 1602452491
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     17 |          516.673 | 2750464 |  242.255 |              292.081 |              110.414 |            829.743 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3450.4649071925755
    time_step_min: 3128
  date: 2020-10-11_21-42-01
  done: false
  episode_len_mean: 826.8947065592636
  episode_reward_max: 292.08080808080786
  episode_reward_mean: 243.50054340877116
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 236
  episodes_total: 3476
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8522587170203527
        entropy_coeff: 0.0005000000000000001
        kl: 0.006035514796773593
        model: {}
        policy_loss: -0.01462185278069228
        total_loss: 9.00441869099935
        vf_explained_var: 0.9835512042045593
        vf_loss: 9.018561124801636
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.986486486486484
    gpu_util_percent0: 0.394054054054054
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7729729729729744
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15124442206493718
    mean_env_wait_ms: 1.1816979762628295
    mean_inference_ms: 4.5960103826166065
    mean_raw_obs_processing_ms: 0.39700377633957423
  time_since_restore: 547.1127865314484
  time_this_iter_s: 30.440208196640015
  time_total_s: 547.1127865314484
  timers:
    learn_throughput: 6989.634
    learn_time_ms: 23147.422
    sample_throughput: 23213.016
    sample_time_ms: 6969.883
    update_time_ms: 32.968
  timestamp: 1602452521
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     18 |          547.113 | 2912256 |  243.501 |              292.081 |              110.414 |            826.895 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3445.3219633943427
    time_step_min: 3128
  date: 2020-10-11_21-42-32
  done: false
  episode_len_mean: 825.1620803522289
  episode_reward_max: 292.08080808080786
  episode_reward_mean: 244.2067315977607
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8448741982380549
        entropy_coeff: 0.0005000000000000001
        kl: 0.006209404673427343
        model: {}
        policy_loss: -0.014354439704523733
        total_loss: 9.009131034215292
        vf_explained_var: 0.9802733063697815
        vf_loss: 9.022976636886597
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.11621621621622
    gpu_util_percent0: 0.38189189189189193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.786486486486488
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15108384254332827
    mean_env_wait_ms: 1.1825718871856647
    mean_inference_ms: 4.586186292449875
    mean_raw_obs_processing_ms: 0.3964027171208913
  time_since_restore: 577.3866522312164
  time_this_iter_s: 30.273865699768066
  time_total_s: 577.3866522312164
  timers:
    learn_throughput: 6987.332
    learn_time_ms: 23155.048
    sample_throughput: 23179.682
    sample_time_ms: 6979.906
    update_time_ms: 34.01
  timestamp: 1602452552
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | RUNNING  | 172.17.0.4:47956 |     19 |          577.387 | 3074048 |  244.207 |              292.081 |              110.414 |            825.162 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4dbfc_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3439.728111814346
    time_step_min: 3128
  date: 2020-10-11_21-43-02
  done: true
  episode_len_mean: 823.1112565445026
  episode_reward_max: 293.89898989899007
  episode_reward_mean: 245.0826722724628
  episode_reward_min: 110.4141414141407
  episodes_this_iter: 186
  episodes_total: 3820
  experiment_id: 54f5e51dd66a469b890309a89e5c892b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8154856115579605
        entropy_coeff: 0.0005000000000000001
        kl: 0.006414613376061122
        model: {}
        policy_loss: -0.01523474182128363
        total_loss: 9.293313185373941
        vf_explained_var: 0.9829052090644836
        vf_loss: 9.307993412017822
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.572222222222223
    gpu_util_percent0: 0.35277777777777775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15090762392898935
    mean_env_wait_ms: 1.1836265676482758
    mean_inference_ms: 4.575296122327369
    mean_raw_obs_processing_ms: 0.39573492497412066
  time_since_restore: 607.5334911346436
  time_this_iter_s: 30.146838903427124
  time_total_s: 607.5334911346436
  timers:
    learn_throughput: 6986.961
    learn_time_ms: 23156.278
    sample_throughput: 23141.919
    sample_time_ms: 6991.296
    update_time_ms: 33.223
  timestamp: 1602452582
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 4dbfc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | TERMINATED |       |     20 |          607.533 | 3235840 |  245.083 |              293.899 |              110.414 |            823.111 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4dbfc_00000 | TERMINATED |       |     20 |          607.533 | 3235840 |  245.083 |              293.899 |              110.414 |            823.111 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


